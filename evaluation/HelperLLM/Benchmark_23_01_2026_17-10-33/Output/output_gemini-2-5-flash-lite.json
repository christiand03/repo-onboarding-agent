{
  "functions": {
    "backend.AST_Schema.path_to_module": {
      "identifier": "backend.AST_Schema.path_to_module",
      "description": {
        "overall": "This function converts a given file path into a Python module path relative to a specified project root. It first calculates the relative path between the file and the project root. If the file is not within the project root, it uses the base name of the file. It then removes the '.py' extension if present and replaces the operating system's path separator with dots to form a module path. Finally, it handles the special case of '__init__.py' files by removing the '__init__' suffix.",
        "parameters": [
          {
            "name": "filepath",
            "type": "str",
            "description": "The absolute or relative path to the file."
          },
          {
            "name": "project_root",
            "type": "str",
            "description": "The path to the root directory of the project."
          }
        ],
        "returns": [
          {
            "name": "module_path",
            "type": "str",
            "description": "The Python module path derived from the filepath."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "backend.File_Dependency.build_file_dependency_graph": {
      "identifier": "backend.File_Dependency.build_file_dependency_graph",
      "description": {
        "overall": "This function constructs a directed graph representing file dependencies within a Python project. It takes a filename, an Abstract Syntax Tree (AST) of the file, and the repository root path as input. The function initializes a `FileDependencyGraph` visitor to traverse the AST and identify import dependencies. It then iterates through these dependencies, adding nodes for each file and edges to represent the caller-callee relationships, ultimately returning the populated `networkx.DiGraph`.",
        "parameters": [
          {
            "name": "filename",
            "type": "str",
            "description": "The name of the file being analyzed."
          },
          {
            "name": "tree",
            "type": "AST",
            "description": "The Abstract Syntax Tree (AST) representation of the file's content."
          },
          {
            "name": "repo_root",
            "type": "str",
            "description": "The root directory path of the repository."
          }
        ],
        "returns": [
          {
            "name": "graph",
            "type": "nx.DiGraph",
            "description": "A directed graph representing the file dependencies, where nodes are file paths and edges indicate import relationships."
          }
        ],
        "usage_context": {
          "calls": "This function calls backend.File_Dependency.FileDependencyGraph.",
          "called_by": "This function is not called by any other functions within the provided context."
        }
      },
      "error": null
    },
    "backend.File_Dependency.build_repository_graph": {
      "identifier": "backend.File_Dependency.build_repository_graph",
      "description": {
        "overall": "This function constructs a directed graph representing the dependencies between Python files within a Git repository. It iterates through all Python files, parses their Abstract Syntax Trees (ASTs), and builds a file-specific dependency graph for each. These individual graphs are then merged into a single, global graph that captures the overall repository structure. Non-Python files are ignored.",
        "parameters": [
          {
            "name": "repository",
            "type": "GitRepository",
            "description": "An object representing the Git repository, providing methods to access files and the repository's temporary directory."
          }
        ],
        "returns": [
          {
            "name": "global_graph",
            "type": "nx.DiGraph",
            "description": "A NetworkX directed graph where nodes represent file dependencies and edges indicate the direction of these dependencies."
          }
        ],
        "usage_context": {
          "calls": "This function calls backend.File_Dependency.build_file_dependency_graph.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "backend.File_Dependency.get_all_temp_files": {
      "identifier": "backend.File_Dependency.get_all_temp_files",
      "description": {
        "overall": "This function identifies and returns a list of all Python files within a specified directory and its subdirectories. It resolves the root directory path and then uses `rglob` to find all files ending with '.py'. The function returns these files as paths relative to the root directory.",
        "parameters": [
          {
            "name": "directory",
            "type": "str",
            "description": "The path to the directory to search for Python files."
          }
        ],
        "returns": [
          {
            "name": "all_files",
            "type": "list[Path]",
            "description": "A list of Path objects, where each Path represents a Python file found within the specified directory, relative to the root path."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "backend.HelperLLM.main_orchestrator": {
      "identifier": "backend.HelperLLM.main_orchestrator",
      "description": {
        "overall": "This function serves as a dummy orchestrator for testing the LLMHelper class and its documentation generation capabilities. It simulates the process of analyzing individual functions and classes by defining pre-computed analysis data for several methods ('add_item', 'check_stock', 'generate_report') and a class ('InventoryManager'). It then uses an LLMHelper instance to generate documentation for these functions, storing the results in a dictionary that is finally printed as a JSON string. The function is designed to be syntactically correct and logically align with Pydantic models for data validation.",
        "parameters": [],
        "returns": [],
        "usage_context": {
          "calls": "backend.HelperLLM.LLMHelper, schemas.types.ClassAnalysisInput, schemas.types.ClassContextInput",
          "called_by": "This function calls no other functions."
        }
      },
      "error": null
    },
    "backend.callgraph.make_safe_dot": {
      "identifier": "backend.callgraph.make_safe_dot",
      "description": {
        "overall": "This function takes a NetworkX directed graph and an output path as input. It creates a copy of the graph and relabels its nodes to ensure they are safe for DOT format, typically by prefixing them with 'n' and an index. It then assigns the original node names as labels to these new nodes. Finally, it writes the modified graph to a DOT file at the specified output path using the pydot library.",
        "parameters": [
          {
            "name": "graph",
            "type": "nx.DiGraph",
            "description": "The input NetworkX directed graph to be processed."
          },
          {
            "name": "out_path",
            "type": "str",
            "description": "The file path where the DOT representation of the graph will be saved."
          }
        ],
        "returns": [],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is called by no other functions."
        }
      },
      "error": null
    },
    "backend.callgraph.build_filtered_callgraph": {
      "identifier": "backend.callgraph.build_filtered_callgraph",
      "description": {
        "overall": "This function constructs a global call graph for a given Git repository and then filters it to include only functions written within the repository. It iterates through all Python files, parses their Abstract Syntax Trees (ASTs), and uses a `CallGraph` visitor to identify functions and their calls. The function first collects all identified functions into a set and then builds a directed graph (`nx.DiGraph`). During graph construction, it only adds edges (calls) where both the caller and the callee are present in the set of 'own functions'. This ensures the final call graph represents internal project calls.",
        "parameters": [
          {
            "name": "repo",
            "type": "GitRepository",
            "description": "An object representing the Git repository, providing access to its files."
          }
        ],
        "returns": [
          {
            "name": "global_graph",
            "type": "nx.DiGraph",
            "description": "A NetworkX directed graph representing the filtered call graph of functions within the repository."
          }
        ],
        "usage_context": {
          "calls": "This function calls backend.callgraph.CallGraph.",
          "called_by": "This function is not called by any other function within the provided context."
        }
      },
      "error": null
    },
    "backend.converter.wrap_cdata": {
      "identifier": "backend.converter.wrap_cdata",
      "description": {
        "overall": "This function takes a string `content` as input and returns a new string where the input content is wrapped within XML CDATA (Character Data) tags. The CDATA tags are formatted as '<![CDATA[\\n{content}\\n]]>', ensuring that the content inside is treated as raw character data and not parsed as markup. This is useful for embedding XML or HTML snippets within other XML documents without conflicts.",
        "parameters": [
          {
            "name": "content",
            "type": "string",
            "description": "The string content to be wrapped in CDATA tags."
          }
        ],
        "returns": [
          {
            "name": "wrapped_content",
            "type": "string",
            "description": "The input content wrapped within CDATA tags."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "backend.converter.extract_output_content": {
      "identifier": "backend.converter.extract_output_content",
      "description": {
        "overall": "This function iterates through a list of outputs, processing different output types to extract relevant content. It specifically handles 'display_data' and 'execute_result' types by decoding Base64 encoded images (PNG and JPEG) into a list of image data and inserting image placeholders into the output. For other data types, it extracts plain text. It also processes 'stream' outputs by appending their text content and 'error' outputs by formatting them as strings. The function returns a list containing the extracted text snippets and image placeholders.",
        "parameters": [
          {
            "name": "outputs",
            "type": "list",
            "description": "A list of output objects, each potentially containing data, type, and text."
          },
          {
            "name": "image_list",
            "type": "list",
            "description": "A list to which decoded image data (as dictionaries with mime_type and data) will be appended."
          }
        ],
        "returns": [
          {
            "name": "extracted_xml_snippets",
            "type": "list",
            "description": "A list of strings, where each string is either extracted text, an image placeholder (e.g., '<IMAGE_PLACEHOLDER index=\"0\" mime=\"image/png\"/>'), or an error message."
          }
        ],
        "usage_context": {
          "calls": "This function calls backend.converter.process_image.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "backend.converter.process_image": {
      "identifier": "backend.converter.process_image",
      "description": {
        "overall": "This function processes an image based on its MIME type. It checks if the MIME type exists in a predefined data structure. If found, it attempts to decode a base64 encoded string associated with that MIME type. It then appends the image data to a global list and returns an HTML-like placeholder string with the image's index and MIME type. If any error occurs during decoding or processing, it returns an error message. If the MIME type is not found, it returns None.",
        "parameters": [
          {
            "name": "mime_type",
            "type": "str",
            "description": "The MIME type of the image to be processed."
          }
        ],
        "returns": [
          {
            "name": "placeholder_or_error",
            "type": "str",
            "description": "A string representing an image placeholder with index and MIME type, or an error message if processing fails. Returns None if the mime_type is not found."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "backend.converter.convert_notebook_to_xml": {
      "identifier": "backend.converter.convert_notebook_to_xml",
      "description": {
        "overall": "This function takes the content of a Jupyter notebook as a string and converts it into an XML format. It iterates through each cell of the notebook, identifying whether the cell is markdown or code. For markdown cells, it wraps the source content in a '<CELL type=\"markdown\">' tag. For code cells, it wraps the source code in CDATA and appends it within a '<CELL type=\"code\">' tag. If a code cell has outputs, it extracts and formats the content of these outputs, wrapping them in CDATA and enclosing them in a '<CELL type=\"output\">' tag. The function also handles potential errors during the initial parsing of the notebook file, returning an error message if the file cannot be parsed as JSON or a notebook. Finally, it returns the constructed XML string and a list of any extracted images.",
        "parameters": [
          {
            "name": "file_content",
            "type": "str",
            "description": "A string containing the raw content of the Jupyter notebook file."
          }
        ],
        "returns": [
          {
            "name": "xml_output",
            "type": "str",
            "description": "A string representing the notebook content converted to XML format, or an error message if parsing fails."
          },
          {
            "name": "extracted_images",
            "type": "list",
            "description": "A list containing information about any images extracted from the notebook outputs."
          }
        ],
        "usage_context": {
          "calls": "This function calls backend.converter.extract_output_content and backend.converter.wrap_cdata.",
          "called_by": "This function is not called by any other functions within the provided context."
        }
      },
      "error": null
    },
    "backend.converter.process_repo_notebooks": {
      "identifier": "backend.converter.process_repo_notebooks",
      "description": {
        "overall": "This function iterates through a list of repository files, identifies Jupyter Notebook files ('.ipynb'), and processes each one. For every notebook found, it calls `convert_notebook_to_xml` to transform the notebook's content into XML format and extract any associated images. The results, containing the XML output and images for each notebook, are stored in a dictionary keyed by the notebook's file path. Finally, it returns this dictionary of processed notebook data.",
        "parameters": [
          {
            "name": "repo_files",
            "type": "List[FileObject]",
            "description": "A list of file objects, where each object is expected to have 'path' and 'content' attributes."
          }
        ],
        "returns": [
          {
            "name": "results",
            "type": "Dict[str, Dict[str, Union[str, List[str]]]]",
            "description": "A dictionary where keys are notebook file paths and values are dictionaries containing 'xml' (the XML representation) and 'images' (a list of extracted image data) for each notebook."
          }
        ],
        "usage_context": {
          "calls": "This function calls backend.converter.convert_notebook_to_xml.",
          "called_by": "This function is not called by any other functions within the provided context."
        }
      },
      "error": null
    },
    "backend.main.create_savings_chart": {
      "identifier": "backend.main.create_savings_chart",
      "description": {
        "overall": "This function generates a bar chart to visualize the comparison of JSON and TOON tokens, highlighting the savings percentage. It takes the token counts for both formats, the calculated savings percentage, and the desired output path as input. The function configures the chart with specific labels, colors, and titles, and then adds the exact token values above each bar for clarity. Finally, it saves the generated chart to the specified file path and closes the plot to free up resources.",
        "parameters": [
          {
            "name": "json_tokens",
            "type": "int",
            "description": "The number of tokens in the JSON format."
          },
          {
            "name": "toon_tokens",
            "type": "int",
            "description": "The number of tokens in the TOON format."
          },
          {
            "name": "savings_percent",
            "type": "float",
            "description": "The percentage of savings achieved by using the TOON format compared to JSON."
          },
          {
            "name": "output_path",
            "type": "str",
            "description": "The file path where the generated chart image will be saved."
          }
        ],
        "returns": [],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "backend.main.calculate_net_time": {
      "identifier": "backend.main.calculate_net_time",
      "description": {
        "overall": "This function calculates the net processing time by subtracting estimated sleep times from the total duration. It first determines the total duration based on start and end times. If the model name does not start with 'gemini-', it returns the total duration directly. For 'gemini-' models, it calculates the number of batches and the total sleep time incurred from rate limiting. Finally, it subtracts the total sleep time from the total duration, ensuring the net time is not negative.",
        "parameters": [
          {
            "name": "start_time",
            "type": "Any",
            "description": "The start time of the operation."
          },
          {
            "name": "end_time",
            "type": "Any",
            "description": "The end time of the operation."
          },
          {
            "name": "total_items",
            "type": "int",
            "description": "The total number of items processed."
          },
          {
            "name": "batch_size",
            "type": "int",
            "description": "The size of each batch."
          },
          {
            "name": "model_name",
            "type": "str",
            "description": "The name of the model being used."
          }
        ],
        "returns": [
          {
            "name": "net_time",
            "type": "int",
            "description": "The calculated net processing time after subtracting sleep times, or 0 if total_items is 0."
          },
          {
            "name": "total_duration",
            "type": "Any",
            "description": "The total duration if the model_name does not start with 'gemini-'."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is called by no other functions."
        }
      },
      "error": null
    },
    "backend.main.main_workflow": {
      "identifier": "backend.main.main_workflow",
      "description": {
        "overall": "The main_workflow function orchestrates a complex process of analyzing a GitHub repository to generate documentation. It begins by extracting API keys and model names, then clones the specified repository. Subsequently, it extracts basic project information, constructs a file tree, and performs relationship analysis (calls and instantiations) using specialized analyzers. The function then generates an Abstract Syntax Tree (AST) schema and enriches it with the relationship data. Finally, it prepares inputs for a Helper LLM to analyze functions and classes, followed by a Main LLM to generate a final report and associated metrics. The workflow includes status updates throughout the process and handles potential errors at various stages.",
        "parameters": [
          {
            "name": "input",
            "type": "Any",
            "description": "The primary input to the workflow, likely containing information or a URL for the repository to be analyzed."
          },
          {
            "name": "api_keys",
            "type": "dict",
            "description": "A dictionary containing API keys for various services like Gemini, OpenAI, and ScadsLLM, as well as base URLs for services like Ollama."
          },
          {
            "name": "model_names",
            "type": "dict",
            "description": "A dictionary specifying the model names to be used for different tasks, such as 'helper' and 'main' models."
          },
          {
            "name": "status_callback",
            "type": "Optional[Callable]",
            "description": "An optional callback function that can be used to report the status of the workflow's progress."
          }
        ],
        "returns": [
          {
            "name": "report",
            "type": "str",
            "description": "The final generated report, likely in Markdown format, summarizing the analysis of the repository."
          },
          {
            "name": "metrics",
            "type": "dict",
            "description": "A dictionary containing performance metrics and configuration details of the workflow, such as execution times, models used, and token counts."
          }
        ],
        "usage_context": {
          "calls": "This function calls backend.AST_Schema.ASTAnalyzer, backend.AST_Schema.ASTAnalyzer.analyze_repository, backend.AST_Schema.ASTAnalyzer.merge_relationship_data, backend.HelperLLM.LLMHelper, backend.HelperLLM.LLMHelper.generate_for_classes, backend.HelperLLM.LLMHelper.generate_for_functions, backend.MainLLM.MainLLM, backend.MainLLM.MainLLM.call_llm, backend.basic_info.ProjektInfoExtractor, backend.basic_info.ProjektInfoExtractor.extrahiere_info, backend.getRepo.GitRepository, backend.main.calculate_net_time, backend.main.create_savings_chart, backend.main.update_status, backend.relationship_analyzer.ProjectAnalyzer, backend.relationship_analyzer.ProjectAnalyzer.analyze, backend.relationship_analyzer.ProjectAnalyzer.get_raw_relationships, schemas.types.ClassAnalysisInput, schemas.types.ClassContextInput, schemas.types.FunctionAnalysisInput, schemas.types.FunctionContextInput, and schemas.types.MethodContextInput.",
          "called_by": "This function is not called by any other functions within the provided context."
        }
      },
      "error": null
    },
    "backend.main.update_status": {
      "identifier": "backend.main.update_status",
      "description": {
        "overall": "This function is responsible for updating the status message of a process. It first checks if a callback function `status_callback` is defined and, if so, calls it with the provided message. Subsequently, it logs the message using the standard Python `logging` module. This ensures that status updates are both communicated to a potential external handler and recorded for auditing or debugging purposes.",
        "parameters": [
          {
            "name": "msg",
            "type": "string",
            "description": "The status message to be communicated and logged."
          }
        ],
        "returns": [],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "backend.main.notebook_workflow": {
      "identifier": "backend.main.notebook_workflow",
      "description": {
        "overall": "This function orchestrates a workflow for analyzing GitHub repositories containing Jupyter notebooks. It clones a repository, extracts project information, processes notebooks into an XML format with embedded images, and then uses a specified LLM model to generate a report for each notebook. The function handles API key selection based on the model name and manages status updates throughout the process. Finally, it concatenates individual notebook reports into a single report, saves it to a file, and returns the report along with processing metrics.",
        "parameters": [
          {
            "name": "input",
            "type": "str",
            "description": "The input string, expected to contain a GitHub repository URL."
          },
          {
            "name": "api_keys",
            "type": "dict",
            "description": "A dictionary containing API keys for different LLM providers (e.g., 'gpt', 'gemini', 'scadsllm', 'ollama')."
          },
          {
            "name": "model",
            "type": "str",
            "description": "The name of the language model to be used for report generation. Determines which API key and base URL to use."
          },
          {
            "name": "status_callback",
            "type": "Optional[Callable]",
            "description": "An optional callback function to report status updates during the workflow."
          }
        ],
        "returns": [
          {
            "name": "report",
            "type": "str",
            "description": "The concatenated report generated from all processed notebooks."
          },
          {
            "name": "metrics",
            "type": "dict",
            "description": "A dictionary containing performance metrics for the workflow, including total time and model used."
          }
        ],
        "usage_context": {
          "calls": "This function calls backend.MainLLM.MainLLM, backend.MainLLM.MainLLM.call_llm, backend.basic_info.ProjektInfoExtractor, backend.basic_info.ProjektInfoExtractor.extrahiere_info, backend.converter.process_repo_notebooks, backend.getRepo.GitRepository, backend.main.gemini_payload, and backend.main.update_status.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "backend.main.gemini_payload": {
      "identifier": "backend.main.gemini_payload",
      "description": {
        "overall": "This function constructs a payload for a Gemini model, processing basic information, notebook path, XML content, and images. It serializes introductory information into a JSON string and then iterates through the XML content to identify text segments and image placeholders. For each image placeholder, it extracts image data and formats it as a base64 encoded string within the payload. The function handles both text and image content, ensuring that all parts of the XML, including text before the first image and after the last, are included in the final payload. The output is a list of dictionaries, where each dictionary represents a content block of either 'text' or 'image_url' type, suitable for the Gemini API.",
        "parameters": [
          {
            "name": "basic_info",
            "type": "Any",
            "description": "A dictionary containing basic project information."
          },
          {
            "name": "nb_path",
            "type": "str",
            "description": "The file path to the current notebook."
          },
          {
            "name": "xml_content",
            "type": "str",
            "description": "A string containing the XML representation of the notebook structure."
          },
          {
            "name": "images",
            "type": "List[Dict[str, str]]",
            "description": "A list of dictionaries, where each dictionary contains image data, including a base64 encoded string."
          }
        ],
        "returns": [
          {
            "name": "payload_content",
            "type": "List[Dict[str, Any]]",
            "description": "A list of dictionaries, each representing a content block (text or image_url) for the Gemini payload."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is called by no other functions."
        }
      },
      "error": null
    },
    "backend.relationship_analyzer.path_to_module": {
      "identifier": "backend.relationship_analyzer.path_to_module",
      "description": {
        "overall": "This function converts a given file path into a Python module path relative to a specified project root. It handles potential errors during relative path calculation by falling back to the base filename. It also correctly formats the path by replacing directory separators with dots and removes the '.py' extension. Special handling is included for '__init__.py' files to return the parent directory's module path.",
        "parameters": [
          {
            "name": "filepath",
            "type": "str",
            "description": "The absolute or relative path to the file."
          },
          {
            "name": "project_root",
            "type": "str",
            "description": "The root directory of the Python project."
          }
        ],
        "returns": [
          {
            "name": "module_path",
            "type": "str",
            "description": "The calculated Python module path."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.encrypt_text": {
      "identifier": "database.db.encrypt_text",
      "description": {
        "overall": "This function encrypts a given string using a predefined cipher suite. It first checks if the input text is empty or if the cipher suite is not initialized. If either condition is true, it returns the original text without encryption. Otherwise, it strips leading/trailing whitespace from the text, encodes it into bytes, encrypts the bytes using the cipher suite, and then decodes the resulting encrypted bytes back into a string before returning it.",
        "parameters": [
          {
            "name": "text",
            "type": "str",
            "description": "The input string to be encrypted."
          }
        ],
        "returns": [
          {
            "name": "encrypted_text",
            "type": "str",
            "description": "The encrypted string, or the original string if encryption could not be performed."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.decrypt_text": {
      "identifier": "database.db.decrypt_text",
      "description": {
        "overall": "This function decrypts a given string using a cipher suite. It first checks if the input text or the cipher suite is missing, returning the original text if either is absent. If a cipher suite is available, it attempts to decrypt the text. The text is stripped of whitespace and encoded before decryption, and the result is decoded back into a string. If any exception occurs during the decryption process, the original text is returned.",
        "parameters": [
          {
            "name": "text",
            "type": "str",
            "description": "The encrypted string to be decrypted."
          }
        ],
        "returns": [
          {
            "name": "decrypted_text",
            "type": "str",
            "description": "The decrypted string, or the original string if decryption fails or is not possible."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.insert_user": {
      "identifier": "database.db.insert_user",
      "description": {
        "overall": "This function inserts a new user record into the database. It constructs a user dictionary containing username, name, and a hashed password using `stauth.Hasher.hash`. Additional fields like API keys and base URLs are initialized as empty strings. The function then uses `dbusers.insert_one` to add this user data to the database and returns the ID of the newly inserted document.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The unique username for the new user."
          },
          {
            "name": "name",
            "type": "str",
            "description": "The full name of the user."
          },
          {
            "name": "password",
            "type": "str",
            "description": "The plain text password for the new user, which will be hashed."
          }
        ],
        "returns": [
          {
            "name": "result.inserted_id",
            "type": "Any",
            "description": "The unique identifier of the newly inserted user document."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.fetch_all_users": {
      "identifier": "database.db.fetch_all_users",
      "description": {
        "overall": "This function retrieves all user records from a database. It interacts with a database collection named 'dbusers' and returns the entire set of documents found. The function is designed to fetch all available user data without any filtering or specific selection criteria.",
        "parameters": [],
        "returns": [
          {
            "name": "user_records",
            "type": "list",
            "description": "A list containing all user documents fetched from the database."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.fetch_user": {
      "identifier": "database.db.fetch_user",
      "description": {
        "overall": "This function retrieves a user document from the database based on the provided username. It queries a collection named 'dbusers' using the username as the document's '_id'. The function is designed to fetch a single user record.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username of the user to fetch from the database."
          }
        ],
        "returns": [
          {
            "name": "user_document",
            "type": "Any",
            "description": "A dictionary representing the user document if found, or None if the user does not exist."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.update_user_name": {
      "identifier": "database.db.update_user_name",
      "description": {
        "overall": "This function updates the 'name' field for a user in the 'dbusers' collection. It takes the current username and the new name as input. The function uses `update_one` to find the document with the matching `_id` (which is assumed to be the username) and sets the 'name' field to the `new_name`. It returns the count of modified documents, which should ideally be 1 if the update was successful.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The current username of the user whose name needs to be updated. This is used as the identifier to find the document."
          },
          {
            "name": "new_name",
            "type": "str",
            "description": "The new name to be set for the user."
          }
        ],
        "returns": [
          {
            "name": "modified_count",
            "type": "int",
            "description": "The number of documents that were modified by the update operation. This is expected to be 1 if the user was found and updated."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.update_gemini_key": {
      "identifier": "database.db.update_gemini_key",
      "description": {
        "overall": "This function updates the Gemini API key for a given user in the database. It first encrypts the provided API key using a helper function and then updates the user's record in the database with the encrypted key. The function returns the number of documents that were modified.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username of the user whose Gemini API key needs to be updated."
          },
          {
            "name": "gemini_api_key",
            "type": "str",
            "description": "The new Gemini API key to be set for the user."
          }
        ],
        "returns": [
          {
            "name": "modified_count",
            "type": "int",
            "description": "The number of documents modified in the database. Typically 1 if the update was successful."
          }
        ],
        "usage_context": {
          "calls": "This function calls database.db.encrypt_text.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.update_gpt_key": {
      "identifier": "database.db.update_gpt_key",
      "description": {
        "overall": "This function updates the GPT API key for a given user in the database. It first encrypts the provided API key using the `encrypt_text` function. Then, it uses `dbusers.update_one` to find the user by their username and set the `gpt_api_key` field to the encrypted value. The function returns the count of documents that were modified.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username of the user whose GPT API key needs to be updated."
          },
          {
            "name": "gpt_api_key",
            "type": "str",
            "description": "The new GPT API key to be set for the user."
          }
        ],
        "returns": [
          {
            "name": "modified_count",
            "type": "int",
            "description": "The number of documents that were modified in the database. This is expected to be 1 if the update was successful for an existing user."
          }
        ],
        "usage_context": {
          "calls": "This function calls database.db.encrypt_text.",
          "called_by": "This function is not called by any other functions within the provided context."
        }
      },
      "error": null
    },
    "database.db.update_ollama_url": {
      "identifier": "database.db.update_ollama_url",
      "description": {
        "overall": "This function updates the 'ollama_base_url' field for a specific user in the database. It takes the username and the new base URL as input. The function uses `dbusers.update_one` to find the user by their username (using the `_id` field) and sets the `ollama_base_url` to the provided value after stripping any leading or trailing whitespace. The function returns the count of documents that were modified.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username of the user whose 'ollama_base_url' needs to be updated."
          },
          {
            "name": "ollama_base_url",
            "type": "str",
            "description": "The new base URL for the Ollama service, which will be stored for the user."
          }
        ],
        "returns": [
          {
            "name": "modified_count",
            "type": "int",
            "description": "An integer representing the number of documents that were modified in the database. Typically, this will be 1 if the update was successful for a unique user."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.update_opensrc_key": {
      "identifier": "database.db.update_opensrc_key",
      "description": {
        "overall": "This function updates the 'opensrc_api_key' for a given username in the database. It first encrypts the provided API key using the `encrypt_text` function and then updates the corresponding user document in the `dbusers` collection. The function returns the count of modified documents, indicating whether the update was successful.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username of the user whose API key needs to be updated."
          },
          {
            "name": "opensrc_api_key",
            "type": "str",
            "description": "The new open-source API key to be set for the user."
          }
        ],
        "returns": [
          {
            "name": "modified_count",
            "type": "int",
            "description": "The number of documents that were modified in the database. A value of 1 indicates a successful update."
          }
        ],
        "usage_context": {
          "calls": "This function calls database.db.encrypt_text.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.update_opensrc_url": {
      "identifier": "database.db.update_opensrc_url",
      "description": {
        "overall": "This function updates the 'opensrc_base_url' field for a given username in the database. It takes the username and the new URL as input. The function then uses `dbusers.update_one` to find the document corresponding to the username and sets the 'opensrc_base_url' to the stripped version of the provided URL. Finally, it returns the count of modified documents, which should ideally be 1 if the update was successful.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username of the user whose 'opensrc_base_url' needs to be updated."
          },
          {
            "name": "opensrc_base_url",
            "type": "str",
            "description": "The new base URL for the open-source repository to be set for the user."
          }
        ],
        "returns": [
          {
            "name": "modified_count",
            "type": "int",
            "description": "An integer representing the number of documents that were modified. Expected to be 1 if the update was successful."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is called by no other functions."
        }
      },
      "error": null
    },
    "database.db.fetch_gemini_key": {
      "identifier": "database.db.fetch_gemini_key",
      "description": {
        "overall": "This function retrieves the Gemini API key associated with a given username from the database. It queries the database for a user document matching the provided username and specifically requests the 'gemini_api_key' field. If a user document is found, it returns the value of the 'gemini_api_key' field; otherwise, it returns None.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username of the user whose Gemini API key needs to be fetched."
          }
        ],
        "returns": [
          {
            "name": "gemini_api_key",
            "type": "str | None",
            "description": "The Gemini API key for the specified user, or None if the user is not found or has no key."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.fetch_ollama_url": {
      "identifier": "database.db.fetch_ollama_url",
      "description": {
        "overall": "This function retrieves the Ollama base URL associated with a given username from a database. It queries a collection (presumably 'dbusers') for a user document matching the provided username. If the user document is found, it extracts and returns the 'ollama_base_url' field. If the user is not found, it returns None.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username to look up in the database."
          }
        ],
        "returns": [
          {
            "name": "ollama_base_url",
            "type": "str | None",
            "description": "The Ollama base URL for the specified user, or None if the user is not found or does not have an 'ollama_base_url' field."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.fetch_gpt_key": {
      "identifier": "database.db.fetch_gpt_key",
      "description": {
        "overall": "This function retrieves the GPT API key associated with a given username from the database. It queries the database for a user document matching the provided username and specifically requests the 'gpt_api_key' field, excluding other fields. If the user is found, it returns the API key; otherwise, it returns None.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username of the user whose GPT API key needs to be fetched."
          }
        ],
        "returns": [
          {
            "name": "gpt_api_key",
            "type": "str | None",
            "description": "The GPT API key for the specified user, or None if the user is not found or has no key."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.fetch_opensrc_key": {
      "identifier": "database.db.fetch_opensrc_key",
      "description": {
        "overall": "This function retrieves the 'opensrc_api_key' for a given username from a database. It queries the 'dbusers' collection for a user document matching the provided username. If the user is found, it extracts and returns the 'opensrc_api_key'. If the user is not found, it returns None.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username of the user whose opensrc_api_key needs to be fetched."
          }
        ],
        "returns": [
          {
            "name": "opensrc_api_key",
            "type": "str | None",
            "description": "The opensrc_api_key associated with the username, or None if the user is not found."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.fetch_opensrc_url": {
      "identifier": "database.db.fetch_opensrc_url",
      "description": {
        "overall": "This function retrieves the 'opensrc_base_url' for a given username from a database. It queries the 'dbusers' collection for a document matching the provided username. If a user document is found, it attempts to extract and return the 'opensrc_base_url'. If the user is not found or the URL is not present, it returns None.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username to query in the database."
          }
        ],
        "returns": [
          {
            "name": "opensrc_base_url",
            "type": "str | None",
            "description": "The 'opensrc_base_url' associated with the username, or None if the user is not found or the URL is not present."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.delete_user": {
      "identifier": "database.db.delete_user",
      "description": {
        "overall": "This function deletes a user from the database. It takes a username as input and uses the `dbusers.delete_one` method to remove the corresponding document from the database. The function returns the count of deleted documents, which should ideally be 1 if the user existed and was successfully deleted.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username of the user to be deleted."
          }
        ],
        "returns": [
          {
            "name": "deleted_count",
            "type": "int",
            "description": "The number of documents that were deleted. This is expected to be 1 if the user was found and deleted."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.get_decrypted_api_keys": {
      "identifier": "database.db.get_decrypted_api_keys",
      "description": {
        "overall": "This function retrieves and decrypts API keys and related configuration for a given username from a database. It first fetches the user's record using the provided username. If the user is not found, it returns None for all values. Otherwise, it proceeds to decrypt sensitive API keys (Gemini, GPT, Open Source) using a `decrypt_text` function and retrieves non-sensitive information like Ollama base URL and Open Source base URL. Finally, it returns all the decrypted and retrieved values.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username of the user whose API keys and configuration are to be retrieved."
          }
        ],
        "returns": [
          {
            "name": "gemini_plain",
            "type": "str",
            "description": "The decrypted Gemini API key."
          },
          {
            "name": "ollama_plain",
            "type": "str",
            "description": "The Ollama base URL."
          },
          {
            "name": "gpt_plain",
            "type": "str",
            "description": "The decrypted GPT API key."
          },
          {
            "name": "opensrc_plain",
            "type": "str",
            "description": "The decrypted Open Source API key."
          },
          {
            "name": "opensrc_url",
            "type": "str",
            "description": "The Open Source base URL."
          }
        ],
        "usage_context": {
          "calls": "This function calls database.db.decrypt_text.",
          "called_by": "This function is not called by any other function."
        }
      },
      "error": null
    },
    "database.db.insert_chat": {
      "identifier": "database.db.insert_chat",
      "description": {
        "overall": "This function creates a new chat entry in the database. It generates a unique ID, records the username and chat name, and timestamps the creation. The function then inserts this data as a new document into the `dbchats` collection and returns the ID of the newly inserted document.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username associated with the chat."
          },
          {
            "name": "chat_name",
            "type": "str",
            "description": "The name of the chat to be created."
          }
        ],
        "returns": [
          {
            "name": "inserted_id",
            "type": "Any",
            "description": "The unique identifier of the newly created chat document."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.fetch_chats_by_user": {
      "identifier": "database.db.fetch_chats_by_user",
      "description": {
        "overall": "This function retrieves all chats associated with a given username from a database. It queries a collection named 'dbchats' for documents matching the provided username and sorts the results by the 'created_at' field in ascending order. The function then returns the found chats as a list.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username for which to fetch chats."
          }
        ],
        "returns": [
          {
            "name": "chats",
            "type": "list",
            "description": "A list of chat documents associated with the specified username, sorted by creation time."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.check_chat_exists": {
      "identifier": "database.db.check_chat_exists",
      "description": {
        "overall": "This function checks if a chat associated with a specific username and chat name already exists in the database. It queries a collection named 'dbchats' using the provided username and chat name. The function returns a boolean value indicating whether a matching record was found.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username associated with the chat."
          },
          {
            "name": "chat_name",
            "type": "str",
            "description": "The name of the chat to check for existence."
          }
        ],
        "returns": [
          {
            "name": "exists",
            "type": "bool",
            "description": "True if the chat exists, False otherwise."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.rename_chat_fully": {
      "identifier": "database.db.rename_chat_fully",
      "description": {
        "overall": "This function renames a chat and all associated exchanges in the database. It first updates the chat's name in the 'chats' collection and then updates the 'chat_name' field for all related messages in the 'exchanges' collection. The function returns the count of modified documents from the chat update operation.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username associated with the chat."
          },
          {
            "name": "old_name",
            "type": "str",
            "description": "The current name of the chat to be renamed."
          },
          {
            "name": "new_name",
            "type": "str",
            "description": "The new name for the chat."
          }
        ],
        "returns": [
          {
            "name": "modified_count",
            "type": "int",
            "description": "The number of chat documents that were modified."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.insert_exchange": {
      "identifier": "database.db.insert_exchange",
      "description": {
        "overall": "This function inserts a new exchange record into a MongoDB collection named 'dbexchanges'. It constructs a dictionary representing the exchange with various details including question, answer, feedback, user information, usage statistics, and timestamps. A unique ID is generated for each record. The function attempts to insert this record into the database and returns the new record's ID upon success. If an error occurs during the insertion process, it prints an error message and returns None.",
        "parameters": [
          {
            "name": "question",
            "type": "str",
            "description": "The user's question."
          },
          {
            "name": "answer",
            "type": "str",
            "description": "The answer provided to the question."
          },
          {
            "name": "feedback",
            "type": "str",
            "description": "User feedback on the answer."
          },
          {
            "name": "username",
            "type": "str",
            "description": "The username of the user performing the exchange."
          },
          {
            "name": "chat_name",
            "type": "str",
            "description": "The name of the chat session."
          },
          {
            "name": "helper_used",
            "type": "str",
            "description": "Indicates if a helper was used (default: \"\")."
          },
          {
            "name": "main_used",
            "type": "str",
            "description": "Indicates if the main model was used (default: \"\")."
          },
          {
            "name": "total_time",
            "type": "str",
            "description": "Total time taken for the exchange (default: \"\")."
          },
          {
            "name": "helper_time",
            "type": "str",
            "description": "Time spent using the helper (default: \"\")."
          },
          {
            "name": "main_time",
            "type": "str",
            "description": "Time spent using the main model (default: \"\")."
          },
          {
            "name": "json_tokens",
            "type": "int",
            "description": "Number of JSON tokens used (default: 0)."
          },
          {
            "name": "toon_tokens",
            "type": "int",
            "description": "Number of toon tokens used (default: 0)."
          },
          {
            "name": "savings_percent",
            "type": "float",
            "description": "Percentage of savings achieved (default: 0.0)."
          }
        ],
        "returns": [
          {
            "name": "new_id",
            "type": "str",
            "description": "The unique ID of the newly inserted exchange record, or None if an error occurred."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is called by no other functions."
        }
      },
      "error": null
    },
    "database.db.fetch_exchanges_by_user": {
      "identifier": "database.db.fetch_exchanges_by_user",
      "description": {
        "overall": "This function retrieves a list of exchanges associated with a specific username from a database. It queries a collection named 'dbexchanges' for documents matching the provided username. The results are then sorted by the 'created_at' field in ascending order before being returned as a list. The sorting is noted as important for display purposes.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username to filter exchanges by."
          }
        ],
        "returns": [
          {
            "name": "exchanges",
            "type": "list",
            "description": "A list of exchange documents associated with the given username, sorted by 'created_at'."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.fetch_exchanges_by_chat": {
      "identifier": "database.db.fetch_exchanges_by_chat",
      "description": {
        "overall": "This function retrieves a list of exchanges from a database collection based on a provided username and chat name. It queries the 'dbexchanges' collection, filtering documents that match the specified username and chat name. The results are then sorted by the 'created_at' field in ascending order before being returned as a list.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username associated with the exchanges to fetch."
          },
          {
            "name": "chat_name",
            "type": "str",
            "description": "The name of the chat from which to fetch exchanges."
          }
        ],
        "returns": [
          {
            "name": "exchanges",
            "type": "list",
            "description": "A list of exchange documents matching the specified username and chat name, sorted by creation time."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.update_exchange_feedback": {
      "identifier": "database.db.update_exchange_feedback",
      "description": {
        "overall": "This function updates the feedback associated with a specific exchange in the database. It takes an exchange ID and a feedback integer as input. The function then uses `dbexchanges.update_one` to find the exchange by its ID and set the new feedback value. Finally, it returns the count of documents that were modified.",
        "parameters": [
          {
            "name": "exchange_id",
            "type": "any",
            "description": "The unique identifier of the exchange to be updated."
          },
          {
            "name": "feedback",
            "type": "int",
            "description": "The new feedback value to be set for the exchange."
          }
        ],
        "returns": [
          {
            "name": "modified_count",
            "type": "int",
            "description": "The number of documents that were modified in the database."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.update_exchange_feedback_message": {
      "identifier": "database.db.update_exchange_feedback_message",
      "description": {
        "overall": "This function updates the feedback message associated with a specific exchange in the database. It takes an exchange ID and a feedback message string as input. The function then uses the `dbexchanges.update_one` method to find the exchange document by its `_id` and sets the `feedback_message` field to the provided value. Finally, it returns the count of documents that were modified.",
        "parameters": [
          {
            "name": "exchange_id",
            "type": "Any",
            "description": "The unique identifier of the exchange to be updated."
          },
          {
            "name": "feedback_message",
            "type": "str",
            "description": "The new feedback message to be set for the exchange."
          }
        ],
        "returns": [
          {
            "name": "modified_count",
            "type": "int",
            "description": "The number of documents that were modified in the database (expected to be 1 if successful)."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.delete_exchange_by_id": {
      "identifier": "database.db.delete_exchange_by_id",
      "description": {
        "overall": "This function deletes a single exchange record from the database based on its unique identifier. It interacts with a database collection named 'dbexchanges' to perform the deletion. The function returns the count of documents that were deleted, indicating the success or failure of the operation.",
        "parameters": [
          {
            "name": "exchange_id",
            "type": "str",
            "description": "The unique identifier of the exchange to be deleted."
          }
        ],
        "returns": [
          {
            "name": "deleted_count",
            "type": "int",
            "description": "The number of documents deleted from the database. Typically 1 if the exchange was found and deleted, 0 otherwise."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.delete_full_chat": {
      "identifier": "database.db.delete_full_chat",
      "description": {
        "overall": "This function deletes a specific chat and all associated exchanges from the database to ensure consistency between the frontend and backend. It first removes all messages within the specified chat and then deletes the chat itself from the chat list. The function aims to maintain data integrity by performing these operations atomically.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username associated with the chat to be deleted."
          },
          {
            "name": "chat_name",
            "type": "str",
            "description": "The name of the chat to be deleted."
          }
        ],
        "returns": [
          {
            "name": "deleted_count",
            "type": "int",
            "description": "The number of chat documents that were deleted."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "frontend.frontend.clean_names": {
      "identifier": "frontend.frontend.clean_names",
      "description": {
        "overall": "This function takes a list of strings, where each string is expected to be a path or identifier containing at least one '/' character. It processes each string by splitting it at the '/' character and extracting the last element. This is typically used to get the base name from a file path or a hierarchical identifier. The function returns a new list containing these extracted base names.",
        "parameters": [
          {
            "name": "model_list",
            "type": "list[str]",
            "description": "A list of strings, where each string is an identifier or path that needs cleaning."
          }
        ],
        "returns": [
          {
            "name": "cleaned_names",
            "type": "list[str]",
            "description": "A new list containing the last part of each string after splitting by '/'."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "frontend.frontend.get_filtered_models": {
      "identifier": "frontend.frontend.get_filtered_models",
      "description": {
        "overall": "This function filters a list of models based on a specified category name. It retrieves keywords associated with the category from a predefined mapping (CATEGORY_KEYWORDS). If the category is 'STANDARD', it returns models present in both the input list and a 'STANDARD_MODELS' list. Otherwise, it filters the input list to include models whose names contain any of the category's keywords. If no models match the keywords, the original source list is returned.",
        "parameters": [
          {
            "name": "source_list",
            "type": "list",
            "description": "The initial list of models to be filtered."
          },
          {
            "name": "category_name",
            "type": "str",
            "description": "The name of the category to filter by."
          }
        ],
        "returns": [
          {
            "name": "filtered_list",
            "type": "list",
            "description": "A list of models filtered by the specified category, or the original source_list if no models match the criteria or if the category is 'STANDARD' and the model is in STANDARD_MODELS."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is called by no other functions."
        }
      },
      "error": null
    },
    "frontend.frontend.save_gemini_cb": {
      "identifier": "frontend.frontend.save_gemini_cb",
      "description": {
        "overall": "This function is responsible for saving a Gemini API key provided by the user. It retrieves the new key from the Streamlit session state. If a key exists, it updates the user's Gemini key in the database using the `update_gemini_key` function. After a successful update, it clears the temporary session state variable for the key and displays a success toast message to the user.",
        "parameters": [],
        "returns": [],
        "usage_context": {
          "calls": "This function calls database.db.update_gemini_key.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "frontend.frontend.save_ollama_cb": {
      "identifier": "frontend.frontend.save_ollama_cb",
      "description": {
        "overall": "This function is a callback designed to save an Ollama URL. It retrieves a URL from the Streamlit session state, and if a URL is present, it updates the user's Ollama URL in the database. Finally, it displays a confirmation toast message to the user.",
        "parameters": [],
        "returns": [],
        "usage_context": {
          "calls": "This function calls database.db.update_ollama_url.",
          "called_by": "This function is not called by any other function."
        }
      },
      "error": null
    },
    "frontend.frontend.load_data_from_db": {
      "identifier": "frontend.frontend.load_data_from_db",
      "description": {
        "overall": "This function loads chat and exchange data from a database for a given username, ensuring consistency. It first loads predefined chats and then populates them with associated exchanges. If no data exists, it creates a default chat and inserts it into the database. The function also manages the active chat state, setting it to the first available chat if necessary or creating a new one if the user is new or data hasn't been loaded yet. This ensures that chat and exchange data is always available and consistently represented in the session state.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username for whom to load chat and exchange data."
          }
        ],
        "returns": [],
        "usage_context": {
          "calls": "This function calls database.db.fetch_chats_by_user, database.db.fetch_exchanges_by_user, and database.db.insert_chat.",
          "called_by": "This function is not called by any other function."
        }
      },
      "error": null
    },
    "frontend.frontend.handle_feedback_change": {
      "identifier": "frontend.frontend.handle_feedback_change",
      "description": {
        "overall": "This function updates the feedback associated with an exchange and triggers a rerun of the Streamlit application. It takes an exchange dictionary and a feedback value as input. The function modifies the 'feedback' key in the exchange dictionary and then calls a database function to persist this change. Finally, it calls `st.rerun()` to refresh the Streamlit UI.",
        "parameters": [
          {
            "name": "ex",
            "type": "dict",
            "description": "A dictionary representing the exchange, expected to have at least an '_id' key."
          },
          {
            "name": "val",
            "type": "any",
            "description": "The new feedback value to be set for the exchange."
          }
        ],
        "returns": [],
        "usage_context": {
          "calls": "This function calls database.db.update_exchange_feedback.",
          "called_by": "This function is not called by any other function."
        }
      },
      "error": null
    },
    "frontend.frontend.handle_delete_exchange": {
      "identifier": "frontend.frontend.handle_delete_exchange",
      "description": {
        "overall": "This function handles the deletion of an exchange from the system. It first deletes the exchange from the database using its ID. Then, it checks if the chat associated with the exchange exists in the session state. If it does, and the exchange is present in the list of exchanges for that chat, it removes the exchange from the list. Finally, it triggers a rerun of the Streamlit application to reflect the changes.",
        "parameters": [
          {
            "name": "chat_name",
            "type": "str",
            "description": "The name of the chat associated with the exchange to be deleted."
          },
          {
            "name": "ex",
            "type": "dict",
            "description": "A dictionary representing the exchange to be deleted, expected to contain an '_id' key."
          }
        ],
        "returns": [],
        "usage_context": {
          "calls": "This function calls database.db.delete_exchange_by_id.",
          "called_by": "This function is not called by any other function."
        }
      },
      "error": null
    },
    "frontend.frontend.handle_delete_chat": {
      "identifier": "frontend.frontend.handle_delete_chat",
      "description": {
        "overall": "This function handles the deletion of a chat for a given user. It first removes the chat data from the database using `db.delete_full_chat`. Then, it cleans up the session state by removing the chat from `st.session_state.chats`. If there are remaining chats, it sets the first available chat as the active chat. If no chats remain, it creates a new default chat, inserts it into the database, initializes it in the session state, and sets it as the active chat. Finally, it triggers a rerun of the Streamlit application to reflect the changes.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username of the user whose chat is to be deleted."
          },
          {
            "name": "chat_name",
            "type": "str",
            "description": "The name of the chat to be deleted."
          }
        ],
        "returns": [],
        "usage_context": {
          "calls": "This function calls database.db.delete_full_chat and database.db.insert_chat.",
          "called_by": "This function is not called by any other function."
        }
      },
      "error": null
    },
    "frontend.frontend.extract_repo_name": {
      "identifier": "frontend.frontend.extract_repo_name",
      "description": {
        "overall": "This function extracts a repository name from a given text string. It first searches for a URL within the text. If a URL is found, it parses the URL to isolate the path component. It then extracts the last part of the path, which is assumed to be the repository name. The function also handles cases where the repository name might end with '.git', removing that suffix. If no URL is found or if the extracted repository name is empty, the function returns None.",
        "parameters": [
          {
            "name": "text",
            "type": "str",
            "description": "The input text string that may contain a URL."
          }
        ],
        "returns": [
          {
            "name": "repo_name",
            "type": "str | None",
            "description": "The extracted repository name if found, otherwise None."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is called by no other functions."
        }
      },
      "error": null
    },
    "frontend.frontend.stream_text_generator": {
      "identifier": "frontend.frontend.stream_text_generator",
      "description": {
        "overall": "This function takes a string of text as input and yields words from it one by one with a small delay. It splits the input text into words based on spaces and then yields each word followed by a space. A short pause of 0.01 seconds is introduced after yielding each word, creating a streaming effect. This is likely used for simulating real-time text output in a user interface.",
        "parameters": [
          {
            "name": "text",
            "type": "str",
            "description": "The input string of text to be streamed."
          }
        ],
        "returns": [
          {
            "name": "word",
            "type": "str",
            "description": "A single word from the input text, followed by a space."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "frontend.frontend.render_text_with_mermaid": {
      "identifier": "frontend.frontend.render_text_with_mermaid",
      "description": {
        "overall": "This function takes a markdown text string and renders it, specifically handling mermaid code blocks. It splits the input text by mermaid code blocks (delimited by ```mermaid ... ```). For non-mermaid parts, it either streams the text using `st.write_stream` or directly writes it as markdown using `st.markdown`, depending on the `should_stream` flag. For mermaid code blocks, it attempts to render them using `st_mermaid`, falling back to displaying them as code if an error occurs.",
        "parameters": [
          {
            "name": "markdown_text",
            "type": "str",
            "description": "The markdown text to be rendered, potentially containing mermaid code blocks."
          },
          {
            "name": "should_stream",
            "type": "bool",
            "description": "A flag indicating whether to stream the non-mermaid text output. Defaults to False."
          }
        ],
        "returns": [],
        "usage_context": {
          "calls": "This function calls frontend.frontend.stream_text_generator.",
          "called_by": "This function is not called by any other function."
        }
      },
      "error": null
    },
    "frontend.frontend.render_exchange": {
      "identifier": "frontend.frontend.render_exchange",
      "description": {
        "overall": "This function renders a single exchange (a question-answer pair) within a chat interface. It displays the user's question and the assistant's answer, including any associated feedback or error messages. The function also provides interactive elements for user feedback, downloading the answer, and deleting the exchange. It utilizes Streamlit components for UI rendering and integrates with backend functions for data manipulation and display.",
        "parameters": [
          {
            "name": "ex",
            "type": "dict",
            "description": "A dictionary containing the exchange data, expected to have keys like 'question', 'answer', '_id', 'feedback', and 'feedback_message'."
          },
          {
            "name": "current_chat_name",
            "type": "str",
            "description": "The name of the current chat session, used for context in operations like deleting an exchange."
          }
        ],
        "returns": [],
        "usage_context": {
          "calls": "This function calls database.db.update_exchange_feedback_message, frontend.frontend.handle_delete_exchange, frontend.frontend.handle_feedback_change, and frontend.frontend.render_text_with_mermaid.",
          "called_by": "This function is not called by any other function."
        }
      },
      "error": null
    }
  },
  "classes": {
    "backend.AST_Schema.ASTVisitor": {
      "identifier": "backend.AST_Schema.ASTVisitor",
      "description": {
        "overall": "The ASTVisitor class is designed to traverse an Abstract Syntax Tree (AST) generated from Python source code. It specifically focuses on identifying and extracting information about imports, classes, and functions defined within the code. The visitor pattern is employed to systematically process different node types in the AST, populating a schema with the discovered structural elements of the codebase.",
        "init_method": {
          "description": "Initializes the ASTVisitor with the source code, file path, and project root. It sets up instance variables to store this information and initializes an empty schema dictionary to hold the extracted AST information. It also sets up a variable to track the current class being visited.",
          "parameters": [
            {
              "name": "source_code",
              "type": "str",
              "description": "The raw source code of the file being analyzed."
            },
            {
              "name": "file_path",
              "type": "str",
              "description": "The absolute path to the file being analyzed."
            },
            {
              "name": "project_root",
              "type": "str",
              "description": "The root directory of the project."
            }
          ]
        },
        "methods": [
          {
            "identifier": "visit_Import",
            "description": {
              "overall": "This method is called when an 'import' statement is encountered in the AST. It iterates through the imported names and appends them to the 'imports' list within the schema. It then calls the generic_visit method to continue traversal down the AST.",
              "parameters": [
                {
                  "name": "self",
                  "type": "ASTVisitor",
                  "description": "The instance of the ASTVisitor class."
                },
                {
                  "name": "node",
                  "type": "ast.AST",
                  "description": "The AST node representing an import statement."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls the generic_visit method to continue AST traversal.",
                "called_by": "This method is called automatically by the AST traversal mechanism when an import node is encountered."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_ImportFrom",
            "description": {
              "overall": "This method handles 'from ... import ...' statements. It constructs a fully qualified import path by combining the module name with the imported names and adds them to the 'imports' list in the schema. It ensures that the traversal continues by calling generic_visit.",
              "parameters": [
                {
                  "name": "self",
                  "type": "ASTVisitor",
                  "description": "The instance of the ASTVisitor class."
                },
                {
                  "name": "node",
                  "type": "ast.AST",
                  "description": "The AST node representing a 'from import' statement."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls the generic_visit method to continue AST traversal.",
                "called_by": "This method is called automatically by the AST traversal mechanism when a 'from import' node is encountered."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_ClassDef",
            "description": {
              "overall": "This method is invoked when a class definition is found in the AST. It constructs a unique identifier for the class, extracts its name, docstring, and source code segment, and records its line numbers. This information is then appended to the 'classes' list in the schema, and the visitor temporarily sets `_current_class` to store this class's information before continuing the traversal. After visiting child nodes, it resets `_current_class` to None.",
              "parameters": [
                {
                  "name": "self",
                  "type": "ASTVisitor",
                  "description": "The instance of the ASTVisitor class."
                },
                {
                  "name": "node",
                  "type": "ast.AST",
                  "description": "The AST node representing a class definition."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls ast.get_docstring, ast.get_source_segment, and generic_visit to process the class definition and its contents.",
                "called_by": "This method is called automatically by the AST traversal mechanism when a class definition node is encountered."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_FunctionDef",
            "description": {
              "overall": "This method processes function definitions. If the visitor is currently within a class (indicated by `_current_class` not being None), it treats the function as a method, constructs a method identifier, and stores method-specific details like arguments, docstring, and line numbers within the `_current_class`'s context. If not within a class, it treats the definition as a standalone function, creating a function identifier and storing its details in the main schema's 'functions' list. It then proceeds to visit child nodes.",
              "parameters": [
                {
                  "name": "self",
                  "type": "ASTVisitor",
                  "description": "The instance of the ASTVisitor class."
                },
                {
                  "name": "node",
                  "type": "ast.AST",
                  "description": "The AST node representing a function definition."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls ast.get_docstring, ast.get_source_segment, and generic_visit to process the function definition and its contents.",
                "called_by": "This method is called automatically by the AST traversal mechanism when a function definition node is encountered."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_AsyncFunctionDef",
            "description": {
              "overall": "This method handles asynchronous function definitions. It delegates the actual processing to the `visit_FunctionDef` method, ensuring that both synchronous and asynchronous functions are analyzed in the same manner.",
              "parameters": [
                {
                  "name": "self",
                  "type": "ASTVisitor",
                  "description": "The instance of the ASTVisitor class."
                },
                {
                  "name": "node",
                  "type": "ast.AST",
                  "description": "The AST node representing an asynchronous function definition."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls the visit_FunctionDef method to process the asynchronous function definition.",
                "called_by": "This method is called automatically by the AST traversal mechanism when an asynchronous function definition node is encountered."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "The class depends on the 'backend.AST_Schema.path_to_module' function for path manipulation.",
          "instantiated_by": "This class is not instantiated within the provided source code context."
        }
      },
      "error": null
    },
    "backend.AST_Schema.ASTAnalyzer": {
      "identifier": "backend.AST_Schema.ASTAnalyzer",
      "description": {
        "overall": "The ASTAnalyzer class is responsible for processing Abstract Syntax Trees (ASTs) generated from Python code to build a comprehensive schema representing the repository's structure and relationships. It takes raw code analysis data and relationship information to enrich the schema, detailing function calls, class instantiations, and inter-method dependencies. This class acts as a central orchestrator for transforming low-level code parsing results into a structured, analyzable format.",
        "init_method": {
          "description": "Initializes the ASTAnalyzer. Currently, this method does not perform any setup or state initialization.",
          "parameters": []
        },
        "methods": [
          {
            "identifier": "merge_relationship_data",
            "description": {
              "overall": "This method enriches a given schema with relationship data, specifically outgoing calls and incoming calls for functions and classes, as well as dependencies between methods within classes. It iterates through the schema, identifying functions, classes, and methods, and populates their respective context fields with data from `outgoing_calls` and `incoming_calls` dictionaries. It also calculates and stores inter-class dependencies based on method calls.",
              "parameters": [
                {
                  "name": "full_schema",
                  "type": "dict",
                  "description": "A dictionary representing the comprehensive schema of the repository, including file structures and AST nodes."
                },
                {
                  "name": "raw_relationships",
                  "type": "dict",
                  "description": "A dictionary containing raw relationship data, expected to have 'outgoing' and 'incoming' keys for call and instantiation information."
                }
              ],
              "returns": [
                {
                  "name": "full_schema",
                  "type": "dict",
                  "description": "The modified full_schema dictionary, now enriched with relationship data."
                }
              ],
              "usage_context": {
                "calls": "This method retrieves data using dictionary .get() method and iterates through dictionaries and lists. It also converts sets to lists and sorts them.",
                "called_by": "This method is called by the analyze_repository method to merge relationship data into the schema."
              }
            },
            "error": null
          },
          {
            "identifier": "analyze_repository",
            "description": {
              "overall": "This method orchestrates the analysis of a given list of files within a repository. It parses each Python file using the `ast` module and an `ASTVisitor` to generate a schema for each file. It determines the project root directory and handles potential parsing errors, accumulating the schema information into a `full_schema` dictionary. Files that are not Python files or are empty are skipped.",
              "parameters": [
                {
                  "name": "files",
                  "type": "list",
                  "description": "A list of file objects, where each object contains file path and content."
                },
                {
                  "name": "repo",
                  "type": "GitRepository",
                  "description": "An object representing the Git repository, likely used for context or further operations (though not directly used in the provided code snippet)."
                }
              ],
              "returns": [
                {
                  "name": "full_schema",
                  "type": "dict",
                  "description": "A dictionary containing the structured schema of the repository, organized by file path and including AST node information."
                }
              ],
              "usage_context": {
                "calls": "This method calls the ast.parse function to parse Python code into an AST, instantiates and uses the ASTVisitor class to traverse the AST, and uses os.path functions to manipulate file paths.",
                "called_by": "This method is called to initiate the analysis of a code repository."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "This class depends on the ASTVisitor class for parsing and visiting Abstract Syntax Trees, and utilizes the 'ast' and 'os' modules for code parsing and path manipulation.",
          "instantiated_by": "This class is not instantiated by any other part of the provided code."
        }
      },
      "error": null
    },
    "backend.File_Dependency.FileDependencyGraph": {
      "identifier": "backend.File_Dependency.FileDependencyGraph",
      "description": {
        "overall": "The FileDependencyGraph class is designed to analyze Python source code and build a graph of file dependencies based on import statements. It inherits from `ast.NodeVisitor` to traverse the Abstract Syntax Tree (AST) of Python files. The class specifically focuses on resolving both direct and relative imports to map out which files depend on others within a given repository. It stores these dependencies in a dictionary where keys are filenames and values are sets of imported module names.",
        "init_method": {
          "description": "Initializes the FileDependencyGraph with the target filename and the root directory of the repository. This sets up the context for analyzing imports within that specific file and repository.",
          "parameters": [
            {
              "name": "filename",
              "type": "str",
              "description": "The name of the Python file to analyze."
            },
            {
              "name": "repo_root",
              "type": "str",
              "description": "The root path of the repository containing the file."
            }
          ]
        },
        "methods": [
          {
            "identifier": "_resolve_module_name",
            "description": {
              "overall": "This method is responsible for resolving relative import statements (e.g., `from .. import module`) within a Python file. It determines the actual module path based on the current file's location and the repository structure. It checks for the existence of modules and symbols within the repository and raises an `ImportError` if a resolution cannot be made. This is crucial for accurately mapping dependencies when relative imports are used.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ImportFrom",
                  "description": "The AST node representing the import statement."
                }
              ],
              "returns": [
                {
                  "name": "resolved",
                  "type": "list[str]",
                  "description": "A sorted list of unique names of the resolved modules or symbols."
                }
              ],
              "usage_context": {
                "calls": "This method calls `get_all_temp_files` to get a list of all files in the repository, and it internally defines and calls helper functions `module_file_exists` and `init_exports_symbol` to check for module and symbol existence. It also uses `Path` for path manipulations and `ast.parse` and `ast.walk` for analyzing `__init__.py` files.",
                "called_by": "This method is called by `visit_ImportFrom` when it encounters a relative import statement that needs to be resolved."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_Import",
            "description": {
              "overall": "This method is part of the AST visitor pattern and handles direct import statements (e.g., `import module` or `from module import name`). It records the imported module name into the `import_dependencies` dictionary, associating it with the current file being analyzed. If a `base_name` is provided (indicating a resolved relative import), it uses that; otherwise, it uses the direct module name.",
              "parameters": [
                {
                  "name": "node",
                  "type": "Import | ImportFrom",
                  "description": "The AST node representing the import statement."
                },
                {
                  "name": "base_name",
                  "type": "str | None",
                  "description": "An optional base name, typically used for resolved relative imports."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls `self.generic_visit(node)` to continue traversing the AST.",
                "called_by": "This method is called by `visit_ImportFrom` to process both direct and resolved relative imports."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_ImportFrom",
            "description": {
              "overall": "This method handles `from ... import ...` statements in the AST. It first extracts the module name. If it's a direct import (e.g., `from module import name`), it calls `visit_Import` with the last part of the module name as the `base_name`. If it's a relative import (e.g., `from .. import name`), it calls `_resolve_module_name` to determine the actual module path and then calls `visit_Import` for each resolved name. It includes error handling for failed relative import resolutions.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ImportFrom",
                  "description": "The AST node representing the import statement."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls `self._resolve_module_name(node)` for relative imports and `self.visit_Import` to record the dependencies. It also calls `self.generic_visit(node)` to continue AST traversal.",
                "called_by": "This method is called by the AST visitor when it encounters an `ImportFrom` node."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "The class depends on several functions from the `backend.File_Dependency` module: `get_all_temp_files`, `init_exports_symbol`, and `module_file_exists`. It also utilizes standard Python libraries such as `os`, `ast` (for parsing and AST manipulation), `keyword`, and `pathlib`.",
          "instantiated_by": "The provided context does not specify where instances of this class are created."
        }
      },
      "error": null
    },
    "backend.HelperLLM.LLMHelper": {
      "identifier": "backend.HelperLLM.LLMHelper",
      "description": {
        "overall": "LLMHelper is a class designed to facilitate interactions with large language models (LLMs) for generating documentation. It centralizes the configuration and API calls for different LLM providers like Google Gemini, OpenAI, and Ollama. The class handles prompt loading, model selection, batch processing, and structured output generation, ensuring that the output conforms to specified Pydantic schemas for function and class analyses. It also incorporates rate limiting and error handling for robust API interactions.",
        "init_method": {
          "description": "Initializes the LLMHelper with necessary API credentials, prompt file paths, and model configuration. It loads system prompts from specified files, sets up the appropriate LLM client based on the model name (supporting Gemini, OpenAI, and Ollama), and configures batch processing settings. It raises a ValueError if the API key is missing or if required environment variables for custom LLM endpoints are not set.",
          "parameters": [
            {
              "name": "api_key",
              "type": "str",
              "description": "The API key for authenticating with the LLM service."
            },
            {
              "name": "function_prompt_path",
              "type": "str",
              "description": "The file path to the system prompt for function documentation generation."
            },
            {
              "name": "class_prompt_path",
              "type": "str",
              "description": "The file path to the system prompt for class documentation generation."
            },
            {
              "name": "model_name",
              "type": "str",
              "description": "The name of the LLM model to use. Defaults to 'gemini-2.0-flash-lite'."
            },
            {
              "name": "base_url",
              "type": "str",
              "description": "An optional base URL for custom LLM endpoints, used if not using default Ollama or OpenAI endpoints."
            }
          ]
        },
        "methods": [
          {
            "identifier": "_configure_batch_settings",
            "description": {
              "overall": "This private method configures the batch size for API calls based on the specified LLM model name. It defines different batch sizes for various Gemini models, common OpenAI models, and custom or alias models. For unknown models, it defaults to a conservative batch size of 2 and logs a warning. This ensures efficient processing while respecting potential API rate limits.",
              "parameters": [
                {
                  "name": "model_name",
                  "type": "str",
                  "description": "The name of the LLM model for which to configure batch settings."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method is called internally by the __init__ method to set the batch size based on the selected model.",
                "called_by": "This method is called by the __init__ method."
              }
            },
            "error": null
          },
          {
            "identifier": "generate_for_functions",
            "description": {
              "overall": "Generates and validates documentation for a list of function inputs using the configured LLM. It converts the input Pydantic models into JSON payloads, constructs conversation objects with system and human messages, and then processes these in batches according to the `self.batch_size`. The method handles potential API errors by logging them and returning None for failed batches, while also implementing a waiting period between batches to adhere to rate limits. The output is a list of validated `FunctionAnalysis` objects or None for failed items.",
              "parameters": [
                {
                  "name": "function_inputs",
                  "type": "List[FunctionAnalysisInput]",
                  "description": "A list of Pydantic models, each containing the necessary information to generate documentation for a function."
                }
              ],
              "returns": [
                {
                  "name": "all_validated_functions",
                  "type": "List[Optional[FunctionAnalysis]]",
                  "description": "A list containing the generated and validated `FunctionAnalysis` objects for each input function, or None if an error occurred during processing for a specific item."
                }
              ],
              "usage_context": {
                "calls": "This method calls `json.dumps` to serialize input models, constructs `SystemMessage` and `HumanMessage` objects, and uses the `self.function_llm.batch` method to interact with the LLM API. It also uses `time.sleep` for rate limiting.",
                "called_by": "This method is called externally to generate documentation for multiple functions."
              }
            },
            "error": null
          },
          {
            "identifier": "generate_for_classes",
            "description": {
              "overall": "Generates and validates documentation for a list of class inputs using the configured LLM. Similar to `generate_for_functions`, it serializes input Pydantic models into JSON payloads, creates conversation objects, and processes them in batches. It handles API errors gracefully by logging them and returning None for failed items, and includes a delay between batches to manage API rate limits. The method returns a list of validated `ClassAnalysis` objects or None for any items that failed processing.",
              "parameters": [
                {
                  "name": "class_inputs",
                  "type": "List[ClassAnalysisInput]",
                  "description": "A list of Pydantic models, each containing the necessary information to generate documentation for a class."
                }
              ],
              "returns": [
                {
                  "name": "all_validated_classes",
                  "type": "List[Optional[ClassAnalysis]]",
                  "description": "A list containing the generated and validated `ClassAnalysis` objects for each input class, or None if an error occurred during processing for a specific item."
                }
              ],
              "usage_context": {
                "calls": "This method calls `json.dumps` to serialize input models, constructs `SystemMessage` and `HumanMessage` objects, and utilizes the `self.class_llm.batch` method for LLM API interaction. It also employs `time.sleep` for rate limiting.",
                "called_by": "This method is called externally to generate documentation for multiple classes."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "This class depends on various LLM providers (Google Gemini, OpenAI, Ollama) through langchain integrations, Pydantic for data validation, and standard Python libraries for file I/O, logging, and time management. It also relies on specific schema types like `FunctionAnalysis`, `ClassAnalysis`, `FunctionAnalysisInput`, and `ClassAnalysisInput` from a 'schemas.types' module.",
          "instantiated_by": "The context does not explicitly state where this class is instantiated, but it is designed to be instantiated with API keys and prompt file paths to configure LLM interactions."
        }
      },
      "error": null
    },
    "backend.MainLLM.MainLLM": {
      "identifier": "backend.MainLLM.MainLLM",
      "description": {
        "overall": "The MainLLM class serves as a central interface for interacting with various Large Language Models (LLMs). It handles initialization with API keys and model configurations, reads system prompts from files, and dynamically selects the appropriate LLM client (e.g., Google Generative AI, Ollama, or custom APIs) based on the provided model name. The class offers methods to invoke LLMs for direct responses and to stream responses chunk by chunk, managing potential errors during these operations.",
        "init_method": {
          "description": "Initializes the MainLLM class by validating the API key, loading the system prompt from a specified file, and configuring the LLM client based on the model name. It supports different LLM providers like Google Generative AI, OpenAI-compatible custom APIs (via SCADSLLM_URL), and Ollama, setting a default temperature of 1.0 for all.",
          "parameters": [
            {
              "name": "api_key",
              "type": "str",
              "description": "The API key required for authenticating with the LLM service."
            },
            {
              "name": "prompt_file_path",
              "type": "str",
              "description": "The file path to the system prompt that will be used for all LLM interactions."
            },
            {
              "name": "model_name",
              "type": "str",
              "description": "The name of the LLM model to use. Defaults to 'gemini-2.5-pro'."
            },
            {
              "name": "base_url",
              "type": "str",
              "description": "An optional base URL for custom LLM endpoints. Defaults to None."
            }
          ]
        },
        "methods": [
          {
            "identifier": "call_llm",
            "description": {
              "overall": "Invokes the configured LLM with a user-provided input and a system prompt. It constructs a list of messages including the system prompt and the user's input, then uses the LLM's invoke method to get a response. The content of the response is returned, or None if an error occurs during the LLM call. Logging is used to track the process and any errors.",
              "parameters": [
                {
                  "name": "user_input",
                  "type": "str",
                  "description": "The input string provided by the user for the LLM."
                }
              ],
              "returns": [
                {
                  "name": "response.content",
                  "type": "str",
                  "description": "The text content generated by the LLM in response to the user input, or None if an error occurred."
                }
              ],
              "usage_context": {
                "calls": "This method calls the 'invoke' method of the LLM client and logs information using the 'logging' module.",
                "called_by": "This method is called by external users or other parts of the system that need to get a direct response from the LLM."
              }
            },
            "error": null
          },
          {
            "identifier": "stream_llm",
            "description": {
              "overall": "Initiates a streaming call to the configured LLM with user input and the system prompt. It yields content chunks as they are received from the LLM. If an error occurs during the streaming process, an error message is logged and yielded as a final chunk.",
              "parameters": [
                {
                  "name": "user_input",
                  "type": "str",
                  "description": "The input string provided by the user for the LLM."
                }
              ],
              "returns": [
                {
                  "name": "chunk.content",
                  "type": "str",
                  "description": "Yields chunks of text content generated by the LLM as they become available. In case of an error, it yields an error message string."
                }
              ],
              "usage_context": {
                "calls": "This method calls the 'stream' method of the LLM client and logs information using the 'logging' module.",
                "called_by": "This method is called by external users or other parts of the system that require a streaming response from the LLM."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "This class depends on several external libraries for LLM interaction, including 'langchain_google_genai', 'langchain_ollama', and 'langchain_openai'. It also utilizes 'logging' for output and error reporting, and potentially environment variables like 'SCADSLLM_URL' and 'OLLAMA_BASE_URL' for configuration.",
          "instantiated_by": "The context does not specify where this class is instantiated."
        }
      },
      "error": null
    },
    "backend.basic_info.ProjektInfoExtractor": {
      "identifier": "backend.basic_info.ProjektInfoExtractor",
      "description": {
        "overall": "The ProjektInfoExtractor class is designed to extract fundamental project information from common project files such as README, pyproject.toml, and requirements.txt. It initializes a structured dictionary to hold project overview and installation details, populating it by parsing these files. The class prioritizes information from pyproject.toml for dependencies and then falls back to requirements.txt, while README files are used for project title, description, key features, tech stack, status, setup instructions, and quick start guides. It also derives the project title from the repository URL if no title is found in the files.",
        "init_method": {
          "description": "Initializes the ProjektInfoExtractor by setting up a default structure for project information. This structure includes placeholders for project overview (title, description, status, key features, tech stack) and installation details (dependencies, setup instructions, quick start guide), all initially marked as 'Information not found'. It also defines a constant for this placeholder string.",
          "parameters": [
            {
              "name": "self",
              "type": "typing.Self",
              "description": "The instance of the class."
            }
          ]
        },
        "methods": [
          {
            "identifier": "_clean_content",
            "description": {
              "overall": "This method takes a string as input and removes any null bytes ('\\x00') from it. Null bytes can occur due to encoding errors, such as when UTF-16 encoded data is read as UTF-8. The method ensures that the returned string is clean and free of these problematic characters, returning an empty string if the input is empty or None.",
              "parameters": [
                {
                  "name": "self",
                  "type": "typing.Self",
                  "description": "The instance of the class."
                },
                {
                  "name": "content",
                  "type": "str",
                  "description": "The string content to be cleaned."
                }
              ],
              "returns": [
                {
                  "name": "None",
                  "type": "str",
                  "description": "The cleaned string with null bytes removed, or an empty string if the input was empty."
                }
              ],
              "usage_context": {
                "calls": "This method is called by other internal methods to clean file content before parsing.",
                "called_by": "This method is called by _parse_readme, _parse_toml, and _parse_requirements."
              }
            },
            "error": null
          },
          {
            "identifier": "_finde_datei",
            "description": {
              "overall": "This utility method searches through a list of file objects to find a file that matches one of the provided patterns. The search is case-insensitive and checks if the file's path ends with any of the specified patterns. It returns the first matching file object found, or None if no match is found after checking all files and patterns.",
              "parameters": [
                {
                  "name": "self",
                  "type": "typing.Self",
                  "description": "The instance of the class."
                },
                {
                  "name": "patterns",
                  "type": "List[str]",
                  "description": "A list of file name patterns (e.g., 'readme.md') to search for."
                },
                {
                  "name": "dateien",
                  "type": "List[Any]",
                  "description": "A list of file objects, where each object is expected to have a 'path' attribute."
                }
              ],
              "returns": [
                {
                  "name": "Optional[Any]",
                  "type": "typing.Optional[typing.Any]",
                  "description": "The file object that matches one of the patterns, or None if no match is found."
                }
              ],
              "usage_context": {
                "calls": "This method iterates through provided file objects and patterns to find a match.",
                "called_by": "This method is called by extrahiere_info to locate specific project files like README, pyproject.toml, and requirements.txt."
              }
            },
            "error": null
          },
          {
            "identifier": "_extrahiere_sektion_aus_markdown",
            "description": {
              "overall": "This method extracts content from a Markdown string that falls under a specific section heading. It uses regular expressions to find lines starting with '##' followed by one of the provided keywords. The content between the matched heading and the next '##' heading or the end of the file is captured and returned as a stripped string. If no matching section is found, it returns None.",
              "parameters": [
                {
                  "name": "self",
                  "type": "typing.Self",
                  "description": "The instance of the class."
                },
                {
                  "name": "inhalt",
                  "type": "str",
                  "description": "The Markdown content to parse."
                },
                {
                  "name": "keywords",
                  "type": "List[str]",
                  "description": "A list of keywords that identify the desired section heading (e.g., 'Features', 'Installation')."
                }
              ],
              "returns": [
                {
                  "name": "Optional[str]",
                  "type": "typing.Optional[str]",
                  "description": "The extracted section content as a string, or None if the section is not found."
                }
              ],
              "usage_context": {
                "calls": "This method utilizes the 're' module for pattern matching to find and extract specific sections from Markdown text.",
                "called_by": "This method is called by _parse_readme to extract specific sections like 'Features', 'Tech Stack', 'Status', 'Installation', and 'Quick Start'."
              }
            },
            "error": null
          },
          {
            "identifier": "_parse_readme",
            "description": {
              "overall": "This method parses the content of a README file to extract various project details. It first cleans the content by removing null bytes. It then attempts to extract the project title from the main heading (H1), followed by a description from the text immediately after the title. It also uses the `_extrahiere_sektion_aus_markdown` method to find and populate fields for key features, tech stack, current status, setup instructions, and quick start guides. Information is only updated if it hasn't already been found by other parsing methods.",
              "parameters": [
                {
                  "name": "self",
                  "type": "typing.Self",
                  "description": "The instance of the class."
                },
                {
                  "name": "inhalt",
                  "type": "str",
                  "description": "The content of the README file."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls _clean_content to sanitize input and _extrahiere_sektion_aus_markdown to parse specific sections. It also uses the 're' module for title and description extraction.",
                "called_by": "This method is called by extrahiere_info after a README file has been identified."
              }
            },
            "error": null
          },
          {
            "identifier": "_parse_toml",
            "description": {
              "overall": "This method parses the content of a pyproject.toml file using the `tomllib` library. It first cleans the input content. If `tomllib` is available, it attempts to load the TOML data and extracts the project name, description, and dependencies from the 'project' section. It prints a warning if `tomllib` is not installed or if there's a decoding error. Extracted information updates the class's internal info structure.",
              "parameters": [
                {
                  "name": "self",
                  "type": "typing.Self",
                  "description": "The instance of the class."
                },
                {
                  "name": "inhalt",
                  "type": "str",
                  "description": "The content of the pyproject.toml file."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method uses the 'tomllib' library to parse TOML content and calls _clean_content to prepare the input string.",
                "called_by": "This method is called by extrahiere_info after a pyproject.toml file has been identified."
              }
            },
            "error": null
          },
          {
            "identifier": "_parse_requirements",
            "description": {
              "overall": "This method parses the content of a requirements.txt file to extract project dependencies. It cleans the input content and then splits it into lines. It filters out empty lines and lines starting with '#'. The extracted dependencies are stored only if the 'dependencies' field in the class's info structure is still marked as 'Information not found', indicating that dependencies were not found in a pyproject.toml file.",
              "parameters": [
                {
                  "name": "self",
                  "type": "typing.Self",
                  "description": "The instance of the class."
                },
                {
                  "name": "inhalt",
                  "type": "str",
                  "description": "The content of the requirements.txt file."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls _clean_content to sanitize input and uses string manipulation (splitlines, strip) to process the content.",
                "called_by": "This method is called by extrahiere_info after a requirements.txt file has been identified."
              }
            },
            "error": null
          },
          {
            "identifier": "extrahiere_info",
            "description": {
              "overall": "This is the main orchestrating method that drives the extraction of project information. It first identifies relevant files (README, pyproject.toml, requirements.txt) using the `_finde_datei` method. It then parses these files in a specific order of priority: pyproject.toml first for comprehensive project data, then requirements.txt for dependencies if not found in TOML, and finally README for remaining details. After parsing, it formats the dependencies into a readable string. If a repository URL is provided and no project title has been found, it derives a title from the URL.",
              "parameters": [
                {
                  "name": "self",
                  "type": "typing.Self",
                  "description": "The instance of the class."
                },
                {
                  "name": "dateien",
                  "type": "List[Any]",
                  "description": "A list of file objects representing the files in the project directory."
                },
                {
                  "name": "repo_url",
                  "type": "str",
                  "description": "The URL of the repository, used to derive the project title if necessary."
                }
              ],
              "returns": [
                {
                  "name": "Dict[str, Any]",
                  "type": "typing.Dict[str, typing.Any]",
                  "description": "A dictionary containing the extracted project information, structured into 'projekt_uebersicht' and 'installation' sections."
                }
              ],
              "usage_context": {
                "calls": "This method calls _finde_datei to locate project files and then calls _parse_toml, _parse_requirements, and _parse_readme to process their content. It also uses os.path.basename for URL processing.",
                "called_by": "This method is the primary public interface for the ProjektInfoExtractor class, intended to be called to initiate the information extraction process."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "This class utilizes the 're' module for regular expression operations, 'os' for path manipulation, and 'tomllib' for parsing TOML files. It also relies on type hinting from the 'typing' module.",
          "instantiated_by": "This class is instantiated by other parts of the system that need to extract project information from files."
        }
      },
      "error": null
    },
    "backend.callgraph.CallGraph": {
      "identifier": "backend.callgraph.CallGraph",
      "description": {
        "overall": "The CallGraph class is designed to parse Python source code and build a call graph representation. It inherits from `ast.NodeVisitor` to traverse the Abstract Syntax Tree (AST) of a given Python file. The class maintains state about the current file, function, and class being visited, along with mappings for imports and local definitions. It constructs a directed graph (`nx.DiGraph`) where nodes represent functions or code blocks and edges represent calls between them. The analysis focuses on identifying function calls, class definitions, and import statements to accurately map dependencies and execution flow within the codebase.",
        "init_method": {
          "description": "Initializes the CallGraph object with the filename to be analyzed. It sets up internal state variables including placeholders for the current function and class, dictionaries for local definitions and import mappings, a set to store function names, and a directed graph to store the call graph structure. It also initializes an empty dictionary to store edges representing calls.",
          "parameters": [
            {
              "name": "filename",
              "type": "str",
              "description": "The path to the Python file that will be analyzed to build the call graph."
            }
          ]
        },
        "methods": [
          {
            "identifier": "_recursive_call",
            "description": {
              "overall": "This method recursively traverses an AST node, typically representing a function call, to extract the name components of the callee. It handles different AST node types like `ast.Call`, `ast.Name`, and `ast.Attribute` to reconstruct the fully qualified name as a list of strings. For instance, a call like `pkg.mod.Class.method()` would be resolved into `['pkg', 'mod', 'Class', 'method']`. If the node type is not recognized or does not represent a callable entity, it returns an empty list.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.AST",
                  "description": "The AST node to recursively analyze for extracting name components."
                }
              ],
              "returns": [
                {
                  "name": "parts",
                  "type": "list[str]",
                  "description": "A list of strings representing the name components of the callee, e.g., ['module', 'Class', 'method']."
                }
              ],
              "usage_context": {
                "calls": "This method is called internally by other methods within the CallGraph class to resolve the names of called functions or methods.",
                "called_by": "This method is called by `visit_Call` to determine the structure of a function call."
              }
            },
            "error": null
          },
          {
            "identifier": "_resolve_all_callee_names",
            "description": {
              "overall": "This method takes a list of callee name components (obtained from `_recursive_call`) and resolves them into fully qualified names within the context of the current analysis. It prioritizes checking local definitions and then import mappings to determine the actual target of a call. If a direct match is not found, it constructs a name based on the current filename, class, and function context. This ensures that calls are mapped to their defined locations, whether they are local functions, imported modules, or methods within the current class.",
              "parameters": [
                {
                  "name": "callee_nodes",
                  "type": "list[list[str]]",
                  "description": "A list where each element is a list of strings representing the name components of a potential callee."
                }
              ],
              "returns": [
                {
                  "name": "resolved",
                  "type": "list[str]",
                  "description": "A list of fully resolved callee names as strings."
                }
              ],
              "usage_context": {
                "calls": "This method internally uses string manipulation and checks against `self.local_defs` and `self.import_mapping` to resolve names.",
                "called_by": "This method is called by `visit_Call` to resolve the names of the functions or methods being called."
              }
            },
            "error": null
          },
          {
            "identifier": "_make_full_name",
            "description": {
              "overall": "This utility method constructs a fully qualified name for a function or method within the context of the analyzed file. It takes a base name (e.g., a function name) and an optional class name. If a class name is provided, it formats the name as 'filename::ClassName::basename'. Otherwise, it formats it as 'filename::basename'. This consistent naming convention is used throughout the call graph construction.",
              "parameters": [
                {
                  "name": "basename",
                  "type": "str",
                  "description": "The base name of the function or method."
                },
                {
                  "name": "class_name",
                  "type": "str | None",
                  "description": "The name of the class the function belongs to, if any."
                }
              ],
              "returns": [
                {
                  "name": "full_name",
                  "type": "str",
                  "description": "The fully qualified name of the function or method."
                }
              ],
              "usage_context": {
                "calls": "This method uses f-strings for string formatting.",
                "called_by": "This method is called by `visit_FunctionDef` to generate the unique identifier for a function."
              }
            },
            "error": null
          },
          {
            "identifier": "_current_caller",
            "description": {
              "overall": "This method returns the identifier of the current code context that is making a call. If `self.current_function` is set, it returns that value. Otherwise, it returns a string representing the global scope of the file, formatted as '<filename>' if a filename is available, or '<global-scope>' if not. This helps in correctly attributing calls to their originating functions or the main script block.",
              "parameters": [
                {
                  "name": "self",
                  "type": "CallGraph",
                  "description": "The instance of the CallGraph class."
                }
              ],
              "returns": [
                {
                  "name": "caller_identifier",
                  "type": "str",
                  "description": "The string identifier for the current caller context."
                }
              ],
              "usage_context": {
                "calls": "This method uses conditional logic based on `self.current_function` and `self.filename`.",
                "called_by": "This method is called by `visit_Call` to determine the source of a function call."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_Import",
            "description": {
              "overall": "This method is called when an `import` statement is encountered in the AST. It iterates through the imported modules and their aliases, populating the `self.import_mapping` dictionary. The dictionary maps the alias (or the module name if no alias is used) to the original module name. This mapping is crucial for resolving calls to imported functions or classes later in the analysis.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.Import",
                  "description": "The AST node representing an import statement."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls `self.generic_visit(node)` to continue traversal of the AST.",
                "called_by": "This method is automatically called by the `ast.NodeVisitor` when it encounters an `import` statement."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_ImportFrom",
            "description": {
              "overall": "This method handles `from ... import ...` statements in the AST. It extracts the module name and the imported names (and their aliases). It then updates the `self.import_mapping` dictionary, mapping the alias (or the imported name if no alias is used) to the base module name. This allows the call graph to correctly track calls to specific objects imported from modules.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.ImportFrom",
                  "description": "The AST node representing a 'from ... import ...' statement."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method performs string splitting and dictionary updates.",
                "called_by": "This method is automatically called by the `ast.NodeVisitor` when it encounters a `from ... import ...` statement."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_ClassDef",
            "description": {
              "overall": "This method is invoked when a class definition (`class ...:`) is found in the AST. It temporarily updates `self.current_class` to the name of the class being visited to provide context for methods defined within it. After visiting all nodes within the class definition (using `self.generic_visit`), it restores `self.current_class` to its previous value, ensuring correct context management when returning to the outer scope.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.ClassDef",
                  "description": "The AST node representing a class definition."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls `self.generic_visit(node)` to process the contents of the class definition.",
                "called_by": "This method is automatically called by the `ast.NodeVisitor` when it encounters a class definition."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_FunctionDef",
            "description": {
              "overall": "This method processes standard function definitions (`def ...:`). It constructs a full name for the function using `_make_full_name`, considering the `self.current_class` if applicable. This full name is stored in `self.local_defs` for both the function's base name and its qualified name (e.g., 'ClassName.functionName'). It then updates `self.current_function` to this full name, adds the function as a node to the graph, recursively visits the function's body, adds the function to `self.function_set`, and finally restores `self.current_function` to its previous state.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.FunctionDef",
                  "description": "The AST node representing a function definition."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls `self._make_full_name`, `self._current_caller`, `self.graph.add_node`, and `self.generic_visit(node)`.",
                "called_by": "This method is automatically called by the `ast.NodeVisitor` when it encounters a function definition."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_AsyncFunctionDef",
            "description": {
              "overall": "This method handles asynchronous function definitions (`async def ...:`). It simply delegates the processing to the `visit_FunctionDef` method, as the logic for analyzing function definitions is the same for both synchronous and asynchronous functions in this context. This ensures that async functions are correctly identified and added to the call graph.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.AsyncFunctionDef",
                  "description": "The AST node representing an asynchronous function definition."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls `self.visit_FunctionDef(node)`.",
                "called_by": "This method is automatically called by the `ast.NodeVisitor` when it encounters an asynchronous function definition."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_Call",
            "description": {
              "overall": "This method is triggered when a function or method call is encountered in the AST. It first determines the current caller using `_current_caller`. Then, it uses `_recursive_call` to extract the name components of the callee and `_resolve_all_callee_names` to resolve these components into a fully qualified name. If the caller is not already in the `self.edges` dictionary, it initializes an empty set for it. Finally, it adds edges from the caller to each resolved callee in the graph, representing the call relationship, and continues the AST traversal.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.Call",
                  "description": "The AST node representing a function or method call."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls `self._current_caller`, `self._recursive_call`, `self._resolve_all_callee_names`, and `self.generic_visit(node)`.",
                "called_by": "This method is automatically called by the `ast.NodeVisitor` when it encounters a function call."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_If",
            "description": {
              "overall": "This method handles `if` statements in the AST. It includes specific logic to detect the main execution block of a script, typically guarded by `if __name__ == \"__main__\":`. If such a block is detected, it temporarily sets `self.current_function` to '<main_block>' to correctly attribute any calls within this block. It then proceeds with the generic visit to process the `if` statement's body and conditions, and finally restores the `self.current_function` to its previous state.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.If",
                  "description": "The AST node representing an if statement."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls `self.generic_visit(node)`.",
                "called_by": "This method is automatically called by the `ast.NodeVisitor` when it encounters an if statement."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "The CallGraph class relies on the `ast` module for parsing Python code and the `networkx` library for creating and managing the graph structure. It also utilizes typing hints from the `typing` module.",
          "instantiated_by": "The provided source code does not specify where the CallGraph class is instantiated. However, based on its purpose, it would typically be instantiated within a script or module responsible for code analysis or documentation generation, likely passing a filename to its constructor."
        }
      },
      "error": null
    },
    "backend.getRepo.RepoFile": {
      "identifier": "backend.getRepo.RepoFile",
      "description": {
        "overall": "The RepoFile class represents a single file within a Git repository. It is designed to load file content and metadata lazily, meaning information like the blob object, content, and size are only fetched when they are first accessed. This class provides methods to access file properties, analyze its content (like word count), and represent it as a dictionary.",
        "init_method": {
          "description": "Initializes a RepoFile object with the file's path and the commit tree it belongs to. It sets up internal attributes to store the path and the commit tree, and initializes placeholders for the blob, content, and size to None, indicating they are not yet loaded.",
          "parameters": [
            {
              "name": "file_path",
              "type": "str",
              "description": "The path to the file within the repository."
            },
            {
              "name": "commit_tree",
              "type": "git.Tree",
              "description": "The Tree object of the commit from which the file originates."
            }
          ]
        },
        "methods": [
          {
            "identifier": "blob",
            "description": {
              "overall": "This property provides lazy loading for the Git blob object associated with the file. If the blob has not been loaded yet, it attempts to retrieve it from the commit tree using the file path. If the file is not found in the tree, it raises a FileNotFoundError. Once loaded, the blob object is cached for subsequent access.",
              "parameters": [
                {
                  "name": "self",
                  "type": "RepoFile",
                  "description": "The instance of the RepoFile class."
                }
              ],
              "returns": [
                {
                  "name": "self._blob",
                  "type": "git.Blob",
                  "description": "The Git blob object representing the file."
                }
              ],
              "usage_context": {
                "calls": "This method calls `self._tree[self.path]` to retrieve the blob and raises `FileNotFoundError` if the file is not found.",
                "called_by": "This method is called by other methods within the RepoFile class that require access to the file's blob object, such as `content` and `size`."
              }
            },
            "error": null
          },
          {
            "identifier": "content",
            "description": {
              "overall": "This property provides lazy loading for the decoded content of the file. It first retrieves the blob object using the `blob` property. If the content has not been loaded, it reads the data from the blob's data stream, decodes it as UTF-8 (ignoring errors), and caches it. This ensures the file content is only read and decoded when it's actually needed.",
              "parameters": [
                {
                  "name": "self",
                  "type": "RepoFile",
                  "description": "The instance of the RepoFile class."
                }
              ],
              "returns": [
                {
                  "name": "self._content",
                  "type": "str",
                  "description": "The decoded content of the file as a string."
                }
              ],
              "usage_context": {
                "calls": "This method calls `self.blob` to get the file's blob and then accesses `blob.data_stream.read().decode('utf-8', errors='ignore')` to get and decode the content.",
                "called_by": "This method is called by other methods within the RepoFile class that need to access the file's content, such as `analyze_word_count` and `to_dict`."
              }
            },
            "error": null
          },
          {
            "identifier": "size",
            "description": {
              "overall": "This property provides lazy loading for the size of the file in bytes. It retrieves the blob object using the `blob` property. If the size has not been loaded, it accesses the `size` attribute of the blob object and caches it. This ensures the file size is only fetched when it is required.",
              "parameters": [
                {
                  "name": "self",
                  "type": "RepoFile",
                  "description": "The instance of the RepoFile class."
                }
              ],
              "returns": [
                {
                  "name": "self._size",
                  "type": "int",
                  "description": "The size of the file in bytes."
                }
              ],
              "usage_context": {
                "calls": "This method calls `self.blob` to get the file's blob and then accesses `blob.size` to get the file size.",
                "called_by": "This method is called by other methods within the RepoFile class that need to know the file's size, such as `to_dict`."
              }
            },
            "error": null
          },
          {
            "identifier": "analyze_word_count",
            "description": {
              "overall": "This method performs a basic analysis of the file's content by counting the number of words. It accesses the file's content using the `content` property, splits the content into words based on whitespace, and returns the total count. This serves as an example of a content analysis operation.",
              "parameters": [
                {
                  "name": "self",
                  "type": "RepoFile",
                  "description": "The instance of the RepoFile class."
                }
              ],
              "returns": [
                {
                  "name": "word_count",
                  "type": "int",
                  "description": "The total number of words found in the file's content."
                }
              ],
              "usage_context": {
                "calls": "This method calls `self.content` to retrieve the file's content and then uses the string method `split()` to tokenize the content into words.",
                "called_by": "This method is called directly on a RepoFile instance to perform a word count analysis."
              }
            },
            "error": null
          },
          {
            "identifier": "__repr__",
            "description": {
              "overall": "This method provides a developer-friendly string representation of the RepoFile object. It returns a formatted string that includes the class name and the file path, making it easy to identify the object when debugging or inspecting it.",
              "parameters": [
                {
                  "name": "self",
                  "type": "RepoFile",
                  "description": "The instance of the RepoFile class."
                }
              ],
              "returns": [
                {
                  "name": "representation",
                  "type": "str",
                  "description": "A string representation of the RepoFile object, e.g., '<RepoFile(path='path/to/file.txt')>'."
                }
              ],
              "usage_context": {
                "calls": "This method uses an f-string to format the output string, embedding `self.path`.",
                "called_by": "This method is called implicitly when a RepoFile object is represented as a string, for example, when printed or inspected in an interactive session."
              }
            },
            "error": null
          },
          {
            "identifier": "to_dict",
            "description": {
              "overall": "This method converts the RepoFile object into a dictionary representation. It includes basic file information such as path, name, size, and type. Optionally, if `include_content` is set to `True`, it also includes the file's content in the dictionary. This is useful for serializing file information.",
              "parameters": [
                {
                  "name": "self",
                  "type": "RepoFile",
                  "description": "The instance of the RepoFile class."
                },
                {
                  "name": "include_content",
                  "type": "bool",
                  "description": "A flag to indicate whether to include the file's content in the dictionary. Defaults to False."
                }
              ],
              "returns": [
                {
                  "name": "data",
                  "type": "dict",
                  "description": "A dictionary containing the file's metadata and optionally its content."
                }
              ],
              "usage_context": {
                "calls": "This method calls `os.path.basename(self.path)` to extract the filename, `self.size` to get the file size, and `self.content` if `include_content` is True.",
                "called_by": "This method is called on a RepoFile instance to get a dictionary representation of the file, potentially for API responses or data storage."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "The class utilizes the `os` module for path manipulation and relies on the `git` library for interacting with Git repositories, specifically `git.Tree` objects.",
          "instantiated_by": "This class is instantiated within the context of a Git repository, likely when iterating through files of a specific commit or tree."
        }
      },
      "error": null
    },
    "backend.getRepo.GitRepository": {
      "identifier": "backend.getRepo.GitRepository",
      "description": {
        "overall": "The GitRepository class is designed to manage a Git repository. It handles cloning a repository from a given URL into a temporary directory, providing access to its files, and cleaning up the temporary directory upon completion. The class also offers functionality to represent the repository's file structure as a tree, with an option to include file content.",
        "init_method": {
          "description": "Initializes the GitRepository by storing the repository URL, creating a temporary directory for the clone, and attempting to clone the repository. It also captures the latest commit and its tree. If cloning fails, it cleans up and raises a RuntimeError.",
          "parameters": [
            {
              "name": "repo_url",
              "type": "string",
              "description": "The URL of the Git repository to clone."
            }
          ]
        },
        "methods": [
          {
            "identifier": "get_all_files",
            "description": {
              "overall": "Retrieves all files within the cloned Git repository. It uses the Git command `ls-files` to get a list of file paths and then creates a `RepoFile` object for each file. These `RepoFile` objects are stored internally and returned as a list.",
              "parameters": [
                {
                  "name": "self",
                  "type": "GitRepository",
                  "description": "The instance of the GitRepository class."
                }
              ],
              "returns": [
                {
                  "name": "files",
                  "type": "list[RepoFile]",
                  "description": "A list containing RepoFile objects, each representing a file in the repository."
                }
              ],
              "usage_context": {
                "calls": "This method calls the `RepoFile` constructor for each file found in the repository.",
                "called_by": "This method is called by `get_file_tree` if no files have been loaded yet."
              }
            },
            "error": null
          },
          {
            "identifier": "close",
            "description": {
              "overall": "Cleans up the GitRepository by deleting the temporary directory that was created during initialization. It ensures that the temporary directory is removed to free up resources.",
              "parameters": [
                {
                  "name": "self",
                  "type": "GitRepository",
                  "description": "The instance of the GitRepository class."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method does not call any other methods or functions.",
                "called_by": "This method is called by the constructor if an error occurs during cloning, and by the `__exit__` method to ensure cleanup."
              }
            },
            "error": null
          },
          {
            "identifier": "__enter__",
            "description": {
              "overall": "Implements the context management protocol, returning the GitRepository instance itself. This allows the class to be used in a `with` statement for automatic resource management.",
              "parameters": [
                {
                  "name": "self",
                  "type": "GitRepository",
                  "description": "The instance of the GitRepository class."
                }
              ],
              "returns": [
                {
                  "name": "self",
                  "type": "GitRepository",
                  "description": "The current instance of the GitRepository."
                }
              ],
              "usage_context": {
                "calls": "This method does not call any other methods or functions.",
                "called_by": "This method is called when entering a `with` statement with a GitRepository instance."
              }
            },
            "error": null
          },
          {
            "identifier": "__exit__",
            "description": {
              "overall": "Implements the context management protocol's exit behavior. It ensures that the `close` method is called to clean up the temporary directory when exiting the `with` block, regardless of whether an exception occurred.",
              "parameters": [
                {
                  "name": "self",
                  "type": "GitRepository",
                  "description": "The instance of the GitRepository class."
                },
                {
                  "name": "exc_type",
                  "type": "type",
                  "description": "The type of the exception raised within the `with` block, if any."
                },
                {
                  "name": "exc_val",
                  "type": "Exception",
                  "description": "The exception instance raised within the `with` block, if any."
                },
                {
                  "name": "exc_tb",
                  "type": "traceback",
                  "description": "The traceback object associated with the exception, if any."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls the `close` method of the GitRepository instance.",
                "called_by": "This method is called when exiting a `with` statement that uses a GitRepository instance."
              }
            },
            "error": null
          },
          {
            "identifier": "get_file_tree",
            "description": {
              "overall": "Constructs and returns a hierarchical tree representation of the files in the repository. If no files have been loaded, it first calls `get_all_files`. It then iterates through the files, parsing their paths to build a nested dictionary structure representing directories and files.",
              "parameters": [
                {
                  "name": "self",
                  "type": "GitRepository",
                  "description": "The instance of the GitRepository class."
                },
                {
                  "name": "include_content",
                  "type": "bool",
                  "description": "A boolean flag indicating whether to include the content of each file in the tree representation. Defaults to False."
                }
              ],
              "returns": [
                {
                  "name": "tree",
                  "type": "dict",
                  "description": "A dictionary representing the file tree structure of the repository."
                }
              ],
              "usage_context": {
                "calls": "This method calls `get_all_files` if the `files` attribute is empty. It also calls the `to_dict` method on `RepoFile` objects.",
                "called_by": "This method is called to generate a structured view of the repository's files."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "This class depends on `tempfile` for temporary directory creation, `git.Repo` and `git.GitCommandError` for Git operations, `logging` for information messages, and `backend.getRepo.RepoFile` for representing individual files.",
          "instantiated_by": "This class is not explicitly shown to be instantiated by any other code within the provided context."
        }
      },
      "error": null
    },
    "backend.relationship_analyzer.ProjectAnalyzer": {
      "identifier": "backend.relationship_analyzer.ProjectAnalyzer",
      "description": {
        "overall": "The ProjectAnalyzer class is designed to parse a Python project's source code, identify definitions (functions, classes, methods), and build a call graph to represent relationships between these entities. It traverses the project directory, analyzes Python files using the AST module, and stores information about definitions and calls. The class provides methods to retrieve raw relationship data in outgoing and incoming formats.",
        "init_method": {
          "description": "Initializes the ProjectAnalyzer with the root directory of the project. It sets up instance variables to store project root, definitions, call graph, file Abstract Syntax Trees (ASTs), and a set of directories to ignore during the file search.",
          "parameters": [
            {
              "name": "project_root",
              "type": "string",
              "description": "The absolute path to the root directory of the Python project to be analyzed."
            }
          ]
        },
        "methods": [
          {
            "identifier": "analyze",
            "description": {
              "overall": "Orchestrates the analysis of the Python project. It first finds all Python files within the project, then collects definitions from each file, and subsequently resolves function and method calls. Finally, it clears the stored ASTs to free up memory and returns the constructed call graph.",
              "parameters": [
                {
                  "name": "self",
                  "type": "ProjectAnalyzer",
                  "description": "The instance of the ProjectAnalyzer class."
                }
              ],
              "returns": [
                {
                  "name": "call_graph",
                  "type": "defaultdict(list)",
                  "description": "A dictionary representing the call graph, where keys are callee identifiers and values are lists of caller information."
                }
              ],
              "usage_context": {
                "calls": "This method calls the internal methods `_find_py_files`, `_collect_definitions`, and `_resolve_calls` to perform the project analysis.",
                "called_by": "This method is intended to be called by external code to initiate the analysis of a project."
              }
            },
            "error": null
          },
          {
            "identifier": "get_raw_relationships",
            "description": {
              "overall": "Processes the internal call graph to generate structured dictionaries of outgoing and incoming relationships between code entities. It iterates through the call graph, identifying callers and callees, and populates two dictionaries: one for outgoing calls and one for incoming calls. The results are then sorted and returned.",
              "parameters": [
                {
                  "name": "self",
                  "type": "ProjectAnalyzer",
                  "description": "The instance of the ProjectAnalyzer class."
                }
              ],
              "returns": [
                {
                  "name": "relationships",
                  "type": "dict",
                  "description": "A dictionary containing two keys: 'outgoing' and 'incoming', each mapping to a dictionary of entities and their respective related entities."
                }
              ],
              "usage_context": {
                "calls": "This method iterates through the `self.call_graph` and uses `defaultdict(set)` to build outgoing and incoming relationship sets.",
                "called_by": "This method is called to retrieve the analyzed relationships from the ProjectAnalyzer instance."
              }
            },
            "error": null
          },
          {
            "identifier": "_find_py_files",
            "description": {
              "overall": "Recursively searches the project directory for all Python files (`.py`). It uses `os.walk` to traverse the directory tree and filters out files in specified ignored directories. The method returns a list of absolute paths to all found Python files.",
              "parameters": [
                {
                  "name": "self",
                  "type": "ProjectAnalyzer",
                  "description": "The instance of the ProjectAnalyzer class."
                }
              ],
              "returns": [
                {
                  "name": "py_files",
                  "type": "list[str]",
                  "description": "A list of strings, where each string is the absolute path to a Python file found in the project."
                }
              ],
              "usage_context": {
                "calls": "This method utilizes `os.walk` for directory traversal and `os.path.join` for constructing file paths.",
                "called_by": "This method is called internally by the `analyze` method to locate all Python source files."
              }
            },
            "error": null
          },
          {
            "identifier": "_collect_definitions",
            "description": {
              "overall": "Reads a given Python file, parses its source code into an Abstract Syntax Tree (AST), and identifies function, class, and method definitions. It stores the file path, line number, and type of each definition in the `self.definitions` dictionary. It also stores the AST in `self.file_asts` for later use. Errors during parsing are logged.",
              "parameters": [
                {
                  "name": "self",
                  "type": "ProjectAnalyzer",
                  "description": "The instance of the ProjectAnalyzer class."
                },
                {
                  "name": "filepath",
                  "type": "str",
                  "description": "The path to the Python file to analyze."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls `ast.parse` to generate the AST, `path_to_module` to convert a file path to a module path, and `ast.walk` to traverse the AST. It also calls the internal method `_get_parent`.",
                "called_by": "This method is called by the `analyze` method for each Python file found in the project."
              }
            },
            "error": null
          },
          {
            "identifier": "_get_parent",
            "description": {
              "overall": "A helper method that traverses the AST of a given tree to find the parent node of a specified node. It iterates through all nodes in the tree and checks their child nodes to identify the parent. If the node is a root node or not found, it returns None.",
              "parameters": [
                {
                  "name": "self",
                  "type": "ProjectAnalyzer",
                  "description": "The instance of the ProjectAnalyzer class."
                },
                {
                  "name": "tree",
                  "type": "ast.AST",
                  "description": "The root of the Abstract Syntax Tree to search within."
                },
                {
                  "name": "node",
                  "type": "ast.AST",
                  "description": "The AST node for which to find the parent."
                }
              ],
              "returns": [
                {
                  "name": "parent",
                  "type": "ast.AST | None",
                  "description": "The parent AST node of the given node, or None if the node is the root or not found."
                }
              ],
              "usage_context": {
                "calls": "This method uses `ast.walk` to traverse the AST and `ast.iter_child_nodes` to iterate through children.",
                "called_by": "This method is called internally by `_collect_definitions` to determine the context (e.g., class or module level) of a function definition."
              }
            },
            "error": null
          },
          {
            "identifier": "_resolve_calls",
            "description": {
              "overall": "Analyzes a given Python file's AST to identify function and method calls. It uses a `CallResolverVisitor` to traverse the AST and record calls. The identified calls, along with caller information, are then added to the class's main `self.call_graph`. Errors during call resolution are logged.",
              "parameters": [
                {
                  "name": "self",
                  "type": "ProjectAnalyzer",
                  "description": "The instance of the ProjectAnalyzer class."
                },
                {
                  "name": "filepath",
                  "type": "str",
                  "description": "The path to the Python file whose calls need to be resolved."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method instantiates and uses `CallResolverVisitor` to perform the call resolution. It also accesses `self.file_asts` to retrieve the AST for the given filepath.",
                "called_by": "This method is called by the `analyze` method for each Python file after definitions have been collected."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "This class depends on external modules such as `ast` for parsing Python code, `os` for file system operations, `logging` for error reporting, `collections.defaultdict` for data structures, and specific components like `CallResolverVisitor` and `path_to_module` from its own package.",
          "instantiated_by": "The `ProjectAnalyzer` class is not shown to be instantiated within the provided source code. Its instantiation points are not specified."
        }
      },
      "error": null
    },
    "backend.relationship_analyzer.CallResolverVisitor": {
      "identifier": "backend.relationship_analyzer.CallResolverVisitor",
      "description": {
        "overall": "The CallResolverVisitor is an abstract syntax tree (AST) visitor designed to traverse Python code and identify function and method calls. It maintains scope information, tracks class definitions, and resolves qualified names (QNames) of called functions and methods. The visitor populates a dictionary mapping called QNames to a list of call sites, including file, line number, caller name, and caller type.",
        "init_method": {
          "description": "Initializes the CallResolverVisitor with essential context for analyzing Python code. It stores the file path, derives the module path, and holds a reference to the project's definitions. It also sets up internal state for tracking scope, instance types, current caller information, and a defaultdict to store identified calls.",
          "parameters": [
            {
              "name": "filepath",
              "type": "string",
              "description": "The absolute path to the Python file being analyzed."
            },
            {
              "name": "project_root",
              "type": "string",
              "description": "The root directory of the project, used to determine the module path."
            },
            {
              "name": "definitions",
              "type": "dict",
              "description": "A dictionary containing known definitions within the project, used to validate resolved call QNames."
            }
          ]
        },
        "methods": [
          {
            "identifier": "visit_ClassDef",
            "description": {
              "overall": "Visits an AST node representing a class definition. It updates the current class name context before recursively visiting the nodes within the class body and then restores the previous class name context upon exiting the class definition.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.ClassDef",
                  "description": "The AST node representing the class definition."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls the generic_visit method to continue the AST traversal.",
                "called_by": "This method is called by the AST traversal mechanism when a class definition node is encountered."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_FunctionDef",
            "description": {
              "overall": "Visits an AST node representing a function or method definition. It determines the fully qualified name of the function/method based on whether it's defined within a class or at the module level, updates the current caller name context, and then recursively visits the nodes within the function body before restoring the previous caller name context.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.FunctionDef",
                  "description": "The AST node representing the function or method definition."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls the generic_visit method to continue the AST traversal.",
                "called_by": "This method is called by the AST traversal mechanism when a function definition node is encountered."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_Call",
            "description": {
              "overall": "Visits an AST node representing a function or method call. It resolves the qualified name of the called function/method using the `_resolve_call_qname` helper. If the resolved name exists in the project's definitions, it records the call site information (file, line, caller, caller type) in the `calls` dictionary. It then continues the AST traversal.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.Call",
                  "description": "The AST node representing the function or method call."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls the _resolve_call_qname method to determine the called function's qualified name and the generic_visit method to continue the AST traversal.",
                "called_by": "This method is called by the AST traversal mechanism when a call node is encountered."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_Import",
            "description": {
              "overall": "Visits an AST node representing a standard import statement (e.g., `import module` or `import module as alias`). It updates the current scope dictionary with the imported module names and their corresponding aliases or original names. It then continues the AST traversal.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.Import",
                  "description": "The AST node representing the import statement."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls the generic_visit method to continue the AST traversal.",
                "called_by": "This method is called by the AST traversal mechanism when an import node is encountered."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_ImportFrom",
            "description": {
              "overall": "Visits an AST node representing a from-import statement (e.g., `from module import name` or `from module import name as alias`). It calculates the full module path, considering relative imports, and updates the scope dictionary with the imported names and their qualified paths. It then continues the AST traversal.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.ImportFrom",
                  "description": "The AST node representing the from-import statement."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls the generic_visit method to continue the AST traversal.",
                "called_by": "This method is called by the AST traversal mechanism when a from-import node is encountered."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_Assign",
            "description": {
              "overall": "Visits an AST node representing an assignment statement. If the assignment involves a function call to a known class constructor, it records the type of the instantiated object in the `instance_types` dictionary, mapping the variable name to the qualified class name. It then continues the AST traversal.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.Assign",
                  "description": "The AST node representing the assignment statement."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls the generic_visit method to continue the AST traversal.",
                "called_by": "This method is called by the AST traversal mechanism when an assignment node is encountered."
              }
            },
            "error": null
          },
          {
            "identifier": "_resolve_call_qname",
            "description": {
              "overall": "A helper method to resolve the qualified name (QName) of a function or method call from its AST node. It handles direct name lookups in the scope and attribute access on variables whose types are known or are imported modules. It returns the resolved QName or None if resolution fails.",
              "parameters": [
                {
                  "name": "func_node",
                  "type": "ast.expr",
                  "description": "The AST node representing the function or method being called (e.g., ast.Name or ast.Attribute)."
                }
              ],
              "returns": [
                {
                  "name": "callee_pathname",
                  "type": "string | None",
                  "description": "The resolved qualified name of the called function/method, or None if it cannot be resolved."
                }
              ],
              "usage_context": {
                "calls": "This method checks for the presence of names in the scope and instance_types dictionaries, and constructs strings representing qualified names.",
                "called_by": "This method is called by the visit_Call method to resolve the QName of the function being invoked."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "This class depends on the `path_to_module` function from the `backend.relationship_analyzer` module and standard Python libraries like `ast` and `os`.",
          "instantiated_by": "This class is intended to be instantiated and used as part of a larger code analysis or documentation generation system, likely by a component that orchestrates AST traversal."
        }
      },
      "error": null
    },
    "schemas.types.ParameterDescription": {
      "identifier": "schemas.types.ParameterDescription",
      "description": {
        "overall": "The ParameterDescription class is a Pydantic model used to represent the details of a single function parameter. It captures the parameter's name, its data type, and a textual description of its purpose.",
        "init_method": {
          "description": "Initializes a ParameterDescription instance with the name, type, and description of a function parameter. These are Pydantic model fields, so they are automatically handled upon instantiation.",
          "parameters": [
            {
              "name": "name",
              "type": "str",
              "description": "The name of the parameter."
            },
            {
              "name": "type",
              "type": "str",
              "description": "The data type of the parameter."
            },
            {
              "name": "description",
              "type": "str",
              "description": "A textual description of the parameter's purpose."
            }
          ]
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class depends on Pydantic's BaseModel for its structure and validation.",
          "instantiated_by": "This class is likely instantiated within systems that need to describe function or method signatures, such as documentation generators or code analysis tools."
        }
      },
      "error": null
    },
    "schemas.types.ReturnDescription": {
      "identifier": "schemas.types.ReturnDescription",
      "description": {
        "overall": "The ReturnDescription class is a Pydantic BaseModel used to define the structure for describing the return value of a function. It captures the name, type, and a textual description of the return value.",
        "init_method": {
          "description": "Initializes a ReturnDescription object with the name, type, and description of a function's return value. These are defined as class attributes.",
          "parameters": [
            {
              "name": "name",
              "type": "str",
              "description": "The name of the return value, if applicable."
            },
            {
              "name": "type",
              "type": "str",
              "description": "The data type of the return value."
            },
            {
              "name": "description",
              "type": "str",
              "description": "A textual explanation of the return value."
            }
          ]
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class does not have any external dependencies beyond Pydantic's BaseModel.",
          "instantiated_by": "This class is intended to be instantiated wherever a structured description of a function's return value is needed, likely within a larger documentation or code analysis system."
        }
      },
      "error": null
    },
    "schemas.types.UsageContext": {
      "identifier": "schemas.types.UsageContext",
      "description": {
        "overall": "The UsageContext class is a Pydantic model designed to describe the calling context of a function. It encapsulates information about what functions or methods a particular function calls and which functions or methods call it. This is useful for documenting and analyzing code dependencies and call graphs.",
        "init_method": {
          "description": "Initializes the UsageContext model with information about the functions called by and the functions that call the current function. It takes two string arguments, 'calls' and 'called_by', to define these relationships.",
          "parameters": [
            {
              "name": "calls",
              "type": "str",
              "description": "A string describing the functions or methods that this function calls."
            },
            {
              "name": "called_by",
              "type": "str",
              "description": "A string describing the functions or methods that call this function."
            }
          ]
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class depends on the BaseModel from the pydantic library for its structure and validation.",
          "instantiated_by": "This class is intended to be instantiated within Pydantic models or data structures that require a description of a function's calling context."
        }
      },
      "error": null
    },
    "schemas.types.FunctionDescription": {
      "identifier": "schemas.types.FunctionDescription",
      "description": {
        "overall": "The FunctionDescription class is a Pydantic model designed to encapsulate a comprehensive analysis of a function. It details the function's overall purpose, its parameters, its return values, and its usage context within a larger system. This class serves as a structured data format for representing function-related metadata.",
        "init_method": {
          "description": "Initializes a FunctionDescription object. As this is a Pydantic model, initialization is handled by Pydantic's base model, which validates and assigns the provided attributes: overall description, a list of parameter descriptions, a list of return value descriptions, and usage context information.",
          "parameters": []
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class depends on other Pydantic models like BaseModel, ParameterDescription, ReturnDescription, and UsageContext to define its structure and data validation. It does not have external runtime dependencies beyond Pydantic.",
          "instantiated_by": "This class is intended to be instantiated by systems that perform code analysis or documentation generation, where a structured representation of function details is required."
        }
      },
      "error": null
    },
    "schemas.types.FunctionAnalysis": {
      "identifier": "schemas.types.FunctionAnalysis",
      "description": {
        "overall": "The FunctionAnalysis class is a Pydantic model designed to represent the structured analysis of a single function or method. It encapsulates the function's identifier, a detailed description object, and an optional error field for reporting analysis issues. This model serves as a key component in a larger documentation generation system, providing a standardized format for function-level insights.",
        "init_method": {
          "description": "Initializes a FunctionAnalysis object. It takes the function's identifier, a FunctionDescription object, and an optional error string as arguments. The identifier is a required string representing the function's name, and the description is a required FunctionDescription object containing the detailed analysis. An optional error string can be provided if there were issues during the analysis.",
          "parameters": [
            {
              "name": "identifier",
              "type": "str",
              "description": "The name of the function or method being analyzed."
            },
            {
              "name": "description",
              "type": "FunctionDescription",
              "description": "A FunctionDescription object containing the detailed analysis of the function, including its overall purpose, parameters, return values, and usage context."
            },
            {
              "name": "error",
              "type": "Optional[str]",
              "description": "An optional string that provides details if an error occurred during the analysis of the function. Defaults to None if no error occurred."
            }
          ]
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class relies on the pydantic.BaseModel for its structure and validation, and typing.Optional for handling potentially null error values. It also implicitly depends on a 'FunctionDescription' type, which is not detailed here but is expected to contain the core analysis details of a function.",
          "instantiated_by": "This class is likely instantiated by a higher-level analysis process that breaks down code into individual functions or methods for detailed examination. It serves as a building block within a larger system that aggregates these analyses."
        }
      },
      "error": null
    },
    "schemas.types.ConstructorDescription": {
      "identifier": "schemas.types.ConstructorDescription",
      "description": {
        "overall": "The ConstructorDescription class is a Pydantic model used to represent the initialization method of a Python class. It captures a textual description of the constructor and a list of its parameters, each detailed in a ParameterDescription object.",
        "init_method": {
          "description": "Initializes a ConstructorDescription object. It takes a string description and a list of ParameterDescription objects as arguments.",
          "parameters": [
            {
              "name": "description",
              "type": "str",
              "description": "A textual summary of the constructor's purpose and behavior."
            },
            {
              "name": "parameters",
              "type": "List[ParameterDescription]",
              "description": "A list containing detailed descriptions of each parameter accepted by the constructor."
            }
          ]
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class has no external dependencies beyond Pydantic's BaseModel.",
          "instantiated_by": "This class is intended to be instantiated by systems that analyze Python class structures and need to represent constructor details in a structured format."
        }
      },
      "error": null
    },
    "schemas.types.ClassContext": {
      "identifier": "schemas.types.ClassContext",
      "description": {
        "overall": "The ClassContext class is a Pydantic model designed to describe a class's external dependencies and its primary points of instantiation. It serves as a structured way to document where a class relies on other components and where instances of that class are created within a system.",
        "init_method": {
          "description": "Initializes the ClassContext model with details about the class's dependencies and instantiation points. It directly assigns the provided values to the corresponding attributes.",
          "parameters": [
            {
              "name": "dependencies",
              "type": "str",
              "description": "A string describing the external dependencies of the class."
            },
            {
              "name": "instantiated_by",
              "type": "str",
              "description": "A string describing where the class is instantiated within the system."
            }
          ]
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class does not explicitly list external dependencies in its context.",
          "instantiated_by": "This class does not explicitly list where it is instantiated in its context."
        }
      },
      "error": null
    },
    "schemas.types.ClassDescription": {
      "identifier": "schemas.types.ClassDescription",
      "description": {
        "overall": "The ClassDescription class serves as a comprehensive data structure for holding the detailed analysis of a Python class. It encapsulates information about the class's overall purpose, its initialization method, a list of its constituent methods, and its usage context within a larger system.",
        "init_method": {
          "description": "The __init__ method for ClassDescription initializes a new instance of the class. It takes four arguments: overall, init_method, methods, and usage_context, which are directly assigned to the corresponding attributes of the instance. These arguments represent the core components of the class analysis.",
          "parameters": [
            {
              "name": "overall",
              "type": "str",
              "description": "A string providing an overall summary of the class's purpose and responsibilities."
            },
            {
              "name": "init_method",
              "type": "ConstructorDescription",
              "description": "An object detailing the constructor's functionality, including its description and parameters."
            },
            {
              "name": "methods",
              "type": "List[FunctionAnalysis]",
              "description": "A list of FunctionAnalysis objects, each detailing a method within the class."
            },
            {
              "name": "usage_context",
              "type": "ClassContext",
              "description": "An object describing the class's dependencies and where it is instantiated."
            }
          ]
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class does not appear to have any external dependencies explicitly listed.",
          "instantiated_by": "There is no information provided about where this class is instantiated."
        }
      },
      "error": null
    },
    "schemas.types.ClassAnalysis": {
      "identifier": "schemas.types.ClassAnalysis",
      "description": {
        "overall": "The ClassAnalysis model represents the top-level structure for analyzing a Python class. It encapsulates the class's identifier, a detailed description of its components (constructor, methods, overall purpose), and any potential errors encountered during analysis. It also includes usage context such as dependencies and instantiation points.",
        "init_method": {
          "description": "Initializes a ClassAnalysis object. It takes the class identifier, a ClassDescription object, and an optional error string as input. The error field defaults to None, indicating no error during analysis.",
          "parameters": [
            {
              "name": "identifier",
              "type": "str",
              "description": "The name of the class being analyzed."
            },
            {
              "name": "description",
              "type": "ClassDescription",
              "description": "A detailed description of the class, including its methods and overall purpose."
            },
            {
              "name": "error",
              "type": "Optional[str]",
              "description": "An optional string representing any error encountered during the analysis of the class. Defaults to None."
            }
          ]
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class relies on Pydantic's BaseModel for its structure and typing. It also utilizes Optional from the typing module.",
          "instantiated_by": "This class is likely instantiated by a system that performs code analysis and requires a structured representation of the analyzed class."
        }
      },
      "error": null
    },
    "schemas.types.CallInfo": {
      "identifier": "schemas.types.CallInfo",
      "description": {
        "overall": "The CallInfo class is a Pydantic BaseModel used to represent detailed information about a specific call event within a system. It is designed to capture the source file, the calling function or method, the mode of the call (e.g., 'method', 'function', 'module'), and the line number where the call occurred. This structure is particularly useful for logging and analyzing relationships between different parts of the codebase, such as tracking which functions call a particular piece of code or where a class instance is created.",
        "init_method": {
          "description": "Initializes a CallInfo object with details about a specific call event. It takes the file path, function name, call mode, and line number as arguments and assigns them to corresponding instance attributes. This constructor is essential for creating structured records of code execution flow.",
          "parameters": [
            {
              "name": "file",
              "type": "str",
              "description": "The path to the file where the call originated."
            },
            {
              "name": "function",
              "type": "str",
              "description": "The name of the function or method that made the call."
            },
            {
              "name": "mode",
              "type": "str",
              "description": "The type of call, such as 'method', 'function', or 'module'."
            },
            {
              "name": "line",
              "type": "int",
              "description": "The line number in the source file where the call occurred."
            }
          ]
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class depends on pydantic.BaseModel for its structure and validation.",
          "instantiated_by": "This class is intended to be instantiated by systems that analyze code relationships, such as 'called_by' and 'instantiated_by' lists within other data structures."
        }
      },
      "error": null
    },
    "schemas.types.FunctionContextInput": {
      "identifier": "schemas.types.FunctionContextInput",
      "description": {
        "overall": "The FunctionContextInput class is a Pydantic model designed to structure the context for analyzing a function. It specifically captures information about the functions or methods that the target function calls and the functions or methods that call the target function.",
        "init_method": {
          "description": "Initializes the FunctionContextInput model with lists of calls and called_by information. This constructor is part of the Pydantic BaseModel and handles the validation and storage of the provided data.",
          "parameters": [
            {
              "name": "calls",
              "type": "List[str]",
              "description": "A list of strings, where each string represents a function or method called by the target function."
            },
            {
              "name": "called_by",
              "type": "List[CallInfo]",
              "description": "A list of CallInfo objects, where each object details a function or method that calls the target function."
            }
          ]
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class depends on Pydantic's BaseModel for its structure and validation. It also utilizes typing.List for type hinting.",
          "instantiated_by": "This class is intended to be instantiated by systems or processes that need to provide structured context for function analysis, likely within a larger documentation generation or code analysis pipeline."
        }
      },
      "error": null
    },
    "schemas.types.FunctionAnalysisInput": {
      "identifier": "schemas.types.FunctionAnalysisInput",
      "description": {
        "overall": "The FunctionAnalysisInput class is a Pydantic model designed to encapsulate all necessary information for analyzing a Python function. It specifies the analysis mode, the function's identifier and source code, a list of relevant import statements, and a nested context object containing further details about the function's environment and relationships.",
        "init_method": {
          "description": "Initializes a FunctionAnalysisInput object, setting up the required fields for function analysis. It takes the analysis mode, function identifier, source code, import statements, and a function context as input.",
          "parameters": [
            {
              "name": "mode",
              "type": "Literal[\"function_analysis\"]",
              "description": "Specifies the type of analysis to be performed, which must be 'function_analysis' for this input model."
            },
            {
              "name": "identifier",
              "type": "str",
              "description": "The unique name or identifier of the function being analyzed."
            },
            {
              "name": "source_code",
              "type": "str",
              "description": "The raw source code of the function to be analyzed."
            },
            {
              "name": "imports",
              "type": "List[str]",
              "description": "A list of import statements relevant to the source code of the function."
            },
            {
              "name": "context",
              "type": "FunctionContextInput",
              "description": "A nested object containing contextual information about the function, such as its dependencies and call relationships."
            }
          ]
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class does not appear to have external functional dependencies beyond its Pydantic base class and typing modules.",
          "instantiated_by": "This class is intended to be instantiated by systems that require structured input for function analysis, likely as part of a larger documentation or code analysis pipeline."
        }
      },
      "error": null
    },
    "schemas.types.MethodContextInput": {
      "identifier": "schemas.types.MethodContextInput",
      "description": {
        "overall": "The MethodContextInput class is a Pydantic model designed to structure contextual information about a class's methods. It captures details such as the method's identifier, lists of functions or methods it calls and is called by, its arguments, and an optional docstring. This class serves as a data container for method-specific metadata within a larger system, likely for documentation generation or code analysis.",
        "init_method": {
          "description": "Initializes a MethodContextInput object, which is a Pydantic BaseModel. It takes several arguments to define the context of a method, including its identifier, lists of calls and callers, arguments, and an optional docstring. All fields are validated by Pydantic.",
          "parameters": [
            {
              "name": "identifier",
              "type": "str",
              "description": "The unique name or identifier of the method."
            },
            {
              "name": "calls",
              "type": "List[str]",
              "description": "A list of strings representing other methods, classes, or functions that this method calls."
            },
            {
              "name": "called_by",
              "type": "List[CallInfo]",
              "description": "A list of CallInfo objects indicating which methods or functions call this method."
            },
            {
              "name": "args",
              "type": "List[str]",
              "description": "A list of strings representing the arguments accepted by the method."
            },
            {
              "name": "docstring",
              "type": "Optional[str]",
              "description": "An optional string containing the docstring of the method."
            }
          ]
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class depends on Pydantic's BaseModel for data validation and typing. It also utilizes List and Optional from the typing module. The 'CallInfo' type is expected to be defined elsewhere.",
          "instantiated_by": "This class is intended to be instantiated wherever structured method context information needs to be represented, likely within a code analysis or documentation generation framework."
        }
      },
      "error": null
    },
    "schemas.types.ClassContextInput": {
      "identifier": "schemas.types.ClassContextInput",
      "description": {
        "overall": "The ClassContextInput class is a Pydantic model designed to structure contextual information for analyzing a Python class. It holds lists of dependencies, instantiation call information, and method-specific contexts, providing a comprehensive data structure for class analysis.",
        "init_method": {
          "description": "Initializes the ClassContextInput model with lists of dependencies, instantiation call information, and method contexts. This constructor sets up the data structure for holding detailed context about a class.",
          "parameters": [
            {
              "name": "dependencies",
              "type": "List[str]",
              "description": "A list of strings representing external dependencies required by the class."
            },
            {
              "name": "instantiated_by",
              "type": "List[CallInfo]",
              "description": "A list of CallInfo objects detailing where and how this class is instantiated."
            },
            {
              "name": "method_context",
              "type": "List[MethodContextInput]",
              "description": "A list of MethodContextInput objects, each providing context for a specific method within the class."
            }
          ]
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class does not appear to have any external dependencies beyond Pydantic's BaseModel.",
          "instantiated_by": "The context provided does not specify where this class is instantiated."
        }
      },
      "error": null
    },
    "schemas.types.ClassAnalysisInput": {
      "identifier": "schemas.types.ClassAnalysisInput",
      "description": {
        "overall": "The ClassAnalysisInput class is a Pydantic model designed to structure the input required for a class analysis process. It defines the necessary fields for providing source code, identifier, import statements, and contextual information for analyzing a Python class.",
        "init_method": {
          "description": "Initializes the ClassAnalysisInput model with all the required fields for class analysis. This includes the mode, the identifier of the class to be analyzed, its source code, a list of import statements, and a ClassContextInput object containing further contextual details.",
          "parameters": [
            {
              "name": "mode",
              "type": "Literal[\"class_analysis\"]",
              "description": "Specifies the analysis mode, which must be 'class_analysis' for this input type."
            },
            {
              "name": "identifier",
              "type": "str",
              "description": "The name or identifier of the Python class that is the subject of the analysis."
            },
            {
              "name": "source_code",
              "type": "str",
              "description": "The raw source code of the Python class definition."
            },
            {
              "name": "imports",
              "type": "List[str]",
              "description": "A list of import statements relevant to the source code file."
            },
            {
              "name": "context",
              "type": "ClassContextInput",
              "description": "An object containing additional contextual information for the analysis, such as dependencies and instantiation points."
            }
          ]
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class does not specify any external functional dependencies within its definition. It relies on Pydantic for its structure and validation.",
          "instantiated_by": "This class is intended to be instantiated by systems or processes that require structured input for performing a 'class_analysis' operation. Specific instantiating code is not provided in the context."
        }
      },
      "error": null
    }
  }
}