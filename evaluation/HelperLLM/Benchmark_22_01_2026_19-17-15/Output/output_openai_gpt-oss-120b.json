{
  "functions": {
    "backend.AST_Schema.path_to_module": {
      "identifier": "backend.AST_Schema.path_to_module",
      "description": {
        "overall": "The function converts a filesystem file path into a dotted Python module path relative to a given project root. It first attempts to compute the relative path using `os.path.relpath`; if that fails, it falls back to the file's basename. The `.py` extension is stripped, path separators are replaced with dots, and a trailing `.__init__` segment is removed to yield the module name. The resulting module path string is returned.",
        "parameters": [
          {
            "name": "filepath",
            "type": "str",
            "description": "The absolute or relative path to the file that should be converted."
          },
          {
            "name": "project_root",
            "type": "str",
            "description": "The root directory of the project against which the relative path is calculated."
          }
        ],
        "returns": [
          {
            "name": "",
            "type": "str",
            "description": "A dotted module path corresponding to the given file, without the `.py` extension and without a trailing `.__init__`."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "backend.File_Dependency.build_file_dependency_graph": {
      "identifier": "backend.File_Dependency.build_file_dependency_graph",
      "description": {
        "overall": "The function build_file_dependency_graph constructs a directed dependency graph for a given Python file. It receives the file name, its parsed abstract syntax tree (AST), and the repository root path. Using a FileDependencyGraph visitor, it traverses the AST to collect import relationships and adds corresponding nodes and edges to a NetworkX DiGraph. Finally, it returns the populated graph representing which modules import which others.",
        "parameters": [
          {
            "name": "filename",
            "type": "str",
            "description": "The name of the file for which the dependency graph is being built."
          },
          {
            "name": "tree",
            "type": "AST",
            "description": "The abstract syntax tree (AST) representation of the file's source code."
          },
          {
            "name": "repo_root",
            "type": "str",
            "description": "The root directory of the repository containing the file."
          }
        ],
        "returns": [
          {
            "name": "",
            "type": "nx.DiGraph",
            "description": "A directed graph where nodes represent files/modules and edges represent import dependencies."
          }
        ],
        "usage_context": {
          "calls": "This function calls backend.File_Dependency.FileDependencyGraph.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "backend.File_Dependency.build_repository_graph": {
      "identifier": "backend.File_Dependency.build_repository_graph",
      "description": {
        "overall": "The function constructs a global dependency graph for a Git repository containing Python source files. It obtains all files from the repository, filters to those ending with the .py extension, and derives a module name from each file path. For each Python file it parses the source code into an AST and delegates to `build_file_dependency_graph` to create a per\u2011file dependency graph. Nodes and edges from each per\u2011file graph are merged into a single directed NetworkX graph, which is then returned.",
        "parameters": [
          {
            "name": "repository",
            "type": "GitRepository",
            "description": "A GitRepository instance providing access to the repository's files via `get_all_files()` and its temporary directory via `temp_dir`."
          }
        ],
        "returns": [
          {
            "name": "global_graph",
            "type": "nx.DiGraph",
            "description": "A directed graph (NetworkX DiGraph) containing nodes representing symbols and edges representing dependency relationships across all Python files in the repository."
          }
        ],
        "usage_context": {
          "calls": "This function calls backend.File_Dependency.build_file_dependency_graph.",
          "called_by": "This function is not called by any other functions in the provided context."
        }
      },
      "error": null
    },
    "backend.File_Dependency.get_all_temp_files": {
      "identifier": "backend.File_Dependency.get_all_temp_files",
      "description": {
        "overall": "The function `get_all_temp_files` collects all Python source files within a given directory tree. It first resolves the provided directory string to an absolute `Path` object. Using `Path.rglob` it recursively searches for files matching the pattern `*.py`. For each discovered file it computes a path relative to the root directory and aggregates these relative paths into a list, which is then returned.",
        "parameters": [
          {
            "name": "directory",
            "type": "str",
            "description": "The directory path to search for Python files."
          }
        ],
        "returns": [
          {
            "name": "",
            "type": "list[Path]",
            "description": "A list of `Path` objects representing the relative paths of all discovered `.py` files."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "No other functions are recorded as calling this function."
        }
      },
      "error": null
    },
    "backend.HelperLLM.main_orchestrator": {
      "identifier": "backend.HelperLLM.main_orchestrator",
      "description": {
        "overall": "The `main_orchestrator` function acts as a test harness that builds example inputs for function analysis and assembles them for documentation generation. It creates `FunctionAnalysisInput` objects for three sample methods, validates them, and also constructs a `ClassAnalysisInput` that includes pre\u2011computed method analyses. After preparing these objects, it instantiates an `LLMHelper` to generate documentation for the functions, aggregates the results, and prints the final JSON output. The implementation relies on logging, JSON handling, and the provided system prompts to drive the LLM processing.",
        "parameters": [],
        "returns": [],
        "usage_context": {
          "calls": "backend.HelperLLM.LLMHelper, schemas.types.ClassAnalysisInput, and schemas.types.ClassContextInput",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "backend.callgraph.make_safe_dot": {
      "identifier": "backend.callgraph.make_safe_dot",
      "description": {
        "overall": "The function `make_safe_dot` generates a DOT\u2011compatible version of a NetworkX directed graph. It first creates a copy of the supplied graph and then builds a mapping from each original node to a deterministic safe identifier of the form `n{i}`. The graph is relabeled using this mapping, and the original node names are stored as a `label` attribute on the new nodes. Finally, the transformed graph is written to the given file path using NetworkX's pydot writer, ensuring that the resulting DOT file contains only safe node identifiers.",
        "parameters": [
          {
            "name": "graph",
            "type": "nx.DiGraph",
            "description": "The directed graph to be converted into a safe DOT representation."
          },
          {
            "name": "out_path",
            "type": "str",
            "description": "Filesystem path where the DOT file will be written."
          }
        ],
        "returns": [],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "backend.callgraph.build_filtered_callgraph": {
      "identifier": "backend.callgraph.build_filtered_callgraph",
      "description": {
        "overall": "The function `build_filtered_callgraph` constructs a call graph for a given Git repository and filters it to include only functions defined within the repository itself. It retrieves all files from the repository, parses each Python file into an abstract syntax tree, and uses a `CallGraph` visitor to collect the set of functions defined in the project. Afterwards it iterates over the collected ASTs again, adding edges to a NetworkX directed graph only when both the caller and callee belong to the previously identified own functions. The resulting `nx.DiGraph` contains nodes for each internal function and directed edges representing calls between them, and is returned to the caller.",
        "parameters": [
          {
            "name": "repo",
            "type": "GitRepository",
            "description": "A repository object providing access to the project's files via `get_all_files()`."
          }
        ],
        "returns": [
          {
            "name": "global_graph",
            "type": "nx.DiGraph",
            "description": "A directed graph where nodes are functions defined in the repository and edges represent calls between those functions."
          }
        ],
        "usage_context": {
          "calls": "This function calls backend.callgraph.CallGraph.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "backend.converter.wrap_cdata": {
      "identifier": "backend.converter.wrap_cdata",
      "description": {
        "overall": "The function `wrap_cdata` takes a piece of text and encloses it within CDATA markup. It constructs a string that begins with the opening CDATA tag, adds a newline, inserts the provided content, adds another newline, and closes with the CDATA end tag. The implementation uses an f\u2011string to interpolate the content directly into the CDATA template. The resulting string is returned to the caller.",
        "parameters": [
          {
            "name": "content",
            "type": "str",
            "description": "The raw text that should be wrapped inside CDATA tags."
          }
        ],
        "returns": [
          {
            "name": "",
            "type": "str",
            "description": "A string containing the original content surrounded by CDATA opening and closing tags, each on its own line."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "backend.converter.extract_output_content": {
      "identifier": "backend.converter.extract_output_content",
      "description": {
        "overall": "The function iterates over a collection of notebook output objects and extracts textual content or image placeholders. For each output, it checks the output type and, when appropriate, extracts plain text, stream text, or error messages. If the output contains image data (PNG or JPEG), it decodes the Base64 string, appends a dictionary describing the image to the provided image list, and inserts an XML placeholder referencing the image index. All extracted snippets are accumulated in a list, which is returned at the end of the function.",
        "parameters": [
          {
            "name": "outputs",
            "type": "Any",
            "description": "An iterable of output objects (e.g., nbformat cells) that may contain text, streams, errors, or image data."
          },
          {
            "name": "image_list",
            "type": "list",
            "description": "A mutable list that will be extended with dictionaries describing each extracted image (mime_type and Base64 data)."
          }
        ],
        "returns": [
          {
            "name": "extracted_xml_snippets",
            "type": "list[str]",
            "description": "A list containing extracted plain\u2011text strings, error messages, stream text, or XML placeholders for images."
          }
        ],
        "usage_context": {
          "calls": "This function calls backend.converter.process_image.",
          "called_by": "No functions are listed as callers of this function."
        }
      },
      "error": null
    },
    "backend.converter.process_image": {
      "identifier": "backend.converter.process_image",
      "description": {
        "overall": "The function `process_image` receives a MIME type string. It checks a global dictionary `data` for that MIME type. If found, it retrieves the associated base64\u2011encoded image data, removes newline characters, and appends a dictionary with the MIME type and cleaned data to a global list `image_list`, recording its index. It then returns a placeholder markup string containing the image index and MIME type; if any exception occurs during this process, it returns an error markup string with the exception message. If the MIME type is not present in `data`, the function returns `None`.",
        "parameters": [
          {
            "name": "mime_type",
            "type": "str",
            "description": "MIME type identifier for the image to be processed."
          }
        ],
        "returns": [
          {
            "name": "",
            "type": "str",
            "description": "Placeholder markup for the image when processing succeeds, or an error markup string if decoding fails."
          },
          {
            "name": "",
            "type": "None",
            "description": "Returned when the provided MIME type is not present in the data dictionary."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "backend.converter.convert_notebook_to_xml": {
      "identifier": "backend.converter.convert_notebook_to_xml",
      "description": {
        "overall": "The function `convert_notebook_to_xml` transforms a Jupyter notebook represented as a JSON string into an XML representation. It first attempts to parse the input using `nbformat.reads`; if parsing fails, it returns an error XML snippet and an empty image list. For each cell in the notebook, markdown cells are wrapped in a `<CELL type=\"markdown\">` element, while code cells are wrapped in a `<CELL type=\"code\">` element with their source wrapped in CDATA. If a code cell contains outputs, the outputs are extracted, concatenated, wrapped in CDATA, and added as a `<CELL type=\"output\">` element. Finally, the function returns the concatenated XML string together with a list of any images extracted from the notebook.",
        "parameters": [
          {
            "name": "file_content",
            "type": "str",
            "description": "The raw notebook file content as a JSON-formatted string."
          }
        ],
        "returns": [
          {
            "name": "xml_string",
            "type": "str",
            "description": "A string containing the XML representation of the notebook."
          },
          {
            "name": "extracted_images",
            "type": "list",
            "description": "A list of image data extracted from the notebook's output cells."
          }
        ],
        "usage_context": {
          "calls": "This function calls backend.converter.extract_output_content and backend.converter.wrap_cdata.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "backend.converter.process_repo_notebooks": {
      "identifier": "backend.converter.process_repo_notebooks",
      "description": {
        "overall": "The function iterates over a collection of repository files and selects those that are Jupyter notebooks (files ending with .ipynb). It logs the number of notebooks found and then processes each notebook individually. For each notebook, it converts the notebook content to an XML representation and extracts any embedded images by calling `backend.converter.convert_notebook_to_xml`. The conversion results are stored in a dictionary keyed by the notebook's file path and finally returned.",
        "parameters": [
          {
            "name": "repo_files",
            "type": "Iterable",
            "description": "A collection of file objects from the repository; each object is expected to have a `path` attribute (the file's path) and a `content` attribute containing the file's data."
          }
        ],
        "returns": [
          {
            "name": "results",
            "type": "dict",
            "description": "A dictionary mapping each notebook file path to a sub\u2011dictionary with keys `xml` (the XML string produced from the notebook) and `images` (a list of extracted image data)."
          }
        ],
        "usage_context": {
          "calls": "This function calls backend.converter.convert_notebook_to_xml.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "backend.main.create_savings_chart": {
      "identifier": "backend.main.create_savings_chart",
      "description": {
        "overall": "The function creates a bar chart that compares two token counts, one for JSON and one for TOON. It uses Matplotlib to plot the values with distinct colors, adds a title that includes the savings percentage, and labels the y\u2011axis. Each bar is annotated with its exact token count for clarity. Finally, the chart is saved to the specified output path and the figure is closed to free resources.",
        "parameters": [
          {
            "name": "json_tokens",
            "type": "int",
            "description": "Number of tokens counted for the JSON representation."
          },
          {
            "name": "toon_tokens",
            "type": "int",
            "description": "Number of tokens counted for the TOON representation."
          },
          {
            "name": "savings_percent",
            "type": "float",
            "description": "Percentage of token savings, displayed in the chart title."
          },
          {
            "name": "output_path",
            "type": "str",
            "description": "Filesystem path where the generated chart image will be saved."
          }
        ],
        "returns": [],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not documented as being called by any other functions."
        }
      },
      "error": null
    },
    "backend.main.calculate_net_time": {
      "identifier": "backend.main.calculate_net_time",
      "description": {
        "overall": "The function calculates the net execution time between a start and end timestamp, subtracting any artificial sleep periods that are introduced to respect rate\u2011limit constraints. It first determines the total elapsed duration. If the model name does not begin with \"gemini-\", the raw duration is returned unchanged; if there are no items to process, zero is returned. For Gemini models, it computes the number of batches required, derives the number of sleep intervals (one less than the number of batches), multiplies by a fixed 61\u2011second pause, and subtracts this from the total duration, ensuring the result is not negative.",
        "parameters": [
          {
            "name": "start_time",
            "type": "int | float",
            "description": "The timestamp marking the beginning of the operation."
          },
          {
            "name": "end_time",
            "type": "int | float",
            "description": "The timestamp marking the end of the operation."
          },
          {
            "name": "total_items",
            "type": "int",
            "description": "The total number of items that will be processed."
          },
          {
            "name": "batch_size",
            "type": "int",
            "description": "The maximum number of items that can be processed in a single batch."
          },
          {
            "name": "model_name",
            "type": "str",
            "description": "Identifier of the model; special handling is applied when it starts with \"gemini-\"."
          }
        ],
        "returns": [
          {
            "name": "net_time",
            "type": "int | float",
            "description": "The net elapsed time after subtracting estimated sleep time, never less than zero."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "backend.main.main_workflow": {
      "identifier": "backend.main.main_workflow",
      "description": {
        "overall": "The `main_workflow` function orchestrates a complete analysis pipeline for a given GitHub repository URL supplied in the user input. It extracts API keys and model names, clones the repository, gathers basic project information, builds an AST schema, enriches it with relationship data, and then uses a Helper LLM to generate documentation for functions and classes. Afterwards it prepares a combined input for a Main LLM, which produces a final markdown report and optional token\u2011savings visualisation. The function finally returns the generated report together with a collection of execution metrics.",
        "parameters": [
          {
            "name": "input",
            "type": "str",
            "description": "Raw user input string that should contain a GitHub repository URL; it is later parsed with a regular expression."
          },
          {
            "name": "api_keys",
            "type": "dict",
            "description": "Dictionary mapping service identifiers (e.g., \"gemini\", \"gpt\", \"scadsllm\") to their respective API keys."
          },
          {
            "name": "model_names",
            "type": "dict",
            "description": "Dictionary containing the names of the helper and main language models under the keys \"helper\" and \"main\"."
          },
          {
            "name": "status_callback",
            "type": "Callable[[str], None] | None",
            "description": "Optional callback function that receives status messages; if provided it is invoked for each progress update."
          }
        ],
        "returns": [
          {
            "name": "result",
            "type": "dict",
            "description": "A dictionary with two keys: \"report\" containing the final markdown report string and \"metrics\" containing timing and token\u2011usage statistics."
          }
        ],
        "usage_context": {
          "calls": "This function calls backend.AST_Schema.ASTAnalyzer, backend.AST_Schema.ASTAnalyzer.analyze_repository, backend.AST_Schema.ASTAnalyzer.merge_relationship_data, backend.HelperLLM.LLMHelper, backend.HelperLLM.LLMHelper.generate_for_classes, backend.HelperLLM.LLMHelper.generate_for_functions, backend.MainLLM.MainLLM, backend.MainLLM.MainLLM.call_llm, backend.basic_info.ProjektInfoExtractor, backend.basic_info.ProjektInfoExtractor.extrahiere_info, backend.getRepo.GitRepository, backend.main.calculate_net_time, backend.main.create_savings_chart, backend.main.update_status, backend.relationship_analyzer.ProjectAnalyzer, backend.relationship_analyzer.ProjectAnalyzer.analyze, backend.relationship_analyzer.ProjectAnalyzer.get_raw_relationships, schemas.types.ClassAnalysisInput, schemas.types.ClassContextInput, schemas.types.FunctionAnalysisInput, schemas.types.FunctionContextInput, schemas.types.MethodContextInput.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "backend.main.update_status": {
      "identifier": "backend.main.update_status",
      "description": {
        "overall": "The `update_status` function forwards a status message to a globally defined callback if one exists, and then records the message using the standard logging facility. It accepts a single argument representing the message to be processed. The function performs no further transformation on the message. Its primary purpose is to centralize status reporting and logging in one place.",
        "parameters": [
          {
            "name": "msg",
            "type": "Any",
            "description": "The status message to be sent to the callback and logged."
          }
        ],
        "returns": [],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions in the provided context."
        }
      },
      "error": null
    },
    "backend.main.notebook_workflow": {
      "identifier": "backend.main.notebook_workflow",
      "description": {
        "overall": "The `notebook_workflow` function orchestrates the analysis of Jupyter notebooks contained in a GitHub repository. It extracts a repository URL from the provided input string, clones the repository, and processes each notebook into XML and image data. For each notebook it builds a payload suitable for a Gemini\u2011style LLM, invokes the model to generate a markdown report, and aggregates all reports into a final document that is saved to disk. Finally, it returns the combined report together with timing metrics for the operation.",
        "parameters": [
          {
            "name": "input",
            "type": "str",
            "description": "A free\u2011form string that should contain a GitHub repository URL; the function extracts the URL using a regular expression."
          },
          {
            "name": "api_keys",
            "type": "dict",
            "description": "A dictionary mapping service identifiers (e.g., \"gpt\", \"gemini\", \"scadsllm\", \"ollama\") to their respective API keys and optional base URLs."
          },
          {
            "name": "model",
            "type": "str",
            "description": "The name of the LLM model to use; determines which API key and base URL are selected."
          },
          {
            "name": "status_callback",
            "type": "Callable[[str], None] | None",
            "description": "An optional callable that receives status messages; if provided it is invoked to report progress."
          }
        ],
        "returns": [
          {
            "name": "report",
            "type": "str",
            "description": "The concatenated markdown report generated from all processed notebooks."
          },
          {
            "name": "metrics",
            "type": "dict",
            "description": "A dictionary containing timing information and model identifiers for the workflow."
          }
        ],
        "usage_context": {
          "calls": "This function calls backend.MainLLM.MainLLM, backend.MainLLM.MainLLM.call_llm, backend.basic_info.ProjektInfoExtractor, backend.basic_info.ProjektInfoExtractor.extrahiere_info, backend.converter.process_repo_notebooks, backend.getRepo.GitRepository, backend.main.gemini_payload, and backend.main.update_status.",
          "called_by": "No functions call this function."
        }
      },
      "error": null
    },
    "backend.main.gemini_payload": {
      "identifier": "backend.main.gemini_payload",
      "description": {
        "overall": "The function builds a payload suitable for the Gemini API by combining textual context with embedded images. It first serialises basic information and the notebook path into a JSON string and adds it as an introductory text block. It then scans the provided XML content for image placeholders, inserting the surrounding text as separate text blocks and replacing each placeholder with an image URL entry that encodes the image data in base64. Finally, any remaining text after the last placeholder is appended and the assembled list of content blocks is returned.",
        "parameters": [
          {
            "name": "basic_info",
            "type": "dict",
            "description": "A dictionary containing basic metadata that will be included in the introductory JSON block of the payload."
          },
          {
            "name": "nb_path",
            "type": "str",
            "description": "The file system path of the current notebook, inserted into the introductory JSON block."
          },
          {
            "name": "xml_content",
            "type": "str",
            "description": "A string containing the notebook's XML representation, which may include <IMAGE_PLACEHOLDER> tags that indicate where images should be inserted."
          },
          {
            "name": "images",
            "type": "list",
            "description": "A list of dictionaries, each representing an image with a 'data' key holding a base64\u2011encoded image string."
          }
        ],
        "returns": [
          {
            "name": "payload_content",
            "type": "list",
            "description": "A list of dictionaries, each describing a content block for the Gemini API (either a text block or an image_url block)."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "No functions are documented as calling this function."
        }
      },
      "error": null
    },
    "backend.relationship_analyzer.path_to_module": {
      "identifier": "backend.relationship_analyzer.path_to_module",
      "description": {
        "overall": "The function converts a filesystem path to a dotted Python module path. It first attempts to compute a path relative to the given project root, falling back to the filename if the relative calculation fails. The function strips a trailing '.py' extension, replaces OS-specific path separators with dots, and removes a trailing '.__init__' segment to handle package initializers. Finally, it returns the resulting module path as a string.",
        "parameters": [
          {
            "name": "filepath",
            "type": "str",
            "description": "The absolute or relative path to a Python file whose module path should be derived."
          },
          {
            "name": "project_root",
            "type": "str",
            "description": "The root directory of the project used to compute a relative path."
          }
        ],
        "returns": [
          {
            "name": "module_path",
            "type": "str",
            "description": "The dotted module import path corresponding to the given file path."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not referenced by any other functions in the provided context."
        }
      },
      "error": null
    },
    "database.db.encrypt_text": {
      "identifier": "database.db.encrypt_text",
      "description": {
        "overall": "The function `encrypt_text` accepts a string and returns an encrypted version of that string. It first checks whether the input text is falsy or whether a global `cipher_suite` object is unavailable; in either case it returns the original text unchanged. If both are valid, it strips leading and trailing whitespace, encodes the text to bytes, encrypts it using the `cipher_suite.encrypt` method, decodes the encrypted bytes back to a string, and returns the result. The encryption relies on an external `cipher_suite` (presumably a `cryptography.fernet.Fernet` instance) that must be defined elsewhere in the module.",
        "parameters": [
          {
            "name": "text",
            "type": "str",
            "description": "The plaintext string that should be encrypted."
          }
        ],
        "returns": [
          {
            "name": "",
            "type": "str",
            "description": "The encrypted string if encryption succeeds, otherwise the original input text."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "No functions are listed as callers of this function."
        }
      },
      "error": null
    },
    "database.db.decrypt_text": {
      "identifier": "database.db.decrypt_text",
      "description": {
        "overall": "The function `decrypt_text` attempts to decrypt a given string using a globally defined `cipher_suite`. It first checks whether the input `text` is falsy or if `cipher_suite` is unavailable; in those cases it returns the original text unchanged. If both are present, it strips whitespace, encodes the text to bytes, and passes it to `cipher_suite.decrypt`, then decodes the resulting bytes back to a string. Any exception raised during decryption is caught and the original text is returned.",
        "parameters": [
          {
            "name": "text",
            "type": "str",
            "description": "The text string to be decrypted."
          }
        ],
        "returns": [
          {
            "name": "",
            "type": "str",
            "description": "The decrypted string if decryption succeeds; otherwise the original input text."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "No other functions are documented as calling this function."
        }
      },
      "error": null
    },
    "database.db.insert_user": {
      "identifier": "database.db.insert_user",
      "description": {
        "overall": "The `insert_user` function creates a new user document for storage in a MongoDB collection. It receives a username, a display name, and a plaintext password, then hashes the password using `stauth.Hasher.hash`. The function assembles the document with additional empty fields for various API keys and inserts it into the `dbusers` collection via `insert_one`. Finally, it returns the identifier of the newly inserted document. This process encapsulates user creation and persistence in a single callable routine.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The unique identifier for the user; used as the `_id` field in the database document."
          },
          {
            "name": "name",
            "type": "str",
            "description": "The display name of the user."
          },
          {
            "name": "password",
            "type": "str",
            "description": "The user's plaintext password, which will be hashed before storage."
          }
        ],
        "returns": [
          {
            "name": "inserted_id",
            "type": "ObjectId",
            "description": "The MongoDB identifier of the newly inserted user document."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.fetch_all_users": {
      "identifier": "database.db.fetch_all_users",
      "description": {
        "overall": "The function `fetch_all_users` retrieves every user record from the MongoDB collection `dbusers`. It invokes the `find` method on the collection to obtain a cursor over all documents, then converts that cursor into a concrete Python `list`. The resulting list is returned to the caller. No input parameters are required and no additional processing is performed on the data.",
        "parameters": [],
        "returns": [
          {
            "name": "result",
            "type": "list",
            "description": "A list containing all user documents returned by `dbusers.find()`."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions in the provided context."
        }
      },
      "error": null
    },
    "database.db.fetch_user": {
      "identifier": "database.db.fetch_user",
      "description": {
        "overall": "The function `fetch_user` is responsible for retrieving a user record from the database. It accepts a single parameter `username` of type `str`. Inside the function it calls the `find_one` method on the `dbusers` collection, searching for a document whose `_id` matches the provided username. The result of this query is returned directly to the caller.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username to look up in the user collection."
          }
        ],
        "returns": [
          {
            "name": "",
            "type": "dict or None",
            "description": "The user document retrieved from the `dbusers` collection, or `None` if no matching record exists."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "No other functions are listed as callers of this function."
        }
      },
      "error": null
    },
    "database.db.update_user_name": {
      "identifier": "database.db.update_user_name",
      "description": {
        "overall": "The function `update_user_name` updates the name field of a user record in a MongoDB collection. It locates the document by matching the `_id` field with the provided `username`. The update is performed using the `$set` operator to assign `new_name` to the `name` field. Finally, it returns the count of modified documents as reported by the operation.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The user's identifier used as the MongoDB document `_id`."
          },
          {
            "name": "new_name",
            "type": "str",
            "description": "The new name value to set in the user's document."
          }
        ],
        "returns": [
          {
            "name": "",
            "type": "int",
            "description": "The number of documents that were modified by the update operation."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.update_gemini_key": {
      "identifier": "database.db.update_gemini_key",
      "description": {
        "overall": "The function updates a user's stored Gemini API key in the database. It first removes any surrounding whitespace from the supplied key and encrypts it using the `encrypt_text` helper. The encrypted key is then written to the `dbusers` collection with an `update_one` operation that matches the document whose `_id` equals the provided username. Finally, the function returns the count of documents that were modified by the update.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The identifier of the user whose record will be updated (used as the document `_id`)."
          },
          {
            "name": "gemini_api_key",
            "type": "str",
            "description": "The raw Gemini API key that should be stored for the user."
          }
        ],
        "returns": [
          {
            "name": "modified_count",
            "type": "int",
            "description": "The number of documents that were modified by the update operation."
          }
        ],
        "usage_context": {
          "calls": "This function calls database.db.encrypt_text.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.update_gpt_key": {
      "identifier": "database.db.update_gpt_key",
      "description": {
        "overall": "The function `update_gpt_key` stores a new GPT API key for a given user in the database. It first trims whitespace from the provided key and encrypts it using `encrypt_text`. It then performs a MongoDB `update_one` operation on the users collection, matching the document by the username and setting the encrypted key in the `gpt_api_key` field. The function returns the number of documents that were modified, as reported by `result.modified_count`. This return value allows callers to determine whether the update was successful.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The identifier of the user whose GPT API key should be updated."
          },
          {
            "name": "gpt_api_key",
            "type": "str",
            "description": "The raw GPT API key to be stored; it will be stripped of surrounding whitespace and encrypted before saving."
          }
        ],
        "returns": [
          {
            "name": "modified_count",
            "type": "int",
            "description": "The number of documents that were modified by the update operation (typically 0 or 1)."
          }
        ],
        "usage_context": {
          "calls": "This function calls database.db.encrypt_text.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.update_ollama_url": {
      "identifier": "database.db.update_ollama_url",
      "description": {
        "overall": "The function `update_ollama_url` updates the `ollama_base_url` field for a specific user in the `dbusers` MongoDB collection. It receives a username and a base URL string, strips any surrounding whitespace from the URL, and performs an update operation matching the user\u2019s `_id`. The MongoDB `update_one` method is used with a `$set` operator to modify the document. Finally, the function returns the number of documents that were modified as an integer.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The identifier of the user whose record is to be updated."
          },
          {
            "name": "ollama_base_url",
            "type": "str",
            "description": "The new Ollama base URL to store, which will be stripped of leading/trailing whitespace."
          }
        ],
        "returns": [
          {
            "name": "modified_count",
            "type": "int",
            "description": "The count of documents that were modified by the update operation."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.update_opensrc_key": {
      "identifier": "database.db.update_opensrc_key",
      "description": {
        "overall": "The function updates a user's Open Source API key in the database. It first removes surrounding whitespace from the provided key and encrypts it using the encrypt_text helper. The encrypted key is then stored in the MongoDB users collection by performing an update_one operation that matches the username. Finally, the function returns the number of documents that were modified by the update. This allows callers to know whether the key was successfully updated.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The identifier of the user whose Open Source API key should be updated."
          },
          {
            "name": "opensrc_api_key",
            "type": "str",
            "description": "The raw Open Source API key to be encrypted and stored."
          }
        ],
        "returns": [
          {
            "name": "modified_count",
            "type": "int",
            "description": "The count of documents modified by the update operation (typically 0 or 1)."
          }
        ],
        "usage_context": {
          "calls": "This function calls database.db.encrypt_text.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.update_opensrc_url": {
      "identifier": "database.db.update_opensrc_url",
      "description": {
        "overall": "The function `update_opensrc_url` updates a user's record in a MongoDB collection with a new open\u2011source base URL. It receives a username and a URL string, strips any surrounding whitespace from the URL, and then performs an `update_one` operation on the `dbusers` collection, matching the document by the `_id` field equal to the provided username. The update sets the `opensrc_base_url` field to the cleaned URL. Finally, the function returns the number of documents that were modified by this operation.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The identifier of the user whose record should be updated; it is used as the `_id` filter in the MongoDB query."
          },
          {
            "name": "opensrc_base_url",
            "type": "str",
            "description": "The new open\u2011source base URL to store; leading and trailing whitespace is removed before saving."
          }
        ],
        "returns": [
          {
            "name": "modified_count",
            "type": "int",
            "description": "The count of documents that were modified by the update operation (typically 0 or 1)."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "No other functions are recorded as calling this function."
        }
      },
      "error": null
    },
    "database.db.fetch_gemini_key": {
      "identifier": "database.db.fetch_gemini_key",
      "description": {
        "overall": "The function `fetch_gemini_key` retrieves a Gemini API key for a given username from a MongoDB collection. It queries the `dbusers` collection for a document whose `_id` matches the supplied username, projecting only the `gemini_api_key` field. If a matching document is found, the function returns the stored API key; otherwise it returns `None`. No additional processing or error handling is performed beyond this lookup.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username whose Gemini API key should be retrieved."
          }
        ],
        "returns": [
          {
            "name": "gemini_api_key",
            "type": "Optional[str]",
            "description": "The Gemini API key associated with the user, or `None` if no such user or key exists."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.fetch_ollama_url": {
      "identifier": "database.db.fetch_ollama_url",
      "description": {
        "overall": "The function `fetch_ollama_url` retrieves the Ollama base URL associated with a specific user from a MongoDB collection. It accepts a single argument `username`, which is used to query the `dbusers` collection for a document whose `_id` matches the provided username. The query projects only the `ollama_base_url` field, excluding the `_id`. If a matching document exists, the function returns the value of `ollama_base_url`; otherwise it returns `None`.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The identifier of the user whose Ollama base URL should be fetched."
          }
        ],
        "returns": [
          {
            "name": "",
            "type": "Optional[str]",
            "description": "The Ollama base URL for the given user if found; otherwise `None`."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions in the provided context."
        }
      },
      "error": null
    },
    "database.db.fetch_gpt_key": {
      "identifier": "database.db.fetch_gpt_key",
      "description": {
        "overall": "The function fetch_gpt_key retrieves a stored GPT API key for a given username from a MongoDB collection. It queries the dbusers collection for a document whose _id matches the provided username, projecting only the gpt_api_key field. If a matching document is found, the function extracts and returns the gpt_api_key value; otherwise it returns None. The implementation relies on the pymongo driver but does not invoke any other helper functions.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username whose GPT API key should be fetched from the database."
          }
        ],
        "returns": [
          {
            "name": "gpt_api_key",
            "type": "Optional[str]",
            "description": "The GPT API key associated with the given username, or None if no such user or key exists."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions in the provided context."
        }
      },
      "error": null
    },
    "database.db.fetch_opensrc_key": {
      "identifier": "database.db.fetch_opensrc_key",
      "description": {
        "overall": "The function `fetch_opensrc_key` retrieves an Open Source API key for a specified user from the MongoDB `dbusers` collection. It performs a `find_one` query using the provided `username` as the document identifier and projects only the `opensrc_api_key` field. If a matching document is found, the function returns the value of `opensrc_api_key`; otherwise it returns `None`. This enables callers to obtain the stored API key without exposing other user data.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username whose Open Source API key is to be retrieved."
          }
        ],
        "returns": [
          {
            "name": "",
            "type": "str | None",
            "description": "The Open Source API key associated with the given username, or None if no such user exists."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "No functions are documented as calling this function."
        }
      },
      "error": null
    },
    "database.db.fetch_opensrc_url": {
      "identifier": "database.db.fetch_opensrc_url",
      "description": {
        "overall": "The function fetch_opensrc_url retrieves the base URL for an open\u2011source resource associated with a given user. It accepts a single argument, username, which is expected to be a string representing the user's identifier in the database. Using the MongoDB collection dbusers, it performs a find_one query filtering on the _id field and projecting only the opensrc_base_url field. If a matching document is found, the function extracts the opensrc_base_url value; otherwise it returns None.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The identifier of the user whose open\u2011source base URL should be fetched."
          }
        ],
        "returns": [
          {
            "name": "opensrc_base_url",
            "type": "Optional[str]",
            "description": "The open\u2011source base URL associated with the user, or None if the user does not exist or the field is absent."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "No functions are documented as calling this function."
        }
      },
      "error": null
    },
    "database.db.delete_user": {
      "identifier": "database.db.delete_user",
      "description": {
        "overall": "The `delete_user` function removes a user record from the MongoDB collection `dbusers` based on the provided username. It builds a query that matches the document whose `_id` field equals the given username. The function then invokes the `delete_one` method on the collection, which attempts to delete a single matching document. Finally, it returns the `deleted_count` attribute, indicating how many documents were removed.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username of the user to be removed from the database."
          }
        ],
        "returns": [
          {
            "name": "",
            "type": "int",
            "description": "The number of documents deleted (0 if no matching user was found, 1 if the user was deleted)."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not referenced by any other functions in the provided context."
        }
      },
      "error": null
    },
    "database.db.get_decrypted_api_keys": {
      "identifier": "database.db.get_decrypted_api_keys",
      "description": {
        "overall": "The function retrieves a user document from the MongoDB collection `dbusers` using the supplied username. If no matching user is found, it returns a pair of `None` values to indicate the absence of data. When a user document exists, the function extracts stored API keys and base URLs, decrypting the encrypted keys via the `decrypt_text` helper. Finally, it returns the decrypted Gemini API key, the Ollama base URL, the GPT API key, the Opensrc API key, and the Opensrc base URL as a tuple of strings.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The identifier of the user whose encrypted API keys should be retrieved."
          }
        ],
        "returns": [
          {
            "name": "gemini_plain",
            "type": "str",
            "description": "Decrypted Gemini API key; empty string if the key is not stored."
          },
          {
            "name": "ollama_plain",
            "type": "str",
            "description": "Ollama base URL retrieved directly from the user document; empty string if not present."
          },
          {
            "name": "gpt_plain",
            "type": "str",
            "description": "Decrypted GPT API key; empty string if the key is not stored."
          },
          {
            "name": "opensrc_plain",
            "type": "str",
            "description": "Decrypted Opensrc API key; empty string if the key is not stored."
          },
          {
            "name": "opensrc_url",
            "type": "str",
            "description": "Opensrc base URL retrieved directly from the user document; empty string if not present."
          }
        ],
        "usage_context": {
          "calls": "This function calls database.db.decrypt_text.",
          "called_by": "No functions call this function."
        }
      },
      "error": null
    },
    "database.db.insert_chat": {
      "identifier": "database.db.insert_chat",
      "description": {
        "overall": "The function `insert_chat` creates a new chat record for a given user. It generates a unique identifier using `uuid.uuid4()` and captures the current timestamp with `datetime.now()`. The assembled dictionary is then inserted into the `dbchats` MongoDB collection via `insert_one`. Finally, the function returns the identifier of the newly inserted document.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The name of the user who owns the chat."
          },
          {
            "name": "chat_name",
            "type": "str",
            "description": "The display name of the chat to be created."
          }
        ],
        "returns": [
          {
            "name": "inserted_id",
            "type": "ObjectId",
            "description": "The unique identifier assigned by MongoDB to the newly inserted chat document."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not recorded as being called by any other functions."
        }
      },
      "error": null
    },
    "database.db.fetch_chats_by_user": {
      "identifier": "database.db.fetch_chats_by_user",
      "description": {
        "overall": "The function fetch_chats_by_user retrieves all chat entries associated with a given username from the MongoDB collection `dbchats`. It constructs a query filtering on the `username` field and sorts the results by the `created_at` timestamp in ascending order. The resulting cursor is converted into a Python list. Finally, the list of chat documents is returned to the caller.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username whose chat records are to be retrieved."
          }
        ],
        "returns": [
          {
            "name": "chats",
            "type": "list[dict]",
            "description": "A list of chat documents belonging to the specified user, sorted by creation time in ascending order."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions in the provided context."
        }
      },
      "error": null
    },
    "database.db.check_chat_exists": {
      "identifier": "database.db.check_chat_exists",
      "description": {
        "overall": "The function `check_chat_exists` determines whether a chat with a particular name exists for a specified user in the database. It accepts the user's identifier and the chat name as string arguments. Internally it queries the `dbchats` collection using `find_one` with a filter matching both fields. The result of the query is compared to `None`, and the function returns `True` if a document is found, otherwise `False`.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username whose chats are being queried."
          },
          {
            "name": "chat_name",
            "type": "str",
            "description": "The name of the chat to check for existence."
          }
        ],
        "returns": [
          {
            "name": "",
            "type": "bool",
            "description": "True if a chat matching the given username and chat_name exists; otherwise False."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not listed as being called by any other functions."
        }
      },
      "error": null
    },
    "database.db.rename_chat_fully": {
      "identifier": "database.db.rename_chat_fully",
      "description": {
        "overall": "The function `rename_chat_fully` renames a chat for a given user and updates all related exchange records to reflect the new chat name. It first updates the chat document in the `dbchats` collection by setting the `chat_name` field to the new value. Afterwards, it updates every exchange document in the `dbexchanges` collection that belongs to the same user and old chat name, also setting their `chat_name` to the new name. Finally, it returns the number of chat documents that were modified by the first update operation.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username of the user whose chat is being renamed."
          },
          {
            "name": "old_name",
            "type": "str",
            "description": "The current name of the chat that should be changed."
          },
          {
            "name": "new_name",
            "type": "str",
            "description": "The new name to assign to the chat and its associated exchanges."
          }
        ],
        "returns": [
          {
            "name": "modified_count",
            "type": "int",
            "description": "The number of chat documents that were modified by the update operation."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "No functions are listed as calling this function."
        }
      },
      "error": null
    },
    "database.db.insert_exchange": {
      "identifier": "database.db.insert_exchange",
      "description": {
        "overall": "The function `insert_exchange` records a conversational exchange in a MongoDB collection. It generates a unique identifier using UUID, assembles all provided exchange details into a dictionary, and adds a timestamp of creation. The dictionary is then inserted into the `dbexchanges` collection. If the insertion succeeds, the generated identifier is returned; otherwise the function prints the error and returns `None`.",
        "parameters": [
          {
            "name": "question",
            "type": "str",
            "description": "The question text of the exchange."
          },
          {
            "name": "answer",
            "type": "str",
            "description": "The answer text generated for the question."
          },
          {
            "name": "feedback",
            "type": "str",
            "description": "Feedback provided for the exchange."
          },
          {
            "name": "username",
            "type": "str",
            "description": "The username of the participant."
          },
          {
            "name": "chat_name",
            "type": "str",
            "description": "The name of the chat session."
          },
          {
            "name": "helper_used",
            "type": "str",
            "description": "Identifier of the helper model used (default empty)."
          },
          {
            "name": "main_used",
            "type": "str",
            "description": "Identifier of the main model used (default empty)."
          },
          {
            "name": "total_time",
            "type": "str",
            "description": "Total time taken for the exchange (default empty)."
          },
          {
            "name": "helper_time",
            "type": "str",
            "description": "Time spent using the helper model (default empty)."
          },
          {
            "name": "main_time",
            "type": "str",
            "description": "Time spent using the main model (default empty)."
          },
          {
            "name": "json_tokens",
            "type": "int",
            "description": "Number of JSON tokens used (default 0)."
          },
          {
            "name": "toon_tokens",
            "type": "int",
            "description": "Number of toon tokens used (default 0)."
          },
          {
            "name": "savings_percent",
            "type": "float",
            "description": "Percentage of token savings achieved (default 0.0)."
          }
        ],
        "returns": [
          {
            "name": "",
            "type": "str | None",
            "description": "The UUID of the inserted exchange on success, or None if insertion fails."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "No other functions are documented as calling this function."
        }
      },
      "error": null
    },
    "database.db.fetch_exchanges_by_user": {
      "identifier": "database.db.fetch_exchanges_by_user",
      "description": {
        "overall": "The function `fetch_exchanges_by_user` retrieves all exchange records associated with a given username from the MongoDB collection `dbexchanges`. It constructs a query filtering documents where the `username` field matches the provided argument. The results are sorted in ascending order by the `created_at` timestamp to ensure chronological display. Finally, the cursor is materialized into a Python list and returned to the caller.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username used to filter exchange records."
          }
        ],
        "returns": [
          {
            "name": "",
            "type": "list",
            "description": "A list of exchange documents matching the username, ordered by creation time."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "No functions are recorded as calling this function."
        }
      },
      "error": null
    },
    "database.db.fetch_exchanges_by_chat": {
      "identifier": "database.db.fetch_exchanges_by_chat",
      "description": {
        "overall": "The function fetch_exchanges_by_chat retrieves all exchange records for a specific user and chat from the database. It builds a query filtering on the provided username and chat_name, executes the find operation on the dbexchanges collection, and sorts the results by the \"created_at\" field in ascending order. The resulting cursor is converted into a Python list. Finally, the list of exchanges is returned to the caller.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username of the user whose exchanges are being fetched."
          },
          {
            "name": "chat_name",
            "type": "str",
            "description": "The name of the chat whose exchanges are being fetched."
          }
        ],
        "returns": [
          {
            "name": "",
            "type": "list",
            "description": "A list containing the exchange documents matching the query, ordered by their creation timestamp."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "No other functions are recorded as calling this function."
        }
      },
      "error": null
    },
    "database.db.update_exchange_feedback": {
      "identifier": "database.db.update_exchange_feedback",
      "description": {
        "overall": "The function updates the feedback value for a specific exchange record stored in a MongoDB collection. It receives an identifier for the exchange and an integer representing the new feedback score. Using the MongoDB `update_one` method, it sets the `feedback` field of the matching document to the supplied value. The function then returns the number of documents that were modified by the operation, which can be used to verify that the update succeeded.",
        "parameters": [
          {
            "name": "exchange_id",
            "type": "Any",
            "description": "The unique identifier of the exchange document to be updated."
          },
          {
            "name": "feedback",
            "type": "int",
            "description": "The new feedback score to store for the exchange."
          }
        ],
        "returns": [
          {
            "name": "modified_count",
            "type": "int",
            "description": "The count of documents that were modified by the update operation."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "No other functions are documented as calling this function."
        }
      },
      "error": null
    },
    "database.db.update_exchange_feedback_message": {
      "identifier": "database.db.update_exchange_feedback_message",
      "description": {
        "overall": "This function updates the ``feedback_message`` field of a specific exchange document in the database. It accepts an exchange identifier and a new feedback message string as inputs. Using the ``dbexchanges`` collection it calls ``update_one`` with a filter on ``_id`` and a ``$set`` operation to replace the existing feedback message. Finally, it returns the ``modified_count`` attribute of the update result, indicating how many documents were modified.",
        "parameters": [
          {
            "name": "exchange_id",
            "type": "Any",
            "description": "Identifier of the exchange document to be updated."
          },
          {
            "name": "feedback_message",
            "type": "str",
            "description": "The new feedback message to store in the exchange document."
          }
        ],
        "returns": [
          {
            "name": "modified_count",
            "type": "int",
            "description": "Number of documents that were modified by the update operation (typically 0 or 1)."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.delete_exchange_by_id": {
      "identifier": "database.db.delete_exchange_by_id",
      "description": {
        "overall": "The function `delete_exchange_by_id` removes a specific exchange record from a MongoDB collection. It accepts a single argument `exchange_id` which is expected to be a string representing the document's `_id`. Inside the function, it calls the `delete_one` method on the `dbexchanges` collection, passing a filter that matches the provided identifier. The result of this operation is stored in `result`, and the function returns `result.deleted_count`, an integer indicating how many documents were deleted (typically 0 or 1). This allows callers to know whether the deletion was successful.",
        "parameters": [
          {
            "name": "exchange_id",
            "type": "str",
            "description": "The identifier of the exchange document to be deleted."
          }
        ],
        "returns": [
          {
            "name": "",
            "type": "int",
            "description": "The number of documents deleted (0 if none were found, 1 if the exchange was removed)."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "No other functions are documented as calling this function."
        }
      },
      "error": null
    },
    "database.db.delete_full_chat": {
      "identifier": "database.db.delete_full_chat",
      "description": {
        "overall": "The function `delete_full_chat` removes all message exchanges belonging to a specific chat for a given user, and then deletes the chat entry itself from the chat list. It first calls `dbexchanges.delete_many` with a filter on `username` and `chat_name` to purge related exchange documents. Next, it calls `dbchats.delete_one` with the same filter to remove the chat document. Finally, it returns the `deleted_count` from the chat deletion operation, indicating whether a chat was removed.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username associated with the chat to be deleted."
          },
          {
            "name": "chat_name",
            "type": "str",
            "description": "The name of the chat whose exchanges and record should be deleted."
          }
        ],
        "returns": [
          {
            "name": "deleted_count",
            "type": "int",
            "description": "The number of chat documents deleted (typically 0 if none existed, or 1 if the chat was removed)."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "No functions are listed as callers of this function."
        }
      },
      "error": null
    },
    "frontend.frontend.clean_names": {
      "identifier": "frontend.frontend.clean_names",
      "description": {
        "overall": "The `clean_names` function receives a collection of model identifier strings. It processes each string by splitting it on the '/' character. The last element of the split result, which represents the bare model name, is selected. These extracted names are gathered into a new list that the function returns. The implementation uses a concise list comprehension and has no side effects.",
        "parameters": [
          {
            "name": "model_list",
            "type": "List[str]",
            "description": "A list (or iterable) of model identifier strings, each potentially containing '/' separators."
          }
        ],
        "returns": [
          {
            "name": "",
            "type": "List[str]",
            "description": "A list containing the last segment of each input string after splitting by '/'."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "No functions are shown to call this function."
        }
      },
      "error": null
    },
    "frontend.frontend.get_filtered_models": {
      "identifier": "frontend.frontend.get_filtered_models",
      "description": {
        "overall": "The function get_filtered_models filters a list of model names according to a specified category. It obtains a list of keywords for the given category from the global CATEGORY_KEYWORDS mapping, defaulting to an empty string when the category is not found. If the keyword list contains the special token \"STANDARD\", the function returns only those models that also appear in the predefined STANDARD_MODELS list. Otherwise, it builds a filtered list of models whose lowercase names contain any of the keywords and returns that list; if no models match, it falls back to returning the original source list.",
        "parameters": [
          {
            "name": "source_list",
            "type": "list",
            "description": "A list of model name strings that should be filtered."
          },
          {
            "name": "category_name",
            "type": "str",
            "description": "The name of the category whose associated keywords are used for filtering."
          }
        ],
        "returns": [
          {
            "name": "filtered_models",
            "type": "list",
            "description": "A list of model names that match the category keywords, or the original source_list if no matches are found."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "No other functions are documented as calling this function."
        }
      },
      "error": null
    },
    "frontend.frontend.save_gemini_cb": {
      "identifier": "frontend.frontend.save_gemini_cb",
      "description": {
        "overall": "The function `save_gemini_cb` retrieves a Gemini key from the Streamlit session state. If a key is present, it updates the stored key for the current user by invoking `database.db.update_gemini_key`. After updating, it clears the temporary session entry for the key. Finally, it displays a toast notification indicating successful storage.",
        "parameters": [],
        "returns": [],
        "usage_context": {
          "calls": "This function calls database.db.update_gemini_key.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "frontend.frontend.save_ollama_cb": {
      "identifier": "frontend.frontend.save_ollama_cb",
      "description": {
        "overall": "The function `save_ollama_cb` retrieves an Ollama URL from Streamlit's session state. It checks whether the retrieved URL is non\u2011empty. If a URL is present, it updates the stored Ollama URL for the current user in the database and shows a confirmation toast in the Streamlit UI. The function does not accept any arguments and does not return a value.",
        "parameters": [],
        "returns": [],
        "usage_context": {
          "calls": "This function calls database.db.update_ollama_url.",
          "called_by": "No functions call this function."
        }
      },
      "error": null
    },
    "frontend.frontend.load_data_from_db": {
      "identifier": "frontend.frontend.load_data_from_db",
      "description": {
        "overall": "The function loads a user's chats and exchanges from the database into Streamlit's session state, ensuring the data is consistent across the application. It first checks whether the user has already been loaded; if not, it clears any existing chat data. It then retrieves defined chats, creates empty exchange lists for each, loads all exchanges (adding NaN feedback where missing) and assigns them to the appropriate chats, handling legacy cases where exchanges exist for undefined chats. If no chats exist after loading, it creates a default chat both in memory and in the database. Finally, it sets an active chat (defaulting to the first available) and records the loaded user in session state.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The identifier of the user whose chats and exchanges should be loaded from the database."
          }
        ],
        "returns": [],
        "usage_context": {
          "calls": "This function calls database.db.fetch_chats_by_user, database.db.fetch_exchanges_by_user, and database.db.insert_chat.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "frontend.frontend.handle_feedback_change": {
      "identifier": "frontend.frontend.handle_feedback_change",
      "description": {
        "overall": "The function `handle_feedback_change` updates the feedback field of an exchange record. It assigns the provided value to the `feedback` key in the given exchange dictionary. The change is persisted by calling `database.db.update_exchange_feedback` with the exchange's identifier and the new feedback value. Finally, it triggers a Streamlit rerun with `st.rerun()` to refresh the UI.",
        "parameters": [
          {
            "name": "ex",
            "type": "dict",
            "description": "A dictionary representing the exchange record, expected to contain at least the keys '_id' and 'feedback'."
          },
          {
            "name": "val",
            "type": "Any",
            "description": "The new feedback value to be stored."
          }
        ],
        "returns": [],
        "usage_context": {
          "calls": "This function calls database.db.update_exchange_feedback.",
          "called_by": "This function is called by no other functions."
        }
      },
      "error": null
    },
    "frontend.frontend.handle_delete_exchange": {
      "identifier": "frontend.frontend.handle_delete_exchange",
      "description": {
        "overall": "The function `handle_delete_exchange` removes a specific exchange record from persistent storage. It calls `database.db.delete_exchange_by_id` with the exchange's `_id` to delete the record from the database. If the exchange is present in the Streamlit session state's chat data, it also removes the exchange from the in\u2011memory list. Finally, it triggers a Streamlit rerun to refresh the UI.",
        "parameters": [
          {
            "name": "chat_name",
            "type": "str",
            "description": "The name of the chat whose exchanges are being managed."
          },
          {
            "name": "ex",
            "type": "dict",
            "description": "A dictionary representing the exchange to delete; it must contain an \"_id\" key identifying the record in the database."
          }
        ],
        "returns": [],
        "usage_context": {
          "calls": "This function calls database.db.delete_exchange_by_id.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "frontend.frontend.handle_delete_chat": {
      "identifier": "frontend.frontend.handle_delete_chat",
      "description": {
        "overall": "The function handle_delete_chat removes a specific chat belonging to a given user from the database and updates the Streamlit session state accordingly. It first calls database.db.delete_full_chat to delete the chat record. It then removes the chat from st.session_state.chats, adjusts the active chat pointer, and if no chats remain, creates a new empty chat using database.db.insert_chat and updates the session state. Finally, it triggers a UI refresh with st.rerun.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The identifier of the user whose chat is to be deleted."
          },
          {
            "name": "chat_name",
            "type": "str",
            "description": "The name of the chat to be removed."
          }
        ],
        "returns": [],
        "usage_context": {
          "calls": "This function calls database.db.delete_full_chat and database.db.insert_chat.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "frontend.frontend.extract_repo_name": {
      "identifier": "frontend.frontend.extract_repo_name",
      "description": {
        "overall": "The function `extract_repo_name` takes a piece of text and attempts to locate a URL within it. It uses a regular expression to find the first HTTP or HTTPS URL and then parses the URL using `urlparse`. From the parsed path it extracts the final segment, removes a trailing `.git` suffix if present, and returns this segment as the repository name. If no URL is found or the path is empty, the function returns `None`.",
        "parameters": [
          {
            "name": "text",
            "type": "str",
            "description": "The input text that may contain a URL from which to extract the repository name."
          }
        ],
        "returns": [
          {
            "name": "",
            "type": "Optional[str]",
            "description": "The repository name extracted from the URL, or None if no suitable URL is found."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "frontend.frontend.stream_text_generator": {
      "identifier": "frontend.frontend.stream_text_generator",
      "description": {
        "overall": "The function accepts a text string, splits it into individual words, and yields each word followed by a space. It uses a generator to produce the output incrementally. After yielding each word, it pauses for a short 0.01\u2011second interval using `time.sleep` to simulate a streaming effect. The caller receives a generator that can be iterated to obtain the spaced words one at a time.",
        "parameters": [
          {
            "name": "text",
            "type": "str",
            "description": "The input text to be split into words."
          }
        ],
        "returns": [
          {
            "name": "",
            "type": "Generator[str, None, None]",
            "description": "A generator that yields each word from the input text with a trailing space, pausing briefly between yields."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "frontend.frontend.render_text_with_mermaid": {
      "identifier": "frontend.frontend.render_text_with_mermaid",
      "description": {
        "overall": "The function `render_text_with_mermaid` processes a markdown string that may contain Mermaid diagram blocks. It splits the input into alternating plain markdown sections and Mermaid code sections using a regular expression. Plain markdown sections are rendered in Streamlit either via streaming or standard markdown, while Mermaid sections are rendered with `st_mermaid` and fall back to a code block on failure. If the provided markdown text is empty, the function returns immediately without rendering anything.",
        "parameters": [
          {
            "name": "markdown_text",
            "type": "str",
            "description": "The markdown content to be rendered, which may include Mermaid diagram code blocks."
          },
          {
            "name": "should_stream",
            "type": "bool",
            "description": "Flag indicating whether plain markdown should be streamed using Streamlit's write_stream (True) or rendered normally (False)."
          }
        ],
        "returns": [],
        "usage_context": {
          "calls": "This function calls frontend.frontend.stream_text_generator.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "frontend.frontend.render_exchange": {
      "identifier": "frontend.frontend.render_exchange",
      "description": {
        "overall": "The `render_exchange` function renders a single chat exchange in a Streamlit interface. It first displays the user's question, then creates an assistant message container that shows the answer, feedback controls, and auxiliary actions such as commenting, downloading, and deleting the exchange. Depending on whether the answer starts with an error indicator, it either presents the normal toolbar with feedback buttons or an error message with a delete option. Finally, it renders the answer content (including possible Mermaid diagrams) inside a scrollable container.",
        "parameters": [
          {
            "name": "ex",
            "type": "dict",
            "description": "A dictionary representing the exchange, expected to contain keys like \"question\", \"answer\", \"feedback\", \"feedback_message\", and \"_id\"."
          },
          {
            "name": "current_chat_name",
            "type": "str",
            "description": "The name of the current chat session, used when handling deletion of the exchange."
          }
        ],
        "returns": [],
        "usage_context": {
          "calls": "This function calls database.db.update_exchange_feedback_message, frontend.frontend.handle_delete_exchange, frontend.frontend.handle_feedback_change, and frontend.frontend.render_text_with_mermaid.",
          "called_by": "No functions are listed as callers of this function."
        }
      },
      "error": null
    }
  },
  "classes": {
    "backend.AST_Schema.ASTVisitor": {
      "identifier": "backend.AST_Schema.ASTVisitor",
      "description": {
        "overall": "ASTVisitor is a concrete subclass of ``ast.NodeVisitor`` that walks a Python abstract syntax tree to build a lightweight schema describing a module. While traversing, it records imported names, top\u2011level functions and class definitions, storing each entry with its fully\u2011qualified identifier, source snippet and line range. The visitor maintains contextual state \u2013 the module path derived from the file location and a temporary holder for the class currently being visited \u2013 to correctly qualify names. The resulting ``schema`` dictionary can be consumed by downstream tools for documentation, analysis or code\u2011generation purposes.",
        "init_method": {
          "description": "The constructor stores the raw source code, the file path, and the project root, computes the module path using ``path_to_module``, and prepares an empty schema dictionary that will be populated with imports, functions, and classes during the AST walk. It also initializes a placeholder for the class currently being visited.",
          "parameters": [
            {
              "name": "source_code",
              "type": "str",
              "description": "The full text of the Python source file that will be parsed."
            },
            {
              "name": "file_path",
              "type": "str",
              "description": "Filesystem path to the source file."
            },
            {
              "name": "project_root",
              "type": "str",
              "description": "Root directory of the project; used together with ``file_path`` to resolve the module's dotted path."
            }
          ]
        },
        "methods": [
          {
            "identifier": "visit_Import",
            "description": {
              "overall": "This method processes an ``ast.Import`` node. It iterates over each alias in ``node.names`` and appends the imported module name to the ``schema['imports']`` list. After recording the imports, it calls ``generic_visit`` to continue traversing any child nodes of the import statement. The method does not produce a return value.",
              "parameters": [
                {
                  "name": "self",
                  "type": "ASTVisitor",
                  "description": "The visitor instance."
                },
                {
                  "name": "node",
                  "type": "ast.Import",
                  "description": "The AST node representing an ``import`` statement."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method does not call any other functions directly.",
                "called_by": "No other functions are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_ImportFrom",
            "description": {
              "overall": "This method handles an ``ast.ImportFrom`` node. For each alias in ``node.names`` it constructs a fully\u2011qualified name ``\"{node.module}.{alias.name}\"`` and appends it to ``schema['imports']``. It then invokes ``generic_visit`` to walk any nested nodes. The method returns ``None``.",
              "parameters": [
                {
                  "name": "self",
                  "type": "ASTVisitor",
                  "description": "The visitor instance."
                },
                {
                  "name": "node",
                  "type": "ast.ImportFrom",
                  "description": "The AST node representing a ``from \u2026 import \u2026`` statement."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method does not call any other functions directly.",
                "called_by": "No other functions are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_ClassDef",
            "description": {
              "overall": "When the visitor encounters a class definition node, this method builds a fully\u2011qualified identifier by concatenating the module path with the class name. It creates a ``class_info`` dictionary containing metadata such as mode, identifier, name, docstring, source code segment, and line numbers, and appends it to ``schema['classes']``. The method sets ``_current_class`` to this dictionary, walks the class body with ``generic_visit``, and finally resets ``_current_class`` to ``None``. No explicit return value is produced.",
              "parameters": [
                {
                  "name": "self",
                  "type": "ASTVisitor",
                  "description": "The visitor instance."
                },
                {
                  "name": "node",
                  "type": "ast.ClassDef",
                  "description": "The AST node representing a class definition."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method does not call any other functions directly.",
                "called_by": "No other functions are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_FunctionDef",
            "description": {
              "overall": "This method processes a function definition node. If the visitor is currently inside a class (``_current_class`` is set), it builds a method identifier, creates a ``method_context_info`` record with identifier, name, arguments, docstring and line numbers, and stores it inside the current class's context. If not inside a class, it creates a top\u2011level ``func_info`` dictionary with similar metadata and adds it to ``schema['functions']``. After recording the information, it calls ``generic_visit`` to walk the function body. The method returns ``None``.",
              "parameters": [
                {
                  "name": "self",
                  "type": "ASTVisitor",
                  "description": "The visitor instance."
                },
                {
                  "name": "node",
                  "type": "ast.FunctionDef",
                  "description": "The AST node representing a function definition."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method does not call any other functions directly.",
                "called_by": "No other functions are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_AsyncFunctionDef",
            "description": {
              "overall": "For asynchronous function definitions, this method simply forwards the node to ``visit_FunctionDef`` so that async functions are recorded using the same logic as regular functions. No additional processing is performed, and the method returns ``None``.",
              "parameters": [
                {
                  "name": "self",
                  "type": "ASTVisitor",
                  "description": "The visitor instance."
                },
                {
                  "name": "node",
                  "type": "ast.AsyncFunctionDef",
                  "description": "The AST node representing an async function definition."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method does not call any other functions directly.",
                "called_by": "No other functions are recorded as calling this method."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "The class depends on ``backend.AST_Schema.path_to_module`` to translate file paths into module identifiers.",
          "instantiated_by": "No known locations instantiate this class based on the provided context."
        }
      },
      "error": null
    },
    "backend.AST_Schema.ASTAnalyzer": {
      "identifier": "backend.AST_Schema.ASTAnalyzer",
      "description": {
        "overall": "ASTAnalyzer is a utility class that extracts abstract\u2011syntax\u2011tree (AST) information from a collection of Python files and enriches that information with call\u2011relationship data. It parses each file using an ASTVisitor, builds a schema describing imports, functions, and classes, and then merges outgoing and incoming call relationships into the schema. The class provides two public methods \u2013 `analyze_repository` for generating the initial schema from a repository and `merge_relationship_data` for augmenting that schema with relationship metadata. It does not maintain any internal state beyond what is passed to its methods.",
        "init_method": {
          "description": "The constructor does not perform any initialization; it simply contains a `pass` statement.",
          "parameters": [
            {
              "name": "self",
              "type": "ASTAnalyzer",
              "description": "Reference to the instance being created."
            }
          ]
        },
        "methods": [
          {
            "identifier": "merge_relationship_data",
            "description": {
              "overall": "This method enriches a previously built `full_schema` with call\u2011relationship information supplied in `raw_relationships`. It extracts outgoing and incoming call mappings, then iterates over each file and its AST nodes. For every function it adds a `calls` list and a `called_by` list based on the outgoing/incoming data. For each class it records which functions instantiate the class and computes a set of dependencies by examining method calls that do not belong to the same class. Finally, it returns the updated schema containing these relationship annotations.",
              "parameters": [
                {
                  "name": "full_schema",
                  "type": "dict",
                  "description": "A dictionary representing the repository schema generated by `analyze_repository`."
                },
                {
                  "name": "raw_relationships",
                  "type": "dict",
                  "description": "A dictionary containing `outgoing` and `incoming` call mappings keyed by function or method identifiers."
                }
              ],
              "returns": [
                {
                  "name": "enriched_schema",
                  "type": "dict",
                  "description": "The input `full_schema` dictionary updated with call and dependency information."
                }
              ],
              "usage_context": {
                "calls": "The method does not invoke any external functions or classes.",
                "called_by": "No other methods are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "analyze_repository",
            "description": {
              "overall": "This method builds a complete AST\u2011based schema for a list of source files belonging to a repository. It determines the common project root, filters out non\u2011Python files and empty contents, and then parses each file with Python's `ast` module. For each file it creates an `ASTVisitor` (provided by `backend.AST_Schema.ASTVisitor`) to walk the tree and collect imports, functions, and classes into a structured schema. Errors during parsing are caught and reported, and the accumulated schema is returned as a dictionary.",
              "parameters": [
                {
                  "name": "files",
                  "type": "list",
                  "description": "A list of file objects, each exposing `path` and `content` attributes."
                },
                {
                  "name": "repo",
                  "type": "GitRepository",
                  "description": "An instance representing the Git repository; currently not used directly in the method."
                }
              ],
              "returns": [
                {
                  "name": "full_schema",
                  "type": "dict",
                  "description": "A dictionary containing a `files` key that maps file paths to their extracted AST node information."
                }
              ],
              "usage_context": {
                "calls": "It calls `backend.AST_Schema.ASTVisitor` to traverse each file's AST.",
                "called_by": "No other methods are recorded as calling this method."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "The class depends on `backend.AST_Schema.ASTVisitor` for AST traversal.",
          "instantiated_by": "No components are listed as instantiating this class."
        }
      },
      "error": null
    },
    "backend.File_Dependency.FileDependencyGraph": {
      "identifier": "backend.File_Dependency.FileDependencyGraph",
      "description": {
        "overall": "The **FileDependencyGraph** class is a specialised ``ast.NodeVisitor`` that walks the abstract syntax tree of a Python file and builds a mapping of import relationships between files in a repository. It records direct imports, resolves relative ``from .. import`` statements to concrete module or symbol names, and stores the results in the ``import_dependencies`` dictionary keyed by the current file name. This enables the construction of a file\u2011level dependency graph for static analysis or visualisation.",
        "init_method": {
          "description": "Initialises a ``FileDependencyGraph`` instance with the target file name and the repository root path, storing them as instance attributes for later use during AST traversal.",
          "parameters": [
            {
              "name": "filename",
              "type": "str",
              "description": "The name of the file whose imports are to be analysed."
            },
            {
              "name": "repo_root",
              "type": "Any",
              "description": "The root directory of the repository containing the file; used to locate other files during relative import resolution."
            }
          ]
        },
        "methods": [
          {
            "identifier": "_resolve_module_name",
            "description": {
              "overall": "Resolves relative ``from .. import name`` statements to the actual module or symbol names that exist in the repository. It determines the import level, finds candidate files matching the current file, walks up the directory hierarchy according to the relative level, and then checks each imported name against the filesystem and ``__init__.py`` exports. Helper functions ``module_file_exists`` and ``init_exports_symbol`` are defined locally to perform these checks. The method returns a sorted list of unique resolved names or raises ``ImportError`` if none can be found.",
              "parameters": [
                {
                  "name": "self",
                  "type": "FileDependencyGraph",
                  "description": "The instance on which the method is invoked."
                },
                {
                  "name": "node",
                  "type": "ImportFrom",
                  "description": "The AST node representing a ``from ... import`` statement."
                }
              ],
              "returns": [
                {
                  "name": "resolved",
                  "type": "list[str]",
                  "description": "A list of module or symbol names that were successfully resolved from the relative import."
                }
              ],
              "usage_context": {
                "calls": "This method calls the external helper ``backend.File_Dependency.get_all_temp_files`` and uses the inner helper functions ``module_file_exists`` and ``init_exports_symbol`` to verify the existence of modules and exported symbols.",
                "called_by": "No other methods in the provided context invoke ``_resolve_module_name`` directly."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_Import",
            "description": {
              "overall": "Processes ``import`` statements (or ``ImportFrom`` nodes passed from ``visit_ImportFrom``) by adding each imported name to the ``import_dependencies`` mapping for the current file. If a ``base_name`` is supplied, that name is recorded; otherwise the original alias name is used. After updating the mapping, the generic visitor is invoked to continue traversing the AST.",
              "parameters": [
                {
                  "name": "self",
                  "type": "FileDependencyGraph",
                  "description": "The instance on which the method is invoked."
                },
                {
                  "name": "node",
                  "type": "Import | ImportFrom",
                  "description": "The AST node representing an ``import`` or ``from ... import`` statement."
                },
                {
                  "name": "base_name",
                  "type": "str | None",
                  "description": "Optional explicit name to record instead of the alias name; used when handling ``ImportFrom`` with a module base."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "No external functions are called directly from this method.",
                "called_by": "It is invoked directly by ``visit_ImportFrom`` and may also be called manually if needed."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_ImportFrom",
            "description": {
              "overall": "Handles ``from ... import`` statements. If the import specifies a module (e.g., ``from a.b.c import d``), the last component of the module path is extracted and passed to ``visit_Import`` as ``base_name``. For relative imports without an explicit module, it delegates to ``_resolve_module_name`` to determine the actual module or symbol names, then records each resolved base via ``visit_Import``. Import errors are caught and reported, after which the generic visitor continues traversal.",
              "parameters": [
                {
                  "name": "self",
                  "type": "FileDependencyGraph",
                  "description": "The instance on which the method is invoked."
                },
                {
                  "name": "node",
                  "type": "ImportFrom",
                  "description": "The AST node representing a ``from ... import`` statement."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "Calls the internal methods ``_resolve_module_name`` and ``visit_Import`` to process the import and record dependencies.",
                "called_by": "No other methods in the provided context call ``visit_ImportFrom`` directly."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "The class relies on external helpers ``backend.File_Dependency.get_all_temp_files``, ``backend.File_Dependency.init_exports_symbol`` and ``backend.File_Dependency.module_file_exists`` to locate files and verify exported symbols during relative import resolution.",
          "instantiated_by": "The provided context does not contain any locations where ``FileDependencyGraph`` is instantiated."
        }
      },
      "error": null
    },
    "backend.HelperLLM.LLMHelper": {
      "identifier": "backend.HelperLLM.LLMHelper",
      "description": {
        "overall": "LLMHelper centralises interaction with various large\u2011language\u2011model back\u2011ends (Google Gemini, OpenAI, custom SCADSLLM endpoints, and Ollama). It loads system prompts for function\u2011 and class\u2011level documentation, determines an appropriate batch size for the selected model, and exposes two high\u2011level methods that generate structured documentation for collections of functions or classes while handling rate\u2011limiting, logging and error recovery.",
        "init_method": {
          "description": "The constructor validates the provided API key, reads the function and class system\u2011prompt files, configures a model\u2011specific batch size, selects the appropriate LLM client based on the model name (Gemini, OpenAI, custom API or Ollama), and creates structured\u2011output LLM wrappers for function and class analysis.",
          "parameters": [
            {
              "name": "api_key",
              "type": "str",
              "description": "API key used to authenticate with the selected LLM provider."
            },
            {
              "name": "function_prompt_path",
              "type": "str",
              "description": "Filesystem path to the text file containing the system prompt for function documentation."
            },
            {
              "name": "class_prompt_path",
              "type": "str",
              "description": "Filesystem path to the text file containing the system prompt for class documentation."
            },
            {
              "name": "model_name",
              "type": "str",
              "description": "Name of the LLM model to use; defaults to \"gemini-2.0-flash-lite\"."
            },
            {
              "name": "base_url",
              "type": "str | None",
              "description": "Optional base URL for custom LLM endpoints (e.g., Ollama); if omitted, defaults are applied."
            }
          ]
        },
        "methods": [
          {
            "identifier": "_configure_batch_settings",
            "description": {
              "overall": "Sets the instance attribute `batch_size` based on the supplied model name. It contains a series of conditional branches that map known model identifiers to empirically chosen batch sizes, falling back to a conservative default of 2 for unknown models. The method logs a warning when the model is not recognised. No value is returned.",
              "parameters": [
                {
                  "name": "self",
                  "type": "LLMHelper",
                  "description": "The instance being configured."
                },
                {
                  "name": "model_name",
                  "type": "str",
                  "description": "The name of the LLM model for which to determine batch size."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method does not call any other methods within the class.",
                "called_by": "No other methods are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "generate_for_functions",
            "description": {
              "overall": "Generates documentation for a batch of functions using the configured function LLM. It converts each `FunctionAnalysisInput` into a JSON payload, pairs it with the function system prompt, and sends the conversations to the LLM in batches respecting the instance's `batch_size`. The method respects rate limits by sleeping between batches, logs progress, and substitutes `None` for any batch that raises an exception. The final result is a list of `FunctionAnalysis` objects (or `None` placeholders) preserving input order.",
              "parameters": [
                {
                  "name": "self",
                  "type": "LLMHelper",
                  "description": "The helper instance."
                },
                {
                  "name": "function_inputs",
                  "type": "List[FunctionAnalysisInput]",
                  "description": "A list of input models describing the functions to be documented."
                }
              ],
              "returns": [
                {
                  "name": "result",
                  "type": "List[Optional[FunctionAnalysis]]",
                  "description": "A list containing the generated `FunctionAnalysis` objects or `None` for failed batches."
                }
              ],
              "usage_context": {
                "calls": "This method does not call any other methods within the class.",
                "called_by": "No other methods are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "generate_for_classes",
            "description": {
              "overall": "Generates documentation for a batch of classes using the configured class LLM. It mirrors the workflow of `generate_for_functions`: serialising each `ClassAnalysisInput` to JSON, pairing it with the class system prompt, batching the calls according to `batch_size`, handling exceptions, and pausing between batches to respect rate limits. The method returns a list of `ClassAnalysis` objects (or `None` placeholders) aligned with the input order.",
              "parameters": [
                {
                  "name": "self",
                  "type": "LLMHelper",
                  "description": "The helper instance."
                },
                {
                  "name": "class_inputs",
                  "type": "List[ClassAnalysisInput]",
                  "description": "A list of input models describing the classes to be documented."
                }
              ],
              "returns": [
                {
                  "name": "result",
                  "type": "List[Optional[ClassAnalysis]]",
                  "description": "A list containing the generated `ClassAnalysis` objects or `None` for failed batches."
                }
              ],
              "usage_context": {
                "calls": "This method does not call any other methods within the class.",
                "called_by": "No other methods are recorded as calling this method."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "The provided context does not list any external dependencies for this class.",
          "instantiated_by": "No instantiation sites are provided in the context."
        }
      },
      "error": null
    },
    "backend.MainLLM.MainLLM": {
      "identifier": "backend.MainLLM.MainLLM",
      "description": {
        "overall": "The **MainLLM** class is a thin wrapper that abstracts interaction with a variety of large\u2011language\u2011model back\u2011ends (Google Gemini, OpenAI\u2011compatible APIs, and Ollama). It reads a system\u2011prompt from a file, selects the appropriate LangChain chat model based on the supplied *model_name*, and exposes two convenience methods \u2013 one for a single synchronous call and one for streaming responses. By handling model\u2011specific initialisation and error logging internally, it provides a uniform interface for the rest of the application to obtain LLM completions.",
        "init_method": {
          "description": "Initialises the MainLLM instance by loading a system prompt from the given file, selecting the appropriate LangChain chat model according to *model_name*, and storing configuration such as the model name and optional base URL. It validates the presence of an API key and raises informative errors if required resources are missing.",
          "parameters": [
            {
              "name": "api_key",
              "type": "str",
              "description": "API key required by the underlying LLM provider (e.g., Gemini or OpenAI)."
            },
            {
              "name": "prompt_file_path",
              "type": "str",
              "description": "Filesystem path to a text file containing the system\u2011prompt that will be sent to the LLM."
            },
            {
              "name": "model_name",
              "type": "str",
              "description": "Identifier of the LLM model to use. Defaults to \"gemini-2.5-pro\" and determines which LangChain client class is instantiated."
            },
            {
              "name": "base_url",
              "type": "str | None",
              "description": "Optional base URL for custom or self\u2011hosted LLM endpoints (used when *model_name* does not match built\u2011in providers)."
            }
          ]
        },
        "methods": [
          {
            "identifier": "call_llm",
            "description": {
              "overall": "Creates a message list consisting of the previously loaded system prompt and the supplied user input, then invokes the configured LLM client synchronously. The method logs the start and successful completion of the call, and returns the textual content of the LLM's response. If any exception occurs during the invocation, it logs the error and returns *None* instead of raising. This method is suitable for use\u2011cases where a single, complete response is required.",
              "parameters": [
                {
                  "name": "user_input",
                  "type": "str",
                  "description": "The end\u2011user's query or instruction that will be sent to the LLM."
                }
              ],
              "returns": [
                {
                  "name": "response_content",
                  "type": "str | None",
                  "description": "The textual content returned by the LLM on success, or *None* if an error was encountered."
                }
              ],
              "usage_context": {
                "calls": "The method does not call any other functions or methods within the provided source code.",
                "called_by": "No calling locations are listed in the supplied context."
              }
            },
            "error": null
          },
          {
            "identifier": "stream_llm",
            "description": {
              "overall": "Prepares the same message list as *call_llm* but invokes the LLM client in streaming mode. It iterates over the streamed chunks, yielding each chunk's textual content to the caller. If an exception occurs, the method logs the error and yields a formatted error message string instead of propagating the exception. This generator\u2011based interface enables callers to process partial LLM outputs in real time.",
              "parameters": [
                {
                  "name": "user_input",
                  "type": "str",
                  "description": "The end\u2011user's query or instruction that will be streamed to the LLM."
                }
              ],
              "returns": [
                {
                  "name": "stream",
                  "type": "Iterator[str]",
                  "description": "An iterator yielding successive pieces of the LLM's response as strings, or an error message string if the stream fails."
                }
              ],
              "usage_context": {
                "calls": "The method does not call any other functions or methods within the provided source code.",
                "called_by": "No calling locations are listed in the supplied context."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "No external dependencies are listed in the provided context.",
          "instantiated_by": "No instantiation sites are provided in the context."
        }
      },
      "error": null
    },
    "backend.basic_info.ProjektInfoExtractor": {
      "identifier": "backend.basic_info.ProjektInfoExtractor",
      "description": {
        "overall": "ProjektInfoExtractor is a utility class that gathers basic project metadata from common project files such as README, pyproject.toml, and requirements.txt. It builds a structured dictionary with sections for project overview (title, description, status, key features, tech stack) and installation details (dependencies, setup guide, quick\u2011start guide). The class provides private helper methods for cleaning file content, locating files, extracting markdown sections, and parsing each file type, all orchestrated by the public `extrahiere_info` method. By consolidating this information, the class enables downstream tools to generate documentation or perform analysis without needing to manually read each source file.",
        "init_method": {
          "description": "The constructor initializes a placeholder string `INFO_NICHT_GEFUNDEN` used to indicate missing information. It also creates an instance attribute `info` containing two top\u2011level sections, `projekt_uebersicht` and `installation`, each pre\u2011populated with placeholder values. No external parameters are required.",
          "parameters": [
            {
              "name": "self",
              "type": "ProjektInfoExtractor",
              "description": "The instance being created."
            }
          ]
        },
        "methods": [
          {
            "identifier": "_clean_content",
            "description": {
              "overall": "This private helper removes null byte characters that may appear when a file encoded as UTF\u201116 is mistakenly read as UTF\u20118. It first checks if the provided content is falsy and returns an empty string in that case. Otherwise it replaces all \"\\\\x00\" characters with an empty string and returns the cleaned result. The method ensures downstream parsers receive clean text.",
              "parameters": [
                {
                  "name": "self",
                  "type": "ProjektInfoExtractor",
                  "description": "The instance on which the method is called."
                },
                {
                  "name": "content",
                  "type": "str",
                  "description": "The raw text content that may contain null\u2011byte characters."
                }
              ],
              "returns": [
                {
                  "name": "cleaned_content",
                  "type": "str",
                  "description": "The input string with all null\u2011byte characters removed."
                }
              ],
              "usage_context": {
                "calls": "This method does not call any other methods.",
                "called_by": "No other methods in this class are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "_finde_datei",
            "description": {
              "overall": "Searches through a list of file objects for the first one whose path matches any of the supplied filename patterns, ignoring case. It iterates over each file and each pattern, checking if the file's path ends with the pattern. If a match is found, the corresponding file object is returned; otherwise None is returned. This utility supports locating README, pyproject.toml, or requirements files.",
              "parameters": [
                {
                  "name": "self",
                  "type": "ProjektInfoExtractor",
                  "description": "The instance on which the method is called."
                },
                {
                  "name": "patterns",
                  "type": "List[str]",
                  "description": "A list of filename patterns to match (e.g., \"readme.md\")."
                },
                {
                  "name": "dateien",
                  "type": "List[Any]",
                  "description": "A list of file objects that have a `path` attribute."
                }
              ],
              "returns": [
                {
                  "name": "matching_file",
                  "type": "Optional[Any]",
                  "description": "The first file object whose path matches one of the patterns, or None if no match is found."
                }
              ],
              "usage_context": {
                "calls": "This method does not call any other methods.",
                "called_by": "No other methods in this class are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "_extrahiere_sektion_aus_markdown",
            "description": {
              "overall": "Extracts the markdown section that follows a level\u20112 heading matching any of the supplied keywords. It builds a regular expression that matches headings like `## Features` and captures all text until the next heading of the same level or the end of the document. The captured block is stripped of surrounding whitespace and returned. If no matching heading is found, the method returns None.",
              "parameters": [
                {
                  "name": "self",
                  "type": "ProjektInfoExtractor",
                  "description": "The instance on which the method is called."
                },
                {
                  "name": "inhalt",
                  "type": "str",
                  "description": "The full markdown text to search within."
                },
                {
                  "name": "keywords",
                  "type": "List[str]",
                  "description": "A list of possible heading titles (e.g., \"Features\", \"Tech Stack\")."
                }
              ],
              "returns": [
                {
                  "name": "section_text",
                  "type": "Optional[str]",
                  "description": "The extracted section content without the heading, or None if no matching heading exists."
                }
              ],
              "usage_context": {
                "calls": "This method does not call any other methods.",
                "called_by": "No other methods in this class are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "_parse_readme",
            "description": {
              "overall": "Parses the content of a README file to fill various fields of the `info` dictionary. It first cleans the raw content, then extracts the title from the first level\u20111 heading, a brief description, key features, tech stack, current status, installation instructions, and a quick\u2011start guide using regular expressions and the markdown section extractor. Each piece of information is stored in the appropriate nested key of `self.info`. The method gracefully skips sections that are not found, leaving their placeholder values unchanged.",
              "parameters": [
                {
                  "name": "self",
                  "type": "ProjektInfoExtractor",
                  "description": "The instance on which the method is called."
                },
                {
                  "name": "inhalt",
                  "type": "str",
                  "description": "The raw text content of the README file."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method does not call any other methods.",
                "called_by": "No other methods in this class are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "_parse_toml",
            "description": {
              "overall": "Parses a pyproject.toml file to obtain project metadata. After cleaning the raw content, it attempts to load the TOML using the tomllib library. If successful, it extracts the project name, description, and dependencies, updating the corresponding entries in `self.info`. Errors during parsing are caught and reported via a warning message.",
              "parameters": [
                {
                  "name": "self",
                  "type": "ProjektInfoExtractor",
                  "description": "The instance on which the method is called."
                },
                {
                  "name": "inhalt",
                  "type": "str",
                  "description": "The raw text content of the pyproject.toml file."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method does not call any other methods.",
                "called_by": "No other methods in this class are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "_parse_requirements",
            "description": {
              "overall": "Parses a requirements.txt file to collect a list of dependencies. After cleaning the content, it splits the file into lines, discarding empty lines and comments. If the `dependencies` field has not already been populated by the TOML parser, the extracted list is stored in `self.info['installation']['dependencies']`. The method leaves the placeholder unchanged when no dependencies are found.",
              "parameters": [
                {
                  "name": "self",
                  "type": "ProjektInfoExtractor",
                  "description": "The instance on which the method is called."
                },
                {
                  "name": "inhalt",
                  "type": "str",
                  "description": "The raw text content of the requirements.txt file."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method does not call any other methods.",
                "called_by": "No other methods in this class are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "extrahiere_info",
            "description": {
              "overall": "Coordinates the overall extraction process for a repository. It first locates relevant files (README, pyproject.toml, requirements.txt) using `_finde_datei`. It then parses each file in order of priority: TOML first, then requirements, then README, populating the `info` structure. After parsing, it formats the dependencies list into a markdown\u2011style bullet list, and if the repository URL is provided, derives a fallback title from the URL when no title was found. Finally, it returns the fully populated `info` dictionary.",
              "parameters": [
                {
                  "name": "self",
                  "type": "ProjektInfoExtractor",
                  "description": "The instance on which the method is called."
                },
                {
                  "name": "dateien",
                  "type": "List[Any]",
                  "description": "A list of file objects that may include README, pyproject.toml, and requirements.txt."
                },
                {
                  "name": "repo_url",
                  "type": "str",
                  "description": "The URL of the repository; used to derive a fallback title if needed."
                }
              ],
              "returns": [
                {
                  "name": "info",
                  "type": "Dict[str, Any]",
                  "description": "A dictionary containing the extracted project overview and installation information."
                }
              ],
              "usage_context": {
                "calls": "This method does not call any other methods.",
                "called_by": "No other methods in this class are recorded as calling this method."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "The class does not depend on any external libraries beyond the standard library imports listed.",
          "instantiated_by": "No recorded locations instantiate this class."
        }
      },
      "error": null
    },
    "backend.callgraph.CallGraph": {
      "identifier": "backend.callgraph.CallGraph",
      "description": {
        "overall": "The **CallGraph** class is an `ast.NodeVisitor` that walks the abstract syntax tree of a Python source file and builds a directed call\u2011graph using a NetworkX `DiGraph`. It records definitions of functions and methods, resolves the fully\u2011qualified names of callees (including handling of imports and class scopes), and stores edges that map each caller to the set of callees it invokes. The resulting graph can be used to analyse intra\u2011module dependencies, detect dead code, or visualise call relationships.",
        "init_method": {
          "description": "Initialises a new `CallGraph` for a given source file. It stores the filename, prepares visitor state (current function/class), creates containers for local definitions, import mappings, the call\u2011graph, and edge collections.",
          "parameters": [
            {
              "name": "filename",
              "type": "str",
              "description": "Path to the Python source file that will be parsed and analysed."
            }
          ]
        },
        "methods": [
          {
            "identifier": "_recursive_call",
            "description": {
              "overall": "Recursively extracts the dotted name components from an AST node that represents a function call. It walks through `ast.Call`, `ast.Name`, and `ast.Attribute` nodes, building a list of identifiers that together form the call expression (e.g., `pkg.mod.Class.method`). If the node type is not one of the handled cases, it returns an empty list.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.AST",
                  "description": "The AST node to analyse \u2013 typically an `ast.Call`, `ast.Name` or `ast.Attribute`."
                }
              ],
              "returns": [
                {
                  "name": "",
                  "type": "list[str]",
                  "description": "A list of name components that constitute the dotted call expression."
                }
              ],
              "usage_context": {
                "calls": "This method does not call any other functions.",
                "called_by": "No other functions are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "_resolve_all_callee_names",
            "description": {
              "overall": "Takes a list of name\u2011component lists (as produced by `_recursive_call`) and resolves each to a fully qualified callee name. It first checks local definitions, then the import mapping, and finally falls back to constructing a name that includes the source filename and optional class context. The resolved names are returned as strings suitable for insertion into the call\u2011graph.",
              "parameters": [
                {
                  "name": "callee_nodes",
                  "type": "list[list[str]]",
                  "description": "A list where each element is a list of name components representing a potential callee."
                }
              ],
              "returns": [
                {
                  "name": "",
                  "type": "list[str]",
                  "description": "A list of resolved callee identifiers as strings."
                }
              ],
              "usage_context": {
                "calls": "This method does not call any other functions.",
                "called_by": "No other functions are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "_make_full_name",
            "description": {
              "overall": "Constructs a fully qualified name for a function or method by concatenating the source filename, an optional class name, and the base identifier. The format used is `filename::[class_name::]basename`.",
              "parameters": [
                {
                  "name": "basename",
                  "type": "str",
                  "description": "The simple name of the function or method."
                },
                {
                  "name": "class_name",
                  "type": "str | None",
                  "description": "The name of the enclosing class, if any."
                }
              ],
              "returns": [
                {
                  "name": "",
                  "type": "str",
                  "description": "The constructed fully qualified name."
                }
              ],
              "usage_context": {
                "calls": "This method does not call any other functions.",
                "called_by": "No other functions are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "_current_caller",
            "description": {
              "overall": "Returns the identifier of the function currently being visited. If no function is active, it falls back to a placeholder that includes the filename or a generic `<global-scope>` marker.",
              "parameters": [],
              "returns": [
                {
                  "name": "",
                  "type": "str",
                  "description": "The fully qualified name of the current caller or a placeholder string."
                }
              ],
              "usage_context": {
                "calls": "This method does not call any other functions.",
                "called_by": "No other functions are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_Import",
            "description": {
              "overall": "Visits an `import` statement, records each imported module in the `import_mapping` dictionary (using the alias if present), and then continues generic traversal of child nodes.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.Import",
                  "description": "The AST node representing an `import` statement."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method does not call any other functions.",
                "called_by": "No other functions are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_ImportFrom",
            "description": {
              "overall": "Handles `from \u2026 import \u2026` statements by mapping each imported name (or its alias) to the originating module name in `import_mapping`. The module name is reduced to its last component. After updating the mapping, generic traversal proceeds.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.ImportFrom",
                  "description": "The AST node representing a `from \u2026 import \u2026` statement."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method does not call any other functions.",
                "called_by": "No other functions are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_ClassDef",
            "description": {
              "overall": "When a class definition is encountered, the visitor records the class name in `current_class`, traverses the class body, and then restores the previous class context. This enables proper name resolution for methods defined inside the class.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.ClassDef",
                  "description": "The AST node representing a class definition."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method does not call any other functions.",
                "called_by": "No other functions are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_FunctionDef",
            "description": {
              "overall": "Processes a function or method definition. It builds a fully qualified name using `_make_full_name`, stores it in `local_defs` (both plain and class\u2011qualified keys), marks it as the current function, adds a node to the call\u2011graph, recursively visits the function body, and finally records the function in `function_set` before restoring the previous function context.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.FunctionDef",
                  "description": "The AST node representing a function or method definition."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method does not call any other functions.",
                "called_by": "No other functions are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_AsyncFunctionDef",
            "description": {
              "overall": "Delegates handling of asynchronous function definitions to `visit_FunctionDef`, thereby treating `async def` the same as regular functions for graph construction.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.AsyncFunctionDef",
                  "description": "The AST node representing an asynchronous function definition."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method does not call any other functions.",
                "called_by": "No other functions are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_Call",
            "description": {
              "overall": "Handles a function call expression. It determines the current caller via `_current_caller`, extracts the callee name components with `_recursive_call`, resolves them to fully qualified names using `_resolve_all_callee_names`, and records each caller\u2011callee edge in the `edges` dictionary. After updating the edges, it continues generic traversal.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.Call",
                  "description": "The AST node representing a function call."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method does not call any other functions.",
                "called_by": "No other functions are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_If",
            "description": {
              "overall": "Special\u2011cases `if __name__ == \"__main__\"` blocks. When such a block is detected, the visitor temporarily sets the current function to `<main_block>` so that any calls inside the block are attributed to a synthetic main entry. For all other `if` statements, normal generic traversal is performed.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.If",
                  "description": "The AST node representing an `if` statement."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method does not call any other functions.",
                "called_by": "No other functions are recorded as calling this method."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "The class does not have external dependencies listed.",
          "instantiated_by": "No locations are recorded where this class is instantiated."
        }
      },
      "error": null
    },
    "backend.getRepo.RepoFile": {
      "identifier": "backend.getRepo.RepoFile",
      "description": {
        "overall": "RepoFile represents a single file inside a Git repository. It lazily loads the underlying Git blob, its decoded text content, and its size only when those properties are accessed. The class also offers a small example analysis (word\u2011count), a helpful ``__repr__`` and a ``to_dict`` method for serialising the file\u2019s metadata (and optionally its content).",
        "init_method": {
          "description": "Initialisiert das RepoFile\u2011Objekt, speichert den relativen Pfad der Datei und das Tree\u2011Objekt des Commits, aus dem die Datei stammt. Alle lazily\u2011geladene Attribute (Blob, Inhalt und Gr\u00f6\u00dfe) werden zun\u00e4chst auf ``None`` gesetzt.",
          "parameters": [
            {
              "name": "file_path",
              "type": "str",
              "description": "Der Pfad zur Datei innerhalb des Repositories."
            },
            {
              "name": "commit_tree",
              "type": "git.Tree",
              "description": "Das Tree\u2011Objekt des Commits, aus dem die Datei stammt."
            }
          ]
        },
        "methods": [
          {
            "identifier": "blob",
            "description": {
              "overall": "The ``blob`` property lazily retrieves the Git blob that corresponds to the stored file path. On first access it looks up the blob in the commit tree; if the path is missing a ``FileNotFoundError`` is raised. Subsequent accesses return the cached blob object.",
              "parameters": [],
              "returns": [
                {
                  "name": "blob",
                  "type": "git.Blob",
                  "description": "The Git blob object representing the file."
                }
              ],
              "usage_context": {
                "calls": "The method does not call any other functions or methods.",
                "called_by": "No callers for this method were provided."
              }
            },
            "error": null
          },
          {
            "identifier": "content",
            "description": {
              "overall": "The ``content`` property lazily reads the blob\u2019s data stream, decodes it as UTF\u20118 (ignoring errors), and caches the resulting string. The first call triggers the lazy load; later calls return the cached text.",
              "parameters": [],
              "returns": [
                {
                  "name": "content",
                  "type": "str",
                  "description": "Decoded file content as a UTF\u20118 string."
                }
              ],
              "usage_context": {
                "calls": "The method does not call any other functions or methods.",
                "called_by": "No callers for this method were provided."
              }
            },
            "error": null
          },
          {
            "identifier": "size",
            "description": {
              "overall": "The ``size`` property lazily obtains the size (in bytes) of the underlying Git blob. The size is cached after the first retrieval.",
              "parameters": [],
              "returns": [
                {
                  "name": "size",
                  "type": "int",
                  "description": "Size of the file in bytes."
                }
              ],
              "usage_context": {
                "calls": "The method does not call any other functions or methods.",
                "called_by": "No callers for this method were provided."
              }
            },
            "error": null
          },
          {
            "identifier": "analyze_word_count",
            "description": {
              "overall": "``analyze_word_count`` is a simple example analysis method that counts how many words are present in the file\u2019s content. It accesses the ``content`` property (triggering lazy loading if necessary) and splits the text on whitespace.",
              "parameters": [],
              "returns": [
                {
                  "name": "word_count",
                  "type": "int",
                  "description": "Number of words in the file content."
                }
              ],
              "usage_context": {
                "calls": "The method does not call any other functions or methods.",
                "called_by": "No callers for this method were provided."
              }
            },
            "error": null
          },
          {
            "identifier": "__repr__",
            "description": {
              "overall": "Provides a concise string representation of the ``RepoFile`` instance, showing the class name and the stored file path. This aids debugging and logging.",
              "parameters": [],
              "returns": [
                {
                  "name": "repr_str",
                  "type": "str",
                  "description": "String representation like ``<RepoFile(path='...')>``."
                }
              ],
              "usage_context": {
                "calls": "The method does not call any other functions or methods.",
                "called_by": "No callers for this method were provided."
              }
            },
            "error": null
          },
          {
            "identifier": "to_dict",
            "description": {
              "overall": "Serialises the file\u2019s metadata into a dictionary containing the path, filename, size and a static type indicator. If ``include_content`` is ``True``, the decoded file content is also added to the dictionary.",
              "parameters": [
                {
                  "name": "include_content",
                  "type": "bool",
                  "description": "When ``True``, the file\u2019s text content is included under the ``content`` key."
                }
              ],
              "returns": [
                {
                  "name": "data",
                  "type": "dict",
                  "description": "Dictionary with file metadata (path, name, size, type) and optionally the file content."
                }
              ],
              "usage_context": {
                "calls": "The method does not call any other functions or methods.",
                "called_by": "No callers for this method were provided."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "The class does not have external runtime dependencies beyond the imported modules (git, os, etc.).",
          "instantiated_by": "No instantiation sites were supplied in the context."
        }
      },
      "error": null
    },
    "backend.getRepo.GitRepository": {
      "identifier": "backend.getRepo.GitRepository",
      "description": {
        "overall": "The **GitRepository** class encapsulates the lifecycle of a remote Git repository for the backend. It clones the repository into a temporary directory, exposes the list of files as `RepoFile` objects, can build a hierarchical file\u2011tree representation, and cleans up the temporary directory when finished. It also implements the context\u2011manager protocol so it can be used with a `with` statement for automatic resource handling.",
        "init_method": {
          "description": "The constructor receives a repository URL, creates a temporary directory, and attempts to clone the repository into that directory using `git.Repo.clone_from`. On success it stores the repository object, the latest commit, and the commit tree; on failure it cleans up and raises a runtime error.",
          "parameters": [
            {
              "name": "repo_url",
              "type": "str",
              "description": "URL of the Git repository to be cloned."
            }
          ]
        },
        "methods": [
          {
            "identifier": "get_all_files",
            "description": {
              "overall": "Retrieves every file tracked in the cloned repository, creates a `RepoFile` instance for each path using the commit tree, stores the collection in `self.files`, and returns the list. It uses `git ls-files` to obtain the file paths and filters out empty entries.",
              "parameters": [],
              "returns": [
                {
                  "name": "",
                  "type": "list[RepoFile]",
                  "description": "A list of `RepoFile` objects, one for each file in the repository."
                }
              ],
              "usage_context": {
                "calls": "Calls the `RepoFile` constructor for each discovered file path.",
                "called_by": "No other methods in the provided context explicitly call `get_all_files`."
              }
            },
            "error": null
          },
          {
            "identifier": "close",
            "description": {
              "overall": "Deletes the temporary directory that was created for the repository clone. The method currently only prints a message and clears the `temp_dir` attribute; actual filesystem removal is not performed in the shown code.",
              "parameters": [],
              "returns": [],
              "usage_context": {
                "calls": "Does not call any other functions.",
                "called_by": "Invoked by `__exit__` and also called from the constructor's exception handling path."
              }
            },
            "error": null
          },
          {
            "identifier": "__enter__",
            "description": {
              "overall": "Implements the context\u2011manager entry method; simply returns the `GitRepository` instance so it can be used inside a `with` block.",
              "parameters": [],
              "returns": [
                {
                  "name": "",
                  "type": "GitRepository",
                  "description": "The current `GitRepository` instance."
                }
              ],
              "usage_context": {
                "calls": "Does not call any other functions.",
                "called_by": "Used automatically when the class is employed in a `with` statement."
              }
            },
            "error": null
          },
          {
            "identifier": "__exit__",
            "description": {
              "overall": "Implements the context\u2011manager exit method; regardless of any exception information it calls `close()` to clean up the temporary directory.",
              "parameters": [
                {
                  "name": "exc_type",
                  "type": "type | None",
                  "description": "Exception type if an exception was raised inside the `with` block, otherwise `None`."
                },
                {
                  "name": "exc_val",
                  "type": "BaseException | None",
                  "description": "Exception instance if an exception was raised, otherwise `None`."
                },
                {
                  "name": "exc_tb",
                  "type": "TracebackType | None",
                  "description": "Traceback object associated with the exception, otherwise `None`."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "Calls the `close` method.",
                "called_by": "Invoked automatically when exiting a `with` block that uses a `GitRepository` instance."
              }
            },
            "error": null
          },
          {
            "identifier": "get_file_tree",
            "description": {
              "overall": "Builds a nested dictionary representing the repository's directory structure. If `self.files` is empty it first populates it via `get_all_files()`. It then iterates over each `RepoFile`, splits its path, creates intermediate directory nodes as needed, and appends the file representation (optionally including content) to the appropriate leaf node. The resulting structure starts with a root directory node.",
              "parameters": [
                {
                  "name": "include_content",
                  "type": "bool",
                  "description": "When `True`, each file node includes its file content; otherwise only metadata is added."
                }
              ],
              "returns": [
                {
                  "name": "",
                  "type": "dict",
                  "description": "A dictionary representing the hierarchical file tree, with keys `name`, `type`, and `children`."
                }
              ],
              "usage_context": {
                "calls": "Calls `get_all_files` if the file list is not yet populated, and calls each `RepoFile.to_dict` method while constructing the tree.",
                "called_by": "No other methods in the provided context directly call `get_file_tree`."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "This class depends on the `RepoFile` class from `backend.getRepo` and on external libraries `git` (for `Repo` and `GitCommandError`) and `tempfile` for temporary directory handling.",
          "instantiated_by": "No instantiation sites are listed in the provided context."
        }
      },
      "error": null
    },
    "backend.relationship_analyzer.ProjectAnalyzer": {
      "identifier": "backend.relationship_analyzer.ProjectAnalyzer",
      "description": {
        "overall": "ProjectAnalyzer walks a Python project's directory tree, discovers all ``.py`` files, parses each file into an AST, records definitions of functions, methods, and classes, and then resolves call relationships between those definitions. It aggregates this information into a call\u2011graph mapping each callee to the callers that reference it, and can expose a simplified view of outgoing and incoming relationships. The class relies on helper utilities ``path_to_module`` and ``CallResolverVisitor`` to translate file paths into module names and to walk the AST for call sites. Its public interface consists of ``analyze`` to build the graph and ``get_raw_relationships`` to retrieve the relationship dictionaries.",
        "init_method": {
          "description": "The constructor stores the absolute path of the project root and initializes internal data structures used during analysis, including a dictionary for definitions, a ``defaultdict(list)`` for the call graph, a cache for parsed ASTs, and a set of directory names to ignore while walking the file system.",
          "parameters": [
            {
              "name": "project_root",
              "type": "str",
              "description": "Path to the root directory of the Python project to be analyzed."
            }
          ]
        },
        "methods": [
          {
            "identifier": "analyze",
            "description": {
              "overall": "The ``analyze`` method coordinates the full analysis workflow. It first calls ``_find_py_files`` to obtain a list of all Python source files under the project root, then iterates over that list invoking ``_collect_definitions`` for each file to build a map of functions, methods, and classes. A second pass over the same file list calls ``_resolve_calls`` to populate the call\u2011graph with caller\u2011callee relationships. After processing, it clears the temporary AST cache and returns the assembled ``call_graph``. This method does not directly call any external functions beyond the private helpers defined in the class.",
              "parameters": [
                {
                  "name": "self",
                  "type": "ProjectAnalyzer",
                  "description": "The instance on which the analysis is performed."
                }
              ],
              "returns": [
                {
                  "name": "call_graph",
                  "type": "defaultdict(list)",
                  "description": "A mapping from callee identifiers to a list of dictionaries describing each caller (file, line, etc.)."
                }
              ],
              "usage_context": {
                "calls": "This method does not call any other functions or methods.",
                "called_by": "No other functions or methods are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "get_raw_relationships",
            "description": {
              "overall": "``get_raw_relationships`` converts the internal ``call_graph`` into a pair of dictionaries that describe outgoing and incoming call relationships. It iterates over each callee entry and, for each caller record, adds the callee to the caller's outgoing set and the caller to the callee's incoming set. After processing, the sets are transformed into sorted lists to produce deterministic output. The method finally returns a dictionary containing the ``outgoing`` and ``incoming`` mappings.",
              "parameters": [
                {
                  "name": "self",
                  "type": "ProjectAnalyzer",
                  "description": "The instance containing the populated call graph."
                }
              ],
              "returns": [
                {
                  "name": "relationships",
                  "type": "dict",
                  "description": "A dictionary with keys ``outgoing`` and ``incoming`` mapping identifiers to sorted lists of related identifiers."
                }
              ],
              "usage_context": {
                "calls": "This method does not call any other functions or methods.",
                "called_by": "No other functions or methods are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "_find_py_files",
            "description": {
              "overall": "The private method ``_find_py_files`` walks the directory tree rooted at ``self.project_root`` using ``os.walk``. It filters out any directories listed in ``self.ignore_dirs`` and collects the full paths of files that end with the ``.py`` extension. The resulting list of Python file paths is returned to the caller.",
              "parameters": [
                {
                  "name": "self",
                  "type": "ProjectAnalyzer",
                  "description": "The instance whose ``project_root`` and ``ignore_dirs`` are used."
                }
              ],
              "returns": [
                {
                  "name": "py_files",
                  "type": "list[str]",
                  "description": "A list of absolute file paths for all discovered Python source files."
                }
              ],
              "usage_context": {
                "calls": "This method does not call any other functions or methods.",
                "called_by": "No other functions or methods are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "_collect_definitions",
            "description": {
              "overall": "``_collect_definitions`` reads a Python source file, parses it into an abstract syntax tree (AST), and stores the AST in ``self.file_asts``. It then determines the module's dotted path using the external ``path_to_module`` helper. By walking the AST, it identifies function, method, and class definitions, constructs fully\u2011qualified names for each (including the containing class for methods), and records their file location, line number, and type in ``self.definitions``. Errors during file I/O or parsing are caught and logged, and a ``None`` placeholder is stored for the AST of the problematic file.",
              "parameters": [
                {
                  "name": "self",
                  "type": "ProjectAnalyzer",
                  "description": "The instance that holds the definitions dictionary and AST cache."
                },
                {
                  "name": "filepath",
                  "type": "str",
                  "description": "Absolute path to the Python file whose definitions are being collected."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls ``backend.relationship_analyzer.path_to_module``.",
                "called_by": "No other functions or methods are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "_get_parent",
            "description": {
              "overall": "The helper ``_get_parent`` searches the AST for the immediate parent node of a given node. It walks the entire tree, examining each node's children, and returns the first parent that directly contains the target node. If no parent is found, it returns ``None``.",
              "parameters": [
                {
                  "name": "self",
                  "type": "ProjectAnalyzer",
                  "description": "The instance (unused in the logic but kept for method signature consistency)."
                },
                {
                  "name": "tree",
                  "type": "ast.AST",
                  "description": "The root of the abstract syntax tree being inspected."
                },
                {
                  "name": "node",
                  "type": "ast.AST",
                  "description": "The AST node whose parent is sought."
                }
              ],
              "returns": [
                {
                  "name": "parent",
                  "type": "ast.AST | None",
                  "description": "The parent node of ``node`` if found, otherwise ``None``."
                }
              ],
              "usage_context": {
                "calls": "This method does not call any other functions or methods.",
                "called_by": "No other functions or methods are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "_resolve_calls",
            "description": {
              "overall": "``_resolve_calls`` retrieves a previously stored AST for a given file and, if present, creates a ``CallResolverVisitor`` (an external helper) to walk the tree and collect call information. The visitor populates a ``calls`` dictionary mapping callee identifiers to caller info lists. These results are merged into the class's ``call_graph``. Any exceptions raised during visitation are caught and logged.",
              "parameters": [
                {
                  "name": "self",
                  "type": "ProjectAnalyzer",
                  "description": "The instance that holds the ``call_graph`` and ``file_asts``."
                },
                {
                  "name": "filepath",
                  "type": "str",
                  "description": "Path to the Python file whose calls are being resolved."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls ``backend.relationship_analyzer.CallResolverVisitor``.",
                "called_by": "No other functions or methods are recorded as calling this method."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "It depends on ``CallResolverVisitor`` and ``path_to_module`` from ``backend.relationship_analyzer``.",
          "instantiated_by": "No known instantiation points are provided."
        }
      },
      "error": null
    },
    "backend.relationship_analyzer.CallResolverVisitor": {
      "identifier": "backend.relationship_analyzer.CallResolverVisitor",
      "description": {
        "overall": "CallResolverVisitor is an AST node visitor that analyses a Python module to resolve function and method calls to their fully\u2011qualified definitions. It tracks imports, class definitions, and instance creations to build a mapping from each callee (identified by its qualified name) to the locations where it is invoked. The visitor records caller information such as file name, line number, full identifier and caller type (module, function, method, or local function). This information can later be used to understand relationships between symbols across a code base.",
        "init_method": {
          "description": "The constructor stores the path of the file being analysed, computes its module path, and initialises several bookkeeping structures used during the AST walk.",
          "parameters": [
            {
              "name": "filepath",
              "type": "str",
              "description": "Absolute or relative path to the source file that is being visited."
            },
            {
              "name": "project_root",
              "type": "str",
              "description": "Root directory of the project; used together with ``filepath`` to compute the module path."
            },
            {
              "name": "definitions",
              "type": "Mapping[str, Any]",
              "description": "A collection (e.g., dict or set) of fully\u2011qualified names that are considered valid definitions for call resolution."
            }
          ]
        },
        "methods": [
          {
            "identifier": "visit_ClassDef",
            "description": {
              "overall": "When the visitor encounters a class definition node, it temporarily records the class name in ``self.current_class_name`` so that any functions defined inside the class can be identified as methods. It then recursively visits the class body using ``generic_visit`` and finally restores the previous class context. This enables the visitor to build fully\u2011qualified identifiers for methods that include the containing class name.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.ClassDef",
                  "description": "The AST node representing the class definition being visited."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method does not call any other functions directly.",
                "called_by": "No other functions are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_FunctionDef",
            "description": {
              "overall": "For each function (or method) definition, the visitor constructs a fully\u2011qualified identifier that includes the module path, optional class name, and function name. It stores this identifier in ``self.current_caller_name`` while traversing the function body, allowing subsequent call nodes to be linked back to the correct caller. After processing the body, the original caller context is restored.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.FunctionDef",
                  "description": "The AST node representing the function or method definition."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method does not call any other functions directly.",
                "called_by": "No other functions are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_Call",
            "description": {
              "overall": "When a call expression is visited, the visitor attempts to resolve the called object's qualified name using ``_resolve_call_qname``. If the resolved name exists in the supplied ``definitions`` set, it records caller information (file, line, full identifier, and caller type) in ``self.calls`` under the callee's name. Caller type is inferred from the current context (module, function, method, or local function). The method then continues traversing any child nodes.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.Call",
                  "description": "The AST node representing the function/method call."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls the internal helper ``_resolve_call_qname`` to obtain a qualified name for the callee.",
                "called_by": "No other functions are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_Import",
            "description": {
              "overall": "Processes ``import`` statements by adding each imported name (or its alias) to the ``self.scope`` dictionary, mapping the local name to its fully\u2011qualified module path. This scope is later used to resolve names during call resolution. After updating the scope, the method continues generic traversal of the import node.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.Import",
                  "description": "The AST node representing an import statement."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method does not call any other functions directly.",
                "called_by": "No other functions are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_ImportFrom",
            "description": {
              "overall": "Handles ``from ... import`` statements, including relative imports, by constructing the full module path for each imported name and storing it in ``self.scope``. It respects the import level to compute the correct package prefix. After populating the scope, it proceeds with generic traversal of the node.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.ImportFrom",
                  "description": "The AST node representing a ``from ... import`` statement."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method does not call any other functions directly.",
                "called_by": "No other functions are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_Assign",
            "description": {
              "overall": "When an assignment is visited, the method checks whether the right\u2011hand side is a call to a class that is known in ``self.scope`` and also present in ``self.definitions``. If so, it records the variable name in ``self.instance_types`` with the qualified class name, enabling later resolution of method calls on that instance. The visitor then continues generic traversal of the assignment node.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.Assign",
                  "description": "The AST node representing an assignment statement."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method does not call any other functions directly.",
                "called_by": "No other functions are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "_resolve_call_qname",
            "description": {
              "overall": "Resolves a function or method node to its fully\u2011qualified name. If the node is a simple name, it looks it up in ``self.scope`` or builds a module\u2011local name. If the node is an attribute access on a known instance, it combines the stored class path with the attribute name. Returns ``None`` when the name cannot be resolved.",
              "parameters": [
                {
                  "name": "func_node",
                  "type": "ast.AST",
                  "description": "The AST node representing the function part of a call expression (either ``ast.Name`` or ``ast.Attribute``)."
                }
              ],
              "returns": [
                {
                  "name": "qualified_name",
                  "type": "str | None",
                  "description": "The fully\u2011qualified name of the called object if it could be resolved, otherwise ``None``."
                }
              ],
              "usage_context": {
                "calls": "This method does not call any other functions directly.",
                "called_by": "It is called by ``visit_Call`` to resolve the callee's qualified name."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "The class depends on the function ``path_to_module`` from the module ``backend.relationship_analyzer``.",
          "instantiated_by": "No known instantiation sites are provided in the context."
        }
      },
      "error": null
    },
    "schemas.types.ParameterDescription": {
      "identifier": "schemas.types.ParameterDescription",
      "description": {
        "overall": "ParameterDescription is a lightweight Pydantic model that encapsulates metadata for a single function parameter. It stores the parameter's name, its type (as a string), and a human\u2011readable description. By inheriting from BaseModel, it gains automatic validation, serialization, and an autogenerated __init__ that accepts the three fields as keyword arguments.",
        "init_method": {
          "description": "The class does not define an explicit __init__; Pydantic's BaseModel provides an autogenerated initializer that accepts the declared fields (name, type, description) as keyword arguments and validates them according to their type hints.",
          "parameters": []
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class only relies on standard typing imports and Pydantic's BaseModel; no additional runtime dependencies are required.",
          "instantiated_by": "No instantiation sites were supplied, so the places where ParameterDescription is created are unknown."
        }
      },
      "error": null
    },
    "schemas.types.ReturnDescription": {
      "identifier": "schemas.types.ReturnDescription",
      "description": {
        "overall": "ReturnDescription is a Pydantic model that encapsulates metadata about a function's return value. It defines three fields\u2014`name`, `type`, and `description`\u2014which store the return variable's identifier, its type as a string, and a human\u2011readable description respectively. This model can be used by documentation generators or API schema tools to convey detailed return information for functions.",
        "init_method": {
          "description": "The class relies on the default initializer supplied by `pydantic.BaseModel`, which accepts the defined fields as keyword arguments and performs validation automatically.",
          "parameters": []
        },
        "methods": [],
        "usage_context": {
          "dependencies": "The class does not have any external runtime dependencies beyond the imported modules listed (e.g., `pydantic.BaseModel`).",
          "instantiated_by": "No instantiation sites are provided in the current context."
        }
      },
      "error": null
    },
    "schemas.types.UsageContext": {
      "identifier": "schemas.types.UsageContext",
      "description": {
        "overall": "UsageContext is a lightweight Pydantic model that captures the calling context of a function. It stores two string fields: `calls`, which records the functions that are invoked, and `called_by`, which records the functions that invoke the current function. The model provides automatic validation and serialization via Pydantic's BaseModel, making it easy to pass around contextual information within the system.",
        "init_method": {
          "description": "The class relies on Pydantic's generated `__init__` method, which accepts the declared fields as keyword arguments and performs type validation.",
          "parameters": []
        },
        "methods": [],
        "usage_context": {
          "dependencies": "The class does not have external dependencies beyond the imported modules.",
          "instantiated_by": "There is no information about where this class is instantiated."
        }
      },
      "error": null
    },
    "schemas.types.FunctionDescription": {
      "identifier": "schemas.types.FunctionDescription",
      "description": {
        "overall": "FunctionDescription is a Pydantic model that encapsulates a comprehensive description of a function, including a textual overall summary, a list of parameter descriptions, a list of return descriptions, and contextual usage information.",
        "init_method": {
          "description": "The class inherits from pydantic.BaseModel, so its constructor is provided by BaseModel and initializes the fields `overall`, `parameters`, `returns`, and `usage_context` from the arguments passed when an instance is created.",
          "parameters": []
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class has no external dependencies.",
          "instantiated_by": "No parts of the codebase are shown to instantiate this class."
        }
      },
      "error": null
    },
    "schemas.types.FunctionAnalysis": {
      "identifier": "schemas.types.FunctionAnalysis",
      "description": {
        "overall": "FunctionAnalysis is a Pydantic model that encapsulates the complete JSON schema for representing a function's analysis. It stores the function identifier, a nested FunctionDescription object describing the function, and an optional error message. The model serves as the top\u2011level container for serializing and validating function analysis data.",
        "init_method": {
          "description": "The class relies on Pydantic's BaseModel for initialization; no custom __init__ is defined, so instance fields are set directly via BaseModel's constructor.",
          "parameters": []
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class does not depend on any external modules beyond the standard typing imports and Pydantic.",
          "instantiated_by": "No specific locations are indicated where this class is instantiated."
        }
      },
      "error": null
    },
    "schemas.types.ConstructorDescription": {
      "identifier": "schemas.types.ConstructorDescription",
      "description": {
        "overall": "The `ConstructorDescription` class is a Pydantic model that captures a textual description of a class's `__init__` method together with a list of its parameters. It serves as a structured container for documenting how a constructor is defined, enabling downstream tooling to render or validate constructor metadata.",
        "init_method": {
          "description": "The class does not define an explicit `__init__` method; it inherits the default initializer from `pydantic.BaseModel`, which accepts the declared fields (`description` and `parameters`) as keyword arguments.",
          "parameters": []
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class does not depend on any external modules beyond the imports already listed (typing and pydantic).",
          "instantiated_by": "No parts of the provided codebase are shown to instantiate this class."
        }
      },
      "error": null
    },
    "schemas.types.ClassContext": {
      "identifier": "schemas.types.ClassContext",
      "description": {
        "overall": "ClassContext is a lightweight Pydantic model that captures a component's external dependencies and the locations where it is instantiated. It stores these two pieces of information as string fields, enabling other parts of the system to query or serialize the context of a class.",
        "init_method": {
          "description": "ClassContext relies on the default Pydantic BaseModel initializer, which accepts the defined fields as keyword arguments.",
          "parameters": []
        },
        "methods": [],
        "usage_context": {
          "dependencies": "No external dependencies are listed for this class.",
          "instantiated_by": "There are no recorded locations where this class is instantiated."
        }
      },
      "error": null
    },
    "schemas.types.ClassDescription": {
      "identifier": "schemas.types.ClassDescription",
      "description": {
        "overall": "ClassDescription is a Pydantic model that encapsulates the full analysis of another class, including its overall purpose, constructor details, a list of its methods, and the context in which it is used.",
        "init_method": {
          "description": "No explicit __init__ method is defined; the class relies on Pydantic's default BaseModel initializer.",
          "parameters": []
        },
        "methods": [],
        "usage_context": {
          "dependencies": "",
          "instantiated_by": ""
        }
      },
      "error": null
    },
    "schemas.types.ClassAnalysis": {
      "identifier": "schemas.types.ClassAnalysis",
      "description": {
        "overall": "ClassAnalysis is a Pydantic model that defines the top\u2011level JSON schema used to represent a Python class analysis. It holds the class identifier, a nested description object containing detailed information about the class\u2019s constructor, methods, and usage, and an optional error field for reporting analysis problems.",
        "init_method": {
          "description": "The class does not define an explicit __init__ method; it relies on Pydantic's BaseModel initializer to accept the fields `identifier`, `description`, and `error` and store them as instance attributes.",
          "parameters": []
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class does not have external dependencies.",
          "instantiated_by": "No information about where this class is instantiated is provided."
        }
      },
      "error": null
    },
    "schemas.types.CallInfo": {
      "identifier": "schemas.types.CallInfo",
      "description": {
        "overall": "CallInfo is a lightweight Pydantic model that encapsulates metadata about a single call site discovered by the relationship analyzer. It records the source file, the caller's name, the kind of call (method, function, or module), and the line number where the call occurs. Instances of this model are stored in the `called_by` and `instantiated_by` collections to trace how functions and classes are used throughout the codebase.",
        "init_method": {
          "description": "The class is instantiated by providing the file name, caller name, call mode, and line number, which are stored as attributes on the model.",
          "parameters": [
            {
              "name": "file",
              "type": "str",
              "description": "Path or name of the source file where the call occurs."
            },
            {
              "name": "function",
              "type": "str",
              "description": "Name of the caller function or method."
            },
            {
              "name": "mode",
              "type": "str",
              "description": "Context type of the call, e.g., \"method\", \"function\", or \"module\"."
            },
            {
              "name": "line",
              "type": "int",
              "description": "Line number in the source file where the call is made."
            }
          ]
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class does not depend on external modules beyond the imported ones (typing and pydantic).",
          "instantiated_by": "No locations in the provided context instantiate CallInfo."
        }
      },
      "error": null
    },
    "schemas.types.FunctionContextInput": {
      "identifier": "schemas.types.FunctionContextInput",
      "description": {
        "overall": "The `FunctionContextInput` class is a Pydantic model that encapsulates structured information about a function's execution context. It records a list of function names that the analyzed function calls (`calls`) and a list of `CallInfo` objects representing locations where the function is invoked (`called_by`). This lightweight container is used by analysis tools to pass around call\u2011graph data in a typed, validated form.",
        "init_method": {
          "description": "The class relies on the automatically generated `__init__` method provided by `pydantic.BaseModel`. When instantiated, it accepts values for the `calls` and `called_by` fields, validates their types, and stores them as instance attributes.",
          "parameters": []
        },
        "methods": [],
        "usage_context": {
          "dependencies": "The class does not depend on any external modules beyond the standard `typing` imports and the Pydantic library already listed in the file imports.",
          "instantiated_by": "There are no recorded locations where `FunctionContextInput` is instantiated."
        }
      },
      "error": null
    },
    "schemas.types.FunctionAnalysisInput": {
      "identifier": "schemas.types.FunctionAnalysisInput",
      "description": {
        "overall": "FunctionAnalysisInput is a Pydantic model that defines the schema for the input required to generate a FunctionAnalysis object. It contains fields for the operation mode (restricted to the literal value \"function_analysis\"), the identifier of the function to be analyzed, the raw source code string, a list of import statements, and a nested context object describing function\u2011specific information. The class relies on BaseModel for validation and automatic attribute creation, providing a structured and type\u2011checked way to pass analysis data throughout the system.",
        "init_method": {
          "description": "The class does not define a custom __init__ method; it inherits BaseModel's initializer, which automatically creates instance attributes from the declared fields.",
          "parameters": []
        },
        "methods": [],
        "usage_context": {
          "dependencies": "The class does not have any external dependencies beyond the imports listed in the file.",
          "instantiated_by": "There are no recorded locations that instantiate this class."
        }
      },
      "error": null
    },
    "schemas.types.MethodContextInput": {
      "identifier": "schemas.types.MethodContextInput",
      "description": {
        "overall": "MethodContextInput is a Pydantic model that encapsulates structured information about a class method's execution context. It stores the method's identifier, a list of calls made by the method, information about callers via CallInfo objects, the argument names, and an optional docstring. This model can be used to pass method metadata throughout the system.",
        "init_method": {
          "description": "The class inherits from Pydantic's BaseModel, which automatically generates an __init__ method that accepts values for each declared field. No explicit constructor is defined in the source code.",
          "parameters": []
        },
        "methods": [],
        "usage_context": {
          "dependencies": "The class does not have external dependencies in the provided context.",
          "instantiated_by": "The class is not shown to be instantiated anywhere in the provided context."
        }
      },
      "error": null
    },
    "schemas.types.ClassContextInput": {
      "identifier": "schemas.types.ClassContextInput",
      "description": {
        "overall": "ClassContextInput is a Pydantic model that encapsulates the structured context required for analyzing another class. It holds three fields: a list of dependency names (`dependencies`), a list of `CallInfo` objects describing where the class is instantiated (`instantiated_by`), and a list of `MethodContextInput` objects that capture call relationships for each method (`method_context`). This model serves as a container for all external information needed during class\u2011level analysis.",
        "init_method": {
          "description": "The class inherits from `pydantic.BaseModel`, so it uses the default BaseModel initializer which accepts the defined fields as keyword arguments.",
          "parameters": []
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class does not declare any external dependencies.",
          "instantiated_by": "No information is provided about where instances of this class are created."
        }
      },
      "error": null
    },
    "schemas.types.ClassAnalysisInput": {
      "identifier": "schemas.types.ClassAnalysisInput",
      "description": {
        "overall": "ClassAnalysisInput is a Pydantic model that encapsulates all data required to perform a class\u2011analysis operation. It stores the analysis mode, the identifier of the target class, the raw source code, any import statements needed for parsing, and a context object describing dependencies and instantiation sites. The model is used as the standardized input for downstream documentation\u2011generation pipelines.",
        "init_method": {
          "description": "The class is instantiated by providing values for all declared fields; Pydantic generates an __init__ that assigns each argument to a corresponding instance attribute.",
          "parameters": [
            {
              "name": "mode",
              "type": "Literal[\"class_analysis\"]",
              "description": "A literal flag indicating that the input is for a class analysis operation; must be the string \"class_analysis\"."
            },
            {
              "name": "identifier",
              "type": "str",
              "description": "The name of the class that will be analysed."
            },
            {
              "name": "source_code",
              "type": "str",
              "description": "The full source code of the target class as a string."
            },
            {
              "name": "imports",
              "type": "List[str]",
              "description": "A list of import statements (as strings) that appear in the source file containing the target class."
            },
            {
              "name": "context",
              "type": "ClassContextInput",
              "description": "An object that provides additional analysis context such as external dependencies and locations where the class is instantiated."
            }
          ]
        },
        "methods": [],
        "usage_context": {
          "dependencies": "",
          "instantiated_by": ""
        }
      },
      "error": null
    }
  }
}