{
  "functions": {
    "backend.AST_Schema.path_to_module": {
      "identifier": "backend.AST_Schema.path_to_module",
      "description": {
        "overall": "The function `path_to_module` converts a filesystem file path into a Python dotted module path relative to a given project root. It first attempts to compute the relative path using `os.path.relpath`; if that fails, it falls back to using the file's basename. The function strips a trailing `.py` extension and replaces path separators with dots. If the resulting module path ends with `.__init__`, that suffix is removed before returning the final module name.",
        "parameters": [
          {
            "name": "filepath",
            "type": "str",
            "description": "The absolute or relative path to the file whose module name is to be derived."
          },
          {
            "name": "project_root",
            "type": "str",
            "description": "The root directory of the Python project used as the base for computing the relative path."
          }
        ],
        "returns": [
          {
            "name": "",
            "type": "str",
            "description": "The dotted module path corresponding to the given file, with any trailing `.__init__` removed."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "backend.File_Dependency.build_file_dependency_graph": {
      "identifier": "backend.File_Dependency.build_file_dependency_graph",
      "description": {
        "overall": "The function builds a directed dependency graph for a given source file. It creates an empty NetworkX DiGraph, then instantiates a FileDependencyGraph visitor with the filename and repository root. The visitor traverses the provided AST to collect import relationships, which are stored in `import_dependencies`. The function iterates over these relationships, adding callers and callees as nodes and edges to the graph, and finally returns the populated graph.",
        "parameters": [
          {
            "name": "filename",
            "type": "str",
            "description": "The name of the file for which the dependency graph is being constructed."
          },
          {
            "name": "tree",
            "type": "AST",
            "description": "The abstract syntax tree representing the parsed source code of the file."
          },
          {
            "name": "repo_root",
            "type": "str",
            "description": "The root directory path of the repository containing the file."
          }
        ],
        "returns": [
          {
            "name": "graph",
            "type": "nx.DiGraph",
            "description": "A directed graph where nodes are modules/files and edges represent import (caller \u2192 callee) relationships."
          }
        ],
        "usage_context": {
          "calls": "This function calls backend.File_Dependency.FileDependencyGraph.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "backend.File_Dependency.build_repository_graph": {
      "identifier": "backend.File_Dependency.build_repository_graph",
      "description": {
        "overall": "The function `build_repository_graph` constructs a dependency graph for an entire Git repository. It retrieves all files from the repository and filters to Python source files. For each Python file, it parses the file content into an AST, derives a filename, and invokes `backend.File_Dependency.build_file_dependency_graph` to obtain a per\u2011file dependency graph. Nodes and edges from each per\u2011file graph are merged into a single global directed graph using NetworkX. The resulting `nx.DiGraph` representing cross\u2011file dependencies is returned.",
        "parameters": [
          {
            "name": "repository",
            "type": "GitRepository",
            "description": "The GitRepository instance from which files are retrieved."
          }
        ],
        "returns": [
          {
            "name": "",
            "type": "nx.DiGraph",
            "description": "A NetworkX directed graph that aggregates file\u2011level dependency relationships across the repository."
          }
        ],
        "usage_context": {
          "calls": "This function calls backend.File_Dependency.build_file_dependency_graph.",
          "called_by": "No functions are listed as callers of this function."
        }
      },
      "error": null
    },
    "backend.File_Dependency.get_all_temp_files": {
      "identifier": "backend.File_Dependency.get_all_temp_files",
      "description": {
        "overall": "The function `get_all_temp_files` receives a directory path as a string, resolves it to an absolute `Path`, and searches recursively for all Python files (`*.py`) within that directory. It uses `Path.rglob` to locate matching files and builds a list of each file's path relative to the root directory. The resulting list of relative `Path` objects is then returned to the caller. This provides a convenient way to enumerate all temporary Python files in a given folder hierarchy.",
        "parameters": [
          {
            "name": "directory",
            "type": "str",
            "description": "The filesystem directory (as a string) in which to search for Python files."
          }
        ],
        "returns": [
          {
            "name": "",
            "type": "list[Path]",
            "description": "A list containing `Path` objects representing the relative paths of all `.py` files found under the given directory."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "backend.HelperLLM.main_orchestrator": {
      "identifier": "backend.HelperLLM.main_orchestrator",
      "description": {
        "overall": "The `main_orchestrator` function serves as a test harness that prepares dummy analysis inputs for several inventory\u2011related methods. It constructs `FunctionAnalysisInput` objects for `add_item`, `check_stock`, and `generate_report`, validates them, and also builds a `ClassAnalysisInput` for the `InventoryManager` class. After setting up these objects, it invokes an `LLMHelper` instance to generate documentation for the functions by calling `generate_for_functions`. The resulting documentation objects are collected, logged, and finally printed as a formatted JSON structure. The function performs no I/O beyond logging and printing and does not return a value.",
        "parameters": [],
        "returns": [],
        "usage_context": {
          "calls": "This function calls backend.HelperLLM.LLMHelper, schemas.types.ClassAnalysisInput, and schemas.types.ClassContextInput.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "backend.callgraph.make_safe_dot": {
      "identifier": "backend.callgraph.make_safe_dot",
      "description": {
        "overall": "The function generates a DOT representation of a directed graph with node identifiers sanitized for DOT compatibility. It builds a mapping from each original node to a safe placeholder name such as \"n0\", relabels the graph using this mapping, and records the original node name in a \"label\" attribute on the new node. After relabeling, it writes the resulting graph to the provided file path using NetworkX's write_dot utility. The function performs these steps without returning any value.",
        "parameters": [
          {
            "name": "graph",
            "type": "nx.DiGraph",
            "description": "The directed graph whose nodes will be relabeled and exported."
          },
          {
            "name": "out_path",
            "type": "str",
            "description": "Filesystem path where the generated DOT file will be saved."
          }
        ],
        "returns": [],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "No functions call this function."
        }
      },
      "error": null
    },
    "backend.callgraph.build_filtered_callgraph": {
      "identifier": "backend.callgraph.build_filtered_callgraph",
      "description": {
        "overall": "The function build_filtered_callgraph constructs a call graph for a given Git repository and filters it to include only functions defined within the repository itself. It iterates over all Python files in the repository, parses their abstract syntax trees, and uses a CallGraph visitor to collect defined functions and call relationships. After gathering the set of own functions, it builds a global directed graph, adding edges only when both caller and callee belong to the repository's own functions. Finally, the filtered directed graph is returned as a NetworkX DiGraph.",
        "parameters": [
          {
            "name": "repo",
            "type": "GitRepository",
            "description": "A repository object providing access to the project's files via methods such as get_all_files()."
          }
        ],
        "returns": [
          {
            "name": "global_graph",
            "type": "nx.DiGraph",
            "description": "A directed graph (NetworkX DiGraph) representing call relationships between functions that are defined within the repository."
          }
        ],
        "usage_context": {
          "calls": "This function calls backend.callgraph.CallGraph.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "backend.converter.wrap_cdata": {
      "identifier": "backend.converter.wrap_cdata",
      "description": {
        "overall": "The function `wrap_cdata` takes a piece of content and returns it enclosed within CDATA tags. It constructs a string that starts with the CDATA opening marker, includes a newline, the original content, another newline, and the CDATA closing marker. The implementation uses an f\u2011string to embed the provided content directly into the CDATA template. No external resources or side effects are involved; the function simply returns the newly formatted string.",
        "parameters": [
          {
            "name": "content",
            "type": "str",
            "description": "The text or data that should be wrapped inside CDATA tags."
          }
        ],
        "returns": [
          {
            "name": "",
            "type": "str",
            "description": "A string containing the original content surrounded by CDATA delimiters."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "backend.converter.extract_output_content": {
      "identifier": "backend.converter.extract_output_content",
      "description": {
        "overall": "The function `extract_output_content` iterates over a collection of notebook output objects and extracts textual content or image placeholders. For each output, it checks the output type and, when appropriate, processes image data encoded in Base64, adding a placeholder XML tag to the result list while also storing the raw image data in the supplied `image_list`. If the output contains plain text or stream data, that text is appended directly. Errors are captured as simple string messages. The function finally returns a list of extracted strings and placeholders representing the original notebook outputs.",
        "parameters": [
          {
            "name": "outputs",
            "type": "Iterable[object]",
            "description": "A sequence of notebook output objects that may contain display data, stream text, or error information."
          },
          {
            "name": "image_list",
            "type": "list",
            "description": "A mutable list that will be populated with dictionaries describing extracted images (mime type and Base64 data)."
          }
        ],
        "returns": [
          {
            "name": "extracted_xml_snippets",
            "type": "list[str]",
            "description": "A list containing extracted plain\u2011text strings, XML image placeholders, or error messages for each processed output."
          }
        ],
        "usage_context": {
          "calls": "This function calls backend.converter.process_image.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "backend.converter.process_image": {
      "identifier": "backend.converter.process_image",
      "description": {
        "overall": "The function process_image extracts a base64\u2011encoded image string from a global data mapping based on the supplied MIME type. If the MIME type exists, it cleans newline characters from the string, records the image and its MIME type in a global image_list, and returns an HTML\u2011like placeholder referencing the image index. If an exception occurs while handling the data, it returns an error message containing the exception details. When the MIME type is absent, the function returns None.",
        "parameters": [
          {
            "name": "mime_type",
            "type": "str",
            "description": "The MIME type of the image to be processed."
          }
        ],
        "returns": [
          {
            "name": "placeholder_or_error",
            "type": "str",
            "description": "An HTML placeholder string for the image or an error message if decoding fails."
          },
          {
            "name": "no_match",
            "type": "None",
            "description": "Returned when the provided MIME type is not present in the data dictionary."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "backend.converter.convert_notebook_to_xml": {
      "identifier": "backend.converter.convert_notebook_to_xml",
      "description": {
        "overall": "The function `convert_notebook_to_xml` takes the raw content of a Jupyter notebook, parses it using nbformat, and converts each cell into an XML representation. It handles markdown cells by embedding their source directly, and code cells by wrapping the source in CDATA sections. For code cells with outputs, it extracts output content and any embedded images, wraps the output in CDATA, and adds it as an output cell. The function returns the concatenated XML string together with a list of extracted images, or an error XML string if parsing fails.",
        "parameters": [
          {
            "name": "file_content",
            "type": "str",
            "description": "The raw notebook file content, typically a JSON string representing the notebook."
          }
        ],
        "returns": [
          {
            "name": "result",
            "type": "Tuple[str, List]",
            "description": "A tuple where the first element is the generated XML string (or an error XML string) and the second element is a list of extracted images."
          }
        ],
        "usage_context": {
          "calls": "This function calls backend.converter.extract_output_content and backend.converter.wrap_cdata.",
          "called_by": "No functions call this function."
        }
      },
      "error": null
    },
    "backend.converter.process_repo_notebooks": {
      "identifier": "backend.converter.process_repo_notebooks",
      "description": {
        "overall": "The function processes a collection of repository files to locate Jupyter notebook files. It filters the input list for entries whose path ends with the '.ipynb' extension and logs the number of notebooks found. For each notebook, it logs the processing step, converts the notebook content to XML and extracts any images using the convert_notebook_to_xml function, and stores the results in a dictionary keyed by the notebook's path. Finally, it returns the dictionary containing the XML output and associated images for each processed notebook.",
        "parameters": [
          {
            "name": "repo_files",
            "type": "list",
            "description": "A list (or iterable) of file objects from a repository, each expected to have 'path' and 'content' attributes."
          }
        ],
        "returns": [
          {
            "name": "results",
            "type": "dict",
            "description": "A dictionary mapping each notebook's path to another dictionary with keys 'xml' (the converted XML string) and 'images' (any extracted images)."
          }
        ],
        "usage_context": {
          "calls": "This function calls backend.converter.convert_notebook_to_xml.",
          "called_by": "No functions call this function."
        }
      },
      "error": null
    },
    "backend.main.create_savings_chart": {
      "identifier": "backend.main.create_savings_chart",
      "description": {
        "overall": "The function creates a bar chart that compares token counts between two formats, JSON and TOON, and saves the chart to a file. It first prepares labels, values, and colors for the two bars. Using Matplotlib, it draws the bars, adds a title that includes the savings percentage, labels the y\u2011axis, and displays the exact token counts above each bar. Finally, it writes the figure to the specified output path and closes the plot to free resources.",
        "parameters": [
          {
            "name": "json_tokens",
            "type": "int or float",
            "description": "Number of tokens counted for the JSON representation."
          },
          {
            "name": "toon_tokens",
            "type": "int or float",
            "description": "Number of tokens counted for the TOON representation."
          },
          {
            "name": "savings_percent",
            "type": "float",
            "description": "Percentage of token savings, displayed in the chart title."
          },
          {
            "name": "output_path",
            "type": "str",
            "description": "Filesystem path where the generated chart image will be saved."
          }
        ],
        "returns": [],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "No functions are documented as calling this function."
        }
      },
      "error": null
    },
    "backend.main.calculate_net_time": {
      "identifier": "backend.main.calculate_net_time",
      "description": {
        "overall": "The function `calculate_net_time` computes the effective elapsed time between a start and end timestamp, subtracting any artificial sleep periods that are introduced for rate\u2011limit handling. It first determines the raw duration by subtracting `start_time` from `end_time`. If the provided `model_name` does not begin with the prefix \"gemini-\", the raw duration is returned unchanged. For Gemini models, it calculates how many batches are needed for the given `total_items` and `batch_size`, derives the number of required sleep intervals (one less than the number of batches), multiplies this by a fixed 61\u2011second pause, and subtracts the total sleep time from the raw duration. The final result is clamped to a minimum of zero before being returned.",
        "parameters": [
          {
            "name": "start_time",
            "type": "int | float",
            "description": "The timestamp marking the beginning of the operation."
          },
          {
            "name": "end_time",
            "type": "int | float",
            "description": "The timestamp marking the end of the operation."
          },
          {
            "name": "total_items",
            "type": "int",
            "description": "The total number of items that will be processed."
          },
          {
            "name": "batch_size",
            "type": "int",
            "description": "The maximum number of items that can be processed in a single batch."
          },
          {
            "name": "model_name",
            "type": "str",
            "description": "Name of the model being used; determines whether rate\u2011limit sleep time should be subtracted."
          }
        ],
        "returns": [
          {
            "name": "net_time",
            "type": "int | float",
            "description": "The effective elapsed time after removing any sleep intervals, never less than zero."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "No other functions are documented as calling this function."
        }
      },
      "error": null
    },
    "backend.main.main_workflow": {
      "identifier": "backend.main.main_workflow",
      "description": {
        "overall": "The function orchestrates a complete analysis pipeline for a software repository provided via a user input string. It extracts a GitHub URL, clones the repository, gathers basic project information, builds a file tree, performs relationship and AST analyses, and enriches the AST with relationship data. The enriched data is then fed to a Helper LLM to generate documentation for each discovered function and class, after which a Main LLM creates a final report. Finally, the function returns the generated report together with execution metrics such as timing and token\u2011usage statistics.",
        "parameters": [
          {
            "name": "input",
            "type": "Any",
            "description": "Raw user input string that should contain a GitHub repository URL."
          },
          {
            "name": "api_keys",
            "type": "dict",
            "description": "Dictionary mapping service names (e.g., \"gemini\", \"gpt\", \"scadsllm\", \"ollama\") to their respective API keys or base URLs."
          },
          {
            "name": "model_names",
            "type": "dict",
            "description": "Dictionary specifying the model identifiers for the helper and main LLMs under the keys \"helper\" and \"main\"."
          },
          {
            "name": "status_callback",
            "type": "Any",
            "description": "Optional callable that receives status messages; if provided, it is invoked to report progress."
          }
        ],
        "returns": [
          {
            "name": "result",
            "type": "dict",
            "description": "A dictionary with two keys: \"report\" containing the final markdown report string, and \"metrics\" containing timing and token\u2011usage statistics."
          }
        ],
        "usage_context": {
          "calls": "This function calls backend.AST_Schema.ASTAnalyzer, backend.AST_Schema.ASTAnalyzer.analyze_repository, backend.AST_Schema.ASTAnalyzer.merge_relationship_data, backend.HelperLLM.LLMHelper, backend.HelperLLM.LLMHelper.generate_for_classes, backend.HelperLLM.LLMHelper.generate_for_functions, backend.MainLLM.MainLLM, backend.MainLLM.MainLLM.call_llm, backend.basic_info.ProjektInfoExtractor, backend.basic_info.ProjektInfoExtractor.extrahiere_info, backend.getRepo.GitRepository, backend.main.calculate_net_time, backend.main.create_savings_chart, backend.main.update_status, backend.relationship_analyzer.ProjectAnalyzer, backend.relationship_analyzer.ProjectAnalyzer.analyze, backend.relationship_analyzer.ProjectAnalyzer.get_raw_relationships, schemas.types.ClassAnalysisInput, schemas.types.ClassContextInput, schemas.types.FunctionAnalysisInput, schemas.types.FunctionContextInput, and schemas.types.MethodContextInput.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "backend.main.update_status": {
      "identifier": "backend.main.update_status",
      "description": {
        "overall": "The `update_status` function forwards a status message to a globally defined callback if one is present, and then records the same message using the standard logging facility. It accepts a single argument `msg` which represents the status information to be propagated. The function first checks the truthiness of `status_callback`; if it evaluates to true, it invokes `status_callback(msg)`. Finally, it logs the message at the INFO level via `logging.info(msg)`.",
        "parameters": [
          {
            "name": "msg",
            "type": "Any",
            "description": "The status message to be sent to the callback and logged."
          }
        ],
        "returns": [],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "backend.main.notebook_workflow": {
      "identifier": "backend.main.notebook_workflow",
      "description": {
        "overall": "The `notebook_workflow` function orchestrates a complete analysis pipeline for Jupyter notebooks stored in a GitHub repository. It extracts a repository URL from the provided input string, clones the repository, and converts all notebooks to an intermediate XML representation. Basic project information is extracted and combined with each notebook's content to build a payload that is sent to a language model (LLM) for report generation. The individual notebook reports are concatenated, saved to a timestamped markdown file, and a summary report together with execution metrics are returned.",
        "parameters": [
          {
            "name": "input",
            "type": "str",
            "description": "A text string containing the user\u2011provided input; the function searches this string for a GitHub repository URL."
          },
          {
            "name": "api_keys",
            "type": "dict",
            "description": "A dictionary mapping service identifiers (e.g., \"gpt\", \"gemini\", \"scadsllm\") to their corresponding API keys and optional base URLs."
          },
          {
            "name": "model",
            "type": "str",
            "description": "The name of the language\u2011model to use for generating notebook reports (e.g., \"gpt-4\", \"gemini-pro\")."
          },
          {
            "name": "status_callback",
            "type": "Callable[[str], None] | None",
            "description": "An optional callable that receives status messages; if provided, it is invoked to report progress."
          }
        ],
        "returns": [
          {
            "name": "result",
            "type": "dict",
            "description": "A dictionary with two keys: `report` (a markdown string containing the concatenated notebook analyses) and `metrics` (a dictionary of timing and model information)."
          }
        ],
        "usage_context": {
          "calls": "This function calls backend.MainLLM.MainLLM, backend.MainLLM.MainLLM.call_llm, backend.basic_info.ProjektInfoExtractor, backend.basic_info.ProjektInfoExtractor.extrahiere_info, backend.converter.process_repo_notebooks, backend.getRepo.GitRepository, backend.main.gemini_payload, and backend.main.update_status.",
          "called_by": "No functions call this function."
        }
      },
      "error": null
    },
    "backend.main.gemini_payload": {
      "identifier": "backend.main.gemini_payload",
      "description": {
        "overall": "The function constructs a payload suitable for the Gemini API by merging basic project information, the notebook path, and the notebook's XML content. It inserts a textual block that contains the serialized basic info and notebook path, then iterates through the XML to replace image placeholders with image URL blocks that embed base64\u2011encoded image data. Any remaining textual segments of the XML are added as separate text blocks. Finally, it returns the assembled list of content blocks.",
        "parameters": [
          {
            "name": "basic_info",
            "type": "dict",
            "description": "A JSON\u2011serializable collection of basic information about the project that will be included in the payload."
          },
          {
            "name": "nb_path",
            "type": "str",
            "description": "The file system path to the current notebook, inserted into the introductory JSON block."
          },
          {
            "name": "xml_content",
            "type": "str",
            "description": "The notebook's XML representation containing text and <IMAGE_PLACEHOLDER> tags that mark where images should be inserted."
          },
          {
            "name": "images",
            "type": "list[dict]",
            "description": "A list of image dictionaries; each dictionary must contain a 'data' key holding a base64\u2011encoded image string."
          }
        ],
        "returns": [
          {
            "name": "payload_content",
            "type": "list[dict]",
            "description": "A list of payload blocks where each block is a dictionary with a 'type' field (either \"text\" or \"image_url\") and the corresponding content."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "backend.relationship_analyzer.path_to_module": {
      "identifier": "backend.relationship_analyzer.path_to_module",
      "description": {
        "overall": "The function `path_to_module` converts a filesystem path to a Python dotted module path. It first attempts to compute a path relative to the provided project root using `os.path.relpath`; if that fails it falls back to using only the filename. It strips a trailing `.py` extension, replaces OS\u2011specific path separators with periods, and removes a trailing `.__init__` segment to represent package modules correctly. Finally, it returns the resulting module path as a string.",
        "parameters": [
          {
            "name": "filepath",
            "type": "str",
            "description": "The absolute or relative path to the Python file whose module path should be derived."
          },
          {
            "name": "project_root",
            "type": "str",
            "description": "The root directory of the project against which the file path is made relative."
          }
        ],
        "returns": [
          {
            "name": "module_path",
            "type": "str",
            "description": "A dotted string representing the module path corresponding to the given file, e.g., \"package.submodule\"."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.encrypt_text": {
      "identifier": "database.db.encrypt_text",
      "description": {
        "overall": "The function `encrypt_text` encrypts a given string using a globally defined cipher suite. It first checks whether the input text is falsy or whether the `cipher_suite` object is unavailable; in either case it returns the original text unchanged. If both are present, the function strips whitespace from the text, encodes it to bytes, encrypts it with the cipher suite, and decodes the resulting bytes back to a string. The returned value is therefore an encrypted string representation of the original input.",
        "parameters": [
          {
            "name": "text",
            "type": "str",
            "description": "The text string to be encrypted."
          }
        ],
        "returns": [
          {
            "name": "",
            "type": "str",
            "description": "The encrypted version of the input text, or the original text if the input is empty or the cipher suite is not available."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.decrypt_text": {
      "identifier": "database.db.decrypt_text",
      "description": {
        "overall": "The function `decrypt_text` is responsible for converting an encrypted string back to its original plaintext form. It first checks whether the input `text` is empty or whether the global `cipher_suite` object is unavailable; in either case it returns the input unchanged. If both are present, it strips whitespace, encodes the text to bytes, and uses `cipher_suite.decrypt` to attempt decryption, decoding the result back to a string. Any exception raised during decryption is caught, and the original input text is returned as a fallback.",
        "parameters": [
          {
            "name": "text",
            "type": "str",
            "description": "The encrypted text to be processed."
          }
        ],
        "returns": [
          {
            "name": "",
            "type": "str",
            "description": "The decrypted plaintext if decryption succeeds, otherwise the original input text."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not referenced by any other functions in the provided context."
        }
      },
      "error": null
    },
    "database.db.insert_user": {
      "identifier": "database.db.insert_user",
      "description": {
        "overall": "The function `insert_user` constructs a user document from the provided `username`, `name`, and `password`. It hashes the password using `stauth.Hasher.hash` and initializes several API\u2011key related fields with empty strings. The document is then inserted into the MongoDB collection `dbusers` via `insert_one`. Finally, the function returns the identifier of the newly inserted document.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The unique identifier for the user; stored as the `_id` field in the database document."
          },
          {
            "name": "name",
            "type": "str",
            "description": "The display name of the user; stored in the `name` field of the document."
          },
          {
            "name": "password",
            "type": "str",
            "description": "The user's plaintext password, which is hashed before being stored in the `hashed_password` field."
          }
        ],
        "returns": [
          {
            "name": "inserted_id",
            "type": "ObjectId",
            "description": "The identifier assigned by MongoDB to the newly inserted user document."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "It is not referenced by any other functions in the provided context."
        }
      },
      "error": null
    },
    "database.db.fetch_all_users": {
      "identifier": "database.db.fetch_all_users",
      "description": {
        "overall": "The function `fetch_all_users` retrieves every document from the `dbusers` collection in the database. It invokes the `find` method on the `dbusers` collection to obtain a cursor over all user records. The cursor is then converted into a concrete Python `list`. Finally, the list of user documents is returned to the caller.",
        "parameters": [],
        "returns": [
          {
            "name": "users",
            "type": "list",
            "description": "A list containing all user documents fetched from the `dbusers` collection."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not listed as being called by any other functions."
        }
      },
      "error": null
    },
    "database.db.fetch_user": {
      "identifier": "database.db.fetch_user",
      "description": {
        "overall": "The function `fetch_user` retrieves a user record from the `dbusers` collection based on a provided username. It accepts a single argument, `username`, which is used as the value for the `_id` field in the query. The function constructs a MongoDB query dictionary and delegates the lookup to the `find_one` method of the `dbusers` collection. The result of this database call is returned directly to the caller.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username identifier used to look up the user document; it is matched against the `_id` field in the collection."
          }
        ],
        "returns": [
          {
            "name": "user_document",
            "type": "dict | None",
            "description": "A dictionary representing the user document if a matching record is found, otherwise `None`."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "It is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.update_user_name": {
      "identifier": "database.db.update_user_name",
      "description": {
        "overall": "The function `update_user_name` updates the name field of a user document in a MongoDB collection. It accepts the user's identifier (`username`) and the desired new name (`new_name`) as string arguments. Using the `dbusers.update_one` method, it matches the document where the `_id` equals the provided username and sets the `name` field to the new value. The result of the update operation is stored in `result`, and the function returns the `modified_count` attribute, indicating how many documents were modified. This allows callers to verify whether the update was successful.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The identifier of the user whose name should be updated; used as the value for the `_id` field in the query."
          },
          {
            "name": "new_name",
            "type": "str",
            "description": "The new name to assign to the user's `name` field."
          }
        ],
        "returns": [
          {
            "name": "modified_count",
            "type": "int",
            "description": "The number of documents that were modified by the update operation."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions in the provided context."
        }
      },
      "error": null
    },
    "database.db.update_gemini_key": {
      "identifier": "database.db.update_gemini_key",
      "description": {
        "overall": "The function updates a user's stored Gemini API key in the MongoDB collection. It first removes surrounding whitespace from the provided key and encrypts it using the `encrypt_text` helper. The encrypted key is then written to the document whose `_id` matches the supplied username via an `$set` operation. Finally, the function returns the number of documents that were modified by the update.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The identifier of the user whose record will be updated; used as the `_id` field in the database query."
          },
          {
            "name": "gemini_api_key",
            "type": "str",
            "description": "The raw Gemini API key to be stored for the user; it will be stripped of whitespace and encrypted before persistence."
          }
        ],
        "returns": [
          {
            "name": "modified_count",
            "type": "int",
            "description": "The count of documents that were modified by the update operation (typically 0 or 1)."
          }
        ],
        "usage_context": {
          "calls": "This function calls database.db.encrypt_text.",
          "called_by": "No functions call this function."
        }
      },
      "error": null
    },
    "database.db.update_gpt_key": {
      "identifier": "database.db.update_gpt_key",
      "description": {
        "overall": "The function `update_gpt_key` updates a stored GPT API key for a given user in the database. It first strips whitespace from the provided key and encrypts it using `encrypt_text`. It then performs a MongoDB `update_one` operation on the `dbusers` collection, setting the `gpt_api_key` field to the encrypted value for the document whose `_id` matches the username. Finally, it returns the number of documents that were modified as an integer.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The identifier of the user whose GPT API key is being updated."
          },
          {
            "name": "gpt_api_key",
            "type": "str",
            "description": "The new GPT API key to store for the user."
          }
        ],
        "returns": [
          {
            "name": "modified_count",
            "type": "int",
            "description": "The number of documents that were modified by the update operation."
          }
        ],
        "usage_context": {
          "calls": "This function calls database.db.encrypt_text.",
          "called_by": "No functions are listed as callers of this function."
        }
      },
      "error": null
    },
    "database.db.update_ollama_url": {
      "identifier": "database.db.update_ollama_url",
      "description": {
        "overall": "The function `update_ollama_url` updates the stored Ollama base URL for a specific user in the MongoDB collection `dbusers`. It receives the username, which is used as the document `_id`, and the new URL string. The function performs an `update_one` operation, setting the `ollama_base_url` field to the stripped version of the provided URL. Finally, it returns the number of documents that were modified as an integer.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The identifier of the user whose document will be updated; used as the `_id` field in the collection."
          },
          {
            "name": "ollama_base_url",
            "type": "str",
            "description": "The new Ollama base URL to store for the user; whitespace is stripped before saving."
          }
        ],
        "returns": [
          {
            "name": "modified_count",
            "type": "int",
            "description": "The number of documents that were modified by the update operation."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "No other functions are documented as calling this function."
        }
      },
      "error": null
    },
    "database.db.update_opensrc_key": {
      "identifier": "database.db.update_opensrc_key",
      "description": {
        "overall": "The function `update_opensrc_key` updates a stored OpenSRC API key for a given user in the database. It first removes any surrounding whitespace from the provided key and encrypts it using the `encrypt_text` helper. The encrypted key is then written to the MongoDB collection via an `update_one` operation that matches the user by their username. Finally, the function returns the number of documents that were modified by the update operation.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The identifier of the user whose OpenSRC API key should be updated."
          },
          {
            "name": "opensrc_api_key",
            "type": "str",
            "description": "The raw OpenSRC API key to be encrypted and stored."
          }
        ],
        "returns": [
          {
            "name": "modified_count",
            "type": "int",
            "description": "The count of documents that were modified by the update operation (typically 0 or 1)."
          }
        ],
        "usage_context": {
          "calls": "This function calls database.db.encrypt_text.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.update_opensrc_url": {
      "identifier": "database.db.update_opensrc_url",
      "description": {
        "overall": "The function `update_opensrc_url` updates a user's Open Source base URL in the database. It receives a `username` and an `opensrc_base_url` string, removes any surrounding whitespace from the URL, and executes a MongoDB `update_one` operation on the `dbusers` collection, matching the document by its `_id` field. The update sets the `opensrc_base_url` field to the cleaned URL value. Finally, the function returns the number of documents that were modified by the operation.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The identifier of the user whose record is being updated; used as the `_id` field in the query."
          },
          {
            "name": "opensrc_base_url",
            "type": "str",
            "description": "The new Open Source base URL to store for the user; whitespace is stripped before saving."
          }
        ],
        "returns": [
          {
            "name": "modified_count",
            "type": "int",
            "description": "The count of documents that were modified by the update operation."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "No functions are listed as callers of this function."
        }
      },
      "error": null
    },
    "database.db.fetch_gemini_key": {
      "identifier": "database.db.fetch_gemini_key",
      "description": {
        "overall": "The function `fetch_gemini_key` retrieves a Gemini API key associated with a given username from a MongoDB collection named `dbusers`. It queries the collection for a document whose `_id` matches the provided username and projects only the `gemini_api_key` field. If a matching document is found, the function extracts and returns the API key; otherwise, it returns `None`. This provides a simple lookup utility for accessing stored Gemini credentials.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username (used as the document `_id`) for which the Gemini API key should be fetched."
          }
        ],
        "returns": [
          {
            "name": "",
            "type": "Optional[str]",
            "description": "The Gemini API key as a string if the user exists and the key is stored; otherwise `None`."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.fetch_ollama_url": {
      "identifier": "database.db.fetch_ollama_url",
      "description": {
        "overall": "The function `fetch_ollama_url` retrieves the Ollama base URL associated with a given username from the MongoDB collection `dbusers`. It queries the collection for a document whose `_id` matches the provided username, projecting only the `ollama_base_url` field. If a matching document is found, it extracts the `ollama_base_url` value; otherwise it returns `None`. The function therefore provides a simple lookup utility for obtaining a user's Ollama service endpoint.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username used as the document `_id` to look up the user's Ollama base URL."
          }
        ],
        "returns": [
          {
            "name": "",
            "type": "Optional[str]",
            "description": "The Ollama base URL string if the user exists, otherwise `None`."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "No other functions are listed as callers of this function."
        }
      },
      "error": null
    },
    "database.db.fetch_gpt_key": {
      "identifier": "database.db.fetch_gpt_key",
      "description": {
        "overall": "The function `fetch_gpt_key` retrieves a stored GPT API key for a given user from a MongoDB collection. It accepts a single parameter `username` of type `str`, which is used to query the `dbusers` collection for a document whose `_id` matches the provided username. The query projects only the `gpt_api_key` field, and the function returns the value of this field if a matching document is found. If no document is found, the function returns `None`.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username whose GPT API key is being retrieved."
          }
        ],
        "returns": [
          {
            "name": "",
            "type": "Optional[str]",
            "description": "The GPT API key associated with the user, or None if the user does not exist or has no key."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "No other functions are recorded as calling this function."
        }
      },
      "error": null
    },
    "database.db.fetch_opensrc_key": {
      "identifier": "database.db.fetch_opensrc_key",
      "description": {
        "overall": "The function `fetch_opensrc_key` retrieves the OpenSRC API key for a specified user from a MongoDB collection. It queries the `dbusers` collection for a document whose `_id` matches the provided `username`, projecting only the `opensrc_api_key` field. If a matching document exists, the function extracts and returns the API key; otherwise it returns `None`. No additional processing or error handling is performed within the function.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The identifier of the user whose OpenSRC API key should be fetched."
          }
        ],
        "returns": [
          {
            "name": "opensrc_api_key",
            "type": "Optional[str]",
            "description": "The OpenSRC API key associated with the user if it exists; otherwise `None`."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.fetch_opensrc_url": {
      "identifier": "database.db.fetch_opensrc_url",
      "description": {
        "overall": "The function fetch_opensrc_url retrieves the Open Source base URL associated with a given username from a MongoDB collection. It queries the `dbusers` collection for a document whose `_id` matches the provided username, projecting only the `opensrc_base_url` field. If a matching document is found, the function extracts and returns the URL; otherwise it returns `None`. The function expects a string username and returns either a string URL or `None`.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username (used as the document `_id`) whose Open Source base URL should be fetched from the database."
          }
        ],
        "returns": [
          {
            "name": "opensrc_base_url",
            "type": "Optional[str]",
            "description": "The Open Source base URL for the given user if the user exists; otherwise `None`."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.delete_user": {
      "identifier": "database.db.delete_user",
      "description": {
        "overall": "The `delete_user` function removes a user entry from the database. It takes a single argument `username`, which should be the unique identifier of the user to delete. The function invokes the `delete_one` method on the `dbusers` collection with a query matching the `_id` field to the provided username. It then returns the `deleted_count` attribute, an integer indicating how many records were removed.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username identifier of the user to be deleted."
          }
        ],
        "returns": [
          {
            "name": "",
            "type": "int",
            "description": "The number of documents deleted (0 if no matching user was found, 1 if the user was removed)."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "No other functions are documented as calling this function."
        }
      },
      "error": null
    },
    "database.db.get_decrypted_api_keys": {
      "identifier": "database.db.get_decrypted_api_keys",
      "description": {
        "overall": "The function retrieves a user's document from the MongoDB collection `dbusers` using the supplied username. If the user does not exist, it returns a pair of `None` values to indicate failure. When a user record is found, the function extracts encrypted API keys, decrypts them via `database.db.decrypt_text`, and also retrieves plain URL fields. It then assembles the decrypted Gemini, GPT, and OpenSource API keys together with the Ollama base URL and OpenSource base URL into a tuple of five strings, which it returns to the caller.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The identifier of the user whose API keys should be fetched; it is used as the `_id` field in the `dbusers` collection."
          }
        ],
        "returns": [
          {
            "name": "gemini_plain",
            "type": "str",
            "description": "Decrypted Gemini API key for the user."
          },
          {
            "name": "ollama_plain",
            "type": "str",
            "description": "Plain Ollama base URL stored for the user."
          },
          {
            "name": "gpt_plain",
            "type": "str",
            "description": "Decrypted GPT API key for the user."
          },
          {
            "name": "opensrc_plain",
            "type": "str",
            "description": "Decrypted OpenSource API key for the user."
          },
          {
            "name": "opensrc_url",
            "type": "str",
            "description": "Plain OpenSource base URL stored for the user."
          }
        ],
        "usage_context": {
          "calls": "This function calls database.db.decrypt_text.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.insert_chat": {
      "identifier": "database.db.insert_chat",
      "description": {
        "overall": "The function `insert_chat` creates a new chat record and stores it in a MongoDB collection. It generates a unique identifier for the chat using `uuid.uuid4()`, captures the current timestamp, and bundles these with the provided `username` and `chat_name` into a dictionary. The dictionary is then inserted into the `dbchats` collection via `insert_one`. Finally, the function returns the identifier of the newly inserted document.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The name of the user who owns the chat."
          },
          {
            "name": "chat_name",
            "type": "str",
            "description": "The name or title of the chat to be created."
          }
        ],
        "returns": [
          {
            "name": "inserted_id",
            "type": "ObjectId",
            "description": "The unique identifier assigned by MongoDB to the newly inserted chat document."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not referenced by any other functions in the provided context."
        }
      },
      "error": null
    },
    "database.db.fetch_chats_by_user": {
      "identifier": "database.db.fetch_chats_by_user",
      "description": {
        "overall": "The function fetch_chats_by_user retrieves all chat records associated with a specific username from the MongoDB collection `dbchats`. It filters documents where the `username` field matches the provided argument, sorts the results by the `created_at` timestamp in ascending order, and converts the cursor to a list. The sorted list of chat documents is then returned to the caller. This operation enables downstream code to access a user's chat history in chronological order.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username whose chat records should be fetched from the database."
          }
        ],
        "returns": [
          {
            "name": "chats",
            "type": "list",
            "description": "A list of chat documents (typically dictionaries) belonging to the specified user, ordered by creation time."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "It is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.check_chat_exists": {
      "identifier": "database.db.check_chat_exists",
      "description": {
        "overall": "The function `check_chat_exists` determines whether a chat with a given name exists for a specific user in the database. It accepts a username and a chat name as string arguments. It queries the `dbchats` collection using `find_one` with a filter that matches both the provided username and chat name. The function returns `True` if a matching document is found, otherwise `False`.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username of the user whose chats are being queried."
          },
          {
            "name": "chat_name",
            "type": "str",
            "description": "The name of the chat to check for existence."
          }
        ],
        "returns": [
          {
            "name": "",
            "type": "bool",
            "description": "True if a chat with the specified name exists for the given user, otherwise False."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "It is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.rename_chat_fully": {
      "identifier": "database.db.rename_chat_fully",
      "description": {
        "overall": "The function renames a chat belonging to a specific user and updates all related exchange records to reflect the new name. It first updates the chat document in the `dbchats` collection by setting the `chat_name` field to the new value. Afterwards it updates every message (exchange) in the `dbexchanges` collection that matches the user and the old chat name, also setting their `chat_name` to the new name. Finally, it returns the number of chat documents that were modified as an integer.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username of the owner of the chat to be renamed."
          },
          {
            "name": "old_name",
            "type": "str",
            "description": "The current name of the chat that should be changed."
          },
          {
            "name": "new_name",
            "type": "str",
            "description": "The desired new name for the chat."
          }
        ],
        "returns": [
          {
            "name": "modified_count",
            "type": "int",
            "description": "The number of chat documents that were updated (typically 0 or 1)."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "No functions are documented as calling this function."
        }
      },
      "error": null
    },
    "database.db.insert_exchange": {
      "identifier": "database.db.insert_exchange",
      "description": {
        "overall": "The function `insert_exchange` creates a new exchange record for storage in a MongoDB collection. It generates a unique identifier using UUID, assembles a dictionary containing the supplied question, answer, feedback, user and chat information, as well as optional timing and token usage metrics. The record also includes a creation timestamp generated at runtime. The function attempts to insert this document into the `dbexchanges` collection and returns the generated identifier if successful, otherwise it logs the error and returns `None`.",
        "parameters": [
          {
            "name": "question",
            "type": "str",
            "description": "The question text to be stored in the exchange."
          },
          {
            "name": "answer",
            "type": "str",
            "description": "The answer text corresponding to the question."
          },
          {
            "name": "feedback",
            "type": "str",
            "description": "Feedback associated with the exchange."
          },
          {
            "name": "username",
            "type": "str",
            "description": "The username of the participant who generated the exchange."
          },
          {
            "name": "chat_name",
            "type": "str",
            "description": "The name of the chat session where the exchange occurred."
          },
          {
            "name": "helper_used",
            "type": "str",
            "description": "Identifier of any helper model used; defaults to an empty string."
          },
          {
            "name": "main_used",
            "type": "str",
            "description": "Identifier of any main model used; defaults to an empty string."
          },
          {
            "name": "total_time",
            "type": "str",
            "description": "Total time taken for the exchange; defaults to an empty string."
          },
          {
            "name": "helper_time",
            "type": "str",
            "description": "Time taken by the helper model; defaults to an empty string."
          },
          {
            "name": "main_time",
            "type": "str",
            "description": "Time taken by the main model; defaults to an empty string."
          },
          {
            "name": "json_tokens",
            "type": "int",
            "description": "Number of JSON tokens used; defaults to 0."
          },
          {
            "name": "toon_tokens",
            "type": "int",
            "description": "Number of Toon tokens used; defaults to 0."
          },
          {
            "name": "savings_percent",
            "type": "float",
            "description": "Percentage of token savings achieved; defaults to 0.0."
          }
        ],
        "returns": [
          {
            "name": "new_id",
            "type": "Optional[str]",
            "description": "The generated UUID string of the inserted exchange if the insertion succeeds, otherwise `None`."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "No functions are listed as calling this function."
        }
      },
      "error": null
    },
    "database.db.fetch_exchanges_by_user": {
      "identifier": "database.db.fetch_exchanges_by_user",
      "description": {
        "overall": "The function `fetch_exchanges_by_user` retrieves exchange records associated with a specific user. It accepts a username string as input and queries the `dbexchanges` collection for matching documents. The query results are sorted by the `created_at` timestamp in ascending order to ensure chronological display. The sorted cursor is converted to a list, which is then returned to the caller.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username whose exchange records should be fetched from the database."
          }
        ],
        "returns": [
          {
            "name": "exchanges",
            "type": "list",
            "description": "A list of exchange documents (typically dictionaries) for the given user, ordered by their creation timestamp."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions in the provided context."
        }
      },
      "error": null
    },
    "database.db.fetch_exchanges_by_chat": {
      "identifier": "database.db.fetch_exchanges_by_chat",
      "description": {
        "overall": "This function retrieves all exchange records associated with a specific user and chat from a MongoDB collection. It accepts the user's username and the name of the chat as string arguments. Inside the function it queries the `dbexchanges` collection using these criteria, sorts the results by the `created_at` field in ascending order, and converts the cursor to a list. The resulting list of exchange documents is then returned to the caller.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username identifying the user whose exchanges are to be fetched."
          },
          {
            "name": "chat_name",
            "type": "str",
            "description": "The name of the chat whose exchanges are to be fetched."
          }
        ],
        "returns": [
          {
            "name": "exchanges",
            "type": "list",
            "description": "A list of exchange documents matching the given username and chat name, ordered by creation time."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "No other functions are documented as calling this function."
        }
      },
      "error": null
    },
    "database.db.update_exchange_feedback": {
      "identifier": "database.db.update_exchange_feedback",
      "description": {
        "overall": "The function updates the feedback value for a specific exchange record in the MongoDB collection `dbexchanges`. It builds a filter using the provided `exchange_id` and sets the `feedback` field to the supplied integer value. The update is performed with `update_one`, which affects at most one matching document. Finally, the function returns the number of documents that were modified by the operation.",
        "parameters": [
          {
            "name": "exchange_id",
            "type": "Any",
            "description": "The unique identifier of the exchange document to be updated (e.g., a MongoDB ObjectId or string)."
          },
          {
            "name": "feedback",
            "type": "int",
            "description": "An integer representing the feedback rating to store in the exchange document."
          }
        ],
        "returns": [
          {
            "name": "modified_count",
            "type": "int",
            "description": "The count of documents that were modified by the update operation (typically 0 or 1)."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.update_exchange_feedback_message": {
      "identifier": "database.db.update_exchange_feedback_message",
      "description": {
        "overall": "The function updates the ``feedback_message`` field of a specific exchange document in the ``dbexchanges`` MongoDB collection. It builds a filter using the provided ``exchange_id`` and applies an ``$set`` operation with the new ``feedback_message``. The update is performed with ``update_one`` which affects at most one matching document. Finally, the function returns the number of documents that were actually modified by the operation.",
        "parameters": [
          {
            "name": "exchange_id",
            "type": "Any",
            "description": "The identifier of the exchange document to be updated (used as the ``_id`` filter in the MongoDB query)."
          },
          {
            "name": "feedback_message",
            "type": "str",
            "description": "The new feedback message to store in the ``feedback_message`` field of the exchange document."
          }
        ],
        "returns": [
          {
            "name": "modified_count",
            "type": "int",
            "description": "The number of documents that were modified by the update operation (typically 0 or 1)."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.delete_exchange_by_id": {
      "identifier": "database.db.delete_exchange_by_id",
      "description": {
        "overall": "The function deletes a single exchange document from the `dbexchanges` collection whose `_id` matches the provided `exchange_id`. It constructs a filter dictionary with the `_id` field set to `exchange_id` and passes it to MongoDB's `delete_one` method. The result of the deletion operation is stored in `result`. Finally, the function returns the `deleted_count` attribute of the result, indicating how many documents were removed.",
        "parameters": [
          {
            "name": "exchange_id",
            "type": "str",
            "description": "The identifier of the exchange document to be removed from the database."
          }
        ],
        "returns": [
          {
            "name": "deleted_count",
            "type": "int",
            "description": "The number of documents deleted (typically 0 if no matching document was found, or 1 if the deletion succeeded)."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "No other functions are documented as calling this function."
        }
      },
      "error": null
    },
    "database.db.delete_full_chat": {
      "identifier": "database.db.delete_full_chat",
      "description": {
        "overall": "The function `delete_full_chat` removes an entire chat and all of its associated message exchanges for a given user. It first deletes all exchange documents that match the provided username and chat name using the `delete_many` method on the `dbexchanges` collection. Afterwards it deletes the chat document itself from the `dbchats` collection with `delete_one`. Finally, it returns the number of chat documents that were removed, which indicates whether the operation succeeded.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username of the user whose chat and exchanges are to be deleted."
          },
          {
            "name": "chat_name",
            "type": "str",
            "description": "The name of the chat to delete along with its exchanges."
          }
        ],
        "returns": [
          {
            "name": "deleted_count",
            "type": "int",
            "description": "The count of chat documents deleted (typically 0 if not found, or 1 if the chat was removed)."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "No other functions are documented as calling this function."
        }
      },
      "error": null
    },
    "frontend.frontend.clean_names": {
      "identifier": "frontend.frontend.clean_names",
      "description": {
        "overall": "The function clean_names takes a list of model identifiers and returns a new list containing only the base name of each model. It does this by splitting each string on '/' and selecting the last segment. The implementation uses a list comprehension for concise processing. No side effects or external dependencies are involved.",
        "parameters": [
          {
            "name": "model_list",
            "type": "list",
            "description": "A list of strings representing model identifiers, potentially containing '/' separators."
          }
        ],
        "returns": [
          {
            "name": "",
            "type": "list",
            "description": "A list of strings containing the last segment of each input string after splitting by '/'."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "frontend.frontend.get_filtered_models": {
      "identifier": "frontend.frontend.get_filtered_models",
      "description": {
        "overall": "The function `get_filtered_models` filters a list of model names based on a specified category. It first retrieves the keyword list for the given category from the global `CATEGORY_KEYWORDS` mapping. If the keyword list contains the special token \"STANDARD\", it returns only those models that also appear in the global `STANDARD_MODELS` list. Otherwise, it builds a filtered list containing models whose names include any of the category keywords (case\u2011insensitive). If no models match, the original `source_list` is returned unchanged.",
        "parameters": [
          {
            "name": "source_list",
            "type": "list",
            "description": "A list of model identifiers (typically strings) to be filtered."
          },
          {
            "name": "category_name",
            "type": "str",
            "description": "The name of the category whose associated keywords determine the filtering criteria."
          }
        ],
        "returns": [
          {
            "name": "filtered_models",
            "type": "list",
            "description": "A list of model names that match the category criteria, or the original `source_list` if no matches are found."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions in the provided context."
        }
      },
      "error": null
    },
    "frontend.frontend.save_gemini_cb": {
      "identifier": "frontend.frontend.save_gemini_cb",
      "description": {
        "overall": "The function `save_gemini_cb` retrieves a Gemini API key from Streamlit's session state, checks whether the key is non\u2011empty, and if so updates the stored key for the current user in the database. After updating, it clears the input field in the session state and displays a toast notification confirming that the Gemini key was saved successfully. The function operates without any input parameters and performs its actions purely through side effects. It does not return any value.",
        "parameters": [],
        "returns": [],
        "usage_context": {
          "calls": "This function calls database.db.update_gemini_key.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "frontend.frontend.save_ollama_cb": {
      "identifier": "frontend.frontend.save_ollama_cb",
      "description": {
        "overall": "The function `save_ollama_cb` is a callback intended to persist a user\u2011provided Ollama service URL. It first reads the value associated with the key `in_ollama_url` from Streamlit's session state, defaulting to an empty string if the key is missing. If a non\u2011empty URL is present, it calls `database.db.update_ollama_url` with the current username and the new URL to store the information in the database. After successfully updating, it displays a toast message in the Streamlit UI indicating that the URL has been saved. The function does not return any value.",
        "parameters": [],
        "returns": [],
        "usage_context": {
          "calls": "This function calls database.db.update_ollama_url.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "frontend.frontend.load_data_from_db": {
      "identifier": "frontend.frontend.load_data_from_db",
      "description": {
        "overall": "The function `load_data_from_db` loads a user's chat history and associated exchanges from the database into Streamlit's session state. It first checks whether the data for the given username has already been loaded, and if not, it clears any existing chat data. It then retrieves the defined chats, creates empty exchange lists, and subsequently fetches exchanges, handling legacy chats and filling missing feedback values with `np.nan`. If no chats exist for the user, it creates a default chat both in the database and in the session state; otherwise it ensures that an active chat is set. Finally, it records the loaded username in `st.session_state.loaded_user`.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username whose chats and exchanges should be loaded from the database."
          }
        ],
        "returns": [],
        "usage_context": {
          "calls": "This function calls database.db.fetch_chats_by_user, database.db.fetch_exchanges_by_user, and database.db.insert_chat.",
          "called_by": "No functions call this function."
        }
      },
      "error": null
    },
    "frontend.frontend.handle_feedback_change": {
      "identifier": "frontend.frontend.handle_feedback_change",
      "description": {
        "overall": "The function handle_feedback_change updates the feedback value of a given exchange object. It writes the new feedback into the exchange dictionary, persists the change to the database by calling update_exchange_feedback, and finally triggers a Streamlit rerun to refresh the UI. The implementation is straightforward, consisting of three sequential statements that modify in\u2011memory data, invoke a database helper, and request a UI refresh.",
        "parameters": [
          {
            "name": "ex",
            "type": "dict",
            "description": "A dictionary representing an exchange, expected to contain at least the keys \"feedback\" and \"_id\"."
          },
          {
            "name": "val",
            "type": "Any",
            "description": "The new feedback value to assign to the exchange."
          }
        ],
        "returns": [],
        "usage_context": {
          "calls": "This function calls database.db.update_exchange_feedback.",
          "called_by": "No functions call this function."
        }
      },
      "error": null
    },
    "frontend.frontend.handle_delete_exchange": {
      "identifier": "frontend.frontend.handle_delete_exchange",
      "description": {
        "overall": "The function removes an exchange record from the persistent database using its unique identifier. After the database deletion, it checks whether the specified chat exists in Streamlit's session state and, if so, removes the exchange from that chat's list of exchanges. Finally, it triggers a Streamlit rerun to refresh the UI. The function performs no explicit return.",
        "parameters": [
          {
            "name": "chat_name",
            "type": "str",
            "description": "The name of the chat whose exchanges are being managed."
          },
          {
            "name": "ex",
            "type": "dict",
            "description": "A dictionary representing the exchange to delete; expected to contain an \"_id\" key."
          }
        ],
        "returns": [],
        "usage_context": {
          "calls": "This function calls database.db.delete_exchange_by_id.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "frontend.frontend.handle_delete_chat": {
      "identifier": "frontend.frontend.handle_delete_chat",
      "description": {
        "overall": "The function `handle_delete_chat` removes a specified chat for a given user from the database and updates the Streamlit session state accordingly. It first calls `db.delete_full_chat` to delete the chat record. It then cleans up the in\u2011memory `st.session_state.chats` dictionary, selects a new active chat if any remain, or creates a fresh default chat when none are left. Finally, it triggers a UI refresh with `st.rerun()`. The implementation relies on the `database.db` module and Streamlit's session state handling.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The identifier of the user whose chat is being deleted."
          },
          {
            "name": "chat_name",
            "type": "str",
            "description": "The name of the chat to delete."
          }
        ],
        "returns": [],
        "usage_context": {
          "calls": "This function calls database.db.delete_full_chat and database.db.insert_chat.",
          "called_by": "No functions call this function."
        }
      },
      "error": null
    },
    "frontend.frontend.extract_repo_name": {
      "identifier": "frontend.frontend.extract_repo_name",
      "description": {
        "overall": "The function `extract_repo_name` scans a given text for the first URL it can find. If a URL is present, it parses the URL to isolate the path component, trims leading and trailing slashes, and extracts the final segment of the path as the repository name. It also removes a trailing \".git\" suffix if present. If any step fails (no URL, empty path, etc.), the function returns `None`.",
        "parameters": [
          {
            "name": "text",
            "type": "str",
            "description": "A string that may contain a URL from which the repository name should be extracted."
          }
        ],
        "returns": [
          {
            "name": "repo_name",
            "type": "Optional[str]",
            "description": "The extracted repository name without a trailing \".git\" suffix, or `None` if no suitable URL is found."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions in the provided context."
        }
      },
      "error": null
    },
    "frontend.frontend.stream_text_generator": {
      "identifier": "frontend.frontend.stream_text_generator",
      "description": {
        "overall": "The function `stream_text_generator` takes a string and produces a lazy sequence of its words. It splits the input text on spaces, iterates over each word, and yields the word followed by a space. After yielding each word, it pauses briefly (0.01 seconds) to simulate streaming. This generator can be consumed to display text incrementally, for example in a UI.",
        "parameters": [
          {
            "name": "text",
            "type": "str",
            "description": "The input string to be split into words and streamed."
          }
        ],
        "returns": [
          {
            "name": "",
            "type": "Generator[str, None, None]",
            "description": "Yields each word from the input text followed by a space, one at a time."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "No functions are listed as callers of this function."
        }
      },
      "error": null
    },
    "frontend.frontend.render_text_with_mermaid": {
      "identifier": "frontend.frontend.render_text_with_mermaid",
      "description": {
        "overall": "The function `render_text_with_mermaid` processes a markdown string and optionally streams its output. It first checks whether the provided `markdown_text` is empty and returns early if so. The markdown is split into alternating non\u2011mermaid and mermaid sections using a regular expression. Non\u2011mermaid sections are either streamed via `st.write_stream` or rendered as regular markdown, while mermaid sections are rendered with `st_mermaid`; if rendering fails, the mermaid code is displayed as a code block.",
        "parameters": [
          {
            "name": "markdown_text",
            "type": "str",
            "description": "The markdown content to be rendered, potentially containing mermaid diagram blocks."
          },
          {
            "name": "should_stream",
            "type": "bool",
            "description": "If True, the non\u2011mermaid text is streamed to the UI using `st.write_stream`; otherwise it is rendered directly with `st.markdown`."
          }
        ],
        "returns": [],
        "usage_context": {
          "calls": "This function calls frontend.frontend.stream_text_generator.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "frontend.frontend.render_exchange": {
      "identifier": "frontend.frontend.render_exchange",
      "description": {
        "overall": "The function `render_exchange` displays a single chat exchange in a Streamlit interface. It first writes the user's question, then creates an assistant message block where it shows the answer and a toolbar with status text, feedback buttons, a comment popover, a download button, and a delete button. The toolbar adapts based on whether the answer indicates an error, showing an error message and a delete option in that case. Interaction callbacks invoke helper functions to update feedback, delete the exchange, or render the answer with Mermaid diagrams. The function does not return any value.",
        "parameters": [
          {
            "name": "ex",
            "type": "dict",
            "description": "A dictionary representing an exchange, expected to contain keys such as \"question\", \"answer\", \"_id\", \"feedback\", \"feedback_message\", etc."
          },
          {
            "name": "current_chat_name",
            "type": "str",
            "description": "The name of the current chat session."
          }
        ],
        "returns": [],
        "usage_context": {
          "calls": "This function calls database.db.update_exchange_feedback_message, frontend.frontend.handle_delete_exchange, frontend.frontend.handle_feedback_change, and frontend.frontend.render_text_with_mermaid.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    }
  },
  "classes": {
    "backend.AST_Schema.ASTVisitor": {
      "identifier": "backend.AST_Schema.ASTVisitor",
      "description": {
        "overall": "The **ASTVisitor** class walks a Python abstract syntax tree (AST) to construct a lightweight schema describing the source file. It records imported module names, top\u2011level functions, and class definitions\u2014including their metadata such as docstrings, source code snippets, and line numbers\u2014into a nested dictionary called `schema`. While traversing, it maintains a temporary `_current_class` context so that methods are attached to the appropriate class entry. The visitor relies on the helper `path_to_module` to translate a file path into a fully\u2011qualified module identifier. The resulting `schema` can be used by downstream tooling to understand the structure of a Python project without executing the code.",
        "init_method": {
          "description": "The constructor stores the raw source code, the file's path, and the project root, then computes the module path using `path_to_module`. It also initializes an empty `schema` dictionary that will be populated with imports, functions, and classes during the AST walk, and prepares a placeholder for the currently visited class.",
          "parameters": [
            {
              "name": "source_code",
              "type": "str",
              "description": "The full text of the Python source file being analysed."
            },
            {
              "name": "file_path",
              "type": "str",
              "description": "Filesystem path to the source file."
            },
            {
              "name": "project_root",
              "type": "str",
              "description": "Root directory of the project; used together with `file_path` to compute the module path."
            }
          ]
        },
        "methods": [
          {
            "identifier": "backend.AST_Schema.ASTVisitor.visit_Import",
            "description": {
              "overall": "The `visit_Import` method processes `import` statements encountered in the AST. For each alias in the `Import` node it appends the imported module name to the `schema[\"imports\"]` list. After recording the imports it delegates to `generic_visit` to continue traversing any child nodes of the import statement. This method therefore builds a flat list of all top\u2011level imports present in the source file. No value is returned; the method's effect is side\u2011effects on the internal `schema`.",
              "parameters": [
                {
                  "name": "self",
                  "type": "ASTVisitor",
                  "description": "The visitor instance."
                },
                {
                  "name": "node",
                  "type": "ast.Import",
                  "description": "The AST node representing an `import` statement."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "The `visit_Import` method does not call any other functions or methods.",
                "called_by": "No other functions or methods are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "backend.AST_Schema.ASTVisitor.visit_ImportFrom",
            "description": {
              "overall": "The `visit_ImportFrom` method handles `from ... import ...` statements. It iterates over each alias in the node and records a fully\u2011qualified import string (`module.name`) in the `schema[\"imports\"]` list. After populating the list it calls `generic_visit` to continue walking any nested nodes. This method enriches the import collection with both absolute and relative imports. It returns nothing, affecting only the internal `schema`.",
              "parameters": [
                {
                  "name": "self",
                  "type": "ASTVisitor",
                  "description": "The visitor instance."
                },
                {
                  "name": "node",
                  "type": "ast.ImportFrom",
                  "description": "The AST node representing a `from ... import ...` statement."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "The `visit_ImportFrom` method does not call any other functions or methods.",
                "called_by": "No other functions or methods are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "backend.AST_Schema.ASTVisitor.visit_ClassDef",
            "description": {
              "overall": "The `visit_ClassDef` method is invoked for each class definition in the source file. It builds a fully\u2011qualified class identifier using the previously computed `module_path` and the class name, then assembles a dictionary containing metadata such as the class name, docstring, source code segment, start and end line numbers, and an empty context placeholder. This dictionary is appended to `schema[\"classes\"]`. The method also sets `_current_class` to this dictionary so that subsequent method definitions can be associated with the class, walks the class body with `generic_visit`, and finally resets `_current_class` to `None`. No explicit return value is produced.",
              "parameters": [
                {
                  "name": "self",
                  "type": "ASTVisitor",
                  "description": "The visitor instance."
                },
                {
                  "name": "node",
                  "type": "ast.ClassDef",
                  "description": "The AST node representing a class definition."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "The `visit_ClassDef` method does not call any other functions or methods.",
                "called_by": "No other functions or methods are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "backend.AST_Schema.ASTVisitor.visit_FunctionDef",
            "description": {
              "overall": "The `visit_FunctionDef` method processes every function definition encountered in the AST. If the visitor is currently inside a class (`_current_class` is set), it creates a method context entry containing the method's identifier, name, argument list, docstring, and line numbers, and appends it to the current class's `context[\"method_context\"]`. If the function is top\u2011level, it builds a separate function information dictionary with similar metadata and adds it to `schema[\"functions\"]`. After recording the appropriate information, it calls `generic_visit` to continue traversing the function body. The method does not return a value; its effect is the population of the schema structures.",
              "parameters": [
                {
                  "name": "self",
                  "type": "ASTVisitor",
                  "description": "The visitor instance."
                },
                {
                  "name": "node",
                  "type": "ast.FunctionDef",
                  "description": "The AST node representing a function definition."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "The `visit_FunctionDef` method does not call any other functions or methods.",
                "called_by": "No other functions or methods are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "backend.AST_Schema.ASTVisitor.visit_AsyncFunctionDef",
            "description": {
              "overall": "The `visit_AsyncFunctionDef` method handles asynchronous function definitions. Its implementation simply forwards the node to `visit_FunctionDef`, thereby reusing the same logic for recording async functions as for regular functions. No additional processing is performed, and the method does not return a value.",
              "parameters": [
                {
                  "name": "self",
                  "type": "ASTVisitor",
                  "description": "The visitor instance."
                },
                {
                  "name": "node",
                  "type": "ast.AsyncFunctionDef",
                  "description": "The AST node representing an async function definition."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "The `visit_AsyncFunctionDef` method calls `visit_FunctionDef` to process the async function node.",
                "called_by": "No other functions or methods are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "backend.AST_Schema.ASTVisitor.__init__",
            "description": {
              "overall": "The constructor initializes the visitor with the source code, file path, and project root, computes the module path, and prepares an empty schema dictionary for later population. It also sets up a placeholder `_current_class` used while traversing class definitions. No value is returned; the method's effect is the creation of the visitor's internal state.",
              "parameters": [
                {
                  "name": "self",
                  "type": "ASTVisitor",
                  "description": "The instance being created."
                },
                {
                  "name": "source_code",
                  "type": "str",
                  "description": "The full source text of the Python file."
                },
                {
                  "name": "file_path",
                  "type": "str",
                  "description": "The filesystem path to the source file."
                },
                {
                  "name": "project_root",
                  "type": "str",
                  "description": "The root directory of the project, used for module path resolution."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "The `__init__` method calls the function `backend.AST_Schema.path_to_module` to compute the module path.",
                "called_by": "No other functions or methods are recorded as calling this method."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "The class depends on the function `backend.AST_Schema.path_to_module` for converting file paths to module identifiers.",
          "instantiated_by": "No instantiation sites are provided in the context."
        }
      },
      "error": null
    },
    "backend.AST_Schema.ASTAnalyzer": {
      "identifier": "backend.AST_Schema.ASTAnalyzer",
      "description": {
        "overall": "The **ASTAnalyzer** class aggregates abstract syntax\u2011tree (AST) information from a Python codebase and enriches it with relationship data. It can parse a collection of repository files into a structured schema and then merge call\u2011relationship mappings (outgoing and incoming calls) into that schema, producing a comprehensive representation of functions, classes, their instantiation sites, and dependencies.",
        "init_method": {
          "description": "The constructor does not accept any configuration parameters and performs no initialization beyond the default object creation; it simply contains a `pass` statement.",
          "parameters": []
        },
        "methods": [
          {
            "identifier": "merge_relationship_data",
            "description": {
              "overall": "This method receives a `full_schema` dictionary that already contains AST information for each file and a `raw_relationships` dictionary that holds outgoing and incoming call mappings. It extracts the outgoing and incoming call data, then iterates over every file in the schema. For each function it adds a `calls` list (outgoing) and a `called_by` list (incoming) based on the relationship data. For each class it records which functions instantiate the class and gathers a set of dependencies by examining method calls that do not belong to the same class. Finally, it stores the computed dependencies back into the class context and returns the enriched `full_schema`.\n        ",
              "parameters": [
                {
                  "name": "full_schema",
                  "type": "dict",
                  "description": "A dictionary representing the parsed AST of the repository, keyed by file paths and containing function and class nodes."
                },
                {
                  "name": "raw_relationships",
                  "type": "dict",
                  "description": "A mapping that contains `outgoing` and `incoming` call information for identifiers across the codebase."
                }
              ],
              "returns": [
                {
                  "name": "full_schema",
                  "type": "dict",
                  "description": "The same schema dictionary, now enriched with call contexts, instantiation information, and class dependencies."
                }
              ],
              "usage_context": {
                "calls": "This method does not call any other functions.",
                "called_by": "No other functions call this method."
              }
            },
            "error": null
          },
          {
            "identifier": "analyze_repository",
            "description": {
              "overall": "This method builds a complete AST schema for a list of files belonging to a repository. It first determines the common project root path, then iterates over each provided file object, skipping non\u2011Python files and empty contents. For each Python file it parses the source code with `ast.parse` and walks the tree using an `ASTVisitor`, which collects imports, functions, and classes into a `schema` structure. The collected schema for each file is stored under the `files` key of `full_schema`. Syntax errors or parsing failures are caught and reported as warnings, allowing the analysis to continue for the remaining files. The method finally returns the assembled `full_schema` dictionary.\n        ",
              "parameters": [
                {
                  "name": "files",
                  "type": "list",
                  "description": "A list of file objects, each exposing a `path` attribute and a `content` attribute containing the file's source code."
                },
                {
                  "name": "repo",
                  "type": "GitRepository",
                  "description": "An instance representing the Git repository from which the files originate."
                }
              ],
              "returns": [
                {
                  "name": "full_schema",
                  "type": "dict",
                  "description": "A dictionary containing the AST representation of all parsed Python files in the repository."
                }
              ],
              "usage_context": {
                "calls": "This method calls backend.AST_Schema.ASTVisitor.",
                "called_by": "No other functions call this method."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "ASTAnalyzer depends on the backend.AST_Schema.ASTVisitor component for AST traversal.",
          "instantiated_by": "There are no recorded locations where ASTAnalyzer is instantiated."
        }
      },
      "error": null
    },
    "backend.File_Dependency.FileDependencyGraph": {
      "identifier": "backend.File_Dependency.FileDependencyGraph",
      "description": {
        "overall": "FileDependencyGraph is an AST NodeVisitor that builds a graph of file\u2011level import relationships within a repository. It records, for each source file, the set of modules or symbols it imports, handling both absolute and relative import statements. The class resolves relative imports by analysing the repository layout and the contents of __init__.py files, delegating to helper functions defined elsewhere. The collected data is stored in the class\u2011level dictionary `import_dependencies`, which maps a filename to the set of its import callees.",
        "init_method": {
          "description": "The constructor stores the name of the file being analysed and the root path of the repository. These values are later used to locate the file on disk and to resolve relative import statements. No additional processing is performed during initialisation.",
          "parameters": [
            {
              "name": "filename",
              "type": "str",
              "description": "The name of the source file whose imports are to be analysed."
            },
            {
              "name": "repo_root",
              "type": "Any",
              "description": "The root directory of the repository; used for locating files and resolving relative imports."
            }
          ]
        },
        "methods": [
          {
            "identifier": "_resolve_module_name",
            "description": {
              "overall": "This private method resolves relative import statements of the form `from .. import name1, name2`. It determines the directory depth indicated by the import's level, walks up the file hierarchy accordingly, and then checks whether each imported name corresponds to a module file or is exported from a package's __init__.py. To perform these checks it calls three external helper functions: `get_all_temp_files`, `module_file_exists`, and `init_exports_symbol`. If none of the names can be resolved, it raises an ImportError; otherwise it returns a sorted list of unique module or symbol names that were successfully resolved.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ImportFrom",
                  "description": "The AST node representing a relative import statement."
                }
              ],
              "returns": [
                {
                  "name": "",
                  "type": "list[str]",
                  "description": "A list of resolved module or symbol names that exist in the repository."
                }
              ],
              "usage_context": {
                "calls": "The method calls backend.File_Dependency.get_all_temp_files, backend.File_Dependency.init_exports_symbol, and backend.File_Dependency.module_file_exists to locate files and verify symbol exports.",
                "called_by": "No other methods in this class are recorded as calling _resolve_module_name."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_Import",
            "description": {
              "overall": "This visitor method processes generic import statements (`import X` or `from X import Y`). For each alias in the import node it ensures that the current file has an entry in the `import_dependencies` dictionary and then adds either the provided base name or the alias name to the set of dependencies. After updating the data structure it continues the generic AST traversal.",
              "parameters": [
                {
                  "name": "node",
                  "type": "Import | ImportFrom",
                  "description": "The AST node representing an import statement."
                },
                {
                  "name": "base_name",
                  "type": "str | None",
                  "description": "Optional explicit base module name to record; if omitted the alias name is used."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method does not call any external functions.",
                "called_by": "No other methods in this class are recorded as calling visit_Import."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_ImportFrom",
            "description": {
              "overall": "This visitor method handles `from ... import ...` statements. If the import specifies a module path, it extracts the last component of the module name and forwards the node to `visit_Import` with that component as the base name. For relative imports (where `module` is None) it attempts to resolve the module name using `_resolve_module_name`; any successfully resolved base names are then processed by `visit_Import`. Errors during resolution are caught and reported, after which the generic AST traversal continues.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ImportFrom",
                  "description": "The AST node representing a from\u2011import statement."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls the private helper `_resolve_module_name` when dealing with relative imports, and forwards work to `visit_Import`.",
                "called_by": "No other methods in this class are recorded as calling visit_ImportFrom."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "The class relies on three external helpers: backend.File_Dependency.get_all_temp_files, backend.File_Dependency.init_exports_symbol, and backend.File_Dependency.module_file_exists to locate repository files and verify module exports.",
          "instantiated_by": "No instantiation sites are recorded in the provided context."
        }
      },
      "error": null
    },
    "backend.HelperLLM.LLMHelper": {
      "identifier": "backend.HelperLLM.LLMHelper",
      "description": {
        "overall": "LLMHelper centralises interaction with various large\u2011language\u2011model back\u2011ends (Google Gemini, OpenAI, Ollama and custom SCADSLLM endpoints) to generate structured documentation for Python functions and classes. It loads system prompts from files, determines an appropriate batch size for the selected model, and provides two high\u2011level methods \u2013 `generate_for_functions` and `generate_for_classes` \u2013 that batch\u2011process inputs, call the LLM with structured\u2011output schemas, handle rate\u2011limit waiting, and return validated documentation objects.",
        "init_method": {
          "description": "The constructor validates the provided API key, reads function and class system\u2011prompt files, configures model\u2011specific batch settings, selects the appropriate LLM provider based on the model name, and creates specialised LLM wrappers that output `FunctionAnalysis` and `ClassAnalysis` JSON schemas.",
          "parameters": [
            {
              "name": "api_key",
              "type": "str",
              "description": "Gemini (or other provider) API key; required for authenticating LLM requests."
            },
            {
              "name": "function_prompt_path",
              "type": "str",
              "description": "Filesystem path to the prompt that guides function\u2011level documentation generation."
            },
            {
              "name": "class_prompt_path",
              "type": "str",
              "description": "Filesystem path to the prompt that guides class\u2011level documentation generation."
            },
            {
              "name": "model_name",
              "type": "str",
              "description": "Identifier of the LLM model to use (e.g., \"gemini-2.0-flash-lite\"). Defaults to \"gemini-2.0-flash-lite\"."
            },
            {
              "name": "base_url",
              "type": "str | None",
              "description": "Optional base URL for custom LLM APIs; used when the model requires a specific endpoint."
            }
          ]
        },
        "methods": [
          {
            "identifier": "_configure_batch_settings",
            "description": {
              "overall": "Sets the instance attribute `batch_size` based on the supplied `model_name`. The method contains a series of conditional branches that map known model identifiers to empirically chosen batch sizes, falling back to a conservative default of 2 for unknown models. No value is returned; the method solely mutates internal state.",
              "parameters": [
                {
                  "name": "model_name",
                  "type": "str",
                  "description": "The name of the LLM model for which a batch size should be configured."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method does not call any other functions or methods.",
                "called_by": "No other functions or methods are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "generate_for_functions",
            "description": {
              "overall": "Generates documentation for a list of functions by batching requests to the configured LLM. It serialises each `FunctionAnalysisInput` to JSON, builds system\u2011human message pairs using the loaded function prompt, and processes the payloads in batches of size `self.batch_size`. After each batch it optionally sleeps to respect rate limits, handling any exceptions by inserting `None` placeholders to preserve ordering. The method finally returns a list of `FunctionAnalysis` objects (or `None` where a batch failed).",
              "parameters": [
                {
                  "name": "function_inputs",
                  "type": "List[FunctionAnalysisInput]",
                  "description": "A list of input models describing the functions to be documented."
                }
              ],
              "returns": [
                {
                  "name": "result",
                  "type": "List[Optional[FunctionAnalysis]]",
                  "description": "A list containing the LLM\u2011generated `FunctionAnalysis` objects for each input, or `None` for failed batches."
                }
              ],
              "usage_context": {
                "calls": "This method does not call any other functions or methods.",
                "called_by": "No other functions or methods are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "generate_for_classes",
            "description": {
              "overall": "Generates documentation for a list of classes using the same batching logic as `generate_for_functions`, but with the class\u2011specific system prompt and output schema. It serialises each `ClassAnalysisInput`, builds conversations, sends them to the LLM in batches, respects rate limits, and returns a list of `ClassAnalysis` objects (or `None` on failure).",
              "parameters": [
                {
                  "name": "class_inputs",
                  "type": "List[ClassAnalysisInput]",
                  "description": "A list of input models describing the classes to be documented."
                }
              ],
              "returns": [
                {
                  "name": "result",
                  "type": "List[Optional[ClassAnalysis]]",
                  "description": "A list containing the LLM\u2011generated `ClassAnalysis` objects for each input, or `None` where a batch failed."
                }
              ],
              "usage_context": {
                "calls": "This method does not call any other functions or methods.",
                "called_by": "No other functions or methods are recorded as calling this method."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "The class does not have listed external dependencies.",
          "instantiated_by": "No instantiation locations are recorded for this class."
        }
      },
      "error": null
    },
    "backend.MainLLM.MainLLM": {
      "identifier": "backend.MainLLM.MainLLM",
      "description": {
        "overall": "The **MainLLM** class acts as a thin wrapper around various Large Language Model (LLM) providers, exposing a uniform interface for synchronous and streaming text generation. It reads a system prompt from a file, selects the appropriate LangChain chat model based on the supplied `model_name`, and stores the configured model in `self.llm`. The class provides two public methods \u2013 `call_llm` for a single\u2011turn request and `stream_llm` for token\u2011by\u2011token streaming \u2013 both of which automatically prepend the system prompt. Logging is used throughout to trace initialization steps, model selection, and any errors that occur during LLM calls. This design abstracts away provider\u2011specific details, allowing the rest of the application to interact with any supported LLM through a consistent API.",
        "init_method": {
          "description": "Initializes the MainLLM instance by loading a system prompt from the given file, selecting the appropriate LangChain chat model based on the `model_name`, and storing the configured model in `self.llm`. It validates the presence of an API key and, for custom endpoints, ensures required environment variables are set.",
          "parameters": [
            {
              "name": "api_key",
              "type": "str",
              "description": "API key required by the underlying LLM provider (e.g., Gemini, OpenAI)."
            },
            {
              "name": "prompt_file_path",
              "type": "str",
              "description": "Path to a UTF\u20118 text file containing the system prompt that will be sent to the LLM."
            },
            {
              "name": "model_name",
              "type": "str",
              "description": "Identifier of the LLM model to use. Defaults to \"gemini-2.5-pro\" and determines which LangChain chat class is instantiated."
            },
            {
              "name": "base_url",
              "type": "str | None",
              "description": "Optional base URL for custom or Ollama endpoints; used when `model_name` does not match a known provider."
            }
          ]
        },
        "methods": [
          {
            "identifier": "call_llm",
            "description": {
              "overall": "`call_llm` performs a single, non\u2011streaming request to the configured LLM. It builds a message list consisting of the stored system prompt and the user\u2011provided input, then invokes the model's `invoke` method. If the call succeeds, the method returns the generated text (`response.content`). Any exception raised by the underlying model is caught, logged, and results in a `None` return value. This method provides a simple, fire\u2011and\u2011forget interface for obtaining a complete response from the LLM.",
              "parameters": [
                {
                  "name": "self",
                  "type": "MainLLM",
                  "description": "The instance on which the method is called."
                },
                {
                  "name": "user_input",
                  "type": "str",
                  "description": "The user's query or prompt that will be sent to the LLM."
                }
              ],
              "returns": [
                {
                  "name": "generated_text",
                  "type": "str | None",
                  "description": "The content of the LLM's response if the call succeeds; otherwise `None` when an error occurs."
                }
              ],
              "usage_context": {
                "calls": "The method does not explicitly call any other functions defined in this class.",
                "called_by": "No external callers were provided in the context."
              }
            },
            "error": null
          },
          {
            "identifier": "stream_llm",
            "description": {
              "overall": "`stream_llm` initiates a streaming request to the configured LLM, yielding partial results as they become available. It constructs the same message list as `call_llm` (system prompt + user input) and calls the model's `stream` method, which returns an iterator of response chunks. The method iterates over this iterator, yielding each chunk's content to the caller. If any exception occurs during streaming, it logs the error and yields a formatted error message instead of raising, allowing the caller to handle the failure gracefully.",
              "parameters": [
                {
                  "name": "self",
                  "type": "MainLLM",
                  "description": "The instance on which the method is called."
                },
                {
                  "name": "user_input",
                  "type": "str",
                  "description": "The user's query or prompt that will be streamed to the LLM."
                }
              ],
              "returns": [
                {
                  "name": "streamed_content",
                  "type": "Generator[str, None, None]",
                  "description": "A generator yielding each chunk of text produced by the LLM, or an error message string if the stream fails."
                }
              ],
              "usage_context": {
                "calls": "The method does not explicitly call any other functions defined in this class.",
                "called_by": "No external callers were provided in the context."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "The class does not declare any additional runtime dependencies beyond the imported modules listed in the file.",
          "instantiated_by": "No information about where the class is instantiated was supplied."
        }
      },
      "error": null
    },
    "backend.basic_info.ProjektInfoExtractor": {
      "identifier": "backend.basic_info.ProjektInfoExtractor",
      "description": {
        "overall": "ProjektInfoExtractor is a helper class that gathers basic project metadata from common project files such as README, pyproject.toml and requirements.txt. It builds a nested dictionary containing a project overview (title, description, status, key features, tech stack) and installation details (dependencies, setup instructions, quick\u2011start guide). The class abstracts the parsing logic and provides a single `extrahiere_info` entry point that returns the collected information in a uniform structure.",
        "init_method": {
          "description": "The constructor creates a placeholder dictionary (`self.info`) that holds the expected project overview and installation sections, each pre\u2011filled with a sentinel value indicating that the information has not yet been found. It also defines a constant `INFO_NICHT_GEFUNDEN` used throughout the class to mark missing data.",
          "parameters": [
            {
              "name": "self",
              "type": "ProjektInfoExtractor",
              "description": "Reference to the instance being created."
            }
          ]
        },
        "methods": [
          {
            "identifier": "_clean_content",
            "description": {
              "overall": "Removes null\u2011byte characters (\\x00) that can appear when a file encoded as UTF\u201116 is mistakenly read as UTF\u20118. If the supplied content is falsy, it returns an empty string; otherwise it returns the content with all null bytes stripped.",
              "parameters": [
                {
                  "name": "self",
                  "type": "ProjektInfoExtractor",
                  "description": "Instance reference."
                },
                {
                  "name": "content",
                  "type": "str",
                  "description": "The raw text content that may contain null\u2011byte characters."
                }
              ],
              "returns": [
                {
                  "name": "",
                  "type": "str",
                  "description": "The cleaned string without null\u2011byte characters."
                }
              ],
              "usage_context": {
                "calls": "This method does not call any other functions.",
                "called_by": "No other methods are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "_finde_datei",
            "description": {
              "overall": "Searches a list of file objects for the first entry whose path ends with one of the supplied patterns, performing a case\u2011insensitive comparison. Returns the matching file object or `None` if no match is found.",
              "parameters": [
                {
                  "name": "self",
                  "type": "ProjektInfoExtractor",
                  "description": "Instance reference."
                },
                {
                  "name": "patterns",
                  "type": "List[str]",
                  "description": "A list of filename suffixes (e.g., \"readme.md\") to match against."
                },
                {
                  "name": "dateien",
                  "type": "List[Any]",
                  "description": "A collection of file\u2011like objects that expose a `path` attribute."
                }
              ],
              "returns": [
                {
                  "name": "",
                  "type": "Optional[Any]",
                  "description": "The first file object whose path matches one of the patterns, or `None` if no match exists."
                }
              ],
              "usage_context": {
                "calls": "This method does not call any other functions.",
                "called_by": "No other methods are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "_extrahiere_sektion_aus_markdown",
            "description": {
              "overall": "Extracts the text that follows a Markdown level\u20112 heading (##) matching any of the supplied keywords. It builds a regular\u2011expression pattern that is case\u2011insensitive and captures everything up to the next level\u20112 heading or the end of the document, returning the stripped section content if found.",
              "parameters": [
                {
                  "name": "self",
                  "type": "ProjektInfoExtractor",
                  "description": "Instance reference."
                },
                {
                  "name": "inhalt",
                  "type": "str",
                  "description": "The full Markdown document content."
                },
                {
                  "name": "keywords",
                  "type": "List[str]",
                  "description": "A list of possible heading titles to look for (e.g., \"Features\", \"Tech Stack\")."
                }
              ],
              "returns": [
                {
                  "name": "",
                  "type": "Optional[str]",
                  "description": "The extracted section text without surrounding whitespace, or `None` if no matching heading is present."
                }
              ],
              "usage_context": {
                "calls": "This method does not call any other functions.",
                "called_by": "No other methods are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "_parse_readme",
            "description": {
              "overall": "Parses the content of a README file to fill various fields of the `self.info` dictionary. It first cleans the raw content, then extracts the title, a short description, key features, tech stack, current status, installation instructions, and a quick\u2011start guide using regular expressions and the `_extrahiere_sektion_aus_markdown` helper. Each piece of information is stored under the appropriate sub\u2011dictionary only if it has not already been set.",
              "parameters": [
                {
                  "name": "self",
                  "type": "ProjektInfoExtractor",
                  "description": "Instance reference."
                },
                {
                  "name": "inhalt",
                  "type": "str",
                  "description": "Raw text of the README file."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method does not call any other functions.",
                "called_by": "No other methods are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "_parse_toml",
            "description": {
              "overall": "Parses a `pyproject.toml` file to extract the project name, description, and declared dependencies. After cleaning the raw content, it attempts to load the TOML using `tomllib`. If successful, the extracted values are written into the appropriate locations of `self.info`; otherwise a warning is printed.",
              "parameters": [
                {
                  "name": "self",
                  "type": "ProjektInfoExtractor",
                  "description": "Instance reference."
                },
                {
                  "name": "inhalt",
                  "type": "str",
                  "description": "Raw text of the pyproject.toml file."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method does not call any other functions.",
                "called_by": "No other methods are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "_parse_requirements",
            "description": {
              "overall": "Parses a `requirements.txt` file to collect a list of dependency specifications. It cleans the content, splits it into lines, discards empty lines and comments, and stores the resulting list in `self.info` only if dependencies have not already been populated from a TOML file.",
              "parameters": [
                {
                  "name": "self",
                  "type": "ProjektInfoExtractor",
                  "description": "Instance reference."
                },
                {
                  "name": "inhalt",
                  "type": "str",
                  "description": "Raw text of the requirements.txt file."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method does not call any other functions.",
                "called_by": "No other methods are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "extrahiere_info",
            "description": {
              "overall": "Coordinates the whole extraction workflow. It locates README, pyproject.toml and requirements.txt files among the supplied `dateien` list, parses them in order of priority (TOML \u2192 requirements \u2192 README), normalises the dependencies list into a bullet\u2011point string, and falls back to deriving a project title from the repository URL if necessary. Finally, it returns the populated `self.info` dictionary.",
              "parameters": [
                {
                  "name": "self",
                  "type": "ProjektInfoExtractor",
                  "description": "Instance reference."
                },
                {
                  "name": "dateien",
                  "type": "List[Any]",
                  "description": "A collection of file\u2011like objects that may contain README, pyproject.toml or requirements.txt."
                },
                {
                  "name": "repo_url",
                  "type": "str",
                  "description": "URL of the Git repository; used to infer a title when none is found in the files."
                }
              ],
              "returns": [
                {
                  "name": "",
                  "type": "Dict[str, Any]",
                  "description": "A dictionary with two top\u2011level keys (`projekt_uebersicht` and `installation`) containing the extracted project metadata."
                }
              ],
              "usage_context": {
                "calls": "This method does not call any other functions.",
                "called_by": "No other methods are recorded as calling this method."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "The class does not have external dependencies listed.",
          "instantiated_by": "No information about where this class is instantiated is provided."
        }
      },
      "error": null
    },
    "backend.callgraph.CallGraph": {
      "identifier": "backend.callgraph.CallGraph",
      "description": {
        "overall": "CallGraph is an AST NodeVisitor that analyses a Python source file and builds a directed call graph of its functions, methods and imported callables. It tracks imports, class definitions and function definitions, assigning each a fully\u2011qualified name that includes the filename and, when applicable, the class name. While traversing the AST it records edges from callers to callees, handling normal calls as well as the special ``if __name__ == '__main__'`` block. The resulting graph (a NetworkX DiGraph) can be used to understand dependencies and execution flow within the file.",
        "init_method": {
          "description": "The constructor stores the target filename and initialises the internal state required for graph construction, including the current function/class trackers, a mapping of local definitions, the NetworkX directed graph, import alias mapping, a set of discovered functions and an edge dictionary.",
          "parameters": [
            {
              "name": "filename",
              "type": "str",
              "description": "Path or name of the Python file that will be analysed."
            }
          ]
        },
        "methods": [
          {
            "identifier": "_recursive_call",
            "description": {
              "overall": "This helper method walks an AST node that represents a function call and extracts the dotted name components that identify the callee. It handles three node types: Call (by recursing into its ``func`` attribute), Name (returning the identifier), and Attribute (building a list of attribute names recursively). The result is a list of strings representing each part of the name, e.g., ``['pkg', 'mod', 'Class', 'method']``. The method returns an empty list for unsupported node types.",
              "parameters": [
                {
                  "name": "node",
                  "type": "Any",
                  "description": "An ``ast`` node that is expected to be a Call, Name, or Attribute."
                }
              ],
              "returns": [
                {
                  "name": "components",
                  "type": "list[str]",
                  "description": "A list of name components that together form the dotted callee name."
                }
              ],
              "usage_context": {
                "calls": "This method does not call any other methods.",
                "called_by": "No other functions are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "_resolve_all_callee_names",
            "description": {
              "overall": "The method receives a list of name\u2011component lists (as produced by ``_recursive_call``) and resolves each to a fully qualified identifier string. It first checks whether the simple or dotted name exists in the local definition mapping, then looks up import aliases, and finally falls back to constructing a name that includes the filename and optional class context. Resolved names are formatted using ``::`` separators to distinguish module, class and function parts. The method returns a list of resolved callee names, omitting any empty entries.",
              "parameters": [
                {
                  "name": "callee_nodes",
                  "type": "list[list[str]]",
                  "description": "A list where each element is a list of name components representing a potential callee."
                }
              ],
              "returns": [
                {
                  "name": "resolved",
                  "type": "list[str]",
                  "description": "Fully qualified callee identifiers derived from the input components."
                }
              ],
              "usage_context": {
                "calls": "This method does not call any other methods.",
                "called_by": "No other functions are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "_make_full_name",
            "description": {
              "overall": "Constructs a fully qualified name string for a function or method by concatenating the filename, optional class name, and the base name. If a class name is supplied, the format is ``filename::ClassName::basename``; otherwise it is ``filename::basename``. This helper is used when registering functions in the call graph to ensure unique identifiers across the analysed file.",
              "parameters": [
                {
                  "name": "basename",
                  "type": "str",
                  "description": "The simple name of the function or method."
                },
                {
                  "name": "class_name",
                  "type": "str | None",
                  "description": "The name of the enclosing class, if any."
                }
              ],
              "returns": [
                {
                  "name": "full_name",
                  "type": "str",
                  "description": "A string representing the fully qualified identifier."
                }
              ],
              "usage_context": {
                "calls": "This method does not call any other methods.",
                "called_by": "No other functions are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "_current_caller",
            "description": {
              "overall": "Determines the identifier of the code location that is currently being visited. If a function is active, its fully qualified name (as stored in ``self.current_function``) is returned. Otherwise a placeholder using the filename (or ``<global-scope>`` when no filename is set) is produced. This identifier is later used as the caller node when recording edges in the call graph.",
              "parameters": [
                {
                  "name": "self",
                  "type": "Any",
                  "description": "The CallGraph instance."
                }
              ],
              "returns": [
                {
                  "name": "caller_id",
                  "type": "str",
                  "description": "Identifier of the current caller context."
                }
              ],
              "usage_context": {
                "calls": "This method does not call any other methods.",
                "called_by": "No other functions are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_Import",
            "description": {
              "overall": "Visits an ``ast.Import`` node and populates ``self.import_mapping`` with alias\u2011to\u2011module entries. For each imported name it records the original module name under the alias (or the name itself if no ``as`` clause is present). After updating the mapping it continues the generic AST traversal.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.Import",
                  "description": "The import statement node being visited."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method does not call any other methods.",
                "called_by": "No other functions are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_ImportFrom",
            "description": {
              "overall": "Handles ``ast.ImportFrom`` nodes by extracting the originating module (the last component of the dotted module path) and mapping each imported name or alias to that module name. The resulting entries are stored in ``self.import_mapping``. The method then proceeds with the generic visitor to traverse any child nodes.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.ImportFrom",
                  "description": "The ``from ... import ...`` statement node."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method does not call any other methods.",
                "called_by": "No other functions are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_ClassDef",
            "description": {
              "overall": "When a class definition node is encountered, the method saves the previous ``self.current_class`` value, sets ``self.current_class`` to the new class name, and recursively visits the class body. After processing the body it restores the previous class context. This tracking enables later methods to resolve names relative to the current class.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.ClassDef",
                  "description": "The class definition node."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method does not call any other methods.",
                "called_by": "No other functions are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_FunctionDef",
            "description": {
              "overall": "Processes a regular function definition. It builds a fully qualified name using ``_make_full_name`` (including the current class if any) and stores it in ``self.local_defs`` for later resolution. The function name is also added to ``self.local_defs`` under the plain name and under ``ClassName.function`` when inside a class. The method then marks the function as the current caller, adds a node to the call graph, visits the function body, records the function in ``self.function_set`` and finally restores the previous caller context.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.FunctionDef",
                  "description": "The function definition node."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method does not call any other methods.",
                "called_by": "No other functions are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_AsyncFunctionDef",
            "description": {
              "overall": "Delegates handling of asynchronous function definitions to ``visit_FunctionDef`` so that async functions are treated identically for graph construction.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.AsyncFunctionDef",
                  "description": "The async function definition node."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method does not call any other methods.",
                "called_by": "No other functions are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_Call",
            "description": {
              "overall": "When a call expression is visited, the method determines the current caller identifier via ``_current_caller``. It extracts the callee name components using ``_recursive_call`` and resolves them to fully qualified names with ``_resolve_all_callee_names``. For each resolved callee, an edge from the caller to the callee is added to ``self.edges``. Finally, it continues generic traversal of the call node's children.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.Call",
                  "description": "The call expression node."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method does not call any other methods.",
                "called_by": "No other functions are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_If",
            "description": {
              "overall": "Handles ``if`` statements with special logic for the ``if __name__ == '__main__'`` pattern. When such a test is detected, the method temporarily sets ``self.current_function`` to ``<main_block>`` while visiting the body, ensuring that calls inside the main block are recorded under a distinct caller. For all other ``if`` statements, it simply performs a generic visit.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.If",
                  "description": "The if statement node."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method does not call any other methods.",
                "called_by": "No other functions are recorded as calling this method."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "The class does not have listed external dependencies.",
          "instantiated_by": "No instantiation sites are recorded for this class."
        }
      },
      "error": null
    },
    "backend.getRepo.RepoFile": {
      "identifier": "backend.getRepo.RepoFile",
      "description": {
        "overall": "RepoFile represents a single file inside a Git repository. It lazily loads the underlying Git blob, its decoded content, and its size only when those properties are accessed. The class also offers helper utilities such as a word\u2011count analysis, a readable string representation, and a method to export its metadata (and optionally its content) as a dictionary.",
        "init_method": {
          "description": "The constructor stores the repository\u2011relative file path and the commit tree from which the file originates. It also prepares internal placeholders for the blob, content, and size, which are populated lazily on first access.",
          "parameters": [
            {
              "name": "file_path",
              "type": "str",
              "description": "Der Pfad zur Datei innerhalb des Repositories."
            },
            {
              "name": "commit_tree",
              "type": "git.Tree",
              "description": "Das Tree\u2011Objekt des Commits, aus dem die Datei stammt."
            }
          ]
        },
        "methods": [
          {
            "identifier": "blob",
            "description": {
              "overall": "The `blob` property lazily retrieves the Git Blob object that corresponds to the stored file path. On first access it looks up the blob in the provided commit tree and caches it; subsequent accesses return the cached object. If the path is not present in the tree, a `FileNotFoundError` is raised.",
              "parameters": [],
              "returns": [
                {
                  "name": "",
                  "type": "git.Blob",
                  "description": "The Git Blob object representing the file's raw data."
                }
              ],
              "usage_context": {
                "calls": "The method does not call any other functions or methods.",
                "called_by": "No callers are recorded in the provided context."
              }
            },
            "error": null
          },
          {
            "identifier": "content",
            "description": {
              "overall": "The `content` property lazily reads and decodes the blob's data stream as UTF\u20118 text, ignoring decoding errors. The decoded string is cached after the first read, so later accesses are fast. It relies on the `blob` property to obtain the raw data.",
              "parameters": [],
              "returns": [
                {
                  "name": "",
                  "type": "str",
                  "description": "The decoded textual content of the file."
                }
              ],
              "usage_context": {
                "calls": "The method does not call any other functions or methods directly, but accesses the `blob` property.",
                "called_by": "No callers are recorded in the provided context."
              }
            },
            "error": null
          },
          {
            "identifier": "size",
            "description": {
              "overall": "The `size` property lazily obtains the size in bytes of the underlying Git Blob. The size is cached after the first retrieval, making subsequent accesses inexpensive.",
              "parameters": [],
              "returns": [
                {
                  "name": "",
                  "type": "int",
                  "description": "The size of the file in bytes."
                }
              ],
              "usage_context": {
                "calls": "The method does not call any other functions or methods directly, but accesses the `blob` property.",
                "called_by": "No callers are recorded in the provided context."
              }
            },
            "error": null
          },
          {
            "identifier": "analyze_word_count",
            "description": {
              "overall": "`analyze_word_count` provides a simple example analysis by counting the number of whitespace\u2011separated words in the file's content. It accesses the `content` property, splits the string on whitespace, and returns the length of the resulting list.",
              "parameters": [],
              "returns": [
                {
                  "name": "",
                  "type": "int",
                  "description": "The number of words found in the file content."
                }
              ],
              "usage_context": {
                "calls": "The method does not call any other functions or methods directly, but accesses the `content` property.",
                "called_by": "No callers are recorded in the provided context."
              }
            },
            "error": null
          },
          {
            "identifier": "__repr__",
            "description": {
              "overall": "`__repr__` returns a concise string that identifies the RepoFile instance by its path, useful for debugging and logging.",
              "parameters": [],
              "returns": [
                {
                  "name": "",
                  "type": "str",
                  "description": "A string representation like \"<RepoFile(path='...')>\"."
                }
              ],
              "usage_context": {
                "calls": "The method does not call any other functions or methods.",
                "called_by": "No callers are recorded in the provided context."
              }
            },
            "error": null
          },
          {
            "identifier": "to_dict",
            "description": {
              "overall": "`to_dict` builds a dictionary containing the file's path, base name, size, and a static type field set to \"file\". If `include_content` is true, the decoded content is also added under the key \"content\". The method uses the `os.path.basename` helper and the `size` property.",
              "parameters": [
                {
                  "name": "include_content",
                  "type": "bool",
                  "description": "If true, the file's decoded content is included in the returned dictionary."
                }
              ],
              "returns": [
                {
                  "name": "",
                  "type": "dict",
                  "description": "A dictionary representation of the file's metadata (and optionally its content)."
                }
              ],
              "usage_context": {
                "calls": "The method calls `os.path.basename` and accesses the `size` property.",
                "called_by": "No callers are recorded in the provided context."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "The class does not have external module dependencies beyond the imports used in its file.",
          "instantiated_by": "No instantiation sites are provided in the context."
        }
      },
      "error": null
    },
    "backend.getRepo.GitRepository": {
      "identifier": "backend.getRepo.GitRepository",
      "description": {
        "overall": "The **GitRepository** class encapsulates the lifecycle of a remote Git repository for backend processing. It clones the repository into a temporary directory, exposes the files as `RepoFile` objects, and can build a hierarchical representation of the repository's file tree. The class also implements the context\u2011manager protocol to ensure the temporary directory is cleaned up automatically.",
        "init_method": {
          "description": "The constructor receives a repository URL, creates a temporary directory, and attempts to clone the repository into that directory. On success it stores the repository object, the latest commit, and the commit tree for later use; on failure it cleans up and raises a `RuntimeError`.",
          "parameters": [
            {
              "name": "repo_url",
              "type": "str",
              "description": "The URL of the Git repository to be cloned."
            }
          ]
        },
        "methods": [
          {
            "identifier": "get_all_files",
            "description": {
              "overall": "`get_all_files` enumerates every file tracked in the cloned repository using Git's `ls-files` command. It splits the output into individual paths, creates a `RepoFile` instance for each path (passing the path and the commit tree), stores the resulting list in `self.files`, and returns this list. The method therefore provides a convenient collection of all repository files wrapped in a higher\u2011level object. It relies on the external `RepoFile` class to represent each file.\n",
              "parameters": [
                {
                  "name": "self",
                  "type": "GitRepository",
                  "description": "The instance on which the method is invoked."
                }
              ],
              "returns": [
                {
                  "name": "files",
                  "type": "list[RepoFile]",
                  "description": "A list of `RepoFile` objects representing every file in the repository."
                }
              ],
              "usage_context": {
                "calls": "The method calls the `RepoFile` class to instantiate objects for each file path.",
                "called_by": "No other functions or methods are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "close",
            "description": {
              "overall": "`close` removes the temporary directory that was created for the cloned repository. It prints a message indicating the directory being deleted and then clears the `temp_dir` attribute so that subsequent operations know the directory no longer exists. The method does not perform any further cleanup of the Git objects because they are managed by the `git` library.\n",
              "parameters": [
                {
                  "name": "self",
                  "type": "GitRepository",
                  "description": "The instance on which the method is invoked."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "The method does not call any other functions or classes.",
                "called_by": "No other functions or methods are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "__enter__",
            "description": {
              "overall": "`__enter__` implements the context\u2011manager entry protocol. It simply returns the repository instance itself, allowing the caller to use the object within a `with` block.\n",
              "parameters": [
                {
                  "name": "self",
                  "type": "GitRepository",
                  "description": "The instance on which the method is invoked."
                }
              ],
              "returns": [
                {
                  "name": "self",
                  "type": "GitRepository",
                  "description": "The repository instance, enabling its use inside the `with` block."
                }
              ],
              "usage_context": {
                "calls": "The method does not call any other functions or classes.",
                "called_by": "No other functions or methods are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "__exit__",
            "description": {
              "overall": "`__exit__` implements the context\u2011manager exit protocol. Regardless of whether an exception occurred, it invokes `self.close()` to clean up the temporary directory.\n",
              "parameters": [
                {
                  "name": "self",
                  "type": "GitRepository",
                  "description": "The instance on which the method is invoked."
                },
                {
                  "name": "exc_type",
                  "type": "type | None",
                  "description": "The exception type, if an exception was raised inside the `with` block."
                },
                {
                  "name": "exc_val",
                  "type": "BaseException | None",
                  "description": "The exception instance, if an exception was raised."
                },
                {
                  "name": "exc_tb",
                  "type": "TracebackType | None",
                  "description": "The traceback object associated with the exception."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "The method calls `self.close()` to perform cleanup.",
                "called_by": "No other functions or methods are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "get_file_tree",
            "description": {
              "overall": "`get_file_tree` builds a nested dictionary representing the directory hierarchy of the repository. If the file list has not yet been populated, it first calls `self.get_all_files()`. It then iterates over each `RepoFile`, splitting its path into components and constructing intermediate directory nodes as needed. Each file node is added using the `RepoFile.to_dict` method, optionally including file content when `include_content=True`. The final structure is a tree with a root directory node and nested children.\n",
              "parameters": [
                {
                  "name": "self",
                  "type": "GitRepository",
                  "description": "The instance on which the method is invoked."
                },
                {
                  "name": "include_content",
                  "type": "bool",
                  "description": "If true, the file nodes will contain the file content; otherwise only metadata is included."
                }
              ],
              "returns": [
                {
                  "name": "tree",
                  "type": "dict",
                  "description": "A nested dictionary representing the repository's file hierarchy, starting with a root directory node."
                }
              ],
              "usage_context": {
                "calls": "The method calls `self.get_all_files()` when the file list is empty and uses `RepoFile.to_dict` for each file.",
                "called_by": "No other functions or methods are recorded as calling this method."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "The class depends on the `RepoFile` class from the `backend.getRepo` module.",
          "instantiated_by": "No recorded locations instantiate this class."
        }
      },
      "error": null
    },
    "backend.relationship_analyzer.ProjectAnalyzer": {
      "identifier": "backend.relationship_analyzer.ProjectAnalyzer",
      "description": {
        "overall": "ProjectAnalyzer walks through a Python project's directory tree, collects definitions of functions, classes, and methods, and resolves call relationships between them. It builds an internal call\u2011graph data structure that maps each callee to the callers that reference it, and can expose this information as simple outgoing/incoming relationship dictionaries. The class therefore provides a lightweight static analysis tool for understanding intra\u2011project dependencies.",
        "init_method": {
          "description": "The constructor stores the absolute path of the project root, prepares containers for definitions, the call graph, parsed ASTs, and a set of directory names to ignore during traversal.",
          "parameters": [
            {
              "name": "project_root",
              "type": "str",
              "description": "Path to the root directory of the Python project that will be analyzed."
            }
          ]
        },
        "methods": [
          {
            "identifier": "analyze",
            "description": {
              "overall": "The analyze method orchestrates the full static analysis workflow. It first discovers all Python files in the project, then iterates over those files to collect function, class, and method definitions. A second pass resolves call sites by visiting each file's AST with a CallResolverVisitor, populating the internal call\u2011graph. Finally, it clears the cached ASTs to free memory and returns the completed call\u2011graph mapping.",
              "parameters": [],
              "returns": [
                {
                  "name": "call_graph",
                  "type": "dict",
                  "description": "A mapping where each key is a callee identifier and each value is a list of caller information dictionaries."
                }
              ],
              "usage_context": {
                "calls": "The method internally calls _find_py_files, _collect_definitions, and _resolve_calls to gather definitions and resolve calls across all discovered Python files.",
                "called_by": "No other methods in this class directly invoke analyze."
              }
            },
            "error": null
          },
          {
            "identifier": "get_raw_relationships",
            "description": {
              "overall": "get_raw_relationships transforms the internal call\u2011graph into a pair of dictionaries that enumerate outgoing and incoming relationships for each identifier. It iterates over the call\u2011graph, populating sets of callee IDs for each caller (outgoing) and sets of caller IDs for each callee (incoming), then returns the data sorted into lists.",
              "parameters": [],
              "returns": [
                {
                  "name": "relationships",
                  "type": "dict",
                  "description": "A dictionary with two keys, \"outgoing\" and \"incoming\", each mapping identifiers to sorted lists of related identifiers."
                }
              ],
              "usage_context": {
                "calls": "The method does not call any other functions defined in this class.",
                "called_by": "No other methods in this class directly invoke get_raw_relationships."
              }
            },
            "error": null
          },
          {
            "identifier": "_find_py_files",
            "description": {
              "overall": "_find_py_files walks the project directory tree, filters out directories listed in ignore_dirs, and collects the absolute paths of all files ending with \".py\". The resulting list of Python file paths is returned for further analysis.",
              "parameters": [],
              "returns": [
                {
                  "name": "py_files",
                  "type": "list[str]",
                  "description": "A list of absolute file paths for all Python source files found under the project root."
                }
              ],
              "usage_context": {
                "calls": "The method uses os.walk and os.path.join from the standard library.",
                "called_by": "The analyze method calls _find_py_files."
              }
            },
            "error": null
          },
          {
            "identifier": "_collect_definitions",
            "description": {
              "overall": "_collect_definitions reads a Python source file, parses it into an AST, and walks the tree to record definitions of functions, classes, and methods. For each definition it stores the file path, line number, and type (function, method, or class) in the definitions dictionary, using a fully\u2011qualified module path generated by path_to_module. The parsed AST is cached in file_asts for later call\u2011resolution.",
              "parameters": [
                {
                  "name": "filepath",
                  "type": "str",
                  "description": "Absolute path to the Python source file whose definitions are being collected."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "The method calls the external helper path_to_module to compute a module path for each definition.",
                "called_by": "The analyze method calls _collect_definitions for each discovered Python file."
              }
            },
            "error": null
          },
          {
            "identifier": "_get_parent",
            "description": {
              "overall": "_get_parent searches the AST for the immediate parent node of a given node. It walks the tree, examining each node's children, and returns the first parent that directly contains the target node, or None if no parent is found.",
              "parameters": [
                {
                  "name": "tree",
                  "type": "ast.AST",
                  "description": "The root of the abstract syntax tree being inspected."
                },
                {
                  "name": "node",
                  "type": "ast.AST",
                  "description": "The AST node whose parent is to be located."
                }
              ],
              "returns": [
                {
                  "name": "parent",
                  "type": "ast.AST | None",
                  "description": "The parent node of the supplied node, or None if the node is the root."
                }
              ],
              "usage_context": {
                "calls": "The method does not invoke any other functions.",
                "called_by": "The _collect_definitions method calls _get_parent to determine whether a function is defined inside a class."
              }
            },
            "error": null
          },
          {
            "identifier": "_resolve_calls",
            "description": {
              "overall": "_resolve_calls retrieves the cached AST for a file, instantiates a CallResolverVisitor with the file path, project root, and the collected definitions, and visits the AST to discover call relationships. The visitor returns a mapping of callee identifiers to caller information, which is merged into the class's call_graph. Errors during visitation are logged but do not halt processing.",
              "parameters": [
                {
                  "name": "filepath",
                  "type": "str",
                  "description": "Absolute path to the Python source file whose call sites are being resolved."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "The method calls the external CallResolverVisitor class to walk the AST.",
                "called_by": "The analyze method calls _resolve_calls for each discovered Python file."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "The class depends on the CallResolverVisitor class and the path_to_module function from the backend.relationship_analyzer module, as well as standard library modules ast, os, logging, and collections.defaultdict.",
          "instantiated_by": "No instantiation sites were provided in the context."
        }
      },
      "error": null
    },
    "backend.relationship_analyzer.CallResolverVisitor": {
      "identifier": "backend.relationship_analyzer.CallResolverVisitor",
      "description": {
        "overall": "CallResolverVisitor is an AST node visitor that walks a Python module, resolves qualified names of function and method calls, and records where each defined callable is invoked. It tracks imports, from\u2011imports, class definitions, and simple assignments to map variable names to their originating modules or classes. By maintaining a scope dictionary and an instance\u2011type map, it can resolve attribute calls on imported modules or instantiated objects. The collected information is stored in a defaultdict mapping each callee pathname to a list of caller metadata (file, line, caller identifier, and caller type). This enables downstream analysis of call relationships across a codebase.",
        "init_method": {
          "description": "The constructor initializes the visitor with the path of the file to analyse, the project root, and a dictionary of known definitions. It computes the module path, sets up empty scopes for imports and instance types, and prepares a container for collected call information.",
          "parameters": [
            {
              "name": "filepath",
              "type": "str",
              "description": "Filesystem path to the Python source file being visited."
            },
            {
              "name": "project_root",
              "type": "str",
              "description": "Root directory of the project; used together with `filepath` to compute the module's dotted path."
            },
            {
              "name": "definitions",
              "type": "dict",
              "description": "Mapping of fully\u2011qualified names to definition metadata; used to verify whether a resolved call target is a known definition."
            }
          ]
        },
        "methods": [
          {
            "identifier": "visit_ClassDef",
            "description": {
              "overall": "When the visitor encounters a class definition node, it records the class name as the current context, walks the class body, and then restores the previous class context. This allows subsequent method and call visits to know whether they belong to a class and to construct fully\u2011qualified identifiers that include the class name. The method does not directly modify any other state besides the temporary `current_class_name` variable.",
              "parameters": [
                {
                  "name": "self",
                  "type": "CallResolverVisitor",
                  "description": "The visitor instance."
                },
                {
                  "name": "node",
                  "type": "ast.ClassDef",
                  "description": "AST node representing the class definition."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method does not call any other functions.",
                "called_by": "No other functions are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_FunctionDef",
            "description": {
              "overall": "When a function (or method) definition node is visited, the visitor builds a fully\u2011qualified identifier that includes the module path and, if inside a class, the class name. It temporarily stores this identifier as the current caller, traverses the function body to capture any calls made within, and finally restores the previous caller context. This enables accurate attribution of calls to the correct function or method.",
              "parameters": [
                {
                  "name": "self",
                  "type": "CallResolverVisitor",
                  "description": "The visitor instance."
                },
                {
                  "name": "node",
                  "type": "ast.FunctionDef",
                  "description": "AST node representing the function or method definition."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method does not call any other functions.",
                "called_by": "No other functions are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_Call",
            "description": {
              "overall": "For each call expression encountered, the visitor attempts to resolve the called object's fully\u2011qualified name using `_resolve_call_qname`. If the resolved name exists in the provided definitions, it records a caller entry containing the source file, line number, full caller identifier, and a derived caller type (module, function, method, or local function). The caller type is inferred from the current context (module level, inside a class, etc.). After recording, the visitor continues traversing any nested nodes.",
              "parameters": [
                {
                  "name": "self",
                  "type": "CallResolverVisitor",
                  "description": "The visitor instance."
                },
                {
                  "name": "node",
                  "type": "ast.Call",
                  "description": "AST node representing the call expression."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method does not call any other functions.",
                "called_by": "No other functions are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_Import",
            "description": {
              "overall": "When an import statement is visited, each imported name (or its alias) is added to the visitor's `scope` dictionary, mapping the local name to the fully\u2011qualified module name. This scope is later used to resolve simple name calls to their originating modules. After updating the scope, the method proceeds with a generic visit of child nodes.",
              "parameters": [
                {
                  "name": "self",
                  "type": "CallResolverVisitor",
                  "description": "The visitor instance."
                },
                {
                  "name": "node",
                  "type": "ast.Import",
                  "description": "AST node representing the import statement."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method does not call any other functions.",
                "called_by": "No other functions are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_ImportFrom",
            "description": {
              "overall": "For `from ... import ...` statements, the method resolves the absolute module path, taking into account relative import levels, and records each imported name (or alias) in the `scope` dictionary with its fully\u2011qualified name. This enables later resolution of attribute accesses on imported objects. After populating the scope, it continues a generic traversal of the node's children.",
              "parameters": [
                {
                  "name": "self",
                  "type": "CallResolverVisitor",
                  "description": "The visitor instance."
                },
                {
                  "name": "node",
                  "type": "ast.ImportFrom",
                  "description": "AST node representing the from\u2011import statement."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method does not call any other functions.",
                "called_by": "No other functions are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_Assign",
            "description": {
              "overall": "When an assignment is visited, the method checks whether the right\u2011hand side is a call to a name that exists in the current `scope`. If so, and the called name resolves to a known definition, the left\u2011hand side variable name is recorded in `instance_types` as an instance of that qualified class. This mapping later assists `_resolve_call_qname` in resolving method calls on instantiated objects. The visitor then proceeds with a generic visit of the assignment node.",
              "parameters": [
                {
                  "name": "self",
                  "type": "CallResolverVisitor",
                  "description": "The visitor instance."
                },
                {
                  "name": "node",
                  "type": "ast.Assign",
                  "description": "AST node representing the assignment statement."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method does not call any other functions.",
                "called_by": "No other functions are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "_resolve_call_qname",
            "description": {
              "overall": "This helper resolves the fully\u2011qualified name of a called function or method given its AST node. It handles simple name nodes by looking them up in the `scope` or by constructing a module\u2011local pathname. For attribute accesses where the base is a known variable, it uses `instance_types` to map the variable to its class and appends the attribute as a method name; otherwise it falls back to the scoped module name. If resolution fails, it returns `None`.",
              "parameters": [
                {
                  "name": "self",
                  "type": "CallResolverVisitor",
                  "description": "The visitor instance."
                },
                {
                  "name": "func_node",
                  "type": "ast.AST",
                  "description": "AST node representing the function part of a call expression."
                }
              ],
              "returns": [
                {
                  "name": "qualified_name",
                  "type": "str | None",
                  "description": "The resolved fully\u2011qualified name of the callable, or `None` if it cannot be resolved."
                }
              ],
              "usage_context": {
                "calls": "This method does not call any other functions.",
                "called_by": "No other functions are recorded as calling this method."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "The class depends on the external function backend.relationship_analyzer.path_to_module.",
          "instantiated_by": "No recorded locations instantiate this class."
        }
      },
      "error": null
    },
    "schemas.types.ParameterDescription": {
      "identifier": "schemas.types.ParameterDescription",
      "description": {
        "overall": "ParameterDescription is a lightweight Pydantic model that represents the metadata of a single function parameter. It stores the parameter's name, its type as a string, and a human\u2011readable description. The class provides a structured way to capture and validate this information for documentation or introspection purposes.",
        "init_method": {
          "description": "The class relies on Pydantic's autogenerated __init__, which accepts the three declared fields (name, type, description) as keyword arguments and assigns them to the instance.",
          "parameters": []
        },
        "methods": [],
        "usage_context": {
          "dependencies": "The class does not depend on any external modules beyond the imports listed (typing and pydantic).",
          "instantiated_by": "No instantiation contexts were provided."
        }
      },
      "error": null
    },
    "schemas.types.ReturnDescription": {
      "identifier": "schemas.types.ReturnDescription",
      "description": {
        "overall": "ReturnDescription is a Pydantic model that encapsulates metadata about a function's return value. It stores three string fields\u2014`name`, `type`, and `description`\u2014which respectively represent the identifier of the return value, its data type, and a human\u2011readable explanation. By inheriting from `BaseModel`, it gains automatic validation, serialization, and an autogenerated `__init__` that accepts these fields. This model is intended for use in documentation generation or API schema definitions to convey what a function returns.",
        "init_method": {
          "description": "The class relies on Pydantic's autogenerated `__init__`, which accepts the three model fields defined in the class.",
          "parameters": []
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class does not depend on any external modules beyond the imported `BaseModel` from pydantic.",
          "instantiated_by": "No locations are provided that instantiate `ReturnDescription`."
        }
      },
      "error": null
    },
    "schemas.types.UsageContext": {
      "identifier": "schemas.types.UsageContext",
      "description": {
        "overall": "The **UsageContext** class is a lightweight Pydantic model that captures the calling context of a function. It defines two string fields, `calls` and `called_by`, which respectively record which functions are invoked and which functions invoke the current one. By inheriting from `BaseModel`, it gains automatic data validation, serialization, and a generated `__init__` that accepts values for these attributes. The class serves purely as a typed container for this relationship information.",
        "init_method": {
          "description": "Because the class inherits from `pydantic.BaseModel` and does not define its own `__init__`, the constructor is supplied by the base class. It accepts keyword arguments matching the declared fields (`calls` and `called_by`) and assigns them to the instance.",
          "parameters": []
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class does not rely on any external runtime dependencies beyond the imported modules (typing and pydantic).",
          "instantiated_by": "No information is provided about where or how `UsageContext` instances are created."
        }
      },
      "error": null
    },
    "schemas.types.FunctionDescription": {
      "identifier": "schemas.types.FunctionDescription",
      "description": {
        "overall": "FunctionDescription is a Pydantic model that encapsulates a comprehensive analysis of a function, including a textual overall description, a list of its parameters, a list of its return values, and contextual usage information. It serves as a structured container for documenting function signatures and their purpose within a codebase.",
        "init_method": {
          "description": "The class inherits from pydantic.BaseModel, so initialization is handled by the BaseModel constructor which accepts the defined fields as keyword arguments.",
          "parameters": []
        },
        "methods": [],
        "usage_context": {
          "dependencies": "No external dependencies are specified for this class beyond the imported typing and pydantic modules.",
          "instantiated_by": "There are no recorded locations where this class is instantiated."
        }
      },
      "error": null
    },
    "schemas.types.FunctionAnalysis": {
      "identifier": "schemas.types.FunctionAnalysis",
      "description": {
        "overall": "The **FunctionAnalysis** class is a Pydantic model that encapsulates the complete JSON schema for representing a function analysis. It stores a unique identifier for the function, a detailed description (via the nested **FunctionDescription** model), and an optional error message that can be populated when validation or processing fails. By inheriting from **BaseModel**, it gains automatic data validation, serialization, and helpful error reporting.",
        "init_method": {
          "description": "The class relies on Pydantic's autogenerated ``__init__`` method, which accepts the fields defined in the model and assigns them to the instance. No custom constructor logic is provided.",
          "parameters": []
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class does not depend on any external modules beyond the standard ``typing`` imports and Pydantic's ``BaseModel``.",
          "instantiated_by": "No specific instantiation sites are recorded in the provided context."
        }
      },
      "error": null
    },
    "schemas.types.ConstructorDescription": {
      "identifier": "schemas.types.ConstructorDescription",
      "description": {
        "overall": "ConstructorDescription serves as a structured representation of a class's ``__init__`` method. It stores a free\u2011form textual description of the constructor and a list of ``ParameterDescription`` objects that detail each parameter. As a subclass of ``pydantic.BaseModel`` it gains automatic validation, serialization, and a generated ``__init__`` that accepts the declared fields. This model enables other parts of the system to introspect and document constructors in a uniform way.",
        "init_method": {
          "description": "The class does not define an explicit ``__init__``; Pydantic creates one automatically based on the declared fields. The generated initializer accepts ``description`` (a string) and ``parameters`` (a list of ``ParameterDescription``) and assigns them to the instance. This provides a simple container for constructor metadata.",
          "parameters": []
        },
        "methods": [],
        "usage_context": {
          "dependencies": "The class relies only on standard typing imports (List) and the ``pydantic`` library; no additional external dependencies are required.",
          "instantiated_by": "No specific locations in the supplied context instantiate this class."
        }
      },
      "error": null
    },
    "schemas.types.ClassContext": {
      "identifier": "schemas.types.ClassContext",
      "description": {
        "overall": "The `ClassContext` model captures metadata about a class's external dependencies and the locations in the codebase where the class is instantiated. It provides a lightweight, declarative representation that can be used for documentation, analysis, or tooling purposes. By inheriting from `pydantic.BaseModel`, it benefits from automatic validation and serialization of its fields.",
        "init_method": {
          "description": "Instances of `ClassContext` are created using the default Pydantic constructor, which accepts values for the `dependencies` and `instantiated_by` fields and stores them as instance attributes.",
          "parameters": [
            {
              "name": "dependencies",
              "type": "str",
              "description": "A string describing the external dependencies required by the class."
            },
            {
              "name": "instantiated_by",
              "type": "str",
              "description": "A string indicating where or by which components the class is instantiated."
            }
          ]
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class does not declare any external dependencies.",
          "instantiated_by": "No parts of the codebase are recorded as instantiating this class."
        }
      },
      "error": null
    },
    "schemas.types.ClassDescription": {
      "identifier": "schemas.types.ClassDescription",
      "description": {
        "overall": "ClassDescription is a Pydantic model that serves as a container for the full analysis of another class, including its overall purpose, constructor details, method analyses, and usage context. It does not implement any custom behavior beyond the fields defined for storing this structured information.",
        "init_method": {
          "description": "ClassDescription relies on the default BaseModel constructor provided by Pydantic; no custom __init__ logic is defined.",
          "parameters": []
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class does not depend on any external modules or packages beyond the imports required for its type annotations.",
          "instantiated_by": "There are no recorded locations where this class is instantiated."
        }
      },
      "error": null
    },
    "ClassAnalysis": {
      "identifier": "ClassAnalysis",
      "description": {
        "overall": "ClassAnalysis is a Pydantic model that defines the top\u2011level JSON schema used to represent the analysis of a Python class. It groups together the class identifier, a detailed description of its constructor and methods, and an optional error field. The model serves as a structured container for downstream documentation generation.",
        "init_method": {
          "description": "No explicit __init__ method is defined; the class relies on the default BaseModel initializer provided by Pydantic.",
          "parameters": []
        },
        "methods": [],
        "usage_context": {
          "dependencies": "The class does not depend on any external runtime components beyond the imports listed (typing and pydantic).",
          "instantiated_by": "No information is provided about where or how this class is instantiated."
        }
      },
      "error": null
    },
    "schemas.types.CallInfo": {
      "identifier": "schemas.types.CallInfo",
      "description": {
        "overall": "CallInfo is a Pydantic data model that encapsulates information about a specific call event discovered by a relationship analyzer. It stores the source file, the calling function name, the call mode (e.g., method, function, module), and the line number where the call occurs. This structured representation is used in the 'called_by' and 'instantiated_by' collections to trace code relationships.",
        "init_method": {
          "description": "The class does not define an explicit __init__ method; Pydantic's BaseModel provides a generated initializer that accepts the defined fields.",
          "parameters": []
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class does not rely on any external modules beyond the imported typing utilities and Pydantic's BaseModel.",
          "instantiated_by": "No specific instantiation sites are provided in the context."
        }
      },
      "error": null
    },
    "schemas.types.FunctionContextInput": {
      "identifier": "schemas.types.FunctionContextInput",
      "description": {
        "overall": "FunctionContextInput is a Pydantic model that encapsulates the contextual information required to analyze a function, specifically the functions it calls and the locations from which it is called.",
        "init_method": {
          "description": "The class relies on Pydantic's generated __init__, which accepts values for the defined fields and initializes the BaseModel.",
          "parameters": []
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class does not depend on any external modules beyond the standard typing imports and Pydantic.",
          "instantiated_by": "No known locations instantiate this class in the provided context."
        }
      },
      "error": null
    },
    "schemas.types.FunctionAnalysisInput": {
      "identifier": "schemas.types.FunctionAnalysisInput",
      "description": {
        "overall": "FunctionAnalysisInput is a Pydantic model that encapsulates all data required to perform a function analysis. It stores the analysis mode, the identifier of the target function, its source code, a list of import statements, and a context object describing the function's execution environment. This structured input enables downstream components to generate a detailed FunctionAnalysis.",
        "init_method": {
          "description": "The class relies on Pydantic's autogenerated __init__, which accepts the fields defined in the model.",
          "parameters": []
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class does not depend on any external modules beyond the imports listed in the source file.",
          "instantiated_by": "No instantiation sites are provided in the current context."
        }
      },
      "error": null
    },
    "schemas.types.MethodContextInput": {
      "identifier": "schemas.types.MethodContextInput",
      "description": {
        "overall": "MethodContextInput is a Pydantic data model that encapsulates structured context for a class's methods. It records the method's identifier, a list of method names it calls, detailed information about callers, the argument names, and an optional docstring. This model is used to transport method\u2011level metadata within the system.",
        "init_method": {
          "description": "The class does not define an explicit __init__; it inherits the initializer from pydantic.BaseModel, which automatically creates an __init__ that accepts the declared fields as keyword arguments.",
          "parameters": []
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class does not depend on any external modules beyond the standard typing imports and pydantic.",
          "instantiated_by": "There are no recorded locations where MethodContextInput is instantiated."
        }
      },
      "error": null
    },
    "schemas.types.ClassContextInput": {
      "identifier": "schemas.types.ClassContextInput",
      "description": {
        "overall": "ClassContextInput is a Pydantic BaseModel that encapsulates the structured context required for analyzing a class. It holds three fields: `dependencies`, a list of strings naming external dependencies; `instantiated_by`, a list of `CallInfo` objects describing where instances of the target class are created; and `method_context`, a list of `MethodContextInput` objects that capture call relationships for each method. The model serves as a typed container for passing this analysis context through the system.",
        "init_method": {
          "description": "The class does not define a custom `__init__`; it relies on the initializer generated by Pydantic's BaseModel.",
          "parameters": []
        },
        "methods": [],
        "usage_context": {
          "dependencies": "The class does not declare any external dependencies.",
          "instantiated_by": "No information is provided about where this class is instantiated."
        }
      },
      "error": null
    },
    "schemas.types.ClassAnalysisInput": {
      "identifier": "schemas.types.ClassAnalysisInput",
      "description": {
        "overall": "ClassAnalysisInput is a Pydantic model that defines the required input schema for generating a ClassAnalysis object. It declares the fixed mode value \"class_analysis\", an identifier string, the source code to be examined, a list of import statements, and a context object describing dependencies and instantiation sites. The model acts as a structured container for all information needed by the class\u2011analysis pipeline.",
        "init_method": {
          "description": "The class does not define a custom __init__ method; it inherits the default initializer from pydantic.BaseModel which assigns the declared fields.",
          "parameters": []
        },
        "methods": [],
        "usage_context": {
          "dependencies": "The class does not depend on any external modules beyond those listed in its imports.",
          "instantiated_by": "No instantiation sites are provided in the context."
        }
      },
      "error": null
    }
  }
}