{
  "functions": {
    "backend.AST_Schema.path_to_module": {
      "identifier": "backend.AST_Schema.path_to_module",
      "description": {
        "overall": "This function converts a given file path into a Python module path relative to a specified project root. It first calculates the relative path, handling potential errors by falling back to the base filename. It then removes the '.py' extension if present and replaces the operating system's path separator with dots to form a module path. Special handling is included for '__init__.py' files, where the '__init__' suffix is removed from the module path.",
        "parameters": [
          {
            "name": "filepath",
            "type": "str",
            "description": "The absolute or relative path to the file."
          },
          {
            "name": "project_root",
            "type": "str",
            "description": "The root directory of the project from which the relative path is calculated."
          }
        ],
        "returns": [
          {
            "name": "module_path",
            "type": "str",
            "description": "The calculated Python module path string."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "backend.File_Dependency.build_file_dependency_graph": {
      "identifier": "backend.File_Dependency.build_file_dependency_graph",
      "description": {
        "overall": "This function constructs a directed graph representing file dependencies within a Python project. It takes a filename, an Abstract Syntax Tree (AST) of the file, and the repository root as input. The function initializes a graph and uses a visitor pattern to traverse the AST, identifying import dependencies. It then populates the graph with nodes representing the files and adds edges to show the import relationships. The resulting graph is returned.",
        "parameters": [
          {
            "name": "filename",
            "type": "str",
            "description": "The name of the file being analyzed."
          },
          {
            "name": "tree",
            "type": "AST",
            "description": "The Abstract Syntax Tree (AST) of the file."
          },
          {
            "name": "repo_root",
            "type": "str",
            "description": "The root directory of the repository."
          }
        ],
        "returns": [
          {
            "name": "graph",
            "type": "nx.DiGraph",
            "description": "A directed graph representing the file dependencies."
          }
        ],
        "usage_context": {
          "calls": "This function calls backend.File_Dependency.FileDependencyGraph.",
          "called_by": "This function is not called by any other function."
        }
      },
      "error": null
    },
    "backend.File_Dependency.build_repository_graph": {
      "identifier": "backend.File_Dependency.build_repository_graph",
      "description": {
        "overall": "This function constructs a directed graph representing the dependencies between Python files within a Git repository. It iterates through all Python files, parses their Abstract Syntax Trees (ASTs), and builds a local dependency graph for each file. These local graphs are then merged into a single global graph. The function specifically focuses on Python files, ignoring others, and adds nodes and edges to the global graph based on the identified dependencies. The final global graph captures the call relationships between different functions and classes across the entire repository.",
        "parameters": [
          {
            "name": "repository",
            "type": "GitRepository",
            "description": "An object representing the Git repository, providing methods to access files and repository information."
          }
        ],
        "returns": [
          {
            "name": "global_graph",
            "type": "nx.DiGraph",
            "description": "A NetworkX directed graph where nodes represent functions/classes and edges represent call dependencies between them across the repository."
          }
        ],
        "usage_context": {
          "calls": "This function calls backend.File_Dependency.build_file_dependency_graph.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "backend.File_Dependency.get_all_temp_files": {
      "identifier": "backend.File_Dependency.get_all_temp_files",
      "description": {
        "overall": "This function, `get_all_temp_files`, takes a directory path as input and recursively searches for all Python files (`.py`) within that directory and its subdirectories. It resolves the root path to an absolute path and then uses `rglob` to find all matching files. The function returns a list of these files, represented as paths relative to the provided root directory.",
        "parameters": [
          {
            "name": "directory",
            "type": "str",
            "description": "The path to the directory to search for Python files."
          }
        ],
        "returns": [
          {
            "name": "all_files",
            "type": "list[Path]",
            "description": "A list of Path objects, where each Path represents a Python file found within the directory, relative to the root directory."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "backend.HelperLLM.main_orchestrator": {
      "identifier": "backend.HelperLLM.main_orchestrator",
      "description": {
        "overall": "This function serves as a dummy orchestrator for testing the LLMHelper class and its documentation generation capabilities. It simulates the process of analyzing individual functions and classes by defining pre-computed analysis data for several methods (`add_item`, `check_stock`, `generate_report`) and then uses this data to instantiate a `ClassAnalysisInput` object for an `InventoryManager` class. Finally, it calls the `generate_for_functions` method of an `LLMHelper` instance to process these inputs and prints the aggregated documentation in JSON format.",
        "parameters": [],
        "returns": [],
        "usage_context": {
          "calls": "backend.HelperLLM.LLMHelper, schemas.types.ClassAnalysisInput, schemas.types.ClassContextInput",
          "called_by": "This function is not called by any other function."
        }
      },
      "error": null
    },
    "backend.callgraph.make_safe_dot": {
      "identifier": "backend.callgraph.make_safe_dot",
      "description": {
        "overall": "This function takes a NetworkX directed graph and an output path as input. It creates a copy of the graph and then relabels the nodes to ensure they are safe for DOT format, typically by prefixing them with 'n' followed by an index. It also adds a 'label' attribute to each relabeled node, storing the original node name. Finally, it writes the modified graph to a DOT file at the specified output path using `nx.drawing.nx_pydot.write_dot`.",
        "parameters": [
          {
            "name": "graph",
            "type": "nx.DiGraph",
            "description": "The input NetworkX directed graph to be processed."
          },
          {
            "name": "out_path",
            "type": "str",
            "description": "The file path where the DOT representation of the graph will be saved."
          }
        ],
        "returns": [],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "backend.callgraph.build_filtered_callgraph": {
      "identifier": "backend.callgraph.build_filtered_callgraph",
      "description": {
        "overall": "This function constructs a global call graph for a given Git repository and then filters it to include only functions defined within the repository itself. It iterates through all Python files, parses their Abstract Syntax Trees (ASTs), and identifies all functions defined within these files. It then builds a directed graph where nodes represent functions and edges represent calls between them, ensuring that both the caller and callee are functions defined within the repository. The function uses the `ast` module for parsing and `networkx` for graph manipulation.",
        "parameters": [
          {
            "name": "repo",
            "type": "GitRepository",
            "description": "An object representing the Git repository to analyze, providing methods to access files."
          }
        ],
        "returns": [
          {
            "name": "global_graph",
            "type": "nx.DiGraph",
            "description": "A directed graph representing the filtered call graph, containing only calls between functions defined within the repository."
          }
        ],
        "usage_context": {
          "calls": "This function calls backend.callgraph.CallGraph.",
          "called_by": "This function is not called by any other function within the provided context."
        }
      },
      "error": null
    },
    "backend.converter.wrap_cdata": {
      "identifier": "backend.converter.wrap_cdata",
      "description": {
        "overall": "This function takes a string `content` as input and returns a new string where the input content is wrapped within XML CDATA section tags. The CDATA tags are formatted as '<![CDATA[\\n{content}\\n]]>', ensuring that the content is treated as raw character data and not parsed as markup. This is useful for embedding content that might otherwise be interpreted as XML markup within an XML document.",
        "parameters": [
          {
            "name": "content",
            "type": "str",
            "description": "The string content to be wrapped in CDATA tags."
          }
        ],
        "returns": [
          {
            "name": "wrapped_content",
            "type": "str",
            "description": "The input content wrapped within CDATA tags, including newlines before and after the content."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "backend.converter.extract_output_content": {
      "identifier": "backend.converter.extract_output_content",
      "description": {
        "overall": "This function iterates through a list of outputs, processing different output types to extract relevant content. It specifically handles 'display_data' and 'execute_result' types by extracting plain text or decoding Base64 encoded images (PNG or JPEG) into a list of image placeholders. For 'stream' outputs, it appends the text content, and for 'error' outputs, it formats the error name and value. The function aims to create a list of strings that represent the extracted content, including placeholders for images.",
        "parameters": [
          {
            "name": "outputs",
            "type": "list",
            "description": "A list of output objects, each potentially containing data, type, text, or error information."
          },
          {
            "name": "image_list",
            "type": "list",
            "description": "A list to which decoded image data (as dictionaries with mime_type and data) will be appended. This list is modified in place."
          }
        ],
        "returns": [
          {
            "name": "extracted_xml_snippets",
            "type": "list[str]",
            "description": "A list of strings, where each string is either plain text, an image placeholder (e.g., '<IMAGE_PLACEHOLDER index=\"0\" mime=\"image/png\"/>'), or an error message."
          }
        ],
        "usage_context": {
          "calls": "This function calls backend.converter.process_image.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "backend.converter.process_image": {
      "identifier": "backend.converter.process_image",
      "description": {
        "overall": "This function processes an image based on its MIME type. It checks if the MIME type exists in a predefined data structure. If found, it attempts to decode a base64 encoded string associated with that MIME type, removes newline characters, and stores the image data in a global list `image_list`. It then returns an HTML-like placeholder string indicating the index and MIME type of the added image. If any exception occurs during decoding or processing, it returns an error message. If the MIME type is not found in the data, it returns None.",
        "parameters": [
          {
            "name": "mime_type",
            "type": "str",
            "description": "The MIME type of the image to be processed."
          }
        ],
        "returns": [
          {
            "name": "placeholder_or_error",
            "type": "str",
            "description": "A string representing an image placeholder with its index and MIME type, or an error message if processing fails. Returns None if the mime_type is not found."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "backend.converter.convert_notebook_to_xml": {
      "identifier": "backend.converter.convert_notebook_to_xml",
      "description": {
        "overall": "This function takes the content of a Jupyter notebook as a string and converts it into an XML format. It iterates through the cells of the notebook, processing markdown, code, and output cells. Markdown cells are directly included, code cells have their source wrapped in CDATA, and output cells are extracted and also wrapped in CDATA if they contain content. The function handles potential JSON parsing errors and returns the generated XML along with a list of extracted images.",
        "parameters": [
          {
            "name": "file_content",
            "type": "str",
            "description": "A string containing the raw content of the Jupyter notebook file."
          }
        ],
        "returns": [
          {
            "name": "xml_output",
            "type": "str",
            "description": "A string representing the converted notebook content in XML format."
          },
          {
            "name": "extracted_images",
            "type": "list",
            "description": "A list of image data extracted from the notebook outputs."
          }
        ],
        "usage_context": {
          "calls": "This function calls backend.converter.extract_output_content and backend.converter.wrap_cdata.",
          "called_by": "This function is not called by any other functions within the provided context."
        }
      },
      "error": null
    },
    "backend.converter.process_repo_notebooks": {
      "identifier": "backend.converter.process_repo_notebooks",
      "description": {
        "overall": "This function iterates through a list of repository files, identifies Jupyter Notebook files ('.ipynb'), and processes each one. For every notebook found, it calls `convert_notebook_to_xml` to transform the notebook's content into an XML format and extract any associated images. The results, containing the XML output and images for each notebook, are stored in a dictionary keyed by the notebook's file path.",
        "parameters": [
          {
            "name": "repo_files",
            "type": "List[FileObject]",
            "description": "A list of file objects, where each object is expected to have 'path' and 'content' attributes."
          }
        ],
        "returns": [
          {
            "name": "results",
            "type": "Dict[str, Dict[str, Any]]",
            "description": "A dictionary where keys are notebook file paths and values are dictionaries containing 'xml' (the converted XML string) and 'images' (a list of extracted images)."
          }
        ],
        "usage_context": {
          "calls": "This function calls backend.converter.convert_notebook_to_xml.",
          "called_by": "This function is not called by any other functions within the provided context."
        }
      },
      "error": null
    },
    "backend.main.create_savings_chart": {
      "identifier": "backend.main.create_savings_chart",
      "description": {
        "overall": "This function generates a bar chart to visualize the comparison of two token types, 'JSON' and 'TOON', and indicates the percentage of savings achieved. It sets up the chart with specific labels, values, and colors, then adds a title, y-axis label, and a grid for better readability. Additionally, it displays the exact token counts above each bar and saves the generated chart to a specified file path, finally closing the plot to free up resources.",
        "parameters": [
          {
            "name": "json_tokens",
            "type": "int",
            "description": "The number of tokens for the JSON format."
          },
          {
            "name": "toon_tokens",
            "type": "int",
            "description": "The number of tokens for the TOON format."
          },
          {
            "name": "savings_percent",
            "type": "float",
            "description": "The calculated percentage of savings between the two token formats."
          },
          {
            "name": "output_path",
            "type": "str",
            "description": "The file path where the generated chart image will be saved."
          }
        ],
        "returns": [],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "backend.main.calculate_net_time": {
      "identifier": "backend.main.calculate_net_time",
      "description": {
        "overall": "This function calculates the net processing time by subtracting estimated sleep times from the total duration. It first determines the total duration based on start and end times. If the model name does not start with 'gemini-', it returns the total duration directly. For 'gemini-' models, it calculates the number of batches and the total sleep time incurred by rate limits, then subtracts this sleep time from the total duration. The function ensures that the returned net time is not negative.",
        "parameters": [
          {
            "name": "start_time",
            "type": "Any",
            "description": "The start time of the process."
          },
          {
            "name": "end_time",
            "type": "Any",
            "description": "The end time of the process."
          },
          {
            "name": "total_items",
            "type": "int",
            "description": "The total number of items processed."
          },
          {
            "name": "batch_size",
            "type": "int",
            "description": "The size of each batch."
          },
          {
            "name": "model_name",
            "type": "str",
            "description": "The name of the model being used."
          }
        ],
        "returns": [
          {
            "name": "net_time",
            "type": "int",
            "description": "The calculated net processing time after subtracting sleep times, or 0 if total_items is 0, or the total_duration if the model is not a gemini model."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is called by no other functions."
        }
      },
      "error": null
    },
    "backend.main.main_workflow": {
      "identifier": "backend.main.main_workflow",
      "description": {
        "overall": "The `main_workflow` function orchestrates a comprehensive analysis of a GitHub repository. It begins by extracting API keys and model configurations, then clones the specified repository. Following this, it extracts basic project information, constructs a file tree, and performs relationship analysis (identifying calls and instantiations). The core of the analysis involves generating an Abstract Syntax Tree (AST) for the repository's files and enriching it with the relationship data. This processed data is then prepared as input for a Helper LLM, which analyzes individual functions and classes. Finally, the results from the Helper LLM, along with other extracted information, are fed into a Main LLM to generate a final report. The function also includes metrics tracking, token savings estimation, and saving the report and related statistics.",
        "parameters": [
          {
            "name": "input",
            "type": "Any",
            "description": "The primary input for the workflow, likely containing information or a URL for the repository to be analyzed."
          },
          {
            "name": "api_keys",
            "type": "dict",
            "description": "A dictionary containing API keys for various services like Gemini, OpenAI, and SCADSLLM, as well as base URLs for services like Ollama."
          },
          {
            "name": "model_names",
            "type": "dict",
            "description": "A dictionary specifying the model names to be used for different tasks, such as 'helper' and 'main' models."
          },
          {
            "name": "status_callback",
            "type": "Optional[Callable]",
            "description": "An optional callback function that can be used to report the status of the workflow's progress."
          }
        ],
        "returns": [
          {
            "name": "report",
            "type": "str",
            "description": "The final generated report summarizing the analysis of the repository."
          },
          {
            "name": "metrics",
            "type": "dict",
            "description": "A dictionary containing performance metrics of the workflow, including execution times, models used, and token usage."
          }
        ],
        "usage_context": {
          "calls": "This function calls backend.AST_Schema.ASTAnalyzer, backend.AST_Schema.ASTAnalyzer.analyze_repository, backend.AST_Schema.ASTAnalyzer.merge_relationship_data, backend.HelperLLM.LLMHelper, backend.HelperLLM.LLMHelper.generate_for_classes, backend.HelperLLM.LLMHelper.generate_for_functions, backend.MainLLM.MainLLM, backend.MainLLM.MainLLM.call_llm, backend.basic_info.ProjektInfoExtractor, backend.basic_info.ProjektInfoExtractor.extrahiere_info, backend.getRepo.GitRepository, backend.main.calculate_net_time, backend.main.create_savings_chart, backend.main.update_status, backend.relationship_analyzer.ProjectAnalyzer, backend.relationship_analyzer.ProjectAnalyzer.analyze, backend.relationship_analyzer.ProjectAnalyzer.get_raw_relationships, schemas.types.ClassAnalysisInput, schemas.types.ClassContextInput, schemas.types.FunctionAnalysisInput, schemas.types.FunctionContextInput, and schemas.types.MethodContextInput.",
          "called_by": "This function is not called by any other functions within the provided context."
        }
      },
      "error": null
    },
    "backend.main.update_status": {
      "identifier": "backend.main.update_status",
      "description": {
        "overall": "This function is designed to update a status message. It first checks if a `status_callback` function is defined and, if so, calls it with the provided message. Subsequently, it logs the message using the `logging.info` function. This suggests it's part of a system that needs to report progress or status updates both externally (via callback) and internally (via logging).",
        "parameters": [
          {
            "name": "msg",
            "type": "Any",
            "description": "The status message to be reported and logged."
          }
        ],
        "returns": [],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "backend.main.notebook_workflow": {
      "identifier": "backend.main.notebook_workflow",
      "description": {
        "overall": "This function orchestrates a workflow for analyzing GitHub repositories containing Jupyter notebooks. It clones a repository, extracts project information, processes notebooks into an XML format with embedded images, and then uses a specified LLM (like GPT or Gemini) to generate a report for each notebook. The function handles API key selection based on the model name, updates the status of the workflow via a callback, and logs progress and errors. Finally, it concatenates individual notebook reports into a single markdown file and returns the report along with performance metrics.",
        "parameters": [
          {
            "name": "input",
            "type": "str",
            "description": "The input string, expected to contain a GitHub repository URL."
          },
          {
            "name": "api_keys",
            "type": "dict",
            "description": "A dictionary containing API keys for different LLM providers (e.g., 'gpt', 'gemini', 'scadsllm', 'ollama')."
          },
          {
            "name": "model",
            "type": "str",
            "description": "The name of the language model to use for report generation (e.g., 'gpt-4', 'gemini-pro')."
          },
          {
            "name": "status_callback",
            "type": "Optional[Callable]",
            "description": "An optional callback function to report the status of the workflow steps."
          }
        ],
        "returns": [
          {
            "name": "report",
            "type": "str",
            "description": "The concatenated markdown report generated from all processed notebooks."
          },
          {
            "name": "metrics",
            "type": "dict",
            "description": "A dictionary containing performance metrics for the workflow, including execution times and model information."
          }
        ],
        "usage_context": {
          "calls": "This function calls backend.MainLLM.MainLLM, backend.MainLLM.MainLLM.call_llm, backend.basic_info.ProjektInfoExtractor, backend.basic_info.ProjektInfoExtractor.extrahiere_info, backend.converter.process_repo_notebooks, backend.getRepo.GitRepository, backend.main.gemini_payload, and backend.main.update_status.",
          "called_by": "This function is not called by any other function within the provided context."
        }
      },
      "error": null
    },
    "backend.main.gemini_payload": {
      "identifier": "backend.main.gemini_payload",
      "description": {
        "overall": "This function constructs a payload for the Gemini API, designed to process and present information including basic project details, notebook paths, XML content, and images. It serializes basic information and the notebook path into a JSON string for context. The function then iterates through the XML content, identifying image placeholders. For each placeholder, it extracts image data from a provided list of images and formats it as a base64 encoded data URL. Text segments from the XML are added as text payloads, interspersed with image payloads. Any remaining text after the last image placeholder is also appended. The function returns a list of payload content items, each with a 'type' (either 'text' or 'image_url') and associated content.",
        "parameters": [
          {
            "name": "basic_info",
            "type": "Any",
            "description": "Basic information about the project, likely a dictionary or object."
          },
          {
            "name": "nb_path",
            "type": "str",
            "description": "The file path to the current notebook."
          },
          {
            "name": "xml_content",
            "type": "str",
            "description": "The XML representation of the notebook's structure."
          },
          {
            "name": "images",
            "type": "List[Dict[str, str]]",
            "description": "A list of dictionaries, where each dictionary contains image data, including a base64 encoded string under the 'data' key."
          }
        ],
        "returns": [
          {
            "name": "payload_content",
            "type": "List[Dict[str, Any]]",
            "description": "A list of dictionaries, where each dictionary represents a content block for the Gemini API payload. Each block has a 'type' ('text' or 'image_url') and associated content."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is called by no other functions."
        }
      },
      "error": null
    },
    "backend.relationship_analyzer.path_to_module": {
      "identifier": "backend.relationship_analyzer.path_to_module",
      "description": {
        "overall": "This function converts a given file path into a Python module path relative to a specified project root. It handles potential errors during relative path calculation by falling back to the base filename. It also removes the '.py' extension and replaces directory separators with dots to form the module path. Special handling is included for '__init__.py' files to correctly represent package structure.",
        "parameters": [
          {
            "name": "filepath",
            "type": "str",
            "description": "The absolute or relative path to the file."
          },
          {
            "name": "project_root",
            "type": "str",
            "description": "The root directory of the project, used to calculate the relative path."
          }
        ],
        "returns": [
          {
            "name": "module_path",
            "type": "str",
            "description": "The calculated Python module path string."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is called by no other functions."
        }
      },
      "error": null
    },
    "database.db.encrypt_text": {
      "identifier": "database.db.encrypt_text",
      "description": {
        "overall": "This function, `encrypt_text`, takes a string as input and returns its encrypted form. It first checks if the input text is empty or if a `cipher_suite` is not available. If either condition is true, it returns the original text without modification. Otherwise, it strips leading/trailing whitespace from the text, encodes it into bytes, encrypts the bytes using the `cipher_suite`, and then decodes the resulting encrypted bytes back into a string before returning it.",
        "parameters": [
          {
            "name": "text",
            "type": "str",
            "description": "The plain text string to be encrypted."
          }
        ],
        "returns": [
          {
            "name": "encrypted_text",
            "type": "str",
            "description": "The encrypted string, or the original string if encryption could not be performed."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.decrypt_text": {
      "identifier": "database.db.decrypt_text",
      "description": {
        "overall": "This function, `decrypt_text`, is designed to decrypt a given string using a `cipher_suite`. It first checks if the input text or the `cipher_suite` is null or empty, returning the original text if either is true. The function then attempts to decrypt the text by encoding it, decrypting it using the `cipher_suite`, and decoding the result. If any exception occurs during the decryption process, the original text is returned.",
        "parameters": [
          {
            "name": "text",
            "type": "str",
            "description": "The encrypted string to be decrypted."
          }
        ],
        "returns": [
          {
            "name": "decrypted_text",
            "type": "str",
            "description": "The decrypted string, or the original string if decryption fails or is not possible."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.insert_user": {
      "identifier": "database.db.insert_user",
      "description": {
        "overall": "This function inserts a new user record into the database. It constructs a user dictionary containing the username, name, and a hashed password using `stauth.Hasher.hash`. Additional fields like API keys and base URLs are initialized as empty strings. The function then uses `dbusers.insert_one` to add this user data to the database and returns the unique identifier of the newly inserted document.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The unique username for the new user."
          },
          {
            "name": "name",
            "type": "str",
            "description": "The full name of the user."
          },
          {
            "name": "password",
            "type": "str",
            "description": "The plain text password for the new user, which will be hashed."
          }
        ],
        "returns": [
          {
            "name": "inserted_id",
            "type": "Any",
            "description": "The unique identifier of the newly inserted user document in the database."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.fetch_all_users": {
      "identifier": "database.db.fetch_all_users",
      "description": {
        "overall": "This function retrieves all user records from the database. It interacts with a database collection named 'dbusers' and returns the results as a list. The function is designed to fetch all available user data without any filtering or specific selection criteria.",
        "parameters": [],
        "returns": [
          {
            "name": "user_list",
            "type": "list",
            "description": "A list containing all user documents fetched from the database."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.fetch_user": {
      "identifier": "database.db.fetch_user",
      "description": {
        "overall": "This function retrieves a user document from the database based on the provided username. It queries the 'dbusers' collection using the username as the document's '_id'. The function is designed to fetch a single user record.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username of the user to fetch from the database."
          }
        ],
        "returns": [
          {
            "name": "user_document",
            "type": "Any",
            "description": "A dictionary representing the user document if found, otherwise None."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.update_user_name": {
      "identifier": "database.db.update_user_name",
      "description": {
        "overall": "This function updates the 'name' field for a user in the 'dbusers' collection. It takes the current username and the new name as input. The function uses `update_one` to find the document with the matching `_id` (which is the username) and sets the 'name' field to the `new_name`. It returns the count of modified documents, which should ideally be 1 if the update was successful.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The current username of the user to be updated. This is used as the `_id` to find the document."
          },
          {
            "name": "new_name",
            "type": "str",
            "description": "The new name to be set for the user."
          }
        ],
        "returns": [
          {
            "name": "modified_count",
            "type": "int",
            "description": "The number of documents that were modified. This is expected to be 1 if the update was successful."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.update_gemini_key": {
      "identifier": "database.db.update_gemini_key",
      "description": {
        "overall": "This function updates the Gemini API key for a given user in the database. It first encrypts the provided API key using a separate encryption function and then updates the user's record in the database with the encrypted key. The function returns the count of documents that were modified.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username of the user whose Gemini API key needs to be updated."
          },
          {
            "name": "gemini_api_key",
            "type": "str",
            "description": "The new Gemini API key to be set for the user."
          }
        ],
        "returns": [
          {
            "name": "modified_count",
            "type": "int",
            "description": "The number of documents that were modified in the database. Typically 1 if the update was successful."
          }
        ],
        "usage_context": {
          "calls": "This function calls database.db.encrypt_text.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.update_gpt_key": {
      "identifier": "database.db.update_gpt_key",
      "description": {
        "overall": "This function updates the GPT API key for a given user in the database. It first encrypts the provided API key using the `encrypt_text` function and then updates the user's record in the `dbusers` collection with the encrypted key. The function returns the count of modified documents, indicating whether the update was successful.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username of the user whose GPT API key needs to be updated."
          },
          {
            "name": "gpt_api_key",
            "type": "str",
            "description": "The new GPT API key to be stored for the user."
          }
        ],
        "returns": [
          {
            "name": "modified_count",
            "type": "int",
            "description": "The number of documents that were modified in the database. Typically 1 if the update was successful, 0 otherwise."
          }
        ],
        "usage_context": {
          "calls": "This function calls database.db.encrypt_text.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.update_ollama_url": {
      "identifier": "database.db.update_ollama_url",
      "description": {
        "overall": "This function updates the 'ollama_base_url' field for a specific user in the database. It takes the username and the new base URL as input. The function then uses `dbusers.update_one` to find the user document by their username (using `_id`) and sets the `ollama_base_url` to the stripped version of the provided URL. Finally, it returns the count of modified documents, which indicates whether the update was successful.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username of the user whose ollama_base_url needs to be updated."
          },
          {
            "name": "ollama_base_url",
            "type": "str",
            "description": "The new base URL for the Ollama service, which will be stripped of leading/trailing whitespace before being saved."
          }
        ],
        "returns": [
          {
            "name": "modified_count",
            "type": "int",
            "description": "An integer representing the number of documents that were modified. Typically 1 if the update was successful, and 0 otherwise."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.update_opensrc_key": {
      "identifier": "database.db.update_opensrc_key",
      "description": {
        "overall": "This function updates the 'opensrc_api_key' for a given username in the database. It first encrypts the provided API key using the `encrypt_text` function and then updates the corresponding user document in the `dbusers` collection. The function returns the count of documents that were modified.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username of the user whose API key needs to be updated."
          },
          {
            "name": "opensrc_api_key",
            "type": "str",
            "description": "The new open-source API key to be set for the user."
          }
        ],
        "returns": [
          {
            "name": "modified_count",
            "type": "int",
            "description": "The number of documents that were modified in the database. Typically 1 if the update was successful."
          }
        ],
        "usage_context": {
          "calls": "This function calls database.db.encrypt_text.",
          "called_by": "This function is not called by any other functions within the provided context."
        }
      },
      "error": null
    },
    "database.db.update_opensrc_url": {
      "identifier": "database.db.update_opensrc_url",
      "description": {
        "overall": "This function updates the 'opensrc_base_url' field for a given username in the database. It takes the username and the new URL as input. The function then uses a database update operation to set the 'opensrc_base_url' to the stripped version of the provided URL. Finally, it returns the count of documents that were modified by the update operation.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username of the user whose 'opensrc_base_url' needs to be updated."
          },
          {
            "name": "opensrc_base_url",
            "type": "str",
            "description": "The new base URL for the open-source repository to be set for the user."
          }
        ],
        "returns": [
          {
            "name": "modified_count",
            "type": "int",
            "description": "The number of documents that were modified in the database. This is typically 1 if the update was successful for a unique username."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.fetch_gemini_key": {
      "identifier": "database.db.fetch_gemini_key",
      "description": {
        "overall": "This function retrieves the Gemini API key associated with a given username from the database. It queries the database for a user document matching the provided username and extracts the 'gemini_api_key' field. If the user is found, the API key is returned; otherwise, None is returned.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username of the user whose Gemini API key needs to be fetched."
          }
        ],
        "returns": [
          {
            "name": "gemini_api_key",
            "type": "str | None",
            "description": "The Gemini API key for the specified user, or None if the user is not found or has no key."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.fetch_ollama_url": {
      "identifier": "database.db.fetch_ollama_url",
      "description": {
        "overall": "This function retrieves the Ollama base URL associated with a given username from a database. It queries a user collection, looking for a specific user by their username. If the user is found, it extracts and returns their 'ollama_base_url'. If the user is not found, it returns None.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username of the user whose Ollama base URL needs to be fetched."
          }
        ],
        "returns": [
          {
            "name": "ollama_base_url",
            "type": "str | None",
            "description": "The Ollama base URL for the specified user, or None if the user is not found or does not have an Ollama base URL configured."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.fetch_gpt_key": {
      "identifier": "database.db.fetch_gpt_key",
      "description": {
        "overall": "This function retrieves the GPT API key associated with a given username from the database. It queries the database for a user document based on the provided username and extracts the 'gpt_api_key' field. If the user is found and has a GPT API key, it returns the key; otherwise, it returns None.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username of the user whose GPT API key needs to be fetched."
          }
        ],
        "returns": [
          {
            "name": "gpt_api_key",
            "type": "str | None",
            "description": "The GPT API key for the specified user, or None if the user is not found or does not have a key."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.fetch_opensrc_key": {
      "identifier": "database.db.fetch_opensrc_key",
      "description": {
        "overall": "This function retrieves the 'opensrc_api_key' for a given username from a database. It queries the database for a user document matching the provided username and specifically selects the 'opensrc_api_key' field, excluding the '_id' field. If the user is found, it returns the associated API key; otherwise, it returns None.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username of the user whose opensrc API key needs to be fetched."
          }
        ],
        "returns": [
          {
            "name": "opensrc_api_key",
            "type": "str | None",
            "description": "The opensrc API key associated with the username, or None if the user is not found or has no such key."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.fetch_opensrc_url": {
      "identifier": "database.db.fetch_opensrc_url",
      "description": {
        "overall": "This function retrieves the 'opensrc_base_url' for a given username from a database. It queries the 'dbusers' collection for a user document matching the provided username. If the user is found, it extracts and returns the 'opensrc_base_url' associated with that user. If the user is not found, it returns None.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username to query for in the database."
          }
        ],
        "returns": [
          {
            "name": "opensrc_base_url",
            "type": "str | None",
            "description": "The 'opensrc_base_url' associated with the username, or None if the user is not found or the URL is not present."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.delete_user": {
      "identifier": "database.db.delete_user",
      "description": {
        "overall": "This function deletes a user from the database. It takes a username as input and returns the count of deleted documents. The function interacts with a database collection named 'dbusers' to perform the deletion operation.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username of the user to be deleted."
          }
        ],
        "returns": [
          {
            "name": "deleted_count",
            "type": "int",
            "description": "The number of documents that were deleted. This is expected to be 1 if the user was found and deleted, or 0 otherwise."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.get_decrypted_api_keys": {
      "identifier": "database.db.get_decrypted_api_keys",
      "description": {
        "overall": "This function retrieves and decrypts API keys and related configuration for a given user from a database. It first fetches the user's record using their username. If the user is not found, it returns None for all values. Otherwise, it decrypts sensitive API keys (Gemini, GPT, Open Source) and retrieves base URLs (Ollama, Open Source) from the user's record. The function then returns the decrypted API keys and base URLs.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username of the user whose API keys and configuration are to be retrieved."
          }
        ],
        "returns": [
          {
            "name": "gemini_plain",
            "type": "str",
            "description": "The decrypted Gemini API key."
          },
          {
            "name": "ollama_plain",
            "type": "str",
            "description": "The Ollama base URL."
          },
          {
            "name": "gpt_plain",
            "type": "str",
            "description": "The decrypted GPT API key."
          },
          {
            "name": "opensrc_plain",
            "type": "str",
            "description": "The decrypted Open Source API key."
          },
          {
            "name": "opensrc_url",
            "type": "str",
            "description": "The Open Source base URL."
          }
        ],
        "usage_context": {
          "calls": "This function calls database.db.decrypt_text.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.insert_chat": {
      "identifier": "database.db.insert_chat",
      "description": {
        "overall": "This function creates a new chat entry in the database. It generates a unique ID, records the username and chat name, and timestamps the creation. The function then inserts this data into a collection named 'dbchats' and returns the ID of the newly inserted document.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username associated with the chat."
          },
          {
            "name": "chat_name",
            "type": "str",
            "description": "The name of the chat to be created."
          }
        ],
        "returns": [
          {
            "name": "inserted_id",
            "type": "Any",
            "description": "The unique identifier of the newly created chat document."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.fetch_chats_by_user": {
      "identifier": "database.db.fetch_chats_by_user",
      "description": {
        "overall": "This function retrieves all chats associated with a specific user from a database. It queries a collection named 'dbchats' for documents matching the provided username and sorts the results by their creation timestamp in ascending order. The function then returns the list of matching chat documents.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username of the user whose chats are to be fetched."
          }
        ],
        "returns": [
          {
            "name": "chats",
            "type": "list",
            "description": "A list of chat documents belonging to the specified user, sorted by creation time."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.check_chat_exists": {
      "identifier": "database.db.check_chat_exists",
      "description": {
        "overall": "This function checks if a specific chat exists in the database for a given username and chat name. It queries a collection named 'dbchats' using the provided username and chat_name. The function returns a boolean value indicating whether a matching record was found.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username associated with the chat."
          },
          {
            "name": "chat_name",
            "type": "str",
            "description": "The name of the chat to check for."
          }
        ],
        "returns": [
          {
            "name": "chat_exists",
            "type": "bool",
            "description": "True if the chat exists for the given username and chat name, False otherwise."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.rename_chat_fully": {
      "identifier": "database.db.rename_chat_fully",
      "description": {
        "overall": "This function renames a chat and all associated exchanges in the database. It first updates the chat's name in the 'chats' collection and then updates the 'chat_name' field for all related messages in the 'exchanges' collection. The function returns the count of modified documents from the chat update operation.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username associated with the chat."
          },
          {
            "name": "old_name",
            "type": "str",
            "description": "The current name of the chat to be renamed."
          },
          {
            "name": "new_name",
            "type": "str",
            "description": "The new name to assign to the chat."
          }
        ],
        "returns": [
          {
            "name": "modified_count",
            "type": "int",
            "description": "The number of chat documents that were modified."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.insert_exchange": {
      "identifier": "database.db.insert_exchange",
      "description": {
        "overall": "This function inserts a new exchange record into the database. It constructs a dictionary representing the exchange with various details such as question, answer, feedback, user information, and token usage. It then attempts to insert this record into the 'dbexchanges' collection using `insert_one`. If the insertion is successful, it returns the unique ID of the new record; otherwise, it prints a database error and returns None.",
        "parameters": [
          {
            "name": "question",
            "type": "str",
            "description": "The user's question."
          },
          {
            "name": "answer",
            "type": "str",
            "description": "The answer provided to the question."
          },
          {
            "name": "feedback",
            "type": "str",
            "description": "User feedback on the answer."
          },
          {
            "name": "username",
            "type": "str",
            "description": "The username of the user making the exchange."
          },
          {
            "name": "chat_name",
            "type": "str",
            "description": "The name of the chat session."
          },
          {
            "name": "helper_used",
            "type": "str",
            "description": "Information about whether a helper was used (default: \"\")."
          },
          {
            "name": "main_used",
            "type": "str",
            "description": "Information about whether the main model was used (default: \"\")."
          },
          {
            "name": "total_time",
            "type": "str",
            "description": "Total time taken for the exchange (default: \"\")."
          },
          {
            "name": "helper_time",
            "type": "str",
            "description": "Time taken by the helper model (default: \"\")."
          },
          {
            "name": "main_time",
            "type": "str",
            "description": "Time taken by the main model (default: \"\")."
          },
          {
            "name": "json_tokens",
            "type": "int",
            "description": "Number of JSON tokens used (default: 0)."
          },
          {
            "name": "toon_tokens",
            "type": "int",
            "description": "Number of toon tokens used (default: 0)."
          },
          {
            "name": "savings_percent",
            "type": "float",
            "description": "Percentage of savings achieved (default: 0.0)."
          }
        ],
        "returns": [
          {
            "name": "new_id",
            "type": "str",
            "description": "The unique ID of the newly inserted exchange record, or None if an error occurred."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.fetch_exchanges_by_user": {
      "identifier": "database.db.fetch_exchanges_by_user",
      "description": {
        "overall": "This function retrieves a user's exchange history from a database. It queries a collection named 'dbexchanges' for documents matching the provided username. The results are then sorted by the 'created_at' field in ascending order and returned as a list. The sorting is noted as important for display purposes.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username of the user whose exchange history is to be fetched."
          }
        ],
        "returns": [
          {
            "name": "exchanges",
            "type": "list",
            "description": "A list of exchange documents associated with the specified username, sorted by 'created_at'."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.fetch_exchanges_by_chat": {
      "identifier": "database.db.fetch_exchanges_by_chat",
      "description": {
        "overall": "This function retrieves a list of exchanges from a database collection based on a provided username and chat name. It queries the 'dbexchanges' collection, filtering documents that match the given username and chat name. The results are then sorted by the 'created_at' field in ascending order before being returned as a list.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username to filter exchanges by."
          },
          {
            "name": "chat_name",
            "type": "str",
            "description": "The name of the chat to filter exchanges by."
          }
        ],
        "returns": [
          {
            "name": "exchanges",
            "type": "list",
            "description": "A list of exchange documents matching the specified username and chat name, sorted by creation time."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.update_exchange_feedback": {
      "identifier": "database.db.update_exchange_feedback",
      "description": {
        "overall": "This function updates the feedback associated with a specific exchange in the database. It takes an exchange ID and a feedback integer as input. The function then uses `dbexchanges.update_one` to find the exchange by its ID and set the 'feedback' field to the provided value. Finally, it returns the count of documents that were modified by the update operation.",
        "parameters": [
          {
            "name": "exchange_id",
            "type": "Any",
            "description": "The unique identifier of the exchange to be updated."
          },
          {
            "name": "feedback",
            "type": "int",
            "description": "The integer value representing the feedback to be set for the exchange."
          }
        ],
        "returns": [
          {
            "name": "modified_count",
            "type": "int",
            "description": "The number of documents that were modified in the database. Typically 1 if the update was successful, 0 otherwise."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.update_exchange_feedback_message": {
      "identifier": "database.db.update_exchange_feedback_message",
      "description": {
        "overall": "This function updates the feedback message associated with a specific exchange in the database. It takes an exchange ID and a feedback message string as input. The function then uses the `dbexchanges.update_one` method to find the exchange by its ID and set the `feedback_message` field to the provided value. Finally, it returns the count of documents that were modified.",
        "parameters": [
          {
            "name": "exchange_id",
            "type": "Any",
            "description": "The unique identifier of the exchange to be updated."
          },
          {
            "name": "feedback_message",
            "type": "str",
            "description": "The new feedback message to be associated with the exchange."
          }
        ],
        "returns": [
          {
            "name": "modified_count",
            "type": "int",
            "description": "The number of documents that were modified in the database (expected to be 1 if the update was successful)."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.delete_exchange_by_id": {
      "identifier": "database.db.delete_exchange_by_id",
      "description": {
        "overall": "This function deletes a single exchange record from the database based on its unique identifier. It interacts with a database collection named 'dbexchanges' to perform the deletion operation. The function returns the count of documents that were successfully deleted.",
        "parameters": [
          {
            "name": "exchange_id",
            "type": "str",
            "description": "The unique identifier of the exchange record to be deleted."
          }
        ],
        "returns": [
          {
            "name": "deleted_count",
            "type": "int",
            "description": "The number of documents that were deleted from the database."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.delete_full_chat": {
      "identifier": "database.db.delete_full_chat",
      "description": {
        "overall": "This function deletes a specified chat and all associated exchanges from the database to ensure consistency between the frontend and backend. It first removes all messages within the chat and then deletes the chat itself from the chat list. The function aims to maintain data integrity by performing these deletions atomically.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username associated with the chat to be deleted."
          },
          {
            "name": "chat_name",
            "type": "str",
            "description": "The name of the chat to be deleted."
          }
        ],
        "returns": [
          {
            "name": "deleted_count",
            "type": "int",
            "description": "The number of chat documents that were deleted."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is called by no other functions."
        }
      },
      "error": null
    },
    "frontend.frontend.clean_names": {
      "identifier": "frontend.frontend.clean_names",
      "description": {
        "overall": "This function takes a list of strings, where each string is expected to be a path or identifier that includes a '/'. It processes each string by splitting it at the '/' character and returning the last element of the resulting list. This is effectively used to extract the final component of a path or a name from a structured string.",
        "parameters": [
          {
            "name": "model_list",
            "type": "list",
            "description": "A list of strings, where each string is expected to contain at least one '/' character."
          }
        ],
        "returns": [
          {
            "name": "cleaned_names",
            "type": "list",
            "description": "A new list containing the last component of each string from the input model_list after splitting by '/'."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "frontend.frontend.get_filtered_models": {
      "identifier": "frontend.frontend.get_filtered_models",
      "description": {
        "overall": "This function filters a list of models based on a specified category name. It retrieves keywords associated with the category from a dictionary `CATEGORY_KEYWORDS`. If the category is 'STANDARD', it returns models present in both the input `source_list` and a predefined `STANDARD_MODELS` list. Otherwise, it iterates through the `source_list` and includes models whose names (converted to lowercase) contain any of the category's keywords. If no models match the keywords, the original `source_list` is returned.",
        "parameters": [
          {
            "name": "source_list",
            "type": "list",
            "description": "The list of models to be filtered."
          },
          {
            "name": "category_name",
            "type": "str",
            "description": "The name of the category to filter by."
          }
        ],
        "returns": [
          {
            "name": "filtered_models",
            "type": "list",
            "description": "A list of models filtered by the specified category, or the original list if no matches are found or the category is 'STANDARD' and matches are found."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is called by no other functions."
        }
      },
      "error": null
    },
    "frontend.frontend.save_gemini_cb": {
      "identifier": "frontend.frontend.save_gemini_cb",
      "description": {
        "overall": "This function is responsible for saving a Gemini API key provided by the user. It retrieves the new key from the Streamlit session state. If a key exists, it updates the user's Gemini key in the database using the `update_gemini_key` function. After a successful update, it clears the temporary session state variable for the key and displays a success message to the user via a toast notification.",
        "parameters": [],
        "returns": [],
        "usage_context": {
          "calls": "This function calls database.db.update_gemini_key.",
          "called_by": "This function is not called by any other function."
        }
      },
      "error": null
    },
    "frontend.frontend.save_ollama_cb": {
      "identifier": "frontend.frontend.save_ollama_cb",
      "description": {
        "overall": "This function is a callback designed to save an Ollama URL. It retrieves a URL from the session state, and if a URL is present, it updates the user's Ollama URL in the database. Finally, it displays a success toast message to the user.",
        "parameters": [],
        "returns": [],
        "usage_context": {
          "calls": "This function calls database.db.update_ollama_url.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "frontend.frontend.load_data_from_db": {
      "identifier": "frontend.frontend.load_data_from_db",
      "description": {
        "overall": "This function loads chat and exchange data from a database for a given username in a consistent manner. It first initializes the session state for chats if the user has not been loaded before or if the username has changed. It then fetches defined chats and their associated exchanges from the database, populating the session state. If no chats exist, it creates a default chat and inserts it into the database. Finally, it sets the active chat in the session state.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username for whom to load the data."
          }
        ],
        "returns": [],
        "usage_context": {
          "calls": "This function calls database.db.fetch_chats_by_user, database.db.fetch_exchanges_by_user, and database.db.insert_chat.",
          "called_by": "This function is not called by any other function."
        }
      },
      "error": null
    },
    "frontend.frontend.handle_feedback_change": {
      "identifier": "frontend.frontend.handle_feedback_change",
      "description": {
        "overall": "This function updates the feedback associated with an exchange and then triggers a rerun of the Streamlit application. It takes an exchange dictionary and a new feedback value as input. The function modifies the 'feedback' key within the provided exchange dictionary and then calls a database function to persist this change. Finally, it instructs Streamlit to rerun the application, likely to reflect the updated feedback.",
        "parameters": [
          {
            "name": "ex",
            "type": "dict",
            "description": "A dictionary representing the exchange, expected to contain at least an '_id' key."
          },
          {
            "name": "val",
            "type": "any",
            "description": "The new feedback value to be set for the exchange."
          }
        ],
        "returns": [],
        "usage_context": {
          "calls": "This function calls database.db.update_exchange_feedback.",
          "called_by": "This function is not called by any other functions within the provided context."
        }
      },
      "error": null
    },
    "frontend.frontend.handle_delete_exchange": {
      "identifier": "frontend.frontend.handle_delete_exchange",
      "description": {
        "overall": "This function handles the deletion of an exchange from the system. It first deletes the exchange from the database using its ID. Then, it checks if the chat associated with the exchange exists in the session state. If it does, it removes the exchange from the list of exchanges within that chat. Finally, it triggers a rerun of the Streamlit application to reflect the changes.",
        "parameters": [
          {
            "name": "chat_name",
            "type": "str",
            "description": "The name of the chat associated with the exchange to be deleted."
          },
          {
            "name": "ex",
            "type": "Any",
            "description": "A dictionary or object representing the exchange to be deleted, expected to contain an '_id' key."
          }
        ],
        "returns": [],
        "usage_context": {
          "calls": "This function calls database.db.delete_exchange_by_id.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "frontend.frontend.handle_delete_chat": {
      "identifier": "frontend.frontend.handle_delete_chat",
      "description": {
        "overall": "This function handles the deletion of a chat for a given user. It first deletes the chat data from the database using `db.delete_full_chat`. Then, it cleans up the session state by removing the chat from `st.session_state.chats`. If there are remaining chats, it sets the first available chat as the active chat. If no chats remain, it creates a new default chat, inserts it into the database, initializes it in the session state, and sets it as the active chat. Finally, it triggers a rerun of the Streamlit application.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username of the user whose chat is to be deleted."
          },
          {
            "name": "chat_name",
            "type": "str",
            "description": "The name of the chat to be deleted."
          }
        ],
        "returns": [],
        "usage_context": {
          "calls": "This function calls database.db.delete_full_chat and database.db.insert_chat.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "frontend.frontend.extract_repo_name": {
      "identifier": "frontend.frontend.extract_repo_name",
      "description": {
        "overall": "This function extracts a repository name from a given text string. It first attempts to find a URL within the text using regular expressions. If a URL is found, it parses the URL to isolate the path component. It then extracts the last part of the path, which is assumed to be the repository name. Any trailing '.git' suffix is removed from the extracted name before it is returned. If no URL is found or if the URL does not yield a repository name, the function returns None.",
        "parameters": [
          {
            "name": "text",
            "type": "str",
            "description": "The input string potentially containing a URL."
          }
        ],
        "returns": [
          {
            "name": "repo_name",
            "type": "str | None",
            "description": "The extracted repository name if found, otherwise None."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "frontend.frontend.stream_text_generator": {
      "identifier": "frontend.frontend.stream_text_generator",
      "description": {
        "overall": "This function takes a string of text as input and yields words from it one by one with a small delay between each word. It splits the input text into words based on spaces and then yields each word followed by a space. A short pause of 0.01 seconds is introduced after yielding each word, simulating a streaming effect. This is useful for displaying text in a way that appears as if it's being typed out character by character or word by word.",
        "parameters": [
          {
            "name": "text",
            "type": "str",
            "description": "The input string of text to be streamed."
          }
        ],
        "returns": [
          {
            "name": "word",
            "type": "str",
            "description": "A single word from the input text, followed by a space, yielded iteratively."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "frontend.frontend.render_text_with_mermaid": {
      "identifier": "frontend.frontend.render_text_with_mermaid",
      "description": {
        "overall": "This function takes a markdown text string and renders it, specifically handling mermaid code blocks. It splits the markdown text by mermaid code blocks (delimited by ```mermaid ... ```). For non-mermaid parts, it renders them as markdown, optionally streaming the output if `should_stream` is True. For mermaid code blocks, it attempts to render them using `st_mermaid`; if that fails, it falls back to rendering as a code block with the mermaid language specified. The function returns early if the input markdown text is empty.",
        "parameters": [
          {
            "name": "markdown_text",
            "type": "str",
            "description": "The markdown text to be rendered, potentially containing mermaid code blocks."
          },
          {
            "name": "should_stream",
            "type": "bool",
            "description": "A flag indicating whether the non-mermaid text content should be streamed during rendering. Defaults to False."
          }
        ],
        "returns": [],
        "usage_context": {
          "calls": "This function calls frontend.frontend.stream_text_generator.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "frontend.frontend.render_exchange": {
      "identifier": "frontend.frontend.render_exchange",
      "description": {
        "overall": "This function renders a chat exchange, displaying both the user's question and the assistant's answer. It handles displaying the answer, including error states, and provides interactive elements for user feedback and actions. The function utilizes Streamlit components to create a dynamic user interface for chat interactions. It also manages the display of toolbars with buttons for feedback, comments, downloads, and deletion, as well as rendering the main content of the assistant's answer, potentially including Mermaid diagrams.",
        "parameters": [
          {
            "name": "ex",
            "type": "dict",
            "description": "A dictionary containing the exchange data, including 'question', 'answer', 'feedback', '_id', and 'feedback_message'."
          },
          {
            "name": "current_chat_name",
            "type": "str",
            "description": "The name of the current chat session, used for context in deletion operations."
          }
        ],
        "returns": [],
        "usage_context": {
          "calls": "This function calls database.db.update_exchange_feedback_message, frontend.frontend.handle_delete_exchange, frontend.frontend.handle_feedback_change, and frontend.frontend.render_text_with_mermaid.",
          "called_by": "This function is not called by any other functions within the provided context."
        }
      },
      "error": null
    }
  },
  "classes": {
    "backend.AST_Schema.ASTVisitor": {
      "identifier": "backend.AST_Schema.ASTVisitor",
      "description": {
        "overall": "The ASTVisitor class is designed to traverse an Abstract Syntax Tree (AST) generated from Python source code. It specifically focuses on identifying and extracting information about imports, classes, and functions defined within the code. The visitor pattern is employed to process different types of AST nodes, populating a structured schema with the gathered metadata. This class is instrumental in code analysis tasks, enabling the extraction of structural information for documentation or further processing.",
        "init_method": {
          "description": "Initializes the ASTVisitor with the source code, file path, and project root. It sets up instance variables to store this information and initializes an empty schema dictionary to hold extracted AST information. It also prepares for tracking the current class context during traversal.",
          "parameters": [
            {
              "name": "source_code",
              "type": "str",
              "description": "The raw source code string of the file being analyzed."
            },
            {
              "name": "file_path",
              "type": "str",
              "description": "The absolute path to the source code file."
            },
            {
              "name": "project_root",
              "type": "str",
              "description": "The root directory of the project."
            }
          ]
        },
        "methods": [
          {
            "identifier": "visit_Import",
            "description": {
              "overall": "This method is called when an `import` statement is encountered in the AST. It iterates through the imported names and appends them to the 'imports' list within the schema. It then calls `generic_visit` to ensure that any nested nodes are also processed.",
              "parameters": [
                {
                  "name": "self",
                  "type": "ASTVisitor",
                  "description": "The instance of the ASTVisitor."
                },
                {
                  "name": "node",
                  "type": "ast.Import",
                  "description": "The AST node representing an import statement."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls the `generic_visit` method to continue the AST traversal.",
                "called_by": "This method is called automatically by the `ast.NodeVisitor` when it encounters an `ast.Import` node during traversal."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_ImportFrom",
            "description": {
              "overall": "This method handles `from ... import ...` statements. It extracts the module and the specific names being imported, formatting them as `module.name` and appending them to the 'imports' list in the schema. It ensures further traversal by calling `generic_visit`.",
              "parameters": [
                {
                  "name": "self",
                  "type": "ASTVisitor",
                  "description": "The instance of the ASTVisitor."
                },
                {
                  "name": "node",
                  "type": "ast.ImportFrom",
                  "description": "The AST node representing a 'from import' statement."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls the `generic_visit` method to continue the AST traversal.",
                "called_by": "This method is called automatically by the `ast.NodeVisitor` when it encounters an `ast.ImportFrom` node during traversal."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_ClassDef",
            "description": {
              "overall": "This method processes class definitions within the AST. It constructs a detailed dictionary for the class, including its fully qualified identifier, name, docstring, source code segment, and line numbers. This class information is appended to the 'classes' list in the schema, and `_current_class` is updated to track the current class context for subsequent method analysis. It ensures that the traversal continues into the class body using `generic_visit` and resets `_current_class` upon exiting the class definition.",
              "parameters": [
                {
                  "name": "self",
                  "type": "ASTVisitor",
                  "description": "The instance of the ASTVisitor."
                },
                {
                  "name": "node",
                  "type": "ast.ClassDef",
                  "description": "The AST node representing a class definition."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls `ast.get_docstring`, `ast.get_source_segment`, and `generic_visit` to gather information and continue traversal.",
                "called_by": "This method is called automatically by the `ast.NodeVisitor` when it encounters an `ast.ClassDef` node during traversal."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_FunctionDef",
            "description": {
              "overall": "This method is responsible for analyzing function definitions. If the visitor is currently within a class context (`_current_class` is set), it treats the function as a method, creating a `method_context_info` dictionary and appending it to the current class's context. Otherwise, it treats it as a standalone function, creating a `func_info` dictionary and appending it to the schema's 'functions' list. In both cases, it extracts identifiers, arguments, docstrings, source code, and line numbers. The traversal continues into the function body via `generic_visit`.",
              "parameters": [
                {
                  "name": "self",
                  "type": "ASTVisitor",
                  "description": "The instance of the ASTVisitor."
                },
                {
                  "name": "node",
                  "type": "ast.FunctionDef",
                  "description": "The AST node representing a function definition."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls `ast.get_docstring`, `ast.get_source_segment`, and `generic_visit` to gather information and continue traversal.",
                "called_by": "This method is called automatically by the `ast.NodeVisitor` when it encounters an `ast.FunctionDef` node during traversal."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_AsyncFunctionDef",
            "description": {
              "overall": "This method handles asynchronous function definitions. It delegates the actual processing to the `visit_FunctionDef` method, ensuring that both synchronous and asynchronous functions are analyzed using the same logic.",
              "parameters": [
                {
                  "name": "self",
                  "type": "ASTVisitor",
                  "description": "The instance of the ASTVisitor."
                },
                {
                  "name": "node",
                  "type": "ast.AsyncFunctionDef",
                  "description": "The AST node representing an asynchronous function definition."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls the `visit_FunctionDef` method to process the asynchronous function.",
                "called_by": "This method is called automatically by the `ast.NodeVisitor` when it encounters an `ast.AsyncFunctionDef` node during traversal."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "This class depends on the `backend.AST_Schema.path_to_module` function for determining module paths.",
          "instantiated_by": "This class is not instantiated by any known code within the provided context."
        }
      },
      "error": null
    },
    "backend.AST_Schema.ASTAnalyzer": {
      "identifier": "backend.AST_Schema.ASTAnalyzer",
      "description": {
        "overall": "The ASTAnalyzer class is designed to process and enrich Abstract Syntax Tree (AST) data generated from a codebase. It takes raw relationship data (like function calls and class instantiations) and merges it into a comprehensive schema representing the project's structure. It also orchestrates the analysis of an entire repository by parsing individual files and collecting their AST information.",
        "init_method": {
          "description": "Initializes the ASTAnalyzer. Currently, this method does not perform any setup or attribute initialization.",
          "parameters": [
            {
              "name": "self",
              "type": "ASTAnalyzer",
              "description": "The instance of the ASTAnalyzer class."
            }
          ]
        },
        "methods": [
          {
            "identifier": "merge_relationship_data",
            "description": {
              "overall": "This method enriches a full schema dictionary with relationship data, such as outgoing calls and incoming calls for functions, and instantiation information for classes. It iterates through the files and their AST nodes (functions and classes) within the schema. For each function, it adds 'calls' and 'called_by' information from the provided raw relationships. For classes, it adds 'instantiated_by' information. It also calculates and adds a list of external dependencies for each class based on the methods it calls.",
              "parameters": [
                {
                  "name": "self",
                  "type": "ASTAnalyzer",
                  "description": "The instance of the ASTAnalyzer class."
                },
                {
                  "name": "full_schema",
                  "type": "dict",
                  "description": "A dictionary representing the complete schema of the project, including file structures and AST nodes."
                },
                {
                  "name": "raw_relationships",
                  "type": "dict",
                  "description": "A dictionary containing raw relationship data, typically with keys like 'outgoing' and 'incoming' calls."
                }
              ],
              "returns": [
                {
                  "name": "full_schema",
                  "type": "dict",
                  "description": "The modified full_schema dictionary with merged relationship data."
                }
              ],
              "usage_context": {
                "calls": "This method retrieves data using .get() on dictionaries and iterates through dictionary items and lists. It also converts sets to lists and sorts them.",
                "called_by": "This method is called by the analyze_repository method to integrate relationship data into the project schema."
              }
            },
            "error": null
          },
          {
            "identifier": "analyze_repository",
            "description": {
              "overall": "This method orchestrates the analysis of an entire code repository. It takes a list of file objects and a GitRepository object to determine the project structure. It iterates through the provided files, parsing only Python files that have content. For each valid file, it uses an ASTVisitor to parse the file's content into an AST and then extracts schema information. It constructs a 'full_schema' dictionary that aggregates AST nodes from all processed files, handling potential parsing errors gracefully.",
              "parameters": [
                {
                  "name": "self",
                  "type": "ASTAnalyzer",
                  "description": "The instance of the ASTAnalyzer class."
                },
                {
                  "name": "files",
                  "type": "list",
                  "description": "A list of file objects, each containing file path and content."
                },
                {
                  "name": "repo",
                  "type": "GitRepository",
                  "description": "An object representing the Git repository, used here to determine project root."
                }
              ],
              "returns": [
                {
                  "name": "full_schema",
                  "type": "dict",
                  "description": "A dictionary containing the aggregated AST schema information for all processed files in the repository."
                }
              ],
              "usage_context": {
                "calls": "This method calls the ast.parse function to generate an AST from file content and instantiates and calls the visit method of ASTVisitor. It also uses os.path functions to determine the project root and checks file extensions and content.",
                "called_by": "This method is likely the primary entry point for analyzing a codebase and is called by external processes or higher-level orchestration logic."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "This class depends on the 'ast' module for parsing Python code, the 'os' module for path manipulations, and 'getRepo.GitRepository' for repository information. It also utilizes 'backend.AST_Schema.ASTVisitor' for the core AST traversal and schema generation.",
          "instantiated_by": "This class is not instantiated by any other part of the provided code, suggesting it might be used as a utility class or instantiated by external systems."
        }
      },
      "error": null
    },
    "backend.File_Dependency.FileDependencyGraph": {
      "identifier": "backend.File_Dependency.FileDependencyGraph",
      "description": {
        "overall": "The FileDependencyGraph class is designed to analyze Python source code and build a graph of file dependencies based on import statements. It inherits from `ast.NodeVisitor` to traverse the Abstract Syntax Tree (AST) of Python files. The primary goal is to identify how different files import modules and symbols from each other, particularly handling relative imports.",
        "init_method": {
          "description": "Initializes the FileDependencyGraph with the filename being analyzed and the root directory of the repository. This context is crucial for resolving relative imports and understanding the project structure.",
          "parameters": [
            {
              "name": "filename",
              "type": "str",
              "description": "The name of the Python file currently being processed."
            },
            {
              "name": "repo_root",
              "type": "str",
              "description": "The root path of the repository where the file is located."
            }
          ]
        },
        "methods": [
          {
            "identifier": "_resolve_module_name",
            "description": {
              "overall": "This method is responsible for resolving relative import statements (e.g., `from .. import module`) within a Python file. It determines the actual module path based on the current file's location and the specified import level. It searches for matching Python files or packages within the repository and raises an `ImportError` if a resolution cannot be made.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ImportFrom",
                  "description": "The AST node representing an import from statement."
                }
              ],
              "returns": [
                {
                  "name": "resolved",
                  "type": "list[str]",
                  "description": "A sorted list of unique names that were successfully resolved from the relative import."
                }
              ],
              "usage_context": {
                "calls": "This method calls helper functions like `get_all_temp_files`, `module_file_exists`, and `init_exports_symbol` to determine the correct module path.",
                "called_by": "This method is called by `visit_ImportFrom` when it encounters a relative import statement."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_Import",
            "description": {
              "overall": "This method is called when an `import` statement is encountered in the AST. It processes the imported module names and adds them to the `import_dependencies` dictionary, mapping the current filename to the set of imported module names. It also handles cases where a `base_name` is provided, likely for processing `import from` statements.",
              "parameters": [
                {
                  "name": "node",
                  "type": "Import | ImportFrom",
                  "description": "The AST node representing an import statement."
                },
                {
                  "name": "base_name",
                  "type": "str | None",
                  "description": "An optional base name to add to the dependencies, used for processing `import from` statements."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls `self.generic_visit(node)` to continue traversal of the AST.",
                "called_by": "This method is called by `visit_ImportFrom` and potentially other visitor methods."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_ImportFrom",
            "description": {
              "overall": "This method handles `from ... import ...` statements. It extracts the module name, and if it's a relative import, it uses `_resolve_module_name` to find the actual module. It then calls `visit_Import` to record the dependency, passing the resolved module base name or the last part of the module name. It includes error handling for failed relative import resolutions.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ImportFrom",
                  "description": "The AST node representing a 'from ... import ...' statement."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls `_resolve_module_name` for relative imports and `self.visit_Import` to record dependencies. It also calls `self.generic_visit(node)` to continue AST traversal.",
                "called_by": "This method is called by the AST visitor when it encounters an `ImportFrom` node."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "The class relies on several helper functions from the `backend.File_Dependency` module, specifically `get_all_temp_files`, `init_exports_symbol`, and `module_file_exists`, to resolve module names and check file existence.",
          "instantiated_by": "This class is intended to be instantiated within the analysis process of Python files to build dependency graphs, but the specific instantiation points are not detailed in the provided context."
        }
      },
      "error": null
    },
    "backend.HelperLLM.LLMHelper": {
      "identifier": "backend.HelperLLM.LLMHelper",
      "description": {
        "overall": "The LLMHelper class is designed to facilitate the generation and validation of documentation for code elements like functions and classes using large language models (LLMs). It centralizes the interaction with various LLM providers (Google Gemini, OpenAI, Ollama) by abstracting away the specifics of API calls and model configurations. The class handles prompt loading, API key management, and dynamic model selection based on the provided model name. It also incorporates batch processing with configurable batch sizes and rate-limiting delays to efficiently handle multiple requests and manage API usage.",
        "init_method": {
          "description": "Initializes the LLMHelper with necessary API credentials, prompt file paths, and LLM configuration. It loads system prompts for function and class documentation generation from specified files, sets up the LLM client based on the model name (supporting Gemini, OpenAI, and Ollama), and configures batch processing settings. It raises a ValueError if the API key is missing or if environment variables required for custom LLM endpoints are not set.",
          "parameters": [
            {
              "name": "api_key",
              "type": "str",
              "description": "The API key for authenticating with the LLM service."
            },
            {
              "name": "function_prompt_path",
              "type": "str",
              "description": "The file path to the system prompt used for generating function documentation."
            },
            {
              "name": "class_prompt_path",
              "type": "str",
              "description": "The file path to the system prompt used for generating class documentation."
            },
            {
              "name": "model_name",
              "type": "str",
              "description": "The name of the LLM model to use. Defaults to 'gemini-2.0-flash-lite'."
            },
            {
              "name": "base_url",
              "type": "str",
              "description": "An optional base URL for custom LLM endpoints, used if not using default Ollama or OpenAI configurations. Defaults to None."
            }
          ]
        },
        "methods": [
          {
            "identifier": "_configure_batch_settings",
            "description": {
              "overall": "This private method configures the batch size for processing requests based on the specified LLM model name. It defines different batch sizes for various Gemini models, common OpenAI models, and custom/alias models. For unknown models, it defaults to a conservative batch size and logs a warning. This ensures that the LLMHelper can optimize API calls according to the capabilities and rate limits of different models.",
              "parameters": [
                {
                  "name": "model_name",
                  "type": "str",
                  "description": "The name of the LLM model being used, which determines the batch size."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method is called internally by the __init__ method to set the batch size based on the selected LLM model.",
                "called_by": "This method is called by the __init__ method."
              }
            },
            "error": null
          },
          {
            "identifier": "generate_for_functions",
            "description": {
              "overall": "Generates and validates documentation for a list of function inputs using the configured LLM. It processes the inputs in batches according to the `self.batch_size` and includes a waiting period between batches to respect API rate limits. Each function input is converted into a JSON payload and combined with the system prompt to form a conversation. The method handles potential exceptions during the LLM API calls, returning a list of validated `FunctionAnalysis` objects or `None` for failed batches.",
              "parameters": [
                {
                  "name": "function_inputs",
                  "type": "List[FunctionAnalysisInput]",
                  "description": "A list of FunctionAnalysisInput objects, each containing the necessary information to generate documentation for a function."
                }
              ],
              "returns": [
                {
                  "name": "all_validated_functions",
                  "type": "List[Optional[FunctionAnalysis]]",
                  "description": "A list containing the generated and validated FunctionAnalysis objects for each input, or None if an error occurred during processing for a specific batch."
                }
              ],
              "usage_context": {
                "calls": "This method calls `json.dumps` to serialize input data, constructs `SystemMessage` and `HumanMessage` objects for conversation, and uses the `self.function_llm.batch` method to interact with the LLM API. It also uses `time.sleep` for rate limiting.",
                "called_by": "This method is called to generate documentation for multiple functions."
              }
            },
            "error": null
          },
          {
            "identifier": "generate_for_classes",
            "description": {
              "overall": "Generates and validates documentation for a list of class inputs using the configured LLM. Similar to `generate_for_functions`, it processes inputs in batches, respecting rate limits with a configurable waiting time. Each class input is serialized into a JSON payload and paired with the class system prompt to create a conversation. The method handles API call exceptions and returns a list of validated `ClassAnalysis` objects or `None` for any batches that encountered errors.",
              "parameters": [
                {
                  "name": "class_inputs",
                  "type": "List[ClassAnalysisInput]",
                  "description": "A list of ClassAnalysisInput objects, each containing the necessary information to generate documentation for a class."
                }
              ],
              "returns": [
                {
                  "name": "all_validated_classes",
                  "type": "List[Optional[ClassAnalysis]]",
                  "description": "A list containing the generated and validated ClassAnalysis objects for each input, or None if an error occurred during processing for a specific batch."
                }
              ],
              "usage_context": {
                "calls": "This method calls `json.dumps` to serialize input data, constructs `SystemMessage` and `HumanMessage` objects for conversation, and uses the `self.class_llm.batch` method to interact with the LLM API. It also uses `time.sleep` for rate limiting.",
                "called_by": "This method is called to generate documentation for multiple classes."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "This class depends on several external libraries for LLM interaction, including `langchain_google_genai`, `langchain_ollama`, and `langchain_openai`. It also relies on `pydantic` for data validation, `json` for serialization, `logging` for output, and `time` for managing API call delays. Additionally, it uses custom schema types like `FunctionAnalysis`, `ClassAnalysis`, `FunctionAnalysisInput`, and `ClassAnalysisInput` which are assumed to be defined elsewhere.",
          "instantiated_by": "This class is instantiated by other parts of the application that require LLM-based documentation generation services. The specific instantiation points are not detailed in the provided source code but would typically involve passing API keys and prompt file paths during object creation."
        }
      },
      "error": null
    },
    "backend.MainLLM.MainLLM": {
      "identifier": "backend.MainLLM.MainLLM",
      "description": {
        "overall": "The MainLLM class serves as a central orchestrator for interacting with various Large Language Models (LLMs). It handles the initialization of different LLM clients based on provided configurations, loads system prompts from files, and provides methods to invoke LLMs for single responses or stream their output. This class abstracts away the complexities of different LLM providers and their specific API integrations.",
        "init_method": {
          "description": "Initializes the MainLLM class by setting up the LLM client. It validates the API key, loads the system prompt from a specified file path, and configures the LLM based on the model name. It supports different LLM providers like Google Generative AI, OpenAI-compatible APIs (via SCADSLLM_URL), and Ollama, selecting the appropriate client and its configuration.",
          "parameters": [
            {
              "name": "api_key",
              "type": "str",
              "description": "The API key required for authenticating with the LLM service."
            },
            {
              "name": "prompt_file_path",
              "type": "str",
              "description": "The file path to a text file containing the system prompt for the LLM."
            },
            {
              "name": "model_name",
              "type": "str",
              "description": "The name of the LLM model to use. Defaults to 'gemini-2.5-pro'."
            },
            {
              "name": "base_url",
              "type": "str",
              "description": "An optional base URL for custom LLM endpoints, used primarily for Ollama if not using the default OLLAMA_BASE_URL."
            }
          ]
        },
        "methods": [
          {
            "identifier": "call_llm",
            "description": {
              "overall": "Invokes the configured LLM with a user-provided input and returns the LLM's response content. It constructs a list of messages including the system prompt and the user's input, then uses the LLM client's `invoke` method to get a single response. Errors during the LLM call are logged, and `None` is returned in case of failure.",
              "parameters": [
                {
                  "name": "user_input",
                  "type": "str",
                  "description": "The input string from the user to be processed by the LLM."
                }
              ],
              "returns": [
                {
                  "name": "response.content",
                  "type": "str",
                  "description": "The text content of the LLM's response, or None if an error occurred."
                }
              ],
              "usage_context": {
                "calls": "This method calls the `invoke` method of the LLM client, which is an instance of `ChatGoogleGenerativeAI`, `ChatOpenAI`, or `ChatOllama`.",
                "called_by": "This method is called to get a single, direct response from the LLM."
              }
            },
            "error": null
          },
          {
            "identifier": "stream_llm",
            "description": {
              "overall": "Initiates a streaming call to the configured LLM with user input, yielding chunks of the response content as they become available. It prepares messages similar to `call_llm` but uses the LLM client's `stream` method. Each yielded chunk's content is returned to the caller. If an error occurs during streaming, an error message is logged and yielded.",
              "parameters": [
                {
                  "name": "user_input",
                  "type": "str",
                  "description": "The input string from the user to be processed by the LLM for streaming."
                }
              ],
              "returns": [
                {
                  "name": "chunk.content",
                  "type": "str",
                  "description": "Yields chunks of text content from the LLM's streaming response, or an error message if an exception occurs."
                }
              ],
              "usage_context": {
                "calls": "This method calls the `stream` method of the LLM client, which is an instance of `ChatGoogleGenerativeAI`, `ChatOpenAI`, or `ChatOllama`.",
                "called_by": "This method is called to receive a continuous stream of responses from the LLM."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "This class depends on several external libraries for LLM interaction, including `langchain_google_genai`, `langchain_ollama`, and `langchain_openai`. It also utilizes `dotenv` for environment variable loading and `logging` for output.",
          "instantiated_by": "The class is instantiated with an API key, a prompt file path, and optionally a model name and base URL. Specific instantiation points are not detailed in the provided context."
        }
      },
      "error": null
    },
    "backend.basic_info.ProjektInfoExtractor": {
      "identifier": "backend.basic_info.ProjektInfoExtractor",
      "description": {
        "overall": "The ProjektInfoExtractor class is designed to extract fundamental project information from common project files such as README, pyproject.toml, and requirements.txt. It initializes a structured dictionary to hold project overview and installation details, populating it by parsing these files in a prioritized manner. The class aims to provide a consolidated view of project metadata, including title, description, key features, tech stack, installation instructions, and dependencies, falling back to default 'not found' messages when information is absent.",
        "init_method": {
          "description": "Initializes the ProjektInfoExtractor by setting up a default structure for project information. It defines a constant for indicating missing information and initializes a dictionary `self.info` with nested dictionaries for 'projekt_uebersicht' (project overview) and 'installation', pre-filled with a 'not found' placeholder for all fields.",
          "parameters": [
            {
              "name": "self",
              "type": "self",
              "description": "The instance of the class."
            }
          ]
        },
        "methods": [
          {
            "identifier": "_clean_content",
            "description": {
              "overall": "This method takes a string as input and returns a cleaned version of it by removing null bytes ('\\x00'). Null bytes can occur due to encoding issues, such as reading UTF-16 encoded files as UTF-8. It handles empty input strings gracefully by returning an empty string. This ensures that subsequent parsing operations do not encounter unexpected characters.",
              "parameters": [
                {
                  "name": "self",
                  "type": "self",
                  "description": "The instance of the class."
                },
                {
                  "name": "content",
                  "type": "str",
                  "description": "The string content to be cleaned."
                }
              ],
              "returns": [
                {
                  "name": "cleaned_content",
                  "type": "str",
                  "description": "The cleaned string with null bytes removed."
                }
              ],
              "usage_context": {
                "calls": "This method is called by other internal methods to clean file content before parsing.",
                "called_by": "This method is called by _parse_readme, _parse_toml, and _parse_requirements."
              }
            },
            "error": null
          },
          {
            "identifier": "_finde_datei",
            "description": {
              "overall": "This utility method searches through a list of file objects to find a file that matches one of the provided patterns. The search is case-insensitive and checks if the file's path ends with any of the specified patterns. It returns the first matching file object found or `None` if no match is found after checking all files and patterns. This is crucial for locating specific project files like README or pyproject.toml.",
              "parameters": [
                {
                  "name": "self",
                  "type": "self",
                  "description": "The instance of the class."
                },
                {
                  "name": "patterns",
                  "type": "List[str]",
                  "description": "A list of file name patterns (e.g., 'readme.md') to search for."
                },
                {
                  "name": "dateien",
                  "type": "List[Any]",
                  "description": "A list of file objects, where each object is expected to have a 'path' attribute."
                }
              ],
              "returns": [
                {
                  "name": "matching_file",
                  "type": "Optional[Any]",
                  "description": "The file object that matches one of the patterns, or None if no match is found."
                }
              ],
              "usage_context": {
                "calls": "This method iterates through provided file objects and patterns to find a match.",
                "called_by": "This method is called by extrahiere_info to locate specific project files."
              }
            },
            "error": null
          },
          {
            "identifier": "_extrahiere_sektion_aus_markdown",
            "description": {
              "overall": "This method extracts content from a Markdown string that falls under a specified section heading. It uses regular expressions to find lines starting with '##' followed by one of the provided keywords. The content between the matched heading and the next '##' heading or the end of the file is captured and returned as a stripped string. If no matching section is found, it returns `None`. This is useful for parsing structured information within README files.",
              "parameters": [
                {
                  "name": "self",
                  "type": "self",
                  "description": "The instance of the class."
                },
                {
                  "name": "inhalt",
                  "type": "str",
                  "description": "The Markdown content to parse."
                },
                {
                  "name": "keywords",
                  "type": "List[str]",
                  "description": "A list of keywords that define the section heading to extract."
                }
              ],
              "returns": [
                {
                  "name": "section_content",
                  "type": "Optional[str]",
                  "description": "The extracted content of the section, or None if the section is not found."
                }
              ],
              "usage_context": {
                "calls": "This method utilizes the 're' module for pattern matching to find and extract specific sections from Markdown text.",
                "called_by": "This method is called by _parse_readme to extract specific sections like 'Features', 'Tech Stack', 'Status', 'Installation', and 'Quick Start'."
              }
            },
            "error": null
          },
          {
            "identifier": "_parse_readme",
            "description": {
              "overall": "Parses the content of a README file to extract various project details. It first cleans the content to remove null bytes. Then, it attempts to extract the project title from the first H1 heading and a description from the text following the title. It further uses `_extrahiere_sektion_aus_markdown` to find and populate fields for key features, tech stack, status, setup instructions, and quick start guide. If information is already present in `self.info`, it may be overwritten.",
              "parameters": [
                {
                  "name": "self",
                  "type": "self",
                  "description": "The instance of the class."
                },
                {
                  "name": "inhalt",
                  "type": "str",
                  "description": "The content of the README file."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls _clean_content to preprocess the input string and _extrahiere_sektion_aus_markdown to extract specific sections from the README content. It also uses the 're' module for pattern matching to find the title and description.",
                "called_by": "This method is called by extrahiere_info after a README file has been found."
              }
            },
            "error": null
          },
          {
            "identifier": "_parse_toml",
            "description": {
              "overall": "Parses the content of a `pyproject.toml` file using the `tomllib` library. It first cleans the input content. If `tomllib` is available, it attempts to load the TOML data. It then extracts the project name, description, and dependencies from the `[project]` table and updates the `self.info` dictionary accordingly. It includes error handling for `TOMLDecodeError` and prints a warning if `tomllib` is not installed.",
              "parameters": [
                {
                  "name": "self",
                  "type": "self",
                  "description": "The instance of the class."
                },
                {
                  "name": "inhalt",
                  "type": "str",
                  "description": "The content of the pyproject.toml file."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls _clean_content to preprocess the input string and uses the 'tomllib' library to parse TOML data. It also uses the 'print' function for warnings.",
                "called_by": "This method is called by extrahiere_info after a pyproject.toml file has been found."
              }
            },
            "error": null
          },
          {
            "identifier": "_parse_requirements",
            "description": {
              "overall": "Parses the content of a `requirements.txt` file to extract project dependencies. It cleans the input content and then splits it into lines. It filters out empty lines and lines starting with '#'. The extracted dependencies are stored in `self.info['installation']['dependencies']` only if this field has not already been populated by `pyproject.toml`. This ensures that `pyproject.toml` has a higher priority for dependency information.",
              "parameters": [
                {
                  "name": "self",
                  "type": "self",
                  "description": "The instance of the class."
                },
                {
                  "name": "inhalt",
                  "type": "str",
                  "description": "The content of the requirements.txt file."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls _clean_content to preprocess the input string and uses string manipulation methods like splitlines() and strip().",
                "called_by": "This method is called by extrahiere_info after a requirements.txt file has been found."
              }
            },
            "error": null
          },
          {
            "identifier": "extrahiere_info",
            "description": {
              "overall": "This is the main orchestrator method for extracting project information. It takes a list of file objects and a repository URL as input. It first uses `_finde_datei` to locate `README`, `pyproject.toml`, and `requirements.txt` files. It then parses these files in a specific order of priority: `pyproject.toml` first, then `requirements.txt`, and finally `README.md`. After parsing, it formats the dependencies list into a human-readable string or sets it to 'not found' if empty. If a repository URL is provided and no title has been extracted, it generates a default title from the repository name. Finally, it returns the populated `self.info` dictionary.",
              "parameters": [
                {
                  "name": "self",
                  "type": "self",
                  "description": "The instance of the class."
                },
                {
                  "name": "dateien",
                  "type": "List[Any]",
                  "description": "A list of file objects, each representing a file in the project."
                },
                {
                  "name": "repo_url",
                  "type": "str",
                  "description": "The URL of the repository, used to infer the project title if needed."
                }
              ],
              "returns": [
                {
                  "name": "info",
                  "type": "Dict[str, Any]",
                  "description": "A dictionary containing the extracted project information."
                }
              ],
              "usage_context": {
                "calls": "This method calls _finde_datei to locate specific files, and then calls _parse_toml, _parse_requirements, and _parse_readme to parse their content. It also uses os.path.basename and string manipulation methods. It calls _clean_content indirectly via the parsing methods.",
                "called_by": "This is the primary public method of the class, intended to be called by external code to initiate the information extraction process."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "This class utilizes the 're' module for regular expression operations, the 'os' module for path manipulation, and the 'tomllib' library for parsing TOML files. It also relies on type hinting from the 'typing' module.",
          "instantiated_by": "This class is instantiated by external code that needs to extract project information from a set of files and a repository URL."
        }
      },
      "error": null
    },
    "backend.callgraph.CallGraph": {
      "identifier": "backend.callgraph.CallGraph",
      "description": {
        "overall": "The CallGraph class is designed to parse Python source code using the `ast` module and build a directed graph representing function and method calls. It traverses the Abstract Syntax Tree (AST) of a given Python file, identifying imports, class definitions, function definitions, and actual function calls. The class maintains internal state to track the current file, class, and function context during traversal, and resolves callee names by considering local definitions and import mappings. The resulting graph, stored in `self.graph`, maps callers to sets of callees, providing a call graph for the analyzed code.",
        "init_method": {
          "description": "Initializes the CallGraph object with the filename to be analyzed. It sets up various internal data structures to store information during the AST traversal, including the current scope (function and class), mappings for imports and local definitions, and the graph structure itself. These structures are crucial for building the call graph accurately.",
          "parameters": [
            {
              "name": "filename",
              "type": "str",
              "description": "The path to the Python file that will be analyzed to build the call graph."
            }
          ]
        },
        "methods": [
          {
            "identifier": "_recursive_call",
            "description": {
              "overall": "This method recursively traverses an AST node representing a function call's target to extract its name components. It handles different AST node types like `ast.Call`, `ast.Name`, and `ast.Attribute` to reconstruct the fully qualified name of the called entity. The method returns a list of strings, where each string is a part of the dotted name, such as ['package', 'module', 'Class', 'method']. This is a core utility for identifying what is being called.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.AST",
                  "description": "The AST node to analyze, typically representing the function or method being called."
                }
              ],
              "returns": [
                {
                  "name": "parts",
                  "type": "list[str]",
                  "description": "A list of strings representing the hierarchical name components of the called entity."
                }
              ],
              "usage_context": {
                "calls": "This method is called by `visit_Call` to parse the structure of a function call.",
                "called_by": "This method is called by `visit_Call` to recursively extract name components from AST nodes representing calls."
              }
            },
            "error": null
          },
          {
            "identifier": "_resolve_all_callee_names",
            "description": {
              "overall": "This method takes a list of name components (obtained from `_recursive_call`) and resolves them into fully qualified names within the context of the analyzed file. It prioritizes checking local definitions (`self.local_defs`) and then uses the import mapping (`self.import_mapping`) to determine the actual module or path of the callee. If a callee cannot be resolved through local definitions or imports, it constructs a name based on the current filename and class context. This ensures that callees are represented consistently.",
              "parameters": [
                {
                  "name": "callee_nodes",
                  "type": "list[list[str]]",
                  "description": "A list where each element is a list of strings representing the name components of a potential callee."
                }
              ],
              "returns": [
                {
                  "name": "resolved",
                  "type": "list[str]",
                  "description": "A list of fully resolved callee names as strings."
                }
              ],
              "usage_context": {
                "calls": "This method calls `self.local_defs` and `self.import_mapping` to resolve names.",
                "called_by": "This method is called by `visit_Call` to resolve the names of the functions or methods being called."
              }
            },
            "error": null
          },
          {
            "identifier": "_make_full_name",
            "description": {
              "overall": "This utility method constructs a fully qualified name for a function or method within the context of the analyzed file. It takes a base name (like a function or method name) and an optional class name. If a class name is provided, it formats the name as 'filename::ClassName::basename'; otherwise, it formats it as 'filename::basename'. This ensures consistent naming for nodes in the call graph.",
              "parameters": [
                {
                  "name": "basename",
                  "type": "str",
                  "description": "The base name of the function or method."
                },
                {
                  "name": "class_name",
                  "type": "str | None",
                  "description": "The name of the class if the basename is a method within a class; otherwise, None."
                }
              ],
              "returns": [
                {
                  "name": "full_name",
                  "type": "str",
                  "description": "The constructed fully qualified name string."
                }
              ],
              "usage_context": {
                "calls": "This method constructs strings based on input parameters and instance variables.",
                "called_by": "This method is called by `visit_FunctionDef` and `visit_ClassDef` to generate unique identifiers for functions and methods."
              }
            },
            "error": null
          },
          {
            "identifier": "_current_caller",
            "description": {
              "overall": "This method determines the identifier for the current code context that is making a call. If `self.current_function` is set (meaning the analysis is inside a function or method), it returns that function's name. Otherwise, it returns a string representing the global scope of the file, or '<global-scope>' if the filename is not available. This is used to identify the source node in the call graph.",
              "parameters": [],
              "returns": [
                {
                  "name": "caller_name",
                  "type": "str",
                  "description": "The name of the current function, method, or the global scope."
                }
              ],
              "usage_context": {
                "calls": "This method accesses instance variables `self.current_function` and `self.filename`.",
                "called_by": "This method is called by `visit_Call` to identify the caller of a function or method."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_Import",
            "description": {
              "overall": "This method is an AST visitor that handles `import` statements. It iterates through the imported modules and their aliases, populating the `self.import_mapping` dictionary. This mapping stores how imported module names (or their aliases) correspond to their original module names, which is used later for resolving callee names.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.Import",
                  "description": "The AST node representing an import statement."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls `self.generic_visit` to continue AST traversal.",
                "called_by": "This method is automatically called by the AST visitor pattern when an `import` statement is encountered."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_ImportFrom",
            "description": {
              "overall": "This method handles `from ... import ...` statements in the AST. It extracts the module name and the names being imported (including any aliases). It updates the `self.import_mapping` to record the relationship between the imported name (or its alias) and the module it originates from. This is crucial for correctly resolving calls to functions or classes imported from other modules.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.ImportFrom",
                  "description": "The AST node representing a 'from ... import ...' statement."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method accesses `node.module` and `node.names` to process the import.",
                "called_by": "This method is automatically called by the AST visitor pattern when a `from ... import ...` statement is encountered."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_ClassDef",
            "description": {
              "overall": "This method is an AST visitor responsible for handling class definitions (`class ...:`). It updates `self.current_class` to the name of the class being visited, allowing subsequent method visits to know their class context. After visiting the nodes within the class definition (e.g., methods), it restores `self.current_class` to its previous value, ensuring correct context management.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.ClassDef",
                  "description": "The AST node representing a class definition."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls `self.generic_visit` to process the contents of the class definition and `self._make_full_name`.",
                "called_by": "This method is automatically called by the AST visitor pattern when a class definition is encountered."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_FunctionDef",
            "description": {
              "overall": "This method handles standard function definitions (`def ...:`). It constructs the full name of the function using `_make_full_name`, stores this name in `self.local_defs` for later resolution, and updates `self.current_function` to reflect the current scope. It then adds the function as a node to the call graph (`self.graph`) and proceeds to visit the function's body. Finally, it adds the function to `self.function_set` and restores the previous function context.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.FunctionDef",
                  "description": "The AST node representing a function definition."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls `self._make_full_name`, `self.generic_visit`, and `self.graph.add_node`.",
                "called_by": "This method is automatically called by the AST visitor pattern when a function definition is encountered."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_AsyncFunctionDef",
            "description": {
              "overall": "This method is an alias for `visit_FunctionDef` and handles asynchronous function definitions (`async def ...:`). It ensures that asynchronous functions are processed identically to regular functions, allowing them to be correctly identified and added to the call graph. This maintains consistency in call graph construction regardless of function type.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.AsyncFunctionDef",
                  "description": "The AST node representing an asynchronous function definition."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls `self.visit_FunctionDef`.",
                "called_by": "This method is automatically called by the AST visitor pattern when an `async def` statement is encountered."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_Call",
            "description": {
              "overall": "This method is responsible for processing function call expressions (`func(...)`) within the AST. It first determines the current caller using `_current_caller`, then extracts the name components of the callee using `_recursive_call`. It resolves these components into fully qualified names using `_resolve_all_callee_names`. Finally, it adds an edge to the call graph (`self.edges`) from the caller to each resolved callee, representing the call relationship. It then continues visiting child nodes.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.Call",
                  "description": "The AST node representing a function or method call."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls `self._current_caller`, `self._recursive_call`, `self._resolve_all_callee_names`, and `self.generic_visit`.",
                "called_by": "This method is automatically called by the AST visitor pattern when a function call is encountered."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_If",
            "description": {
              "overall": "This method handles `if` statements in the AST. It includes specific logic to detect if the `if` statement is guarding the main execution block of a script (i.e., `if __name__ == '__main__':`). If it is, it temporarily sets the `self.current_function` to '<main_block>' to correctly attribute any calls within that block to the main script execution. It then proceeds to visit the nodes within the `if` statement and restores the original `current_function` context afterward. For other `if` statements, it simply continues the generic visit.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.If",
                  "description": "The AST node representing an if statement."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls `self.generic_visit`.",
                "called_by": "This method is automatically called by the AST visitor pattern when an `if` statement is encountered."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "This class relies on the `ast` module for parsing Python code and the `networkx` library for graph manipulation. It also uses typing hints like `Dict` and `str | None`.",
          "instantiated_by": "The provided context does not specify where this class is instantiated."
        }
      },
      "error": null
    },
    "backend.getRepo.RepoFile": {
      "identifier": "backend.getRepo.RepoFile",
      "description": {
        "overall": "The RepoFile class represents a single file within a Git repository, providing lazy loading for its content and metadata. It allows access to the file's path, size, and content, and includes methods for basic analysis like word counting and representation as a dictionary. The class is designed to efficiently handle file data by only loading it when explicitly requested.",
        "init_method": {
          "description": "Initializes a RepoFile object with the file's path and the commit tree it belongs to. It sets up internal attributes for the path and the commit tree, and initializes placeholders for the blob, content, and size, which will be loaded lazily upon first access.",
          "parameters": [
            {
              "name": "file_path",
              "type": "str",
              "description": "The path to the file within the repository."
            },
            {
              "name": "commit_tree",
              "type": "git.Tree",
              "description": "The Tree object of the commit from which the file originates."
            }
          ]
        },
        "methods": [
          {
            "identifier": "blob",
            "description": {
              "overall": "This property provides lazy loading for the Git blob object associated with the file. It retrieves the blob from the commit tree using the file's path. If the file is not found in the tree, it raises a FileNotFoundError. The blob is cached after the first retrieval to avoid redundant lookups.",
              "parameters": [],
              "returns": [
                {
                  "name": "self._blob",
                  "type": "git.Blob",
                  "description": "The Git blob object representing the file."
                }
              ],
              "usage_context": {
                "calls": "This method is called by other methods within the RepoFile class to access the underlying Git blob object.",
                "called_by": "This method is called by the 'content' and 'size' properties to retrieve the file's blob object."
              }
            },
            "error": null
          },
          {
            "identifier": "content",
            "description": {
              "overall": "This property provides lazy loading for the file's content. It first retrieves the blob object using the 'blob' property and then reads the data from the blob's data stream. The content is decoded from bytes to a UTF-8 string, ignoring any decoding errors. The decoded content is cached after the first retrieval.",
              "parameters": [],
              "returns": [
                {
                  "name": "self._content",
                  "type": "str",
                  "description": "The decoded content of the file as a UTF-8 string."
                }
              ],
              "usage_context": {
                "calls": "This method calls the 'blob' property to get the file's blob object and then accesses its data_stream to read and decode the content.",
                "called_by": "This method is called by the 'analyze_word_count' and 'to_dict' methods to access the file's content."
              }
            },
            "error": null
          },
          {
            "identifier": "size",
            "description": {
              "overall": "This property provides lazy loading for the file's size in bytes. It retrieves the size from the blob object obtained via the 'blob' property. The size is cached after the first retrieval to avoid redundant lookups.",
              "parameters": [],
              "returns": [
                {
                  "name": "self._size",
                  "type": "int",
                  "description": "The size of the file in bytes."
                }
              ],
              "usage_context": {
                "calls": "This method calls the 'blob' property to get the file's blob object and then accesses its size attribute.",
                "called_by": "This method is called by the 'to_dict' method to retrieve the file's size."
              }
            },
            "error": null
          },
          {
            "identifier": "analyze_word_count",
            "description": {
              "overall": "This method performs a simple analysis of the file's content by counting the number of words. It accesses the file's content using the 'content' property, splits the content into words based on whitespace, and returns the total count. This serves as an example of a file analysis operation.",
              "parameters": [],
              "returns": [
                {
                  "name": "word_count",
                  "type": "int",
                  "description": "The number of words found in the file's content."
                }
              ],
              "usage_context": {
                "calls": "This method calls the 'content' property to retrieve the file's content.",
                "called_by": "This method is called to perform a word count analysis on the file."
              }
            },
            "error": null
          },
          {
            "identifier": "__repr__",
            "description": {
              "overall": "This method provides a developer-friendly string representation of the RepoFile object. It returns a formatted string that includes the file's path, making it easy to identify the object when debugging or inspecting it.",
              "parameters": [],
              "returns": [
                {
                  "name": "representation",
                  "type": "str",
                  "description": "A string representation of the RepoFile object, including its path."
                }
              ],
              "usage_context": {
                "calls": "This method uses an f-string to format the output string.",
                "called_by": "This method is called when the object is represented as a string, for example, when printed or inspected in an interactive session."
              }
            },
            "error": null
          },
          {
            "identifier": "to_dict",
            "description": {
              "overall": "This method converts the RepoFile object's information into a dictionary format. It includes the file's path, name (extracted from the path), size, and type. Optionally, if the 'include_content' flag is set to True, it also includes the file's content in the dictionary. This is useful for serialization or data exchange.",
              "parameters": [
                {
                  "name": "include_content",
                  "type": "bool",
                  "description": "A flag to determine whether to include the file's content in the returned dictionary. Defaults to False."
                }
              ],
              "returns": [
                {
                  "name": "data",
                  "type": "dict",
                  "description": "A dictionary containing the file's metadata and optionally its content."
                }
              ],
              "usage_context": {
                "calls": "This method calls the 'os.path.basename' function to extract the file name from the path, and accesses the 'size' and 'content' properties of the RepoFile object.",
                "called_by": "This method is called to convert the RepoFile object into a dictionary representation."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "The class utilizes the 'os' module for path manipulation.",
          "instantiated_by": "This class is instantiated to represent individual files within a Git repository, likely within a larger system that manages Git repositories."
        }
      },
      "error": null
    },
    "backend.getRepo.GitRepository": {
      "identifier": "backend.getRepo.GitRepository",
      "description": {
        "overall": "The GitRepository class is designed to manage a Git repository. It handles cloning the repository into a temporary directory, providing access to its files, and organizing them into a hierarchical tree structure. The class ensures proper cleanup of the temporary directory after use, implementing context management for safe resource handling.",
        "init_method": {
          "description": "Initializes the GitRepository by storing the repository URL, creating a temporary directory for cloning, and attempting to clone the repository. It also captures the latest commit and its associated tree. If cloning fails, it cleans up any created resources and raises a RuntimeError.",
          "parameters": [
            {
              "name": "repo_url",
              "type": "string",
              "description": "The URL of the Git repository to be cloned."
            }
          ]
        },
        "methods": [
          {
            "identifier": "get_all_files",
            "description": {
              "overall": "Retrieves all files within the cloned Git repository. It uses the Git command `ls-files` to get a list of file paths and then creates `RepoFile` objects for each file, associating them with the current commit's tree. This method populates the `self.files` attribute.",
              "parameters": [
                {
                  "name": "self",
                  "type": "GitRepository",
                  "description": "The instance of the GitRepository class."
                }
              ],
              "returns": [
                {
                  "name": "self.files",
                  "type": "list[RepoFile]",
                  "description": "A list containing RepoFile objects, each representing a file in the repository."
                }
              ],
              "usage_context": {
                "calls": "This method calls the RepoFile constructor to create file objects.",
                "called_by": "This method is called by other methods within the GitRepository class, such as get_file_tree, to ensure file information is available."
              }
            },
            "error": null
          },
          {
            "identifier": "close",
            "description": {
              "overall": "Cleans up the resources used by the GitRepository by deleting the temporary directory where the repository was cloned. It sets the `self.temp_dir` attribute to None to indicate that the directory has been removed.",
              "parameters": [
                {
                  "name": "self",
                  "type": "GitRepository",
                  "description": "The instance of the GitRepository class."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method does not call any other methods.",
                "called_by": "This method is called internally by the GitRepository class, particularly during initialization error handling and when the context manager exits (__exit__)."
              }
            },
            "error": null
          },
          {
            "identifier": "__enter__",
            "description": {
              "overall": "Implements the context management protocol for the GitRepository class. This method is called when entering a `with` statement block and returns the repository instance itself, allowing for direct use within the block.",
              "parameters": [
                {
                  "name": "self",
                  "type": "GitRepository",
                  "description": "The instance of the GitRepository class."
                }
              ],
              "returns": [
                {
                  "name": "self",
                  "type": "GitRepository",
                  "description": "The current GitRepository instance."
                }
              ],
              "usage_context": {
                "calls": "This method does not call any other methods.",
                "called_by": "This method is called automatically when a GitRepository object is used in a 'with' statement."
              }
            },
            "error": null
          },
          {
            "identifier": "__exit__",
            "description": {
              "overall": "Implements the context management protocol for the GitRepository class. This method is automatically called when exiting a `with` statement block. It ensures that the `close` method is called to clean up the temporary directory and any associated resources, regardless of whether an exception occurred within the block.",
              "parameters": [
                {
                  "name": "self",
                  "type": "GitRepository",
                  "description": "The instance of the GitRepository class."
                },
                {
                  "name": "exc_type",
                  "type": "type",
                  "description": "The type of the exception raised within the 'with' block, if any."
                },
                {
                  "name": "exc_val",
                  "type": "Exception",
                  "description": "The exception instance raised within the 'with' block, if any."
                },
                {
                  "name": "exc_tb",
                  "type": "traceback",
                  "description": "The traceback object associated with the exception, if any."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls the `close` method of the GitRepository instance.",
                "called_by": "This method is called automatically when exiting a 'with' statement block that uses a GitRepository object."
              }
            },
            "error": null
          },
          {
            "identifier": "get_file_tree",
            "description": {
              "overall": "Constructs and returns a hierarchical tree structure representing the files and directories within the repository. If no files have been processed yet, it first calls `get_all_files` to populate the file list. The tree is built by iterating through the paths of each file and creating nested directory structures as needed, optionally including file content.",
              "parameters": [
                {
                  "name": "self",
                  "type": "GitRepository",
                  "description": "The instance of the GitRepository class."
                },
                {
                  "name": "include_content",
                  "type": "bool",
                  "description": "A boolean flag indicating whether to include the content of each file in the returned tree structure. Defaults to False."
                }
              ],
              "returns": [
                {
                  "name": "tree",
                  "type": "dict",
                  "description": "A dictionary representing the file tree, with 'name', 'type', and 'children' keys. Directories have a 'children' list, and files are represented by dictionaries containing file details."
                }
              ],
              "usage_context": {
                "calls": "This method calls `get_all_files` if the file list is empty and iterates through `self.files`, calling the `to_dict` method on each `RepoFile` object.",
                "called_by": "This method is intended to be called by external code that needs to visualize or process the repository's file structure."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "This class depends on external libraries such as `tempfile` for temporary directory management, `git.Repo` and `git.GitCommandError` for Git operations, and `logging` for information output. It also relies on a custom `RepoFile` class for representing individual files.",
          "instantiated_by": "This class is not explicitly shown to be instantiated by any other code within the provided context."
        }
      },
      "error": null
    },
    "backend.relationship_analyzer.ProjectAnalyzer": {
      "identifier": "backend.relationship_analyzer.ProjectAnalyzer",
      "description": {
        "overall": "The ProjectAnalyzer class is designed to analyze a Python project's codebase to build a call graph and identify relationships between different code entities. It traverses the project directory, parses Python files to collect definitions of functions, classes, and methods, and then resolves function calls to construct a call graph. Finally, it can provide raw relationship data in terms of outgoing and incoming calls.",
        "init_method": {
          "description": "Initializes the ProjectAnalyzer with the root directory of the project. It sets up instance variables to store project root, definitions, call graph, file ASTs, and a set of directories to ignore during file traversal.",
          "parameters": [
            {
              "name": "project_root",
              "type": "string",
              "description": "The absolute path to the root directory of the Python project to be analyzed."
            }
          ]
        },
        "methods": [
          {
            "identifier": "analyze",
            "description": {
              "overall": "This method orchestrates the entire analysis process. It first finds all Python files within the project, then iterates through them to collect definitions (functions, classes, methods) and builds an Abstract Syntax Tree (AST) for each. Subsequently, it resolves function calls within these files to populate the call graph. Finally, it clears the stored ASTs to free up memory and returns the constructed call graph.",
              "parameters": [
                {
                  "name": "self",
                  "type": "ProjectAnalyzer",
                  "description": "The instance of the ProjectAnalyzer class."
                }
              ],
              "returns": [
                {
                  "name": "call_graph",
                  "type": "defaultdict(list)",
                  "description": "A dictionary representing the call graph, where keys are callee identifiers and values are lists of caller information."
                }
              ],
              "usage_context": {
                "calls": "This method calls _find_py_files to get a list of Python files, then iterates through these files calling _collect_definitions and _resolve_calls.",
                "called_by": "This method is the primary entry point for initiating the analysis of a project and is likely called by external modules that need to understand the project's structure."
              }
            },
            "error": null
          },
          {
            "identifier": "get_raw_relationships",
            "description": {
              "overall": "This method processes the internal call graph to generate structured data representing outgoing and incoming relationships between code entities. It iterates through the call graph, identifying callers and callees, and aggregates them into two dictionaries: one for outgoing calls and one for incoming calls. The results are then sorted for consistent output.",
              "parameters": [
                {
                  "name": "self",
                  "type": "ProjectAnalyzer",
                  "description": "The instance of the ProjectAnalyzer class."
                }
              ],
              "returns": [
                {
                  "name": "relationships",
                  "type": "dict",
                  "description": "A dictionary containing two keys: 'outgoing' and 'incoming', each mapping to a dictionary of sorted lists representing call relationships."
                }
              ],
              "usage_context": {
                "calls": "This method iterates through the self.call_graph and uses defaultdict to build outgoing and incoming relationship dictionaries.",
                "called_by": "This method is likely called after the analysis is complete to retrieve processed relationship data."
              }
            },
            "error": null
          },
          {
            "identifier": "_find_py_files",
            "description": {
              "overall": "This private helper method recursively walks through the project directory starting from `self.project_root`. It identifies all Python files (`.py`) while respecting the `self.ignore_dirs` set to exclude common non-source directories like `.git` or `node_modules`. It returns a list of absolute file paths for all found Python files.",
              "parameters": [
                {
                  "name": "self",
                  "type": "ProjectAnalyzer",
                  "description": "The instance of the ProjectAnalyzer class."
                }
              ],
              "returns": [
                {
                  "name": "py_files",
                  "type": "list[str]",
                  "description": "A list of absolute paths to all Python files found in the project, excluding those in ignored directories."
                }
              ],
              "usage_context": {
                "calls": "This method uses os.walk to traverse directories and os.path.join to construct file paths.",
                "called_by": "This method is called by the `analyze` method to gather all Python files that need to be processed."
              }
            },
            "error": null
          },
          {
            "identifier": "_collect_definitions",
            "description": {
              "overall": "This private method parses a given Python file to extract definitions of classes, functions, and methods. It reads the source code, generates an Abstract Syntax Tree (AST) using the `ast` module, and then walks the tree to identify `ast.FunctionDef` and `ast.ClassDef` nodes. For each definition, it records its file path, line number, type (function, method, or class), and its fully qualified path name, storing this information in `self.definitions` and `self.file_asts`. It includes error handling for file reading and parsing.",
              "parameters": [
                {
                  "name": "self",
                  "type": "ProjectAnalyzer",
                  "description": "The instance of the ProjectAnalyzer class."
                },
                {
                  "name": "filepath",
                  "type": "str",
                  "description": "The absolute path to the Python file to be analyzed."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls ast.parse to create an AST, ast.walk to traverse the AST, ast.iter_child_nodes to find child nodes, and path_to_module to convert a file path to a module path. It also uses logging.error for error reporting.",
                "called_by": "This method is called by the `analyze` method for each Python file found in the project."
              }
            },
            "error": null
          },
          {
            "identifier": "_get_parent",
            "description": {
              "overall": "This private helper method traverses the AST of a given tree to find the parent node of a specific child node. It iterates through all nodes in the tree and checks their direct children. If a child matches the provided `node`, it returns the current parent node. If no parent is found (e.g., the node is the root of the tree), it returns `None`.",
              "parameters": [
                {
                  "name": "self",
                  "type": "ProjectAnalyzer",
                  "description": "The instance of the ProjectAnalyzer class."
                },
                {
                  "name": "tree",
                  "type": "ast.AST",
                  "description": "The Abstract Syntax Tree to search within."
                },
                {
                  "name": "node",
                  "type": "ast.AST",
                  "description": "The child node whose parent is to be found."
                }
              ],
              "returns": [
                {
                  "name": "parent",
                  "type": "ast.AST | None",
                  "description": "The parent node of the given node, or None if the node is the root or not found."
                }
              ],
              "usage_context": {
                "calls": "This method uses ast.walk to iterate through the AST and ast.iter_child_nodes to examine the children of each node.",
                "called_by": "This method is called by `_collect_definitions` to determine if a function definition is a method within a class."
              }
            },
            "error": null
          },
          {
            "identifier": "_resolve_calls",
            "description": {
              "overall": "This private method analyzes a given Python file's AST to identify and resolve function and method calls. It uses a `CallResolverVisitor` (an external dependency) to traverse the AST and record calls. For each call identified, it associates the callee's fully qualified name with the caller's information (including file path and line number). These resolved calls are then aggregated into the class's main `self.call_graph`. Error handling is included for the resolution process.",
              "parameters": [
                {
                  "name": "self",
                  "type": "ProjectAnalyzer",
                  "description": "The instance of the ProjectAnalyzer class."
                },
                {
                  "name": "filepath",
                  "type": "str",
                  "description": "The absolute path to the Python file whose calls are to be resolved."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method instantiates and uses the CallResolverVisitor class to visit the AST of the given file. It also uses logging.error for error reporting.",
                "called_by": "This method is called by the `analyze` method for each Python file after its definitions have been collected."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "This class depends on external modules such as `ast` for parsing Python code, `os` for file system operations, `logging` for error reporting, `collections.defaultdict` for data structures, and specifically relies on `backend.relationship_analyzer.CallResolverVisitor` for call resolution and `backend.relationship_analyzer.path_to_module` for converting file paths to module paths.",
          "instantiated_by": "The `ProjectAnalyzer` class is not explicitly shown to be instantiated within the provided code snippet; it is likely instantiated by an external orchestrating script or module that initiates the project analysis process."
        }
      },
      "error": null
    },
    "backend.relationship_analyzer.CallResolverVisitor": {
      "identifier": "backend.relationship_analyzer.CallResolverVisitor",
      "description": {
        "overall": "The CallResolverVisitor is an Abstract Syntax Tree (AST) visitor designed to traverse Python code and identify function and method calls. It resolves the fully qualified names (QNames) of called functions and methods, keeping track of the scope, imported modules, and instantiated class types. This information is used to build a map of call relationships within a project, which is essential for code analysis and understanding dependencies.",
        "init_method": {
          "description": "Initializes the CallResolverVisitor with the file path, project root, and a dictionary of definitions. It sets up internal state to track the current scope, instance types, caller information, and a defaultdict to store identified calls.",
          "parameters": [
            {
              "name": "filepath",
              "type": "string",
              "description": "The absolute path to the Python file being analyzed."
            },
            {
              "name": "project_root",
              "type": "string",
              "description": "The root directory of the project, used to determine module paths."
            },
            {
              "name": "definitions",
              "type": "dict",
              "description": "A dictionary containing definitions of functions and classes within the project."
            }
          ]
        },
        "methods": [
          {
            "identifier": "visit_ClassDef",
            "description": {
              "overall": "Visits a class definition node in the AST. It updates the current class name context before recursively visiting child nodes and restores the previous class name context upon exiting the class definition.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.ClassDef",
                  "description": "The AST node representing a class definition."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls the generic_visit method to continue traversal down the AST.",
                "called_by": "This method is called automatically by the ast.NodeVisitor when it encounters a ClassDef node during traversal."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_FunctionDef",
            "description": {
              "overall": "Visits a function definition node in the AST. It determines the fully qualified name of the function based on whether it's defined within a class or at the module level, updates the current caller name context, and then recursively visits the function's body.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.FunctionDef",
                  "description": "The AST node representing a function definition."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls the generic_visit method to continue traversal down the AST.",
                "called_by": "This method is called automatically by the ast.NodeVisitor when it encounters a FunctionDef node during traversal."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_Call",
            "description": {
              "overall": "Visits a call expression node in the AST. It resolves the qualified name of the called function or method using `_resolve_call_qname`. If the called entity is found in the project's definitions, it records the call information, including the caller's details and type, in the `self.calls` dictionary.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.Call",
                  "description": "The AST node representing a function or method call."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls the _resolve_call_qname method to determine the callee's identity and the generic_visit method to continue traversal down the AST.",
                "called_by": "This method is called automatically by the ast.NodeVisitor when it encounters a Call node during traversal."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_Import",
            "description": {
              "overall": "Visits an import statement node in the AST. It processes each imported name, adding it to the current scope dictionary with its corresponding module name. This helps in resolving names used later in the code.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.Import",
                  "description": "The AST node representing an import statement."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls the generic_visit method to continue traversal down the AST.",
                "called_by": "This method is called automatically by the ast.NodeVisitor when it encounters an Import node during traversal."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_ImportFrom",
            "description": {
              "overall": "Visits an import-from statement node in the AST. It resolves the full module path for imported names, considering relative imports, and updates the scope dictionary. This allows for accurate resolution of names imported from specific modules.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.ImportFrom",
                  "description": "The AST node representing an import-from statement."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls the generic_visit method to continue traversal down the AST.",
                "called_by": "This method is called automatically by the ast.NodeVisitor when it encounters an ImportFrom node during traversal."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_Assign",
            "description": {
              "overall": "Visits an assignment statement node in the AST. If the assignment involves a call to a known class constructor, it records the type of the instantiated object in `self.instance_types` keyed by the variable name. This helps in resolving method calls on instances.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.Assign",
                  "description": "The AST node representing an assignment statement."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls the generic_visit method to continue traversal down the AST.",
                "called_by": "This method is called automatically by the ast.NodeVisitor when it encounters an Assign node during traversal."
              }
            },
            "error": null
          },
          {
            "identifier": "_resolve_call_qname",
            "description": {
              "overall": "A private helper method that resolves the fully qualified name (QName) of a function or method call based on the AST node representing the function being called. It checks the current scope, instance types, and module path to determine the correct QName.",
              "parameters": [
                {
                  "name": "func_node",
                  "type": "ast.expr",
                  "description": "The AST node representing the function or method being called (e.g., ast.Name or ast.Attribute)."
                }
              ],
              "returns": [
                {
                  "name": "callee_pathname",
                  "type": "string | None",
                  "description": "The fully qualified name of the called function or method, or None if it cannot be resolved."
                }
              ],
              "usage_context": {
                "calls": "This method checks for the presence of names in `self.scope` and `self.instance_types` and constructs potential QNames.",
                "called_by": "This method is called by `visit_Call` to determine the identity of the function or method being invoked."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "This class depends on the `path_to_module` function from `backend.relationship_analyzer` and the `ast` and `os` modules.",
          "instantiated_by": "This class is not instantiated within the provided code snippet, but it is designed to be instantiated and used as an AST visitor."
        }
      },
      "error": null
    },
    "schemas.types.ParameterDescription": {
      "identifier": "schemas.types.ParameterDescription",
      "description": {
        "overall": "The ParameterDescription class is a Pydantic model used to define the structure for describing a single parameter within a function or method. It enforces that each parameter must have a name, a type, and a descriptive string.",
        "init_method": {
          "description": "Initializes a ParameterDescription object with the name, type, and description of a function parameter. This constructor is automatically generated by Pydantic's BaseModel.",
          "parameters": [
            {
              "name": "name",
              "type": "str",
              "description": "The name of the parameter."
            },
            {
              "name": "type",
              "type": "str",
              "description": "The data type of the parameter."
            },
            {
              "name": "description",
              "type": "str",
              "description": "A textual description of the parameter."
            }
          ]
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class depends on Pydantic's BaseModel for its structure and validation.",
          "instantiated_by": "This class is likely instantiated by systems that need to describe function or method parameters in a structured format, such as documentation generators or code analysis tools."
        }
      },
      "error": null
    },
    "schemas.types.ReturnDescription": {
      "identifier": "schemas.types.ReturnDescription",
      "description": {
        "overall": "The ReturnDescription class is a Pydantic model designed to encapsulate the details of a function's return value. It serves to structure information about the name, data type, and a textual description of what a function returns.",
        "init_method": {
          "description": "Initializes a ReturnDescription object with the name, type, and description of a function's return value. This constructor directly maps the provided arguments to the corresponding attributes of the model.",
          "parameters": [
            {
              "name": "name",
              "type": "str",
              "description": "The name of the return value, if applicable."
            },
            {
              "name": "type",
              "type": "str",
              "description": "The data type of the return value."
            },
            {
              "name": "description",
              "type": "str",
              "description": "A textual explanation of the return value."
            }
          ]
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class does not have any external dependencies beyond Pydantic.",
          "instantiated_by": "This class is typically instantiated within systems that need to define and document the return values of functions or methods, likely as part of a larger schema or documentation generation process."
        }
      },
      "error": null
    },
    "schemas.types.UsageContext": {
      "identifier": "schemas.types.UsageContext",
      "description": {
        "overall": "The UsageContext class is a Pydantic model designed to encapsulate information about the calling context of a function. It specifically details what functions or methods the current function calls and which functions or methods call the current function. This is useful for understanding code dependencies and execution flow.",
        "init_method": {
          "description": "Initializes the UsageContext model with information about the functions called by and calling the current function. It directly assigns the provided 'calls' and 'called_by' string values to the corresponding attributes.",
          "parameters": [
            {
              "name": "calls",
              "type": "str",
              "description": "A string describing the functions or methods that this function calls."
            },
            {
              "name": "called_by",
              "type": "str",
              "description": "A string describing the functions or methods that call this function."
            }
          ]
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class depends on Pydantic's BaseModel for data validation and structure.",
          "instantiated_by": "This class is likely instantiated within systems that analyze or document code, specifically to record the invocation relationships between different functions or methods."
        }
      },
      "error": null
    },
    "schemas.types.FunctionDescription": {
      "identifier": "schemas.types.FunctionDescription",
      "description": {
        "overall": "The FunctionDescription class is a Pydantic model designed to encapsulate a comprehensive analysis of a function. It holds details about the function's overall purpose, its parameters, its return values, and its usage context within a larger system. This structure is intended for machine readability and detailed documentation generation.",
        "init_method": {
          "description": "Initializes a FunctionDescription object. As this is a Pydantic model, initialization is handled by Pydantic's base model, which validates and assigns the provided attributes: overall description, a list of parameter descriptions, a list of return value descriptions, and usage context information.",
          "parameters": []
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class depends on other Pydantic models: BaseModel, ParameterDescription, ReturnDescription, and UsageContext, as well as typing.List. These models collectively define the structure for detailed function analysis.",
          "instantiated_by": "This class is likely instantiated by systems that perform code analysis and require a structured way to represent the findings for individual functions. It serves as a data structure for storing and transferring function analysis results."
        }
      },
      "error": null
    },
    "schemas.types.FunctionAnalysis": {
      "identifier": "schemas.types.FunctionAnalysis",
      "description": {
        "overall": "The FunctionAnalysis class is a Pydantic model designed to represent the structured analysis of a single function. It encapsulates the function's identifier, a detailed description of its purpose and signature, and an optional field for any errors encountered during analysis. This model serves as a key component in a larger documentation generation system, providing a standardized format for function-level insights.",
        "init_method": {
          "description": "Initializes a FunctionAnalysis object. It takes the function's identifier, a FunctionDescription object containing details about the function's purpose, parameters, returns, and usage context, and an optional error string. The error field defaults to None, indicating no analysis errors by default.",
          "parameters": [
            {
              "name": "identifier",
              "type": "str",
              "description": "The unique name or identifier of the function being analyzed."
            },
            {
              "name": "description",
              "type": "FunctionDescription",
              "description": "A FunctionDescription object that holds the detailed analysis of the function, including its overall purpose, parameters, return values, and usage context."
            },
            {
              "name": "error",
              "type": "Optional[str]",
              "description": "An optional string that provides details if any errors occurred during the analysis of the function. Defaults to None if no errors are present."
            }
          ]
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class relies on the pydantic.BaseModel for its structure and validation, and typing.Optional for defining optional fields. It also implicitly depends on a FunctionDescription model for its detailed analysis data.",
          "instantiated_by": "This class is intended to be instantiated by the main analysis engine or a component responsible for processing and structuring the analysis of individual functions within a larger codebase."
        }
      },
      "error": null
    },
    "schemas.types.ConstructorDescription": {
      "identifier": "schemas.types.ConstructorDescription",
      "description": {
        "overall": "The ConstructorDescription class is a Pydantic model used to represent the initialization method of a Python class. It captures a textual description of the constructor's purpose and a list of its parameters, each detailed by the ParameterDescription model.",
        "init_method": {
          "description": "Initializes a ConstructorDescription object. It takes a string description of the constructor and a list of ParameterDescription objects, representing the parameters of the __init__ method.",
          "parameters": [
            {
              "name": "description",
              "type": "str",
              "description": "A textual summary of the constructor's purpose."
            },
            {
              "name": "parameters",
              "type": "List[ParameterDescription]",
              "description": "A list of ParameterDescription objects, detailing each parameter of the constructor."
            }
          ]
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class has no external dependencies beyond Pydantic's BaseModel.",
          "instantiated_by": "This class is intended to be instantiated by systems that analyze Python class constructors and need to represent their details in a structured format."
        }
      },
      "error": null
    },
    "schemas.types.ClassContext": {
      "identifier": "schemas.types.ClassContext",
      "description": {
        "overall": "The ClassContext model is a Pydantic BaseModel used to describe a class's external dependencies and its primary points of instantiation. It serves as a structured way to document where a class relies on other components and where instances of that class are created within a system.",
        "init_method": {
          "description": "Initializes the ClassContext model with descriptions of external dependencies and instantiation points.",
          "parameters": []
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class does not specify any external dependencies.",
          "instantiated_by": "This class is not specified as being instantiated by any other components."
        }
      },
      "error": null
    },
    "schemas.types.ClassDescription": {
      "identifier": "schemas.types.ClassDescription",
      "description": {
        "overall": "The ClassDescription class is a Pydantic model designed to hold a comprehensive analysis of a Python class. It encapsulates the class's overall purpose, a detailed description of its constructor (__init__ method), an analysis of each of its methods, and information about its usage context including dependencies and instantiation points.",
        "init_method": {
          "description": "The __init__ method for ClassDescription is implicitly defined by Pydantic's BaseModel. It initializes the model with the provided fields: overall description, constructor details, a list of method analyses, and usage context.",
          "parameters": [
            {
              "name": "overall",
              "type": "str",
              "description": "A string providing an overall summary of the class's purpose and responsibilities."
            },
            {
              "name": "init_method",
              "type": "ConstructorDescription",
              "description": "An object detailing the class's constructor, including its description and parameters."
            },
            {
              "name": "methods",
              "type": "List[FunctionAnalysis]",
              "description": "A list of objects, where each object represents the analysis of a specific method within the class."
            },
            {
              "name": "usage_context",
              "type": "ClassContext",
              "description": "An object detailing how the class is used, including its external dependencies and where it is instantiated."
            }
          ]
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class relies on Pydantic's BaseModel for its structure and validation. It also uses types from the 'typing' module like List.",
          "instantiated_by": "This class is intended to be instantiated by systems that perform code analysis and require a structured way to represent the findings about a Python class."
        }
      },
      "error": null
    },
    "schemas.types.ClassAnalysis": {
      "identifier": "schemas.types.ClassAnalysis",
      "description": {
        "overall": "The ClassAnalysis model represents the comprehensive analysis of a Python class, structured for machine readability. It includes the class identifier, a detailed description encompassing its overall purpose, constructor, methods, and usage context, and an optional field for errors encountered during analysis.",
        "init_method": {
          "description": "Initializes the ClassAnalysis model with the class identifier, its detailed description, and an optional error message.",
          "parameters": [
            {
              "name": "identifier",
              "type": "str",
              "description": "The name of the class being analyzed."
            },
            {
              "name": "description",
              "type": "ClassDescription",
              "description": "An object containing the detailed analysis of the class, including its methods and overall purpose."
            },
            {
              "name": "error",
              "type": "Optional[str]",
              "description": "An optional string that holds an error message if the analysis failed."
            }
          ]
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class does not appear to have external dependencies beyond Pydantic's BaseModel.",
          "instantiated_by": "This class is likely instantiated by systems that perform code analysis and require a structured output format."
        }
      },
      "error": null
    },
    "schemas.types.CallInfo": {
      "identifier": "schemas.types.CallInfo",
      "description": {
        "overall": "The CallInfo class is a Pydantic BaseModel used to represent detailed information about a specific call event within a system. It captures the source file, the calling function or method name, the mode of the call (e.g., 'method', 'function', 'module'), and the line number where the call occurred. This structure is primarily utilized for documenting relationships between different code components, such as identifying which parts of the code call a specific function or where a class is instantiated.",
        "init_method": {
          "description": "Initializes a CallInfo object with details about a specific call event. It takes the file path, function name, call mode, and line number as arguments to construct the object.",
          "parameters": [
            {
              "name": "file",
              "type": "str",
              "description": "The path to the file where the call originated."
            },
            {
              "name": "function",
              "type": "str",
              "description": "The name of the function or method that made the call."
            },
            {
              "name": "mode",
              "type": "str",
              "description": "The type of the call, such as 'method', 'function', or 'module'."
            },
            {
              "name": "line",
              "type": "int",
              "description": "The line number in the source file where the call occurred."
            }
          ]
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class depends on Pydantic's BaseModel for data validation and structure.",
          "instantiated_by": "This class is intended to be instantiated by systems that track code relationships, such as a relationship analyzer, to record details of specific function or method calls."
        }
      },
      "error": null
    },
    "schemas.types.FunctionContextInput": {
      "identifier": "schemas.types.FunctionContextInput",
      "description": {
        "overall": "The FunctionContextInput class is a Pydantic model designed to structure contextual information for analyzing a function. It specifically captures the functions a given function calls and the functions that call it, providing a clear data structure for inter-function analysis.",
        "init_method": {
          "description": "Initializes the FunctionContextInput model with lists of function calls and callers. This constructor leverages Pydantic's BaseModel capabilities to validate the input data types for 'calls' and 'called_by'.",
          "parameters": [
            {
              "name": "calls",
              "type": "List[str]",
              "description": "A list of strings, where each string represents the identifier of a function that this function calls."
            },
            {
              "name": "called_by",
              "type": "List[CallInfo]",
              "description": "A list of CallInfo objects, where each object details a function that calls this function."
            }
          ]
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class depends on Pydantic's BaseModel for its structure and validation, and it uses the 'List' type hint from the typing module. It also relies on a 'CallInfo' type, which is not defined in the provided source code but is expected to be available in the environment.",
          "instantiated_by": "This class is intended to be instantiated wherever structured context for function analysis is required, such as in documentation generation systems or code analysis tools. Specific instantiation points are not detailed in the provided source."
        }
      },
      "error": null
    },
    "schemas.types.FunctionAnalysisInput": {
      "identifier": "schemas.types.FunctionAnalysisInput",
      "description": {
        "overall": "The FunctionAnalysisInput class is a Pydantic model designed to encapsulate all the necessary information required for analyzing a Python function. It serves as a structured input for a function analysis process, ensuring all relevant details like the function's identifier, source code, import statements, and contextual information are provided in a standardized format.",
        "init_method": {
          "description": "Initializes the FunctionAnalysisInput model with all the required fields for function analysis. It takes the mode, identifier, source code, a list of import statements, and a FunctionContextInput object as arguments to define the scope and details of the function to be analyzed.",
          "parameters": [
            {
              "name": "mode",
              "type": "Literal[\"function_analysis\"]",
              "description": "Specifies the analysis mode, which must be 'function_analysis' for this input type."
            },
            {
              "name": "identifier",
              "type": "str",
              "description": "The unique name or identifier of the function being analyzed."
            },
            {
              "name": "source_code",
              "type": "str",
              "description": "The raw source code of the function."
            },
            {
              "name": "imports",
              "type": "List[str]",
              "description": "A list of import statements relevant to the source code's context."
            },
            {
              "name": "context",
              "type": "FunctionContextInput",
              "description": "An object containing contextual information about the function, such as its dependencies and call relationships."
            }
          ]
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class has no external dependencies beyond the Pydantic library for defining its structure and the typing module for type hints.",
          "instantiated_by": "This class is intended to be instantiated by systems or processes that require a structured input for function analysis, such as documentation generation tools or code analysis pipelines."
        }
      },
      "error": null
    },
    "schemas.types.MethodContextInput": {
      "identifier": "schemas.types.MethodContextInput",
      "description": {
        "overall": "The MethodContextInput class is a Pydantic model designed to structure contextual information about a class's methods. It captures details such as the method's identifier, lists of other methods or functions it calls and is called by, its arguments, and an optional docstring. This class is primarily used for data validation and organization within a larger system that analyzes or documents code.",
        "init_method": {
          "description": "Initializes a MethodContextInput object, which is a Pydantic model. It takes the identifier, lists of calls and callers, arguments, and an optional docstring as input to define the context of a method.",
          "parameters": [
            {
              "name": "identifier",
              "type": "str",
              "description": "The unique name or identifier of the method."
            },
            {
              "name": "calls",
              "type": "List[str]",
              "description": "A list of strings representing other methods, functions, or classes that this method calls."
            },
            {
              "name": "called_by",
              "type": "List[CallInfo]",
              "description": "A list of CallInfo objects indicating which methods or functions call this method."
            },
            {
              "name": "args",
              "type": "List[str]",
              "description": "A list of strings representing the arguments accepted by the method."
            },
            {
              "name": "docstring",
              "type": "Optional[str]",
              "description": "An optional string containing the documentation (docstring) of the method."
            }
          ]
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class depends on Pydantic's BaseModel for its structure and validation. It also utilizes typing hints like List and Optional, and potentially a custom 'CallInfo' type which is not defined here.",
          "instantiated_by": "This class is intended to be instantiated by systems that require structured data for method context, likely within code analysis or documentation generation tools. Specific instantiation points are not detailed in the provided source code."
        }
      },
      "error": null
    },
    "schemas.types.ClassContextInput": {
      "identifier": "schemas.types.ClassContextInput",
      "description": {
        "overall": "The ClassContextInput class is a Pydantic model designed to hold structured contextual information for analyzing a Python class. It aggregates data about the class's dependencies, where it is instantiated, and detailed context for each of its methods. This model serves as a data container for facilitating comprehensive class analysis within a larger system.",
        "init_method": {
          "description": "Initializes the ClassContextInput model with lists of dependencies, instantiation information, and method contexts. This constructor sets up the data structure for holding analysis-related information for a class.",
          "parameters": [
            {
              "name": "dependencies",
              "type": "List[str]",
              "description": "A list of strings representing external dependencies of the class being analyzed."
            },
            {
              "name": "instantiated_by",
              "type": "List[CallInfo]",
              "description": "A list of CallInfo objects indicating where the class is instantiated in the codebase."
            },
            {
              "name": "method_context",
              "type": "List[MethodContextInput]",
              "description": "A list of MethodContextInput objects, each providing context for a specific method within the class."
            }
          ]
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class does not appear to have any external code dependencies listed.",
          "instantiated_by": "This class is not instantiated by any other components according to the provided context."
        }
      },
      "error": null
    },
    "schemas.types.ClassAnalysisInput": {
      "identifier": "schemas.types.ClassAnalysisInput",
      "description": {
        "overall": "The ClassAnalysisInput class is a Pydantic model designed to structure the input required for a class analysis process. It defines the necessary fields for providing source code, identifier, import statements, and contextual information related to a Python class, ensuring that the input adheres to a predefined schema for analysis.",
        "init_method": {
          "description": "Initializes a ClassAnalysisInput object, which is a Pydantic model used as input for class analysis. It accepts the mode, identifier, source code, import statements, and a ClassContextInput object to define the parameters for analysis.",
          "parameters": [
            {
              "name": "mode",
              "type": "Literal[\"class_analysis\"]",
              "description": "Specifies the analysis mode, which must be 'class_analysis' for this input type."
            },
            {
              "name": "identifier",
              "type": "str",
              "description": "The name of the class to be analyzed."
            },
            {
              "name": "source_code",
              "type": "str",
              "description": "The raw source code of the class definition."
            },
            {
              "name": "imports",
              "type": "List[str]",
              "description": "A list of import statements relevant to the source code."
            },
            {
              "name": "context",
              "type": "ClassContextInput",
              "description": "An object containing contextual information for the class analysis, such as dependencies and instantiation points."
            }
          ]
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class does not have any external functional dependencies listed.",
          "instantiated_by": "This class is not instantiated by any other components within the provided context."
        }
      },
      "error": null
    }
  }
}