{
  "functions": {
    "backend.AST_Schema.path_to_module": {
      "identifier": "backend.AST_Schema.path_to_module",
      "description": {
        "overall": "This function converts a given file path into a Python module path relative to a specified project root. It first calculates the relative path between the file and the project root. If the file is not within the project root, it defaults to using the base name of the file. It then removes the '.py' extension if present and replaces the operating system's path separator with dots to form a module path. Special handling is included for '__init__.py' files, where the '__init__' suffix is removed from the module path.",
        "parameters": [
          {
            "name": "filepath",
            "type": "str",
            "description": "The absolute or relative path to the file."
          },
          {
            "name": "project_root",
            "type": "str",
            "description": "The root directory of the project."
          }
        ],
        "returns": [
          {
            "name": "module_path",
            "type": "str",
            "description": "The Python module path derived from the filepath."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is called by no other functions."
        }
      },
      "error": null
    },
    "backend.File_Dependency.build_file_dependency_graph": {
      "identifier": "backend.File_Dependency.build_file_dependency_graph",
      "description": {
        "overall": "This function constructs a directed graph representing file dependencies within a Python project. It initializes a graph and then uses a visitor pattern to traverse the Abstract Syntax Tree (AST) of a given file. The visitor collects import dependencies, which are then used to populate the graph by adding nodes for each file and edges representing the import relationships. The function returns the fully constructed dependency graph.",
        "parameters": [
          {
            "name": "filename",
            "type": "str",
            "description": "The name of the file for which the dependency graph is being built."
          },
          {
            "name": "tree",
            "type": "AST",
            "description": "The Abstract Syntax Tree (AST) of the file being analyzed."
          },
          {
            "name": "repo_root",
            "type": "str",
            "description": "The root directory of the repository."
          }
        ],
        "returns": [
          {
            "name": "graph",
            "type": "nx.DiGraph",
            "description": "A directed graph representing the file dependencies."
          }
        ],
        "usage_context": {
          "calls": "This function calls backend.File_Dependency.FileDependencyGraph.",
          "called_by": "This function is not called by any other function."
        }
      },
      "error": null
    },
    "backend.File_Dependency.build_repository_graph": {
      "identifier": "backend.File_Dependency.build_repository_graph",
      "description": {
        "overall": "This function constructs a directed graph representing the dependencies between Python files within a Git repository. It iterates through all Python files, parses their Abstract Syntax Trees (ASTs), and builds a dependency graph for each file. These individual file graphs are then merged into a single, global repository graph. The function specifically focuses on Python files, ignoring others, and uses the `build_file_dependency_graph` helper function to process each file's AST.",
        "parameters": [
          {
            "name": "repository",
            "type": "GitRepository",
            "description": "An object representing the Git repository, providing methods to access its files and temporary directory."
          }
        ],
        "returns": [
          {
            "name": "global_graph",
            "type": "nx.DiGraph",
            "description": "A NetworkX directed graph where nodes represent file names and edges represent dependencies between them."
          }
        ],
        "usage_context": {
          "calls": "This function calls backend.File_Dependency.build_file_dependency_graph.",
          "called_by": "This function is not called by any other function within the provided context."
        }
      },
      "error": null
    },
    "backend.File_Dependency.get_all_temp_files": {
      "identifier": "backend.File_Dependency.get_all_temp_files",
      "description": {
        "overall": "This function, `get_all_temp_files`, takes a directory path as input and recursively searches for all Python files (`.py`) within that directory and its subdirectories. It resolves the root path to an absolute path and then returns a list of `Path` objects, where each `Path` object represents the relative path of a found Python file from the root directory. This function is useful for identifying all source code files within a given project structure.",
        "parameters": [
          {
            "name": "directory",
            "type": "str",
            "description": "The path to the directory to search for Python files."
          }
        ],
        "returns": [
          {
            "name": "all_files",
            "type": "list[Path]",
            "description": "A list of Path objects, each representing the relative path of a Python file found within the specified directory."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "backend.HelperLLM.main_orchestrator": {
      "identifier": "backend.HelperLLM.main_orchestrator",
      "description": {
        "overall": "This function serves as a dummy orchestrator for testing the LLMHelper class and its documentation generation capabilities. It simulates the process of analyzing individual functions and classes by defining pre-computed analysis data for several methods ('add_item', 'check_stock', 'generate_report') and then uses this data to instantiate a `ClassAnalysisInput` object for an `InventoryManager` class. Finally, it calls the `generate_for_functions` method of an `LLMHelper` instance with this input, aiming to produce documentation for the class and its methods.",
        "parameters": [],
        "returns": [],
        "usage_context": {
          "calls": "backend.HelperLLM.LLMHelper, schemas.types.ClassAnalysisInput, schemas.types.ClassContextInput",
          "called_by": "This function is not called by any other function."
        }
      },
      "error": null
    },
    "backend.callgraph.make_safe_dot": {
      "identifier": "backend.callgraph.make_safe_dot",
      "description": {
        "overall": "This function takes a NetworkX directed graph and an output path as input. It creates a copy of the graph and relabels its nodes to ensure they are safe for DOT format, typically by prefixing them with 'n' and an index. It then assigns the original node names as labels to these new nodes in the copied graph. Finally, it writes the modified graph to a DOT file at the specified output path using the pydot library.",
        "parameters": [
          {
            "name": "graph",
            "type": "nx.DiGraph",
            "description": "The input NetworkX directed graph to be processed."
          },
          {
            "name": "out_path",
            "type": "str",
            "description": "The file path where the DOT representation of the graph will be saved."
          }
        ],
        "returns": [],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is called by no other functions."
        }
      },
      "error": null
    },
    "backend.callgraph.build_filtered_callgraph": {
      "identifier": "backend.callgraph.build_filtered_callgraph",
      "description": {
        "overall": "This function constructs a global call graph for a given Git repository and then filters it to include only functions defined within the repository. It iterates through all Python files, parses their Abstract Syntax Trees (ASTs), and uses a `CallGraph` visitor to identify functions and their calls. The function first collects all functions defined in the repository and then builds a directed graph (`nx.DiGraph`) by adding edges only between functions that are both defined within the repository. This results in a call graph representing the internal dependencies of the project's code.",
        "parameters": [
          {
            "name": "repo",
            "type": "GitRepository",
            "description": "An object representing the Git repository to analyze, providing access to its files."
          }
        ],
        "returns": [
          {
            "name": "global_graph",
            "type": "nx.DiGraph",
            "description": "A NetworkX directed graph representing the filtered call graph, where nodes are function names and edges indicate a call from one function to another, restricted to functions within the repository."
          }
        ],
        "usage_context": {
          "calls": "This function calls backend.callgraph.CallGraph.",
          "called_by": "This function is not called by any other function."
        }
      },
      "error": null
    },
    "backend.converter.wrap_cdata": {
      "identifier": "backend.converter.wrap_cdata",
      "description": {
        "overall": "This function takes a string `content` as input and returns a new string where the input content is wrapped within CDATA (Character Data) tags. CDATA sections are used in XML and HTML to allow text content that might otherwise be parsed as markup to be treated as raw character data. The function formats the output string using an f-string, ensuring that the content is placed between the opening `<![CDATA[` and closing `]]>` tags, with newline characters before and after the content for readability.",
        "parameters": [
          {
            "name": "content",
            "type": "str",
            "description": "The string content to be wrapped within CDATA tags."
          }
        ],
        "returns": [
          {
            "name": "wrapped_content",
            "type": "str",
            "description": "A string containing the original content enclosed within CDATA tags."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "backend.converter.extract_output_content": {
      "identifier": "backend.converter.extract_output_content",
      "description": {
        "overall": "This function iterates through a list of outputs, processing different output types to extract relevant content. It specifically handles 'display_data' and 'execute_result' types, decoding Base64 encoded images into a list of image data and returning placeholders. For other data types within these outputs, it extracts plain text. It also processes 'stream' outputs by appending their text content and 'error' outputs by formatting them as strings. The function aims to consolidate various output formats into a list of strings, including image placeholders and error messages.",
        "parameters": [
          {
            "name": "outputs",
            "type": "list",
            "description": "A list of output objects, each potentially containing data, type, and text."
          },
          {
            "name": "image_list",
            "type": "list",
            "description": "A list to which image data (as dictionaries with mime_type and data) will be appended."
          }
        ],
        "returns": [
          {
            "name": "extracted_xml_snippets",
            "type": "list",
            "description": "A list containing extracted text content, image placeholders, or formatted error messages."
          }
        ],
        "usage_context": {
          "calls": "This function calls backend.converter.process_image.",
          "called_by": "This function is not called by any other functions within the provided context."
        }
      },
      "error": null
    },
    "backend.converter.process_image": {
      "identifier": "backend.converter.process_image",
      "description": {
        "overall": "This function processes an image based on its MIME type. It checks if the MIME type exists in a predefined data structure. If found, it attempts to decode a base64 encoded string associated with that MIME type, removes newline characters, and appends the image data to a global list `image_list`. It then returns an HTML-like placeholder string with the index and MIME type of the added image. If any error occurs during decoding or processing, it returns an error message. If the MIME type is not found in the data, it returns None.",
        "parameters": [
          {
            "name": "mime_type",
            "type": "str",
            "description": "The MIME type of the image to be processed."
          }
        ],
        "returns": [
          {
            "name": "placeholder_or_error",
            "type": "str",
            "description": "A string representing an image placeholder with its index and MIME type, or an error message if processing fails."
          },
          {
            "name": "none",
            "type": "None",
            "description": "Returned if the provided mime_type is not found in the data."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "backend.converter.convert_notebook_to_xml": {
      "identifier": "backend.converter.convert_notebook_to_xml",
      "description": {
        "overall": "This function takes the content of a Jupyter notebook as a string and converts it into an XML format. It iterates through each cell of the notebook, identifying whether it's a markdown or code cell. For markdown cells, it directly includes the source. For code cells, it includes the source code wrapped in CDATA and also processes and includes any outputs generated by the code, again wrapped in CDATA. The function handles potential errors during the initial parsing of the notebook file.",
        "parameters": [
          {
            "name": "file_content",
            "type": "str",
            "description": "A string containing the raw content of the Jupyter notebook file."
          }
        ],
        "returns": [
          {
            "name": "xml_output",
            "type": "str",
            "description": "A string representing the converted notebook content in XML format, with cells separated by double newlines."
          },
          {
            "name": "extracted_images",
            "type": "list",
            "description": "A list containing information about any images extracted from the notebook outputs."
          }
        ],
        "usage_context": {
          "calls": "This function calls backend.converter.extract_output_content and backend.converter.wrap_cdata.",
          "called_by": "This function is not called by any other functions within the provided context."
        }
      },
      "error": null
    },
    "backend.converter.process_repo_notebooks": {
      "identifier": "backend.converter.process_repo_notebooks",
      "description": {
        "overall": "This function iterates through a list of repository files, identifies those ending with '.ipynb', and processes each notebook file. For every notebook found, it calls `convert_notebook_to_xml` to transform the notebook's content into XML format and extract any associated images. The results, containing the XML output and extracted images for each notebook, are stored in a dictionary keyed by the notebook's file path.",
        "parameters": [
          {
            "name": "repo_files",
            "type": "List[FileObject]",
            "description": "A list of file objects, where each object is expected to have 'path' and 'content' attributes."
          }
        ],
        "returns": [
          {
            "name": "results",
            "type": "Dict[str, Dict[str, Union[str, List[str]]]]",
            "description": "A dictionary where keys are notebook file paths and values are dictionaries containing 'xml' (the converted XML string) and 'images' (a list of extracted image data)."
          }
        ],
        "usage_context": {
          "calls": "This function calls backend.converter.convert_notebook_to_xml.",
          "called_by": "This function is not called by any other functions within the provided context."
        }
      },
      "error": null
    },
    "backend.main.create_savings_chart": {
      "identifier": "backend.main.create_savings_chart",
      "description": {
        "overall": "This function generates a bar chart to visualize the comparison of JSON and TOON tokens, highlighting the savings percentage. It takes the token counts for both formats, the calculated savings percentage, and the desired output path as input. The chart includes labels for 'JSON' and 'TOON', corresponding token values, and specific colors for each bar. It also features a title indicating the savings percentage, a y-axis label for token count, and a grid for better readability. Additionally, the function displays the exact token values above each bar and saves the generated chart to the specified output path before closing the plot.",
        "parameters": [
          {
            "name": "json_tokens",
            "type": "int",
            "description": "The number of tokens for the JSON format."
          },
          {
            "name": "toon_tokens",
            "type": "int",
            "description": "The number of tokens for the TOON format."
          },
          {
            "name": "savings_percent",
            "type": "float",
            "description": "The percentage of savings achieved with the TOON format compared to JSON."
          },
          {
            "name": "output_path",
            "type": "str",
            "description": "The file path where the generated chart image will be saved."
          }
        ],
        "returns": [],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is called by no other functions."
        }
      },
      "error": null
    },
    "backend.main.calculate_net_time": {
      "identifier": "backend.main.calculate_net_time",
      "description": {
        "overall": "This function calculates the net processing time by subtracting any sleep times incurred due to rate limiting from the total duration. It first determines the total duration based on provided start and end times. If the model name does not start with 'gemini-', the total duration is returned directly. For 'gemini-' models, it calculates the number of batches and the total sleep time, then subtracts this from the total duration. The function ensures that the returned net time is not negative.",
        "parameters": [
          {
            "name": "start_time",
            "type": "Any",
            "description": "The start time of the operation."
          },
          {
            "name": "end_time",
            "type": "Any",
            "description": "The end time of the operation."
          },
          {
            "name": "total_items",
            "type": "int",
            "description": "The total number of items processed."
          },
          {
            "name": "batch_size",
            "type": "int",
            "description": "The size of each batch."
          },
          {
            "name": "model_name",
            "type": "str",
            "description": "The name of the model being used."
          }
        ],
        "returns": [
          {
            "name": "net_time",
            "type": "int",
            "description": "The calculated net time after subtracting sleep durations, or 0 if total_items is 0, or the total_duration if the model is not a 'gemini-' model. The returned value is guaranteed to be non-negative."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is called by no other functions."
        }
      },
      "error": null
    },
    "backend.main.main_workflow": {
      "identifier": "backend.main.main_workflow",
      "description": {
        "overall": "The `main_workflow` function orchestrates a complex process of analyzing a GitHub repository to generate documentation. It begins by extracting API keys and model names, then clones the specified repository. It proceeds to extract basic project information, construct a file tree, and perform relationship analysis (calls and instantiations). An Abstract Syntax Tree (AST) is generated and then enriched with the relationship data. This prepared data is then fed to a Helper LLM for function and class analysis. Finally, the results from the Helper LLM, along with project information, are passed to a Main LLM to generate a final report. The function also includes metrics tracking for execution times and token usage, and optionally saves the report and a savings chart.",
        "parameters": [
          {
            "name": "input",
            "type": "Any",
            "description": "The primary input to the workflow, likely containing the repository URL or other relevant data."
          },
          {
            "name": "api_keys",
            "type": "dict",
            "description": "A dictionary containing API keys for various services like Gemini, OpenAI, and ScadsLLM."
          },
          {
            "name": "model_names",
            "type": "dict",
            "description": "A dictionary specifying the model names to be used for helper and main LLM tasks."
          },
          {
            "name": "status_callback",
            "type": "Optional[Callable]",
            "description": "An optional callback function to report status updates during the workflow execution."
          }
        ],
        "returns": [
          {
            "name": "dict",
            "type": "dict",
            "description": "A dictionary containing the final generated report and performance metrics."
          }
        ],
        "usage_context": {
          "calls": "This function calls backend.AST_Schema.ASTAnalyzer, backend.AST_Schema.ASTAnalyzer.analyze_repository, backend.AST_Schema.ASTAnalyzer.merge_relationship_data, backend.HelperLLM.LLMHelper, backend.HelperLLM.LLMHelper.generate_for_classes, backend.HelperLLM.LLMHelper.generate_for_functions, backend.MainLLM.MainLLM, backend.MainLLM.MainLLM.call_llm, backend.basic_info.ProjektInfoExtractor, backend.basic_info.ProjektInfoExtractor.extrahiere_info, backend.getRepo.GitRepository, backend.main.calculate_net_time, backend.main.create_savings_chart, backend.main.update_status, backend.relationship_analyzer.ProjectAnalyzer, backend.relationship_analyzer.ProjectAnalyzer.analyze, backend.relationship_analyzer.ProjectAnalyzer.get_raw_relationships, schemas.types.ClassAnalysisInput, schemas.types.ClassContextInput, schemas.types.FunctionAnalysisInput, schemas.types.FunctionContextInput, and schemas.types.MethodContextInput.",
          "called_by": "This function is not called by any other functions within the provided context."
        }
      },
      "error": null
    },
    "backend.main.update_status": {
      "identifier": "backend.main.update_status",
      "description": {
        "overall": "This function updates the status message. It first checks if a `status_callback` function is defined and, if so, calls it with the provided message. Subsequently, it logs the message using the `logging.info` function. This function is designed to provide feedback on the progress or state of an operation.",
        "parameters": [
          {
            "name": "msg",
            "type": "string",
            "description": "The status message to be displayed or logged."
          }
        ],
        "returns": [],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "backend.main.notebook_workflow": {
      "identifier": "backend.main.notebook_workflow",
      "description": {
        "overall": "This function orchestrates a workflow for analyzing GitHub repositories containing Jupyter notebooks. It clones the repository, extracts basic project information, processes each notebook by converting it to an XML structure and extracting images, and then uses a specified LLM (like GPT or Gemini) to generate a report for each notebook. Finally, it concatenates these individual reports into a single markdown file, saves it, and returns the report along with processing metrics.",
        "parameters": [
          {
            "name": "input",
            "type": "str",
            "description": "The input string, expected to contain a GitHub repository URL."
          },
          {
            "name": "api_keys",
            "type": "dict",
            "description": "A dictionary containing API keys for different LLM providers (e.g., 'gpt', 'gemini', 'scadsllm', 'ollama')."
          },
          {
            "name": "model",
            "type": "str",
            "description": "The name of the language model to use for report generation (e.g., 'gpt-4', 'gemini-pro')."
          },
          {
            "name": "status_callback",
            "type": "Optional[Callable]",
            "description": "An optional callback function to report status updates during the workflow."
          }
        ],
        "returns": [
          {
            "name": "report",
            "type": "str",
            "description": "The concatenated markdown report generated from all processed notebooks."
          },
          {
            "name": "metrics",
            "type": "dict",
            "description": "A dictionary containing performance metrics for the workflow, including total time, model used, and token counts."
          }
        ],
        "usage_context": {
          "calls": "This function calls backend.MainLLM.MainLLM, backend.MainLLM.MainLLM.call_llm, backend.basic_info.ProjektInfoExtractor, backend.basic_info.ProjektInfoExtractor.extrahiere_info, backend.converter.process_repo_notebooks, backend.getRepo.GitRepository, backend.main.gemini_payload, and backend.main.update_status.",
          "called_by": "This function is not called by any other functions within the provided context."
        }
      },
      "error": null
    },
    "backend.main.gemini_payload": {
      "identifier": "backend.main.gemini_payload",
      "description": {
        "overall": "This function constructs a payload for the Gemini API, designed to process and present information from a Jupyter notebook. It takes basic project information, the notebook's path, its XML content, and associated image data as input. The function serializes basic information and the notebook path into a JSON string. It then iterates through the XML content, identifying text segments and image placeholders. For each image placeholder, it extracts image data (base64 encoded) and appends it to the payload as an image_url type. Any remaining text segments are also appended. The final output is a list of dictionaries, where each dictionary represents a content block (either text or an image URL) formatted for the Gemini API.",
        "parameters": [
          {
            "name": "basic_info",
            "type": "dict",
            "description": "A dictionary containing basic information about the project."
          },
          {
            "name": "nb_path",
            "type": "str",
            "description": "The file path to the notebook."
          },
          {
            "name": "xml_content",
            "type": "str",
            "description": "The XML representation of the notebook's content."
          },
          {
            "name": "images",
            "type": "list[dict]",
            "description": "A list of dictionaries, where each dictionary contains image data, including a base64 encoded string."
          }
        ],
        "returns": [
          {
            "name": "payload_content",
            "type": "list[dict]",
            "description": "A list of dictionaries, each representing a content block (text or image_url) formatted for the Gemini API."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is called by no other functions."
        }
      },
      "error": null
    },
    "backend.relationship_analyzer.path_to_module": {
      "identifier": "backend.relationship_analyzer.path_to_module",
      "description": {
        "overall": "This function converts a given file path into a Python module path relative to a specified project root. It first calculates the relative path from the project root to the file. If the file is a Python file (ends with '.py'), the extension is removed. It then replaces the operating system's path separator with dots to form a module path. Special handling is included for '__init__.py' files, where the '__init__' part is removed from the module path.",
        "parameters": [
          {
            "name": "filepath",
            "type": "str",
            "description": "The absolute or relative path to the file."
          },
          {
            "name": "project_root",
            "type": "str",
            "description": "The root directory of the Python project."
          }
        ],
        "returns": [
          {
            "name": "module_path",
            "type": "str",
            "description": "The calculated Python module path."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is called by no other functions."
        }
      },
      "error": null
    },
    "database.db.encrypt_text": {
      "identifier": "database.db.encrypt_text",
      "description": {
        "overall": "This function encrypts a given string using a predefined cipher suite. It first checks if the input text is empty or if the cipher suite is not initialized. If either condition is true, it returns the original text without encryption. Otherwise, it strips leading/trailing whitespace from the text, encodes it into bytes, encrypts the bytes using the cipher suite, and then decodes the resulting encrypted bytes back into a string before returning it.",
        "parameters": [
          {
            "name": "text",
            "type": "str",
            "description": "The string to be encrypted."
          }
        ],
        "returns": [
          {
            "name": "encrypted_text",
            "type": "str",
            "description": "The encrypted string, or the original string if encryption was not performed."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.decrypt_text": {
      "identifier": "database.db.decrypt_text",
      "description": {
        "overall": "This function decrypts a given string using a cipher suite. It first checks if the input text or the cipher suite is missing, returning the original text if either is absent. If a cipher suite is available, it attempts to decrypt the text. The text is stripped of whitespace and encoded before decryption, and the result is decoded back into a string. If any exception occurs during the decryption process, the original text is returned.",
        "parameters": [
          {
            "name": "text",
            "type": "str",
            "description": "The encrypted string to be decrypted."
          }
        ],
        "returns": [
          {
            "name": "decrypted_text",
            "type": "str",
            "description": "The decrypted string, or the original string if decryption fails or is not possible."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.insert_user": {
      "identifier": "database.db.insert_user",
      "description": {
        "overall": "This function inserts a new user record into the database. It constructs a user dictionary containing the username, name, and a hashed password using `stauth.Hasher.hash`. Additional fields like API keys and base URLs are initialized as empty strings. The function then uses `dbusers.insert_one` to add this user data to the database and returns the unique identifier of the newly inserted document.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The unique username for the new user."
          },
          {
            "name": "name",
            "type": "str",
            "description": "The full name of the new user."
          },
          {
            "name": "password",
            "type": "str",
            "description": "The plain text password for the new user, which will be hashed."
          }
        ],
        "returns": [
          {
            "name": "inserted_id",
            "type": "Any",
            "description": "The unique identifier of the newly inserted user document in the database."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.fetch_all_users": {
      "identifier": "database.db.fetch_all_users",
      "description": {
        "overall": "This function retrieves all user records from the database. It interacts with a database collection named 'dbusers' and returns the entire set of documents found within it. The function is designed to fetch all user data without any specific filtering or modification.",
        "parameters": [],
        "returns": [
          {
            "name": "user_list",
            "type": "list",
            "description": "A list containing all user documents fetched from the 'dbusers' collection."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.fetch_user": {
      "identifier": "database.db.fetch_user",
      "description": {
        "overall": "This function retrieves a user document from the database based on the provided username. It queries the 'dbusers' collection using the username as the document's '_id'. The function is designed to fetch a single user record.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username of the user to fetch from the database."
          }
        ],
        "returns": [
          {
            "name": "user_document",
            "type": "Any",
            "description": "A dictionary representing the user document if found, or None if the user does not exist."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.update_user_name": {
      "identifier": "database.db.update_user_name",
      "description": {
        "overall": "This function updates the 'name' field for a user in the database. It takes the current username and the new name as input. The function targets a specific user document using the username as the '_id' and sets the 'name' field to the new provided name. It returns the count of documents that were modified.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The current username of the user whose name needs to be updated."
          },
          {
            "name": "new_name",
            "type": "str",
            "description": "The new name to be set for the user."
          }
        ],
        "returns": [
          {
            "name": "modified_count",
            "type": "int",
            "description": "The number of documents that were modified in the database."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.update_gemini_key": {
      "identifier": "database.db.update_gemini_key",
      "description": {
        "overall": "This function updates the Gemini API key for a given user in the database. It first encrypts the provided API key using a helper function and then updates the user's record in the database with the encrypted key. The function returns the number of documents that were modified.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username of the user whose Gemini API key needs to be updated."
          },
          {
            "name": "gemini_api_key",
            "type": "str",
            "description": "The new Gemini API key to be set for the user."
          }
        ],
        "returns": [
          {
            "name": "modified_count",
            "type": "int",
            "description": "The number of documents in the database that were modified. This is expected to be 1 if the update was successful."
          }
        ],
        "usage_context": {
          "calls": "This function calls database.db.encrypt_text.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.update_gpt_key": {
      "identifier": "database.db.update_gpt_key",
      "description": {
        "overall": "This function updates the GPT API key for a given username in the database. It first encrypts the provided API key using the `encrypt_text` function. Then, it uses `dbusers.update_one` to find the user by their username and set the `gpt_api_key` field to the encrypted value. The function returns the count of documents that were modified.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username of the user whose GPT API key needs to be updated."
          },
          {
            "name": "gpt_api_key",
            "type": "str",
            "description": "The new GPT API key to be set for the user. Leading/trailing whitespace will be removed."
          }
        ],
        "returns": [
          {
            "name": "modified_count",
            "type": "int",
            "description": "The number of documents that were modified in the database. Typically 1 if the update was successful."
          }
        ],
        "usage_context": {
          "calls": "This function calls database.db.encrypt_text.",
          "called_by": "This function is not called by any other functions in the provided context."
        }
      },
      "error": null
    },
    "database.db.update_ollama_url": {
      "identifier": "database.db.update_ollama_url",
      "description": {
        "overall": "This function updates the 'ollama_base_url' field for a specific user in the database. It takes the username and the new base URL as input. The function uses `dbusers.update_one` to perform the update operation, setting the 'ollama_base_url' to the stripped version of the provided URL. It then returns the count of modified documents, which should ideally be 1 if the update was successful.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username of the user whose 'ollama_base_url' needs to be updated."
          },
          {
            "name": "ollama_base_url",
            "type": "str",
            "description": "The new base URL for Ollama to be associated with the user. Leading/trailing whitespace will be removed."
          }
        ],
        "returns": [
          {
            "name": "modified_count",
            "type": "int",
            "description": "The number of documents that were modified in the database. Expected to be 1 if the update was successful."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.update_opensrc_key": {
      "identifier": "database.db.update_opensrc_key",
      "description": {
        "overall": "This function updates the encrypted 'opensrc_api_key' for a given username in the database. It first encrypts the provided API key after removing leading/trailing whitespace. Then, it uses the `dbusers.update_one` method to set the encrypted key for the specified user. The function returns the count of documents that were modified.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username of the user whose API key needs to be updated."
          },
          {
            "name": "opensrc_api_key",
            "type": "str",
            "description": "The raw Open Source API key to be updated."
          }
        ],
        "returns": [
          {
            "name": "modified_count",
            "type": "int",
            "description": "The number of documents modified in the database (typically 1 if successful)."
          }
        ],
        "usage_context": {
          "calls": "This function calls database.db.encrypt_text.",
          "called_by": "This function is not called by any other functions within the provided context."
        }
      },
      "error": null
    },
    "database.db.update_opensrc_url": {
      "identifier": "database.db.update_opensrc_url",
      "description": {
        "overall": "This function updates the 'opensrc_base_url' field for a given user in the database. It takes a username and a new URL as input. The function then uses `dbusers.update_one` to find the user by their '_id' (which is the username) and sets the 'opensrc_base_url' to the provided URL after stripping any leading or trailing whitespace. Finally, it returns the count of documents that were modified.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username of the user whose 'opensrc_base_url' needs to be updated."
          },
          {
            "name": "opensrc_base_url",
            "type": "str",
            "description": "The new base URL for the open-source repository to be set for the user."
          }
        ],
        "returns": [
          {
            "name": "modified_count",
            "type": "int",
            "description": "An integer representing the number of documents that were modified in the database. Typically, this will be 1 if the update was successful, or 0 if the user was not found or the URL was the same."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.fetch_gemini_key": {
      "identifier": "database.db.fetch_gemini_key",
      "description": {
        "overall": "This function retrieves the Gemini API key associated with a given username from the database. It queries the database for a user document matching the provided username and specifically requests the 'gemini_api_key' field, excluding other fields. If a user document is found, it returns the value of the 'gemini_api_key' field; otherwise, it returns None.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username of the user whose Gemini API key needs to be fetched."
          }
        ],
        "returns": [
          {
            "name": "gemini_api_key",
            "type": "str | None",
            "description": "The Gemini API key for the specified user, or None if the user is not found or has no key."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.fetch_ollama_url": {
      "identifier": "database.db.fetch_ollama_url",
      "description": {
        "overall": "This function retrieves the Ollama base URL associated with a given username from a database. It queries a collection (presumably 'dbusers') for a user document matching the provided username. If the user document is found, it extracts and returns the 'ollama_base_url' field. If the user is not found or the field is missing, it returns None.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username to look up in the database."
          }
        ],
        "returns": [
          {
            "name": "ollama_base_url",
            "type": "str | None",
            "description": "The Ollama base URL for the user, or None if the user is not found or the URL is not set."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.fetch_gpt_key": {
      "identifier": "database.db.fetch_gpt_key",
      "description": {
        "overall": "This function retrieves the GPT API key associated with a given username from the database. It queries a collection named 'dbusers' for a document matching the provided username. If a user document is found, it attempts to extract the 'gpt_api_key' field. The function is designed to handle cases where the user might not exist or might not have an API key stored.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username of the user whose GPT API key needs to be fetched."
          }
        ],
        "returns": [
          {
            "name": "gpt_api_key",
            "type": "str | None",
            "description": "The GPT API key for the specified user, or None if the user is not found or does not have an API key."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.fetch_opensrc_key": {
      "identifier": "database.db.fetch_opensrc_key",
      "description": {
        "overall": "This function retrieves the 'opensrc_api_key' for a given username from a database. It queries the database for a user document matching the provided username and specifically selects the 'opensrc_api_key' field while excluding the '_id' field. If a user document is found, it returns the associated 'opensrc_api_key'; otherwise, it returns None.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username to fetch the opensrc API key for."
          }
        ],
        "returns": [
          {
            "name": "opensrc_api_key",
            "type": "str | None",
            "description": "The opensrc API key associated with the username, or None if the user is not found or has no key."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.fetch_opensrc_url": {
      "identifier": "database.db.fetch_opensrc_url",
      "description": {
        "overall": "This function retrieves the 'opensrc_base_url' for a given username from a database. It queries a collection named 'dbusers' to find a document matching the provided username. If a user document is found, it extracts and returns the value associated with the 'opensrc_base_url' key. If no user is found or the key is missing, it returns None.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username to query in the database."
          }
        ],
        "returns": [
          {
            "name": "opensrc_base_url",
            "type": "str | None",
            "description": "The base URL for open source projects associated with the username, or None if the user is not found or the URL is not present."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.delete_user": {
      "identifier": "database.db.delete_user",
      "description": {
        "overall": "This function deletes a user from the database. It takes a username as input and returns the count of deleted documents. The function interacts with a database collection named 'dbusers' to perform the deletion operation.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username of the user to be deleted."
          }
        ],
        "returns": [
          {
            "name": "deleted_count",
            "type": "int",
            "description": "The number of documents that were deleted. This indicates whether the user was successfully removed."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.get_decrypted_api_keys": {
      "identifier": "database.db.get_decrypted_api_keys",
      "description": {
        "overall": "This function retrieves and decrypts API keys and related base URLs for a given username from a database. It first fetches user data using the username and then decrypts sensitive information like Gemini and GPT API keys. It also retrieves non-sensitive information such as Ollama base URL and Open Source API key and base URL. The function returns multiple values, including decrypted API keys and base URLs.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username to retrieve API keys for."
          }
        ],
        "returns": [
          {
            "name": "gemini_plain",
            "type": "str",
            "description": "The decrypted Gemini API key."
          },
          {
            "name": "ollama_plain",
            "type": "str",
            "description": "The Ollama base URL."
          },
          {
            "name": "gpt_plain",
            "type": "str",
            "description": "The decrypted GPT API key."
          },
          {
            "name": "opensrc_plain",
            "type": "str",
            "description": "The decrypted Open Source API key."
          },
          {
            "name": "opensrc_url",
            "type": "str",
            "description": "The Open Source base URL."
          }
        ],
        "usage_context": {
          "calls": "This function calls database.db.decrypt_text.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.insert_chat": {
      "identifier": "database.db.insert_chat",
      "description": {
        "overall": "This function creates a new chat entry in the database. It generates a unique ID, records the username and chat name, and timestamps the creation. The function then inserts this data as a new document into the 'dbchats' collection and returns the ID of the newly inserted document.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username associated with the chat."
          },
          {
            "name": "chat_name",
            "type": "str",
            "description": "The name of the chat to be created."
          }
        ],
        "returns": [
          {
            "name": "inserted_id",
            "type": "Any",
            "description": "The unique identifier of the newly created chat document."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.fetch_chats_by_user": {
      "identifier": "database.db.fetch_chats_by_user",
      "description": {
        "overall": "This function retrieves all chats associated with a specific user from a database. It queries a collection named 'dbchats' for documents matching the provided username and sorts the results by their creation timestamp in ascending order. The function then returns the fetched chats as a list.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username of the user whose chats are to be fetched."
          }
        ],
        "returns": [
          {
            "name": "chats",
            "type": "list",
            "description": "A list of chat documents associated with the specified user, sorted by creation time."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.check_chat_exists": {
      "identifier": "database.db.check_chat_exists",
      "description": {
        "overall": "This function checks if a specific chat exists for a given username in the database. It queries the 'dbchats' collection using the provided username and chat name. The function returns a boolean value indicating whether a matching record was found. It is a simple lookup operation.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username to check for."
          },
          {
            "name": "chat_name",
            "type": "str",
            "description": "The name of the chat to check for."
          }
        ],
        "returns": [
          {
            "name": "exists",
            "type": "bool",
            "description": "True if the chat exists for the user, False otherwise."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.rename_chat_fully": {
      "identifier": "database.db.rename_chat_fully",
      "description": {
        "overall": "This function renames a chat and all associated exchanges in the database. It first updates the chat's name in the 'chats' collection and then updates the 'chat_name' field for all related messages in the 'exchanges' collection. The function returns the count of modified documents from the chat update operation.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username associated with the chat."
          },
          {
            "name": "old_name",
            "type": "str",
            "description": "The current name of the chat to be renamed."
          },
          {
            "name": "new_name",
            "type": "str",
            "description": "The new name to assign to the chat."
          }
        ],
        "returns": [
          {
            "name": "modified_count",
            "type": "int",
            "description": "The number of chat documents that were modified."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.insert_exchange": {
      "identifier": "database.db.insert_exchange",
      "description": {
        "overall": "This function inserts a new exchange record into a database collection named 'dbexchanges'. It constructs a dictionary representing the exchange with various details including question, answer, feedback, user information, usage statistics, and timestamps. A unique ID is generated for each exchange. The function attempts to insert this record using `dbexchanges.insert_one()`. If the insertion is successful, it returns the newly generated ID; otherwise, it prints a database error message and returns None.",
        "parameters": [
          {
            "name": "question",
            "type": "str",
            "description": "The user's question."
          },
          {
            "name": "answer",
            "type": "str",
            "description": "The answer provided to the question."
          },
          {
            "name": "feedback",
            "type": "str",
            "description": "User feedback on the answer."
          },
          {
            "name": "username",
            "type": "str",
            "description": "The username of the user making the exchange."
          },
          {
            "name": "chat_name",
            "type": "str",
            "description": "The name of the chat session."
          },
          {
            "name": "helper_used",
            "type": "str",
            "description": "Indicates if a helper was used (default: \"\")."
          },
          {
            "name": "main_used",
            "type": "str",
            "description": "Indicates if the main model was used (default: \"\")."
          },
          {
            "name": "total_time",
            "type": "str",
            "description": "Total time taken for the exchange (default: \"\")."
          },
          {
            "name": "helper_time",
            "type": "str",
            "description": "Time taken by the helper model (default: \"\")."
          },
          {
            "name": "main_time",
            "type": "str",
            "description": "Time taken by the main model (default: \"\")."
          },
          {
            "name": "json_tokens",
            "type": "int",
            "description": "Number of JSON tokens used (default: 0)."
          },
          {
            "name": "toon_tokens",
            "type": "int",
            "description": "Number of toon tokens used (default: 0)."
          },
          {
            "name": "savings_percent",
            "type": "float",
            "description": "Percentage of savings achieved (default: 0.0)."
          }
        ],
        "returns": [
          {
            "name": "new_id",
            "type": "str",
            "description": "The unique ID of the inserted exchange record if successful."
          },
          {
            "name": "None",
            "type": "None",
            "description": "Returned if an error occurs during database insertion."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is called by no other functions."
        }
      },
      "error": null
    },
    "database.db.fetch_exchanges_by_user": {
      "identifier": "database.db.fetch_exchanges_by_user",
      "description": {
        "overall": "This function retrieves a list of exchanges associated with a specific username from a database. It queries a collection named 'dbexchanges' for documents matching the provided username. The results are then sorted by the 'created_at' field in ascending order before being returned as a list. The sorting is noted as important for display purposes.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username to filter exchanges by."
          }
        ],
        "returns": [
          {
            "name": "exchanges",
            "type": "list",
            "description": "A list of exchange documents associated with the given username, sorted by 'created_at'."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.fetch_exchanges_by_chat": {
      "identifier": "database.db.fetch_exchanges_by_chat",
      "description": {
        "overall": "This function retrieves a list of exchanges from a database collection based on a provided username and chat name. It queries the 'dbexchanges' collection, filters documents by the 'username' and 'chat_name' fields, sorts the results by 'created_at' in ascending order, and returns them as a list. The function is designed to fetch historical chat data.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username associated with the exchanges to be fetched."
          },
          {
            "name": "chat_name",
            "type": "str",
            "description": "The name of the chat from which to fetch exchanges."
          }
        ],
        "returns": [
          {
            "name": "exchanges",
            "type": "list",
            "description": "A list of exchange documents matching the specified username and chat name, sorted by creation time."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.update_exchange_feedback": {
      "identifier": "database.db.update_exchange_feedback",
      "description": {
        "overall": "This function updates the feedback score for a specific exchange in the database. It takes an exchange ID and a feedback integer as input. The function then uses `dbexchanges.update_one` to find the exchange document by its ID and set the 'feedback' field to the provided value. Finally, it returns the count of documents that were modified.",
        "parameters": [
          {
            "name": "exchange_id",
            "type": "Any",
            "description": "The unique identifier of the exchange to be updated."
          },
          {
            "name": "feedback",
            "type": "int",
            "description": "The new feedback score to be set for the exchange."
          }
        ],
        "returns": [
          {
            "name": "modified_count",
            "type": "int",
            "description": "The number of documents that were modified in the database. This should typically be 1 if the update was successful."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.update_exchange_feedback_message": {
      "identifier": "database.db.update_exchange_feedback_message",
      "description": {
        "overall": "This function updates the feedback message associated with a specific exchange in the database. It takes an exchange ID and a feedback message string as input. The function then uses the `dbexchanges.update_one` method to find the exchange by its ID and set the `feedback_message` field to the provided value. Finally, it returns the count of documents that were modified.",
        "parameters": [
          {
            "name": "exchange_id",
            "type": "Any",
            "description": "The unique identifier of the exchange to be updated."
          },
          {
            "name": "feedback_message",
            "type": "str",
            "description": "The new feedback message to be associated with the exchange."
          }
        ],
        "returns": [
          {
            "name": "modified_count",
            "type": "int",
            "description": "The number of documents that were modified in the database (expected to be 1 if successful)."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.delete_exchange_by_id": {
      "identifier": "database.db.delete_exchange_by_id",
      "description": {
        "overall": "This function deletes a single exchange record from the database based on its unique identifier. It interacts with a database collection named 'dbexchanges' to perform the deletion. The function returns the count of documents that were successfully deleted.",
        "parameters": [
          {
            "name": "exchange_id",
            "type": "str",
            "description": "The unique identifier of the exchange record to be deleted."
          }
        ],
        "returns": [
          {
            "name": "deleted_count",
            "type": "int",
            "description": "The number of documents that were deleted from the database. This is typically 1 if the exchange was found and deleted, or 0 if no matching exchange was found."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.delete_full_chat": {
      "identifier": "database.db.delete_full_chat",
      "description": {
        "overall": "This function deletes a chat and all associated exchanges from the database to ensure consistency between the frontend and backend. It first removes all messages within the specified chat and then deletes the chat itself from the chat list. The function aims to maintain data integrity by performing these operations atomically.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username associated with the chat to be deleted."
          },
          {
            "name": "chat_name",
            "type": "str",
            "description": "The name of the chat to be deleted."
          }
        ],
        "returns": [
          {
            "name": "deleted_count",
            "type": "int",
            "description": "The number of chats that were deleted."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "frontend.frontend.clean_names": {
      "identifier": "frontend.frontend.clean_names",
      "description": {
        "overall": "This function takes a list of strings, where each string is expected to be a path or identifier that includes a '/' separator. It processes each string in the list by splitting it at the '/' character and taking the last element. This effectively extracts the final component of each identifier, assuming it represents a clean name. The function returns a new list containing these cleaned names.",
        "parameters": [
          {
            "name": "model_list",
            "type": "List[str]",
            "description": "A list of strings, where each string is an identifier potentially containing '/' characters."
          }
        ],
        "returns": [
          {
            "name": "cleaned_names",
            "type": "List[str]",
            "description": "A new list containing the last component of each string from the input list after splitting by '/'."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "frontend.frontend.get_filtered_models": {
      "identifier": "frontend.frontend.get_filtered_models",
      "description": {
        "overall": "This function filters a list of models based on a specified category name. It retrieves keywords associated with the category from a predefined mapping (CATEGORY_KEYWORDS). If the category is 'STANDARD', it returns models present in both the source list and a 'STANDARD_MODELS' list. Otherwise, it filters the source list to include models whose names contain any of the category's keywords (case-insensitive). If no models match the keywords, the original source list is returned.",
        "parameters": [
          {
            "name": "source_list",
            "type": "list",
            "description": "The list of models to be filtered."
          },
          {
            "name": "category_name",
            "type": "str",
            "description": "The name of the category to filter by."
          }
        ],
        "returns": [
          {
            "name": "filtered_list",
            "type": "list",
            "description": "A list of models that match the specified category's criteria, or the original source_list if no matches are found or if the category is 'STANDARD' and matches are found."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is called by no other functions."
        }
      },
      "error": null
    },
    "frontend.frontend.save_gemini_cb": {
      "identifier": "frontend.frontend.save_gemini_cb",
      "description": {
        "overall": "This function is responsible for saving a Gemini API key provided by the user. It retrieves the new key from the Streamlit session state. If a key exists, it updates the user's Gemini key in the database using the `update_gemini_key` function. After a successful update, it clears the temporary key from the session state and displays a success message to the user.",
        "parameters": [],
        "returns": [],
        "usage_context": {
          "calls": "This function calls database.db.update_gemini_key.",
          "called_by": "This function is not called by any other function."
        }
      },
      "error": null
    },
    "frontend.frontend.save_ollama_cb": {
      "identifier": "frontend.frontend.save_ollama_cb",
      "description": {
        "overall": "This function is a callback designed to save an Ollama URL. It retrieves a URL from the Streamlit session state, and if a URL is present, it updates the user's Ollama URL in the database. Finally, it displays a confirmation toast message to the user.",
        "parameters": [],
        "returns": [],
        "usage_context": {
          "calls": "This function calls database.db.update_ollama_url.",
          "called_by": "This function is not called by any other function."
        }
      },
      "error": null
    },
    "frontend.frontend.load_data_from_db": {
      "identifier": "frontend.frontend.load_data_from_db",
      "description": {
        "overall": "This function loads chat and exchange data from a database for a given username, ensuring consistency. It first loads predefined chats and then sorts associated exchanges into them. If no chats exist, it creates a default chat and inserts it into the database. It also manages the active chat state, setting it to the first available chat if not already defined or if the current active chat is no longer available. This loading process is conditional, only occurring if the user has not been loaded previously in the current session or if the username has changed.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username for whom to load chat and exchange data."
          }
        ],
        "returns": [],
        "usage_context": {
          "calls": "This function calls database.db.fetch_chats_by_user, database.db.fetch_exchanges_by_user, and database.db.insert_chat.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "frontend.frontend.handle_feedback_change": {
      "identifier": "frontend.frontend.handle_feedback_change",
      "description": {
        "overall": "This function updates the feedback associated with an exchange and then triggers a rerun of the Streamlit application. It modifies a dictionary representing an exchange, updates the feedback in a database, and finally calls `st.rerun()` to refresh the user interface. The function takes the exchange dictionary and the new feedback value as input.",
        "parameters": [
          {
            "name": "ex",
            "type": "dict",
            "description": "A dictionary containing exchange information, including an '_id' field for database updates."
          },
          {
            "name": "val",
            "type": "any",
            "description": "The new feedback value to be set for the exchange."
          }
        ],
        "returns": [],
        "usage_context": {
          "calls": "This function calls database.db.update_exchange_feedback.",
          "called_by": "This function is not called by any other functions within the provided context."
        }
      },
      "error": null
    },
    "frontend.frontend.handle_delete_exchange": {
      "identifier": "frontend.frontend.handle_delete_exchange",
      "description": {
        "overall": "This function handles the deletion of an exchange from the system. It first deletes the exchange from the database using its ID. Then, it checks if the chat associated with the exchange exists in the session state. If it does, it removes the exchange from the list of exchanges within that chat. Finally, it triggers a rerun of the Streamlit application to reflect the changes.",
        "parameters": [
          {
            "name": "chat_name",
            "type": "str",
            "description": "The name of the chat associated with the exchange to be deleted."
          },
          {
            "name": "ex",
            "type": "dict",
            "description": "A dictionary representing the exchange to be deleted, expected to contain an '_id' key."
          }
        ],
        "returns": [],
        "usage_context": {
          "calls": "This function calls database.db.delete_exchange_by_id.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "frontend.frontend.handle_delete_chat": {
      "identifier": "frontend.frontend.handle_delete_chat",
      "description": {
        "overall": "This function handles the deletion of a chat for a given user. It first calls a database function to delete the chat's full content. Then, it cleans up the session state by removing the chat from the list of available chats. If there are remaining chats, it sets the first one as the active chat. If no chats are left, it creates a new default chat, inserts it into the database, and sets it as the active chat. Finally, it reruns the Streamlit application to reflect the changes.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username of the user whose chat is to be deleted."
          },
          {
            "name": "chat_name",
            "type": "str",
            "description": "The name of the chat to be deleted."
          }
        ],
        "returns": [],
        "usage_context": {
          "calls": "This function calls database.db.delete_full_chat and database.db.insert_chat.",
          "called_by": "This function is not called by any other function."
        }
      },
      "error": null
    },
    "frontend.frontend.extract_repo_name": {
      "identifier": "frontend.frontend.extract_repo_name",
      "description": {
        "overall": "This function extracts a repository name from a given text, primarily by searching for a URL. It uses regular expressions to find a URL within the text. If a URL is found, it parses the URL to isolate the path component. It then extracts the last part of the path, which is assumed to be the repository name. It also handles cases where the repository name might end with '.git' by removing that suffix. If no URL is found or if the extracted path does not yield a repository name, the function returns None.",
        "parameters": [
          {
            "name": "text",
            "type": "str",
            "description": "The input text, which may contain a URL to a repository."
          }
        ],
        "returns": [
          {
            "name": "repo_name",
            "type": "str | None",
            "description": "The extracted repository name if found, otherwise None."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "frontend.frontend.stream_text_generator": {
      "identifier": "frontend.frontend.stream_text_generator",
      "description": {
        "overall": "This function takes a string of text as input and yields words from it one by one with a small delay between each word. It splits the input text into words based on spaces and then yields each word followed by a space. A short pause of 0.01 seconds is introduced after yielding each word, simulating a streaming effect. This is likely used for displaying text in a way that appears as if it's being typed out character by character or word by word.",
        "parameters": [
          {
            "name": "text",
            "type": "str",
            "description": "The input string of text to be streamed word by word."
          }
        ],
        "returns": [
          {
            "name": "word",
            "type": "str",
            "description": "A single word from the input text, followed by a space, yielded by the generator."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "frontend.frontend.render_text_with_mermaid": {
      "identifier": "frontend.frontend.render_text_with_mermaid",
      "description": {
        "overall": "This function takes a markdown text string and renders it, specifically handling mermaid code blocks. It splits the input text by mermaid code blocks (```mermaid ... ```). For non-mermaid parts, it either writes them directly using `st.markdown` or streams them using `st.write_stream` if `should_stream` is True. For mermaid code blocks, it attempts to render them using `st_mermaid`; if that fails, it falls back to displaying the code as a mermaid block using `st.code`.",
        "parameters": [
          {
            "name": "markdown_text",
            "type": "str",
            "description": "The markdown text to be rendered, potentially containing mermaid code blocks."
          },
          {
            "name": "should_stream",
            "type": "bool",
            "description": "A flag indicating whether to stream the non-mermaid text output. Defaults to False."
          }
        ],
        "returns": [],
        "usage_context": {
          "calls": "This function calls frontend.frontend.stream_text_generator.",
          "called_by": "This function is not called by any other function within the provided context."
        }
      },
      "error": null
    },
    "frontend.frontend.render_exchange": {
      "identifier": "frontend.frontend.render_exchange",
      "description": {
        "overall": "This function renders a chat exchange, displaying both the user's question and the assistant's answer. It handles various interactive elements for the assistant's response, including feedback buttons (like/dislike), a popover for adding notes, a download button for the answer, and a delete button. The function also differentiates between normal answers and error messages, displaying appropriate UI elements for each. It utilizes Streamlit components for rendering the chat interface and interactive elements.",
        "parameters": [
          {
            "name": "ex",
            "type": "dict",
            "description": "A dictionary containing the exchange data, including 'question', 'answer', '_id', and optional 'feedback' and 'feedback_message'."
          },
          {
            "name": "current_chat_name",
            "type": "str",
            "description": "The name of the current chat session, used for context when deleting exchanges."
          }
        ],
        "returns": [],
        "usage_context": {
          "calls": "This function calls database.db.update_exchange_feedback_message, frontend.frontend.handle_delete_exchange, frontend.frontend.handle_feedback_change, and frontend.frontend.render_text_with_mermaid.",
          "called_by": "This function is not called by any other functions within the provided context."
        }
      },
      "error": null
    }
  },
  "classes": {
    "backend.AST_Schema.ASTVisitor": {
      "identifier": "backend.AST_Schema.ASTVisitor",
      "description": {
        "overall": "The ASTVisitor class is designed to traverse an Abstract Syntax Tree (AST) generated from Python source code. It specifically focuses on identifying and extracting information about imports, classes, and functions within the code. The visitor pattern is employed to systematically process different node types in the AST, populating a schema object with the gathered metadata. This class is a core component for code analysis and schema generation.",
        "init_method": {
          "description": "Initializes the ASTVisitor with the source code, file path, and project root. It sets up instance variables to store this information and initializes an empty schema dictionary to hold the extracted AST information. It also prepares for tracking the current class context during traversal.",
          "parameters": [
            {
              "name": "source_code",
              "type": "str",
              "description": "The raw source code of the file being analyzed."
            },
            {
              "name": "file_path",
              "type": "str",
              "description": "The absolute path to the source code file."
            },
            {
              "name": "project_root",
              "type": "str",
              "description": "The root directory of the project."
            }
          ]
        },
        "methods": [
          {
            "identifier": "visit_Import",
            "description": {
              "overall": "This method handles the visiting of `import` statements in the AST. It iterates through the imported names and appends them to the 'imports' list within the schema. It ensures that the traversal continues to child nodes by calling `generic_visit`.",
              "parameters": [
                {
                  "name": "self",
                  "type": "ASTVisitor",
                  "description": "The instance of the ASTVisitor class."
                },
                {
                  "name": "node",
                  "type": "ast.Import",
                  "description": "The AST node representing an import statement."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls the generic_visit method to continue AST traversal.",
                "called_by": "This method is called by the AST traversal mechanism when an import node is encountered."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_ImportFrom",
            "description": {
              "overall": "This method processes `from ... import ...` statements. It extracts the module and specific names being imported, formatting them as 'module.name' and adding them to the schema's 'imports' list. It then proceeds to visit child nodes.",
              "parameters": [
                {
                  "name": "self",
                  "type": "ASTVisitor",
                  "description": "The instance of the ASTVisitor class."
                },
                {
                  "name": "node",
                  "type": "ast.ImportFrom",
                  "description": "The AST node representing a from-import statement."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls the generic_visit method to continue AST traversal.",
                "called_by": "This method is called by the AST traversal mechanism when a from-import node is encountered."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_ClassDef",
            "description": {
              "overall": "This method is responsible for visiting class definition nodes in the AST. It constructs a detailed dictionary for the class, including its fully qualified identifier, name, docstring, source code segment, and line numbers. This class information is then appended to the schema's 'classes' list, and the `_current_class` attribute is updated to track the class being visited. After visiting child nodes, it resets `_current_class`.",
              "parameters": [
                {
                  "name": "self",
                  "type": "ASTVisitor",
                  "description": "The instance of the ASTVisitor class."
                },
                {
                  "name": "node",
                  "type": "ast.ClassDef",
                  "description": "The AST node representing a class definition."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls ast.get_docstring, ast.get_source_segment, and generic_visit to process the class definition and its contents.",
                "called_by": "This method is called by the AST traversal mechanism when a class definition node is encountered."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_FunctionDef",
            "description": {
              "overall": "This method handles the visiting of function definition nodes. If the visitor is currently within a class context (`_current_class` is set), it records the function as a method, creating a `method_context_info` dictionary with its identifier, name, arguments, docstring, and line numbers, and appends it to the current class's context. If not within a class, it records the function as a standalone function, creating a `func_info` dictionary and appending it to the schema's 'functions' list. It then proceeds to visit child nodes.",
              "parameters": [
                {
                  "name": "self",
                  "type": "ASTVisitor",
                  "description": "The instance of the ASTVisitor class."
                },
                {
                  "name": "node",
                  "type": "ast.FunctionDef",
                  "description": "The AST node representing a function definition."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls ast.get_docstring, ast.get_source_segment, and generic_visit to process the function definition and its contents.",
                "called_by": "This method is called by the AST traversal mechanism when a function definition node is encountered."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_AsyncFunctionDef",
            "description": {
              "overall": "This method serves as an alias for `visit_FunctionDef` to handle asynchronous function definitions. It ensures that `async def` functions are processed using the same logic as regular `def` functions, allowing for consistent analysis of both synchronous and asynchronous code structures.",
              "parameters": [
                {
                  "name": "self",
                  "type": "ASTVisitor",
                  "description": "The instance of the ASTVisitor class."
                },
                {
                  "name": "node",
                  "type": "ast.AsyncFunctionDef",
                  "description": "The AST node representing an asynchronous function definition."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls the visit_FunctionDef method to process the asynchronous function definition.",
                "called_by": "This method is called by the AST traversal mechanism when an asynchronous function definition node is encountered."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "This class depends on the `backend.AST_Schema.path_to_module` function for determining module paths.",
          "instantiated_by": "This class is not explicitly shown to be instantiated within the provided code snippets or context."
        }
      },
      "error": null
    },
    "backend.AST_Schema.ASTAnalyzer": {
      "identifier": "backend.AST_Schema.ASTAnalyzer",
      "description": {
        "overall": "The ASTAnalyzer class is designed to process and enrich Abstract Syntax Tree (AST) data generated from a codebase. It takes raw schema information and relationship data (like function calls and class instantiations) and merges them to provide a more comprehensive view of the code structure. It also facilitates the analysis of an entire repository by parsing individual files and aggregating their AST information.",
        "init_method": {
          "description": "Initializes the ASTAnalyzer. Currently, this method does not perform any setup or attribute initialization.",
          "parameters": []
        },
        "methods": [
          {
            "identifier": "merge_relationship_data",
            "description": {
              "overall": "This method merges relationship data, such as outgoing calls and incoming calls, into a full schema representation. It iterates through files, functions, classes, and methods within the schema, augmenting their context with call and instantiation information derived from the provided raw relationship dictionaries. It also identifies and aggregates dependencies between classes.",
              "parameters": [
                {
                  "name": "full_schema",
                  "type": "dict",
                  "description": "A dictionary representing the complete schema of the codebase, including file structures, AST nodes, functions, and classes."
                },
                {
                  "name": "raw_relationships",
                  "type": "dict",
                  "description": "A dictionary containing raw relationship data, expected to have 'outgoing' and 'incoming' keys for call and instantiation information."
                }
              ],
              "returns": [
                {
                  "name": "full_schema",
                  "type": "dict",
                  "description": "The modified full schema dictionary with relationship data merged into the appropriate context fields."
                }
              ],
              "usage_context": {
                "calls": "This method retrieves data using .get() on dictionaries and iterates through nested structures. It does not explicitly call other methods or functions from external modules within its scope.",
                "called_by": "This method is called by the analyze_repository method to enrich the schema with relationship data."
              }
            },
            "error": null
          },
          {
            "identifier": "analyze_repository",
            "description": {
              "overall": "This method orchestrates the analysis of an entire code repository. It takes a list of file objects and a GitRepository object, parses each Python file to generate an AST, and then uses an ASTVisitor to extract schema information. It aggregates this information into a comprehensive schema, handling potential parsing errors and filtering non-Python files.",
              "parameters": [
                {
                  "name": "files",
                  "type": "list",
                  "description": "A list of file objects, where each object contains file path and content."
                },
                {
                  "name": "repo",
                  "type": "GitRepository",
                  "description": "An object representing the Git repository, though its methods are not directly used within this function's logic."
                }
              ],
              "returns": [
                {
                  "name": "full_schema",
                  "type": "dict",
                  "description": "A dictionary containing the aggregated schema information for all processed Python files in the repository."
                }
              ],
              "usage_context": {
                "calls": "This method calls ast.parse to parse Python code into an AST and instantiates ASTVisitor to traverse the AST. It also uses os.path.commonpath and os.path.isfile for path manipulation.",
                "called_by": "This method is not explicitly called by any other method within the provided source code snippet."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "This class depends on the ASTVisitor class for parsing and visiting AST nodes, and utilizes the 'ast' and 'os' modules for code parsing and path manipulation.",
          "instantiated_by": "This class is not instantiated by any other part of the provided code."
        }
      },
      "error": null
    },
    "backend.File_Dependency.FileDependencyGraph": {
      "identifier": "backend.File_Dependency.FileDependencyGraph",
      "description": {
        "overall": "The FileDependencyGraph class is designed to analyze Python source code and build a graph of file dependencies. It inherits from ast.NodeVisitor, allowing it to traverse the Abstract Syntax Tree (AST) of Python files. The primary goal is to identify and record import relationships between different files within a repository, particularly handling relative imports.",
        "init_method": {
          "description": "Initializes the FileDependencyGraph with the filename being analyzed and the root directory of the repository. This context is crucial for resolving relative imports and understanding the file structure.",
          "parameters": [
            {
              "name": "filename",
              "type": "str",
              "description": "The name of the Python file currently being processed."
            },
            {
              "name": "repo_root",
              "type": "str",
              "description": "The absolute path to the root directory of the repository."
            }
          ]
        },
        "methods": [
          {
            "identifier": "_resolve_module_name",
            "description": {
              "overall": "This method is responsible for resolving relative import statements (e.g., `from .. import module`) within a Python file. It takes an `ImportFrom` AST node and determines the actual module path based on the current file's location and the repository structure. It searches for matching files or `__init__.py` files in parent directories according to the import level. If a resolution is not possible, it raises an `ImportError`.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ImportFrom",
                  "description": "The AST node representing a relative import statement."
                }
              ],
              "returns": [
                {
                  "name": "resolved",
                  "type": "list[str]",
                  "description": "A sorted list of strings representing the resolved module or symbol names."
                }
              ],
              "usage_context": {
                "calls": "This method calls `get_all_temp_files` to get all files in the repository, and internally defines and calls `module_file_exists` and `init_exports_symbol` to check for file existence and symbol exports.",
                "called_by": "This method is called by `visit_ImportFrom` when handling relative imports."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_Import",
            "description": {
              "overall": "This method handles standard import statements (`import module` or `from module import name`). It records the imported module name in the `import_dependencies` dictionary, keyed by the current filename. If a `base_name` is provided (indicating it's part of a larger import resolution), that name is added; otherwise, the direct alias name is used. It ensures that the `import_dependencies` dictionary is initialized for the current file.",
              "parameters": [
                {
                  "name": "node",
                  "type": "Import | ImportFrom",
                  "description": "The AST node representing an import statement."
                },
                {
                  "name": "base_name",
                  "type": "str | None",
                  "description": "An optional base name to add to the dependencies, typically used when resolving parts of a larger import."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls `self.generic_visit(node)` to continue AST traversal.",
                "called_by": "This method is called by `visit_ImportFrom` and potentially directly if `visit_Import` were to be called from elsewhere."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_ImportFrom",
            "description": {
              "overall": "This method specifically handles `from ... import ...` statements. It first extracts the module name from the import statement. If the module name is direct (e.g., `from os import path`), it calls `visit_Import` with the last part of the module name. If it's a relative import (e.g., `from ..utils import helper`), it attempts to resolve the module using `_resolve_module_name` and then calls `visit_Import` for each resolved part. It includes error handling for failed relative import resolutions.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ImportFrom",
                  "description": "The AST node representing a 'from ... import ...' statement."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls `self._resolve_module_name(node)` for relative imports and `self.visit_Import` to record dependencies. It also calls `self.generic_visit(node)` to continue AST traversal.",
                "called_by": "This method is called by the AST visitor when it encounters an `ImportFrom` node."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "This class depends on several functions from the `backend.File_Dependency` module, specifically `get_all_temp_files`, `init_exports_symbol`, and `module_file_exists`, which are used for resolving file paths and import logic.",
          "instantiated_by": "This class is not explicitly shown to be instantiated by any other code within the provided context."
        }
      },
      "error": null
    },
    "backend.HelperLLM.LLMHelper": {
      "identifier": "backend.HelperLLM.LLMHelper",
      "description": {
        "overall": "The LLMHelper class is designed to facilitate the generation and validation of documentation for code elements like functions and classes using large language models (LLMs). It centralizes the interaction with various LLM providers (Google Gemini, OpenAI, Ollama) by abstracting away the specific API calls and configurations. The class handles prompt management, batch processing for efficiency, rate limiting, and structured output generation using Pydantic models for validation. It dynamically configures LLM clients based on the provided model name and supports custom API endpoints.",
        "init_method": {
          "description": "Initializes the LLMHelper with necessary API keys, prompt file paths, and LLM configurations. It reads system prompts from specified files, sets up the LLM client based on the model name (supporting Gemini, OpenAI, and Ollama), configures batch processing settings, and prepares specialized LLM instances for function and class documentation generation with structured output.",
          "parameters": [
            {
              "name": "api_key",
              "type": "str",
              "description": "The API key required for authenticating with the LLM service."
            },
            {
              "name": "function_prompt_path",
              "type": "str",
              "description": "The file path to the system prompt template for function documentation generation."
            },
            {
              "name": "class_prompt_path",
              "type": "str",
              "description": "The file path to the system prompt template for class documentation generation."
            },
            {
              "name": "model_name",
              "type": "str",
              "description": "The name of the LLM model to use. Defaults to 'gemini-2.0-flash-lite'."
            },
            {
              "name": "base_url",
              "type": "str",
              "description": "An optional base URL for custom LLM API endpoints, used if not using default Ollama or OpenAI configurations."
            }
          ]
        },
        "methods": [
          {
            "identifier": "_configure_batch_settings",
            "description": {
              "overall": "This private method configures the batch size for LLM API calls based on the specified model name. It defines different batch sizes for various LLM models, including Gemini and OpenAI variants, and sets a conservative default batch size for unknown models. This helps in optimizing API usage and respecting rate limits.",
              "parameters": [
                {
                  "name": "self",
                  "type": "LLMHelper",
                  "description": "The instance of the LLMHelper class."
                },
                {
                  "name": "model_name",
                  "type": "str",
                  "description": "The name of the LLM model for which to configure batch settings."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method is called internally by the __init__ method to set the batch size based on the selected LLM model.",
                "called_by": "This method is called by the __init__ method."
              }
            },
            "error": null
          },
          {
            "identifier": "generate_for_functions",
            "description": {
              "overall": "Generates and validates documentation for a list of function inputs using the configured LLM. It processes inputs in batches according to the `batch_size` attribute, constructs conversation prompts with system and human messages, and calls the LLM API in parallel using `self.function_llm.batch`. It includes error handling for API calls and implements a waiting period between batches to manage rate limits, returning a list of validated function analyses or None for failed batches.",
              "parameters": [
                {
                  "name": "self",
                  "type": "LLMHelper",
                  "description": "The instance of the LLMHelper class."
                },
                {
                  "name": "function_inputs",
                  "type": "List[FunctionAnalysisInput]",
                  "description": "A list of FunctionAnalysisInput objects, each containing the necessary information to generate documentation for a function."
                }
              ],
              "returns": [
                {
                  "name": "all_validated_functions",
                  "type": "List[Optional[FunctionAnalysis]]",
                  "description": "A list containing the generated FunctionAnalysis objects for each input, or None if an error occurred during processing for that specific input."
                }
              ],
              "usage_context": {
                "calls": "This method calls json.dumps to serialize input data, constructs SystemMessage and HumanMessage objects for conversation, and utilizes the self.function_llm.batch method to interact with the LLM API, along with time.sleep for rate limiting.",
                "called_by": "This method is intended to be called by external code that needs to generate documentation for multiple functions."
              }
            },
            "error": null
          },
          {
            "identifier": "generate_for_classes",
            "description": {
              "overall": "Generates and validates documentation for a list of class inputs using the configured LLM. Similar to `generate_for_functions`, it processes inputs in batches, constructs conversation prompts, and uses `self.class_llm.batch` for parallel LLM API calls. It handles potential exceptions during API calls by returning None for failed items and enforces a waiting period between batches to comply with rate limits, ultimately returning a list of validated class analyses.",
              "parameters": [
                {
                  "name": "self",
                  "type": "LLMHelper",
                  "description": "The instance of the LLMHelper class."
                },
                {
                  "name": "class_inputs",
                  "type": "List[ClassAnalysisInput]",
                  "description": "A list of ClassAnalysisInput objects, each containing the necessary information to generate documentation for a class."
                }
              ],
              "returns": [
                {
                  "name": "all_validated_classes",
                  "type": "List[Optional[ClassAnalysis]]",
                  "description": "A list containing the generated ClassAnalysis objects for each input, or None if an error occurred during processing for that specific input."
                }
              ],
              "usage_context": {
                "calls": "This method calls json.dumps to serialize input data, constructs SystemMessage and HumanMessage objects for conversation, and utilizes the self.class_llm.batch method to interact with the LLM API, along with time.sleep for rate limiting.",
                "called_by": "This method is intended to be called by external code that needs to generate documentation for multiple classes."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "This class depends on several external libraries for LLM interaction and data handling, including `langchain-google-genai`, `langchain-ollama`, `langchain-openai`, `pydantic`, `json`, `logging`, and `time`. It also relies on specific schema types like `FunctionAnalysis`, `ClassAnalysis`, `FunctionAnalysisInput`, and `ClassAnalysisInput` from a `schemas.types` module, and potentially environment variables like `SCADSLLM_URL` and `OLLAMA_BASE_URL`.",
          "instantiated_by": "The `LLMHelper` class is instantiated by code that requires centralized LLM-based documentation generation. Specific instances of its instantiation are not detailed in the provided source code, but it would typically be used in a backend service or a documentation generation pipeline."
        }
      },
      "error": null
    },
    "backend.MainLLM.MainLLM": {
      "identifier": "backend.MainLLM.MainLLM",
      "description": {
        "overall": "The MainLLM class serves as a central orchestrator for interacting with various Large Language Models (LLMs). It handles the initialization of different LLM clients based on provided configuration, such as API keys and model names, and provides methods to invoke or stream responses from these models. The class abstracts away the complexities of setting up different LLM providers like Google Generative AI, Ollama, or custom OpenAI-compatible endpoints.",
        "init_method": {
          "description": "Initializes the MainLLM class by setting up the LLM client. It validates the API key, reads a system prompt from a specified file, and configures the appropriate LLM client (ChatGoogleGenerativeAI, ChatOpenAI, or ChatOllama) based on the provided model name and optional base URL. It logs the initialization process and any potential errors, such as a missing API key or prompt file.",
          "parameters": [
            {
              "name": "api_key",
              "type": "str",
              "description": "The API key required for authenticating with the LLM service."
            },
            {
              "name": "prompt_file_path",
              "type": "str",
              "description": "The file path to the system prompt that will be used for all LLM interactions."
            },
            {
              "name": "model_name",
              "type": "str",
              "description": "The name of the LLM model to use. Defaults to 'gemini-2.5-pro'."
            },
            {
              "name": "base_url",
              "type": "str",
              "description": "An optional base URL for custom LLM endpoints. If not provided, it defaults to OLLAMA_BASE_URL for Ollama models."
            }
          ]
        },
        "methods": [
          {
            "identifier": "call_llm",
            "description": {
              "overall": "Invokes the configured LLM with a user-provided input and returns the model's response. It constructs a list of messages including the system prompt and the user's input, then uses the LLM client's invoke method to get a single response. The method logs the process and handles potential exceptions during the LLM call, returning the content of the response or None if an error occurs.",
              "parameters": [
                {
                  "name": "user_input",
                  "type": "str",
                  "description": "The input string provided by the user to be sent to the LLM."
                }
              ],
              "returns": [
                {
                  "name": "response.content",
                  "type": "str",
                  "description": "The text content of the LLM's response, or None if an error occurred."
                }
              ],
              "usage_context": {
                "calls": "This method calls the 'invoke' method of the underlying LLM client and logs information.",
                "called_by": "This method is called to get a direct response from the LLM."
              }
            },
            "error": null
          },
          {
            "identifier": "stream_llm",
            "description": {
              "overall": "Initiates a streaming response from the configured LLM based on user input. Similar to `call_llm`, it prepares messages including the system prompt and user input. It then uses the LLM client's `stream` method to get an iterator of response chunks. The method yields each chunk's content as it becomes available, logging any errors encountered during the streaming process and yielding an error message if an exception occurs.",
              "parameters": [
                {
                  "name": "user_input",
                  "type": "str",
                  "description": "The input string provided by the user to be sent to the LLM for streaming."
                }
              ],
              "returns": [
                {
                  "name": "chunk.content",
                  "type": "str",
                  "description": "Yields chunks of text content from the LLM's streaming response, or an error message if an exception occurs."
                }
              ],
              "usage_context": {
                "calls": "This method calls the 'stream' method of the underlying LLM client and logs information.",
                "called_by": "This method is called to receive a streaming response from the LLM."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "This class utilizes several external libraries for LLM interaction, including `langchain_google_genai`, `langchain_ollama`, `langchain_openai`, and `langchain.messages`. It also relies on environment variables like `SCADSLLM_URL` and `OLLAMA_BASE_URL`, and potentially `dotenv` for loading them.",
          "instantiated_by": "The context does not specify where this class is instantiated."
        }
      },
      "error": null
    },
    "backend.basic_info.ProjektInfoExtractor": {
      "identifier": "backend.basic_info.ProjektInfoExtractor",
      "description": {
        "overall": "The ProjektInfoExtractor class is designed to extract fundamental project information from common project files such as README, pyproject.toml, and requirements.txt. It initializes a structured dictionary to hold project overview and installation details, populating it by parsing these files. The class prioritizes information from pyproject.toml for dependencies and title, then falls back to requirements.txt for dependencies, and finally uses README for a broader range of project details like title, description, features, tech stack, status, and setup instructions. It also derives the project title from the repository URL if no other title is found.",
        "init_method": {
          "description": "Initializes the ProjektInfoExtractor by setting up a default structure for project information. This structure includes placeholders for project overview (title, description, status, key features, tech stack) and installation details (dependencies, setup instructions, quick start guide). It defines a constant `INFO_NICHT_GEFUNDEN` to represent missing information.",
          "parameters": []
        },
        "methods": [
          {
            "identifier": "_clean_content",
            "description": {
              "overall": "This method cleans the input string content by removing null bytes (`\\x00`). These null bytes can occur due to encoding errors, such as when UTF-16 encoded data is incorrectly read as UTF-8. It ensures that the content is clean before further processing.",
              "parameters": [
                {
                  "name": "content",
                  "type": "str",
                  "description": "The string content to be cleaned."
                }
              ],
              "returns": [
                {
                  "name": "cleaned_content",
                  "type": "str",
                  "description": "The cleaned string content with null bytes removed."
                }
              ],
              "usage_context": {
                "calls": "This method is called by other internal methods to clean file content before parsing.",
                "called_by": "This method is called by _parse_readme, _parse_toml, and _parse_requirements."
              }
            },
            "error": null
          },
          {
            "identifier": "_finde_datei",
            "description": {
              "overall": "This method searches through a list of provided file objects to find a file that matches one of the given patterns. The search is case-insensitive and checks if the file's path ends with any of the specified patterns. It's useful for locating specific project files like README or pyproject.toml.",
              "parameters": [
                {
                  "name": "patterns",
                  "type": "List[str]",
                  "description": "A list of file name patterns (e.g., 'readme.md', 'pyproject.toml') to search for."
                },
                {
                  "name": "dateien",
                  "type": "List[Any]",
                  "description": "A list of file objects, where each object is expected to have a 'path' attribute."
                }
              ],
              "returns": [
                {
                  "name": "found_file",
                  "type": "Optional[Any]",
                  "description": "The first file object that matches any of the patterns, or None if no match is found."
                }
              ],
              "usage_context": {
                "calls": "This method iterates through provided file objects and patterns to find a match.",
                "called_by": "This method is called by extrahiere_info to locate specific project files."
              }
            },
            "error": null
          },
          {
            "identifier": "_extrahiere_sektion_aus_markdown",
            "description": {
              "overall": "This method extracts a specific section of text from a Markdown content string. It looks for a section preceded by a level 2 heading (##) that matches one of the provided keywords. The content between the matched heading and the next level 2 heading or the end of the file is returned. This is useful for parsing structured information within README files.",
              "parameters": [
                {
                  "name": "inhalt",
                  "type": "str",
                  "description": "The Markdown content from which to extract a section."
                },
                {
                  "name": "keywords",
                  "type": "List[str]",
                  "description": "A list of keywords that identify the desired section's heading."
                }
              ],
              "returns": [
                {
                  "name": "section_content",
                  "type": "Optional[str]",
                  "description": "The extracted and stripped content of the section, or None if the section is not found."
                }
              ],
              "usage_context": {
                "calls": "This method uses regular expressions to search for specific Markdown headings and capture content.",
                "called_by": "This method is called by _parse_readme to extract specific sections like 'Features', 'Tech Stack', 'Status', 'Installation', and 'Quick Start'."
              }
            },
            "error": null
          },
          {
            "identifier": "_parse_readme",
            "description": {
              "overall": "This method parses the content of a README file to extract various project details. It first cleans the content to remove null bytes. Then, it attempts to extract the project title from the main heading, a description from the text following the title, and specific sections like 'Key Features', 'Tech Stack', 'Status', 'Installation', and 'Quick Start' using the `_extrahiere_sektion_aus_markdown` helper method. It updates the class's internal `self.info` dictionary with the extracted information.",
              "parameters": [
                {
                  "name": "inhalt",
                  "type": "str",
                  "description": "The content of the README file."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls _clean_content to sanitize input and _extrahiere_sektion_aus_markdown to parse specific sections. It also uses regular expressions to find the title and an initial description.",
                "called_by": "This method is called by extrahiere_info after a README file has been located."
              }
            },
            "error": null
          },
          {
            "identifier": "_parse_toml",
            "description": {
              "overall": "This method parses the content of a `pyproject.toml` file using the `tomllib` library. It extracts project name, description, and dependencies if they are present in the `[project]` section of the TOML data. It includes a warning if `tomllib` is not available and handles potential `TOMLDecodeError` exceptions during parsing. The extracted information is used to update the class's internal `self.info` dictionary.",
              "parameters": [
                {
                  "name": "inhalt",
                  "type": "str",
                  "description": "The content of the pyproject.toml file."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls _clean_content to sanitize input and uses the `tomllib.loads` function to parse the TOML content.",
                "called_by": "This method is called by extrahiere_info after a pyproject.toml file has been located."
              }
            },
            "error": null
          },
          {
            "identifier": "_parse_requirements",
            "description": {
              "overall": "This method parses the content of a `requirements.txt` file to extract project dependencies. It cleans the content and then splits it into lines, filtering out empty lines and comments (lines starting with '#'). The extracted dependencies are stored in the `self.info['installation']['dependencies']` field, but only if dependencies were not already found and populated from a `pyproject.toml` file. This ensures that `pyproject.toml` has a higher priority for dependency information.",
              "parameters": [
                {
                  "name": "inhalt",
                  "type": "str",
                  "description": "The content of the requirements.txt file."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls _clean_content to sanitize input and then processes the content line by line.",
                "called_by": "This method is called by extrahiere_info after a requirements.txt file has been located."
              }
            },
            "error": null
          },
          {
            "identifier": "extrahiere_info",
            "description": {
              "overall": "This is the main orchestrating method of the `ProjektInfoExtractor` class. It takes a list of file objects and a repository URL as input. It first uses `_finde_datei` to locate `README`, `pyproject.toml`, and `requirements.txt` files. It then parses these files in a specific order: `pyproject.toml` first for project details and dependencies, then `requirements.txt` for dependencies (if not already found), and finally `README.md` for remaining project overview and installation details. After parsing, it formats the dependencies into a readable string and attempts to derive the project title from the repository URL if no title was found. Finally, it returns the populated `self.info` dictionary containing all extracted project information.",
              "parameters": [
                {
                  "name": "dateien",
                  "type": "List[Any]",
                  "description": "A list of file objects, each expected to have 'path' and 'content' attributes, representing files in the repository."
                },
                {
                  "name": "repo_url",
                  "type": "str",
                  "description": "The URL of the repository, used to derive the project title if necessary."
                }
              ],
              "returns": [
                {
                  "name": "info",
                  "type": "Dict[str, Any]",
                  "description": "A dictionary containing the extracted project overview and installation information."
                }
              ],
              "usage_context": {
                "calls": "This method calls _finde_datei multiple times to locate relevant files, and then calls _parse_toml, _parse_requirements, and _parse_readme to process their content. It also uses os.path.basename for URL processing.",
                "called_by": "This is the primary public method of the class, intended to be called by external systems to extract project information."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "This class utilizes the 're' module for regular expression operations, 'os' for path manipulation, and 'tomllib' for parsing TOML files. It also uses type hinting from the 'typing' module.",
          "instantiated_by": "This class is instantiated by external systems or scripts that need to extract project metadata from source code repositories."
        }
      },
      "error": null
    },
    "backend.callgraph.CallGraph": {
      "identifier": "backend.callgraph.CallGraph",
      "description": {
        "overall": "The CallGraph class is designed to analyze Python source code and build a call graph. It inherits from `ast.NodeVisitor` to traverse the Abstract Syntax Tree (AST) of a given Python file. The class maintains internal state to track the current file, function, and class being visited, along with mappings for imports and local definitions. It constructs a directed graph (`networkx.DiGraph`) representing function calls and their relationships, enabling the visualization and analysis of code structure and dependencies.",
        "init_method": {
          "description": "Initializes the CallGraph object with the filename of the Python source code to be analyzed. It sets up various internal data structures to store information during the AST traversal, including the current scope (function and class), mappings for imported modules, a set of all functions found, and a dictionary to store the call graph edges.",
          "parameters": [
            {
              "name": "filename",
              "type": "str",
              "description": "The path to the Python file for which the call graph is to be generated."
            }
          ]
        },
        "methods": [
          {
            "identifier": "_recursive_call",
            "description": {
              "overall": "This private helper method recursively traverses an AST node representing a function call to extract the name components of the callee. It handles different AST node types like `ast.Call`, `ast.Name`, and `ast.Attribute` to reconstruct the fully qualified name of the called function or method as a list of strings. This is crucial for resolving call targets within the source code.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.Call | ast.Name | ast.Attribute",
                  "description": "The AST node to process, representing a function call or a part of it."
                }
              ],
              "returns": [
                {
                  "name": "parts",
                  "type": "list[str]",
                  "description": "A list of strings representing the name components of the callee, e.g., ['module', 'Class', 'method']."
                }
              ],
              "usage_context": {
                "calls": "This method calls itself recursively to handle nested call structures and `ast.Attribute` nodes.",
                "called_by": "This method is called by `_resolve_all_callee_names` to parse the structure of a callee's name."
              }
            },
            "error": null
          },
          {
            "identifier": "_resolve_all_callee_names",
            "description": {
              "overall": "This method takes a list of potential callee name components (obtained from `_recursive_call`) and resolves them into fully qualified names. It prioritizes checking against locally defined functions and classes first, then consults the `import_mapping` to resolve imported modules. If a name cannot be resolved through local definitions or imports, it constructs a name relative to the current filename and class context. This ensures that calls are accurately mapped within the project's structure.",
              "parameters": [
                {
                  "name": "callee_nodes",
                  "type": "list[list[str]]",
                  "description": "A list where each element is a list of strings representing the name components of a potential callee."
                }
              ],
              "returns": [
                {
                  "name": "resolved",
                  "type": "list[str]",
                  "description": "A list of fully resolved callee names as strings."
                }
              ],
              "usage_context": {
                "calls": "This method calls `_recursive_call` indirectly through its input and uses string manipulation for name construction.",
                "called_by": "This method is called by `visit_Call` to determine the actual target of a function call."
              }
            },
            "error": null
          },
          {
            "identifier": "_make_full_name",
            "description": {
              "overall": "A utility method to construct a fully qualified name for a function or method within the context of the analyzed file. It prepends the filename and optionally includes the class name if provided, ensuring a unique identifier for each callable entity.",
              "parameters": [
                {
                  "name": "basename",
                  "type": "str",
                  "description": "The base name of the function or method."
                },
                {
                  "name": "class_name",
                  "type": "str | None",
                  "description": "The name of the class if the function is a method; otherwise, None."
                }
              ],
              "returns": [
                {
                  "name": "full_name",
                  "type": "str",
                  "description": "The complete, qualified name of the function or method."
                }
              ],
              "usage_context": {
                "calls": "This method uses string formatting.",
                "called_by": "This method is called by `visit_FunctionDef` to generate unique identifiers for functions and methods."
              }
            },
            "error": null
          },
          {
            "identifier": "_current_caller",
            "description": {
              "overall": "Determines the identifier for the current scope that is making a call. If `self.current_function` is set, it returns that value. Otherwise, it returns a string representing the global scope of the file, or '<global-scope>' if the filename is not available.",
              "parameters": [
                {
                  "name": "self",
                  "type": "CallGraph",
                  "description": "The instance of the CallGraph class."
                }
              ],
              "returns": [
                {
                  "name": "caller",
                  "type": "str",
                  "description": "The identifier of the current calling scope."
                }
              ],
              "usage_context": {
                "calls": "This method accesses instance attributes `self.current_function` and `self.filename`.",
                "called_by": "This method is called by `visit_Call` to identify the source of a function call."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_Import",
            "description": {
              "overall": "Visits an `ast.Import` node to process import statements. It extracts the module name and any aliases, storing them in the `self.import_mapping` dictionary. This mapping is later used to resolve names of imported modules when analyzing calls.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.Import",
                  "description": "The AST node representing an import statement."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls `self.generic_visit(node)` to continue AST traversal.",
                "called_by": "This method is automatically called by `ast.NodeVisitor` when an `ast.Import` node is encountered during tree traversal."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_ImportFrom",
            "description": {
              "overall": "Visits an `ast.ImportFrom` node to process `from ... import ...` statements. It extracts the module name (or the last part of it if it's a submodule) and the imported names (or their aliases), storing them in `self.import_mapping`. This helps in tracking which names are imported from which modules.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.ImportFrom",
                  "description": "The AST node representing a 'from ... import ...' statement."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method uses string manipulation to extract module names and accesses `self.import_mapping`.",
                "called_by": "This method is automatically called by `ast.NodeVisitor` when an `ast.ImportFrom` node is encountered during tree traversal."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_ClassDef",
            "description": {
              "overall": "Visits an `ast.ClassDef` node to process class definitions. It updates `self.current_class` to the name of the class being visited, allowing subsequent methods to know they are within a class scope. After visiting the class body, it restores `self.current_class` to its previous value to correctly handle nested classes or functions outside of classes.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.ClassDef",
                  "description": "The AST node representing a class definition."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls `self.generic_visit(node)` to process the body of the class definition and updates instance attributes `self.current_class`.",
                "called_by": "This method is automatically called by `ast.NodeVisitor` when an `ast.ClassDef` node is encountered during tree traversal."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_FunctionDef",
            "description": {
              "overall": "Visits an `ast.FunctionDef` node to process function definitions. It constructs a full name for the function using `_make_full_name`, stores this name in `self.local_defs` for both the function's base name and its qualified name (if within a class), and sets `self.current_function` to this full name. It then adds the function as a node to the graph and recursively visits the function's body. Finally, it adds the function to `self.function_set` and restores the `self.current_function` context.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.FunctionDef",
                  "description": "The AST node representing a function definition."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls `self._make_full_name`, `self._current_caller`, `self.graph.add_node`, and `self.generic_visit(node)`. It also updates instance attributes like `self.local_defs`, `self.current_function`, and `self.function_set`.",
                "called_by": "This method is automatically called by `ast.NodeVisitor` when an `ast.FunctionDef` node is encountered during tree traversal."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_AsyncFunctionDef",
            "description": {
              "overall": "Visits an `ast.AsyncFunctionDef` node, which represents an asynchronous function definition. This method simply delegates the processing to `visit_FunctionDef`, as the logic for handling function definitions is the same for both synchronous and asynchronous functions in this context.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.AsyncFunctionDef",
                  "description": "The AST node representing an asynchronous function definition."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls `self.visit_FunctionDef(node)`.",
                "called_by": "This method is automatically called by `ast.NodeVisitor` when an `ast.AsyncFunctionDef` node is encountered during tree traversal."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_Call",
            "description": {
              "overall": "Visits an `ast.Call` node to process function or method calls. It determines the current caller using `_current_caller`, extracts the callee's name components using `_recursive_call`, and resolves these components into fully qualified names using `_resolve_all_callee_names`. It then records the call relationship by adding an edge from the caller to each resolved callee in the `self.edges` dictionary. Finally, it continues the AST traversal.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.Call",
                  "description": "The AST node representing a function or method call."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls `self._current_caller`, `self._recursive_call`, `self._resolve_all_callee_names`, and `self.generic_visit(node)`. It also updates `self.edges`.",
                "called_by": "This method is automatically called by `ast.NodeVisitor` when an `ast.Call` node is encountered during tree traversal."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_If",
            "description": {
              "overall": "Visits an `ast.If` node to handle conditional statements. It specifically checks if the condition is a comparison involving the special variable `__name__` (commonly used for script entry points). If it is, it temporarily sets the `self.current_function` to '<main_block>' to correctly attribute any code within that block to the main execution scope. After visiting the `if` block's children, it restores the `self.current_function` to its previous state. Otherwise, it simply proceeds with the generic visit.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.If",
                  "description": "The AST node representing an if statement."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls `self.generic_visit(node)` and accesses instance attributes `self.current_function` and `self.filename`.",
                "called_by": "This method is automatically called by `ast.NodeVisitor` when an `ast.If` node is encountered during tree traversal."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "This class utilizes the `ast` module for parsing Python code and the `networkx` library for graph manipulation. It also implicitly relies on Python's built-in types and the `typing` module for type hints.",
          "instantiated_by": "The `CallGraph` class is instantiated within the backend's callgraph module, likely by a higher-level analysis or orchestration component that provides it with a filename to process."
        }
      },
      "error": null
    },
    "backend.getRepo.RepoFile": {
      "identifier": "backend.getRepo.RepoFile",
      "description": {
        "overall": "The RepoFile class represents a single file within a Git repository. It is designed to load file content and metadata lazily, meaning that information like the file's blob, content, and size are only fetched when they are explicitly accessed. This class provides methods to access file properties, analyze its content (e.g., word count), and represent the file as a dictionary.",
        "init_method": {
          "description": "Initializes a RepoFile object with the file's path and the commit tree it belongs to. It sets up internal attributes to store the path and the commit tree, and initializes placeholders for the blob, content, and size, which will be loaded lazily upon first access.",
          "parameters": [
            {
              "name": "file_path",
              "type": "str",
              "description": "The path to the file within the repository."
            },
            {
              "name": "commit_tree",
              "type": "git.Tree",
              "description": "The Tree object of the commit from which the file originates."
            }
          ]
        },
        "methods": [
          {
            "identifier": "blob",
            "description": {
              "overall": "This property lazily loads and returns the Git blob object associated with the file. If the blob has not been loaded yet, it attempts to retrieve it from the commit tree using the file's path. If the file is not found in the tree, a FileNotFoundError is raised. Once loaded, the blob object is cached for subsequent accesses.",
              "parameters": [],
              "returns": [
                {
                  "name": "self._blob",
                  "type": "git.Blob",
                  "description": "The Git blob object representing the file."
                }
              ],
              "usage_context": {
                "calls": "This method is called by other methods within the RepoFile class to access the file's blob object.",
                "called_by": "This method is called by the 'content' and 'size' properties, and potentially by other methods that require direct access to the file's blob."
              }
            },
            "error": null
          },
          {
            "identifier": "content",
            "description": {
              "overall": "This property lazily loads and returns the decoded content of the file. It first retrieves the file's blob object using the 'blob' property. If the content has not been loaded yet, it reads the data from the blob's data stream, decodes it as UTF-8 (ignoring errors), and caches it. This ensures that the file content is only read and decoded when it's actually needed.",
              "parameters": [],
              "returns": [
                {
                  "name": "self._content",
                  "type": "str",
                  "description": "The decoded content of the file as a string."
                }
              ],
              "usage_context": {
                "calls": "This method calls the 'blob' property to get the file's Git blob object and then accesses its data_stream to read and decode the content.",
                "called_by": "This method is called when the file's content is accessed, for example, in the 'analyze_word_count' method or when 'include_content' is set to True in the 'to_dict' method."
              }
            },
            "error": null
          },
          {
            "identifier": "size",
            "description": {
              "overall": "This property lazily loads and returns the size of the file in bytes. It first retrieves the file's blob object using the 'blob' property. If the size has not been determined yet, it accesses the 'size' attribute of the blob object and caches the result. This ensures that the file size is only fetched when it is required.",
              "parameters": [],
              "returns": [
                {
                  "name": "self._size",
                  "type": "int",
                  "description": "The size of the file in bytes."
                }
              ],
              "usage_context": {
                "calls": "This method calls the 'blob' property to obtain the Git blob object and then accesses its 'size' attribute.",
                "called_by": "This method is called when the file's size is needed, such as in the 'to_dict' method."
              }
            },
            "error": null
          },
          {
            "identifier": "analyze_word_count",
            "description": {
              "overall": "This method provides a sample analysis by counting the number of words present in the file's content. It accesses the file's content using the 'content' property, splits the content into words based on whitespace, and returns the total count of these words. This serves as an example of how file content can be processed for analysis.",
              "parameters": [],
              "returns": [
                {
                  "name": "word_count",
                  "type": "int",
                  "description": "The total number of words found in the file's content."
                }
              ],
              "usage_context": {
                "calls": "This method calls the 'content' property to retrieve the file's content and then uses the string split() method.",
                "called_by": "This method is called when a word count analysis of the file is required."
              }
            },
            "error": null
          },
          {
            "identifier": "__repr__",
            "description": {
              "overall": "This method provides a developer-friendly string representation of the RepoFile object. It returns a formatted string that includes the class name and the file's path, making it easy to identify the object when debugging or inspecting it.",
              "parameters": [],
              "returns": [
                {
                  "name": "representation",
                  "type": "str",
                  "description": "A string representation of the RepoFile object, e.g., '<RepoFile(path='...')>'."
                }
              ],
              "usage_context": {
                "calls": "This method uses an f-string for formatting and accesses the 'self.path' attribute.",
                "called_by": "This method is called implicitly when the object is printed, logged, or inspected in an interactive session."
              }
            },
            "error": null
          },
          {
            "identifier": "to_dict",
            "description": {
              "overall": "This method converts the RepoFile object into a dictionary representation. It includes basic file information such as path, name (derived from the path), size, and type. Optionally, if the 'include_content' flag is set to True, it also includes the file's content in the dictionary. This method is useful for serializing file information.",
              "parameters": [
                {
                  "name": "include_content",
                  "type": "bool",
                  "description": "A flag to indicate whether to include the file's content in the dictionary output. Defaults to False."
                }
              ],
              "returns": [
                {
                  "name": "data",
                  "type": "dict",
                  "description": "A dictionary containing the file's metadata and optionally its content."
                }
              ],
              "usage_context": {
                "calls": "This method calls the 'os.path.basename' function, and accesses 'self.path', 'self.size', and conditionally 'self.content'.",
                "called_by": "This method is called when a dictionary representation of the file object is needed, potentially for data serialization or API responses."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "The class utilizes the 'os' module for path manipulation, specifically 'os.path.basename'. It also interacts with objects from the 'git' library, such as 'git.Tree' and 'git.Blob', for repository file operations.",
          "instantiated_by": "This class is instantiated to represent individual files within a Git repository, likely as part of a larger system that processes or analyzes repository contents."
        }
      },
      "error": null
    },
    "backend.getRepo.GitRepository": {
      "identifier": "backend.getRepo.GitRepository",
      "description": {
        "overall": "The GitRepository class manages a Git repository, handling its cloning into a temporary directory and providing access to its files. It facilitates operations like retrieving all files and constructing a hierarchical file tree, ensuring proper cleanup of temporary resources.",
        "init_method": {
          "description": "Initializes the GitRepository by storing the repository URL, creating a temporary directory, and cloning the repository into it. It also attempts to capture the latest commit and its tree, handling potential Git command errors by cleaning up and raising a RuntimeError.",
          "parameters": [
            {
              "name": "repo_url",
              "type": "string",
              "description": "The URL of the Git repository to be cloned."
            }
          ]
        },
        "methods": [
          {
            "identifier": "get_all_files",
            "description": {
              "overall": "Retrieves all files within the cloned Git repository. It uses the `ls_files` Git command to get a list of file paths, then processes these paths to create `RepoFile` objects. These objects are stored internally and returned as a list, representing all files in the repository at the current commit.",
              "parameters": [
                {
                  "name": "self",
                  "type": "GitRepository",
                  "description": "The instance of the GitRepository class."
                }
              ],
              "returns": [
                {
                  "name": "files",
                  "type": "list[RepoFile]",
                  "description": "A list containing RepoFile objects, each representing a file in the repository."
                }
              ],
              "usage_context": {
                "calls": "This method calls the `RepoFile` constructor to create file objects.",
                "called_by": "This method is called by `get_file_tree` if no files have been loaded yet."
              }
            },
            "error": null
          },
          {
            "identifier": "close",
            "description": {
              "overall": "Cleans up the resources used by the GitRepository instance. Specifically, it deletes the temporary directory that was created during initialization to store the cloned repository. This method ensures that no temporary files are left behind after the repository is no longer needed.",
              "parameters": [
                {
                  "name": "self",
                  "type": "GitRepository",
                  "description": "The instance of the GitRepository class."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method does not call any other methods or functions.",
                "called_by": "This method is called by the `__init__` method in case of an error during cloning and by the `__exit__` method to ensure cleanup."
              }
            },
            "error": null
          },
          {
            "identifier": "__enter__",
            "description": {
              "overall": "Implements the context management protocol's entry point. It allows the `GitRepository` object to be used within a `with` statement, returning the instance itself for use within the `with` block.",
              "parameters": [
                {
                  "name": "self",
                  "type": "GitRepository",
                  "description": "The instance of the GitRepository class."
                }
              ],
              "returns": [
                {
                  "name": "self",
                  "type": "GitRepository",
                  "description": "The current GitRepository instance."
                }
              ],
              "usage_context": {
                "calls": "This method does not call any other methods or functions.",
                "called_by": "This method is called implicitly when entering a `with` statement with a GitRepository object."
              }
            },
            "error": null
          },
          {
            "identifier": "__exit__",
            "description": {
              "overall": "Implements the context management protocol's exit point. It is automatically called when exiting a `with` statement, ensuring that the `close` method is invoked to clean up any temporary resources, such as the cloned repository directory.",
              "parameters": [
                {
                  "name": "self",
                  "type": "GitRepository",
                  "description": "The instance of the GitRepository class."
                },
                {
                  "name": "exc_type",
                  "type": "type",
                  "description": "The type of the exception raised within the `with` block, if any."
                },
                {
                  "name": "exc_val",
                  "type": "Exception",
                  "description": "The exception instance raised within the `with` block, if any."
                },
                {
                  "name": "exc_tb",
                  "type": "traceback",
                  "description": "The traceback object associated with the exception, if any."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls the `close` method of the GitRepository instance.",
                "called_by": "This method is called implicitly when exiting a `with` statement that uses a GitRepository object."
              }
            },
            "error": null
          },
          {
            "identifier": "get_file_tree",
            "description": {
              "overall": "Constructs and returns a hierarchical tree structure representing the files and directories within the repository. If files have not yet been loaded, it first calls `get_all_files`. It then iterates through each file, parsing its path to build a nested dictionary structure that mirrors the repository's organization. Optionally, file content can be included in the dictionary representation.",
              "parameters": [
                {
                  "name": "self",
                  "type": "GitRepository",
                  "description": "The instance of the GitRepository class."
                },
                {
                  "name": "include_content",
                  "type": "bool",
                  "description": "A boolean flag indicating whether to include the content of each file in the tree structure. Defaults to False."
                }
              ],
              "returns": [
                {
                  "name": "tree",
                  "type": "dict",
                  "description": "A dictionary representing the file tree of the repository, with 'root' as the top-level key."
                }
              ],
              "usage_context": {
                "calls": "This method calls `get_all_files` if the file list is empty and `file_obj.to_dict` for each file.",
                "called_by": "This method is called to generate a structured representation of the repository's file system."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "This class depends on `backend.getRepo.RepoFile` for representing individual files and utilizes external libraries such as `tempfile` for temporary directory management, `git.Repo` for Git operations, and `logging` for information output.",
          "instantiated_by": "This class is not explicitly shown to be instantiated by any other part of the code within the provided context."
        }
      },
      "error": null
    },
    "backend.relationship_analyzer.ProjectAnalyzer": {
      "identifier": "backend.relationship_analyzer.ProjectAnalyzer",
      "description": {
        "overall": "The ProjectAnalyzer class is designed to analyze a Python project's codebase to build a call graph and identify relationships between different code elements. It traverses the project directory, parses Python files to collect definitions of functions, classes, and methods, and then resolves function calls to construct a call graph. Finally, it can provide raw relationship data in terms of outgoing and incoming calls.",
        "init_method": {
          "description": "Initializes the ProjectAnalyzer with the root directory of the project. It sets up instance variables to store project root, definitions, call graph, file ASTs, and a set of directories to ignore during the file search.",
          "parameters": [
            {
              "name": "project_root",
              "type": "string",
              "description": "The absolute path to the root directory of the Python project to be analyzed."
            }
          ]
        },
        "methods": [
          {
            "identifier": "analyze",
            "description": {
              "overall": "This method orchestrates the entire analysis process. It first finds all Python files in the project, then iterates through them to collect definitions (functions, classes, methods) and builds an Abstract Syntax Tree (AST) for each. Subsequently, it resolves function calls within these files to populate the call graph. Finally, it clears the stored ASTs to free up memory and returns the constructed call graph.",
              "parameters": [
                {
                  "name": "self",
                  "type": "ProjectAnalyzer",
                  "description": "The instance of the ProjectAnalyzer class."
                }
              ],
              "returns": [
                {
                  "name": "call_graph",
                  "type": "defaultdict(list)",
                  "description": "A dictionary representing the call graph, where keys are callee identifiers and values are lists of caller information."
                }
              ],
              "usage_context": {
                "calls": "This method calls _find_py_files to get a list of Python files, then iterates through them calling _collect_definitions and _resolve_calls.",
                "called_by": "This method is the primary entry point for initiating the analysis of a project."
              }
            },
            "error": null
          },
          {
            "identifier": "get_raw_relationships",
            "description": {
              "overall": "This method processes the internal call graph to generate structured data representing outgoing and incoming relationships between code elements. It iterates through the call graph, identifying callers and callees, and aggregates this information into two dictionaries: one for outgoing calls and one for incoming calls. The results are then sorted and returned.",
              "parameters": [
                {
                  "name": "self",
                  "type": "ProjectAnalyzer",
                  "description": "The instance of the ProjectAnalyzer class."
                }
              ],
              "returns": [
                {
                  "name": "relationships",
                  "type": "dict",
                  "description": "A dictionary containing two keys: 'outgoing' and 'incoming', each mapping to a dictionary of sorted lists representing call relationships."
                }
              ],
              "usage_context": {
                "calls": "This method iterates through the self.call_graph and uses defaultdict(set) to build outgoing and incoming call relationships.",
                "called_by": "This method is called after the analysis is complete to extract structured relationship data."
              }
            },
            "error": null
          },
          {
            "identifier": "_find_py_files",
            "description": {
              "overall": "This private method recursively walks through the project directory starting from `self.project_root`. It identifies all Python files (`.py`) while respecting the `self.ignore_dirs` set to exclude specific directories from the search. It returns a list of absolute file paths for all found Python files.",
              "parameters": [
                {
                  "name": "self",
                  "type": "ProjectAnalyzer",
                  "description": "The instance of the ProjectAnalyzer class."
                }
              ],
              "returns": [
                {
                  "name": "py_files",
                  "type": "list[str]",
                  "description": "A list of absolute paths to all Python files found in the project directory."
                }
              ],
              "usage_context": {
                "calls": "This method uses os.walk to traverse directories and os.path.join to construct file paths.",
                "called_by": "This method is called by the `analyze` method to locate all Python files within the project."
              }
            },
            "error": null
          },
          {
            "identifier": "_collect_definitions",
            "description": {
              "overall": "This private method parses a given Python file to collect definitions of functions, classes, and methods. It reads the source code, uses the `ast` module to build an Abstract Syntax Tree (AST), and then walks the tree to identify `ast.FunctionDef` and `ast.ClassDef` nodes. For each definition, it records its file path, line number, type (function, method, or class), and module path in the `self.definitions` dictionary. It also stores the AST in `self.file_asts` for later use and handles potential file reading or parsing errors by logging them.",
              "parameters": [
                {
                  "name": "self",
                  "type": "ProjectAnalyzer",
                  "description": "The instance of the ProjectAnalyzer class."
                },
                {
                  "name": "filepath",
                  "type": "str",
                  "description": "The path to the Python file to be analyzed."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls ast.parse to parse the source code, ast.walk to traverse the AST, _get_parent to find the parent node of a function definition, and path_to_module to convert a file path to a module path.",
                "called_by": "This method is called by the `analyze` method for each Python file found in the project to gather information about defined code elements."
              }
            },
            "error": null
          },
          {
            "identifier": "_get_parent",
            "description": {
              "overall": "This private helper method traverses the Abstract Syntax Tree (AST) of a given tree to find the direct parent node of a specified child node. It iterates through all nodes in the tree and checks their child nodes. If a child node matches the provided `node`, the current parent node is returned. If the node is not found as a child of any node, or if it's the root node, it returns None.",
              "parameters": [
                {
                  "name": "self",
                  "type": "ProjectAnalyzer",
                  "description": "The instance of the ProjectAnalyzer class."
                },
                {
                  "name": "tree",
                  "type": "ast.AST",
                  "description": "The root of the Abstract Syntax Tree to search within."
                },
                {
                  "name": "node",
                  "type": "ast.AST",
                  "description": "The child node whose parent is to be found."
                }
              ],
              "returns": [
                {
                  "name": "parent",
                  "type": "ast.AST | None",
                  "description": "The parent node of the given node, or None if the node is not found or is the root."
                }
              ],
              "usage_context": {
                "calls": "This method uses ast.walk to iterate through the tree and ast.iter_child_nodes to get the children of each node.",
                "called_by": "This method is called by `_collect_definitions` to determine if a function definition is part of a class (i.e., a method)."
              }
            },
            "error": null
          },
          {
            "identifier": "_resolve_calls",
            "description": {
              "overall": "This private method resolves function and method calls within a given Python file by leveraging a `CallResolverVisitor`. It retrieves the AST for the specified file from `self.file_asts`. If the AST exists, it instantiates `CallResolverVisitor` with the file path, project root, and collected definitions. It then visits the AST using the resolver, which populates its `calls` attribute. Finally, it merges the calls found by the resolver into the class's main `self.call_graph`, handling any exceptions during the process by logging them.",
              "parameters": [
                {
                  "name": "self",
                  "type": "ProjectAnalyzer",
                  "description": "The instance of the ProjectAnalyzer class."
                },
                {
                  "name": "filepath",
                  "type": "str",
                  "description": "The path to the Python file whose calls need to be resolved."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method instantiates and uses CallResolverVisitor to visit the AST of the given file.",
                "called_by": "This method is called by the `analyze` method for each Python file to identify and record function calls."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "This class depends on the `ast` module for parsing Python code, the `os` module for file system operations, the `logging` module for error reporting, `collections.defaultdict` for data structures, and external components `backend.relationship_analyzer.CallResolverVisitor` and `backend.relationship_analyzer.path_to_module` for specialized analysis tasks.",
          "instantiated_by": "The `ProjectAnalyzer` class is intended to be instantiated directly within the `backend.relationship_analyzer` module, likely as a primary tool for analyzing a given project directory."
        }
      },
      "error": null
    },
    "backend.relationship_analyzer.CallResolverVisitor": {
      "identifier": "backend.relationship_analyzer.CallResolverVisitor",
      "description": {
        "overall": "The CallResolverVisitor is an Abstract Syntax Tree (AST) visitor designed to traverse Python code and identify function and method calls. It maintains scope information, tracks class definitions, and resolves qualified names (QNames) of called functions and methods. This allows it to build a map of which definitions are called by which callers, along with their file and line number information. It's a crucial component for understanding code dependencies and call graphs within a project.",
        "init_method": {
          "description": "Initializes the CallResolverVisitor with essential context for analyzing a Python file. It stores the file path, determines the module path relative to the project root, and takes a collection of known definitions. It also sets up internal state for tracking scope, instance types, the current call stack, and a dictionary to store the identified calls.",
          "parameters": [
            {
              "name": "filepath",
              "type": "string",
              "description": "The absolute path to the Python file being analyzed."
            },
            {
              "name": "project_root",
              "type": "string",
              "description": "The root directory of the project, used to determine the module path."
            },
            {
              "name": "definitions",
              "type": "dict",
              "description": "A collection of known definitions within the project, likely mapping qualified names to their details."
            }
          ]
        },
        "methods": [
          {
            "identifier": "visit_ClassDef",
            "description": {
              "overall": "Visits a class definition node in the AST. It updates the `current_class_name` attribute to track the class currently being processed, ensuring that subsequent method definitions within this class are correctly associated. After visiting all child nodes (methods, etc.) within the class definition, it restores the `current_class_name` to its previous state, maintaining the correct scope.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.ClassDef",
                  "description": "The AST node representing a class definition."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls `generic_visit` to continue the traversal down the AST.",
                "called_by": "This method is called automatically by the `ast.NodeVisitor` when it encounters a class definition node."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_FunctionDef",
            "description": {
              "overall": "Visits a function definition node in the AST. It constructs the fully qualified name for the function, considering whether it's defined within a class or at the module level. It updates `current_caller_name` to this new identifier before recursively visiting the function's body. After the function's body has been processed, it restores `current_caller_name` to its previous value, ensuring correct context management.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.FunctionDef",
                  "description": "The AST node representing a function definition."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls `generic_visit` to continue the traversal down the AST.",
                "called_by": "This method is called automatically by the `ast.NodeVisitor` when it encounters a function definition node."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_Call",
            "description": {
              "overall": "Visits a call expression node in the AST. It resolves the qualified name of the called function or method using `_resolve_call_qname`. If the resolved name exists in the project's definitions, it determines the type of the caller (module, method, function, or local function) and records the call details (file, line, caller, caller type) in the `calls` dictionary. This method is central to building the call graph.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.Call",
                  "description": "The AST node representing a function or method call."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls `_resolve_call_qname` to determine the called function's name and `generic_visit` to continue the traversal.",
                "called_by": "This method is called automatically by the `ast.NodeVisitor` when it encounters a call expression node."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_Import",
            "description": {
              "overall": "Visits an import statement node in the AST. It iterates through the imported names and updates the `scope` dictionary, mapping the imported name (or its alias) to its original module name. This helps in resolving names that are directly imported into the current module's namespace.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.Import",
                  "description": "The AST node representing an import statement."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls `generic_visit` to continue the traversal down the AST.",
                "called_by": "This method is called automatically by the `ast.NodeVisitor` when it encounters an import statement node."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_ImportFrom",
            "description": {
              "overall": "Visits an 'import from' statement node in the AST. It processes imported names, constructing their fully qualified module paths based on the current module's path and the import level. These qualified names are then stored in the `scope` dictionary, mapping the imported name (or its alias) to its full path, enabling resolution of names imported from specific modules.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.ImportFrom",
                  "description": "The AST node representing an 'import from' statement."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls `generic_visit` to continue the traversal down the AST.",
                "called_by": "This method is called automatically by the `ast.NodeVisitor` when it encounters an 'import from' statement node."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_Assign",
            "description": {
              "overall": "Visits an assignment statement node in the AST. It specifically checks if the assignment involves a call to a class constructor. If so, it resolves the class name using the current scope and, if the class is a known definition, records the mapping between the variable name (the target of the assignment) and the qualified class name in the `instance_types` dictionary. This helps in tracking the types of instantiated objects.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.Assign",
                  "description": "The AST node representing an assignment statement."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls `generic_visit` to continue the traversal down the AST.",
                "called_by": "This method is called automatically by the `ast.NodeVisitor` when it encounters an assignment statement node."
              }
            },
            "error": null
          },
          {
            "identifier": "_resolve_call_qname",
            "description": {
              "overall": "A helper method to resolve the fully qualified name (QName) of a function or method call from its AST node. It handles direct name lookups in the scope and attribute access (e.g., `module.function` or `instance.method`). It uses the `scope` and `instance_types` dictionaries to determine the most accurate QName, returning `None` if the name cannot be resolved or is not found in the known definitions.",
              "parameters": [
                {
                  "name": "func_node",
                  "type": "ast.expr",
                  "description": "The AST node representing the function or method being called (e.g., ast.Name or ast.Attribute)."
                }
              ],
              "returns": [
                {
                  "name": "qualified_name",
                  "type": "string | None",
                  "description": "The fully qualified name of the function or method, or None if it cannot be resolved."
                }
              ],
              "usage_context": {
                "calls": "This method does not call other methods within the class.",
                "called_by": "This method is called by `visit_Call` to resolve the name of the function being invoked."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "This class depends on the `path_to_module` function from the `backend.relationship_analyzer` module, and utilizes standard Python libraries such as `ast` for AST traversal and `os` for path manipulation.",
          "instantiated_by": "This class is intended to be instantiated and used within a larger code analysis framework, likely as part of a process that iterates through files and collects call information. However, specific instantiation points are not detailed in the provided context."
        }
      },
      "error": null
    },
    "schemas.types.ParameterDescription": {
      "identifier": "schemas.types.ParameterDescription",
      "description": {
        "overall": "This class is a Pydantic model that serves as a data structure for describing a single parameter of a function. It encapsulates the parameter's name, its data type, and a textual description of its purpose or characteristics.",
        "init_method": {
          "description": "Initializes the ParameterDescription object with the name, type, and description of a function parameter. These attributes are directly assigned from the provided arguments.",
          "parameters": [
            {
              "name": "name",
              "type": "str",
              "description": "The name of the parameter."
            },
            {
              "name": "type",
              "type": "str",
              "description": "The data type of the parameter."
            },
            {
              "name": "description",
              "type": "str",
              "description": "A textual description of the parameter."
            }
          ]
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class depends on Pydantic's BaseModel for its structure and validation.",
          "instantiated_by": "This class is typically instantiated within systems that need to represent function or method signatures in a structured format, such as documentation generators or code analysis tools."
        }
      },
      "error": null
    },
    "schemas.types.ReturnDescription": {
      "identifier": "schemas.types.ReturnDescription",
      "description": {
        "overall": "The ReturnDescription class is a Pydantic model used to define the structure for describing the return value of a function. It captures the name, type, and a textual description of the return value.",
        "init_method": {
          "description": "Initializes the ReturnDescription model with the name, type, and description of a function's return value. These attributes are defined as strings.",
          "parameters": [
            {
              "name": "name",
              "type": "str",
              "description": "The name of the return value."
            },
            {
              "name": "type",
              "type": "str",
              "description": "The data type of the return value."
            },
            {
              "name": "description",
              "type": "str",
              "description": "A textual description of the return value."
            }
          ]
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class does not have any external dependencies beyond Pydantic's BaseModel.",
          "instantiated_by": "This class is likely instantiated within systems that need to document or describe function return values, such as API documentation generators or code analysis tools."
        }
      },
      "error": null
    },
    "schemas.types.UsageContext": {
      "identifier": "schemas.types.UsageContext",
      "description": {
        "overall": "The UsageContext class is a Pydantic model designed to encapsulate the calling context of a function. It specifically defines attributes to describe what functions or methods a given function calls and which functions or methods call it.",
        "init_method": {
          "description": "Initializes the UsageContext model with attributes for tracking function calls and callers. It inherits from Pydantic's BaseModel for data validation.",
          "parameters": []
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class has no external dependencies beyond Pydantic's BaseModel.",
          "instantiated_by": "This class is intended to be instantiated as part of a larger data structure, likely for documenting or analyzing code."
        }
      },
      "error": null
    },
    "schemas.types.FunctionDescription": {
      "identifier": "schemas.types.FunctionDescription",
      "description": {
        "overall": "The FunctionDescription class is a Pydantic model designed to encapsulate a comprehensive analysis of a function. It details the function's overall purpose, its parameters, its return values, and its usage context within a larger system. This class serves as a structured data format for representing function-level metadata.",
        "init_method": {
          "description": "Initializes a FunctionDescription object. As this is a Pydantic model, initialization is handled by Pydantic's base model, which validates and assigns the provided fields: overall description, a list of ParameterDescription objects, a list of ReturnDescription objects, and a UsageContext object.",
          "parameters": []
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class depends on other Pydantic models: BaseModel, ParameterDescription, ReturnDescription, and UsageContext, which are likely defined elsewhere in the 'schemas.types' module or imported into it.",
          "instantiated_by": "This class is intended to be instantiated by systems that perform detailed analysis of functions and need to store this analysis in a structured format. It is likely used as a component within a larger documentation generation or code analysis pipeline."
        }
      },
      "error": null
    },
    "schemas.types.FunctionAnalysis": {
      "identifier": "schemas.types.FunctionAnalysis",
      "description": {
        "overall": "The FunctionAnalysis class is a Pydantic model designed to represent the structured analysis of a Python function. It encapsulates the function's identifier, a detailed description of its purpose and signature, and an optional field for any errors encountered during analysis. This model serves as a key component in generating machine-readable documentation for code.",
        "init_method": {
          "description": "Initializes a FunctionAnalysis object. It takes the function's identifier, a FunctionDescription object, and an optional error string as arguments. The identifier is a string representing the function's name, and the FunctionDescription contains the detailed analysis of the function's purpose, parameters, return values, and usage context. An optional error string can be provided if any issues occurred during the analysis.",
          "parameters": [
            {
              "name": "identifier",
              "type": "str",
              "description": "The unique name or identifier of the function being analyzed."
            },
            {
              "name": "description",
              "type": "FunctionDescription",
              "description": "A FunctionDescription object containing the detailed analysis of the function."
            },
            {
              "name": "error",
              "type": "Optional[str]",
              "description": "An optional string that holds error information if the function analysis failed."
            }
          ]
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class has no external dependencies beyond Pydantic's BaseModel.",
          "instantiated_by": "This class is likely instantiated by a system that analyzes Python code and generates structured documentation."
        }
      },
      "error": null
    },
    "schemas.types.ConstructorDescription": {
      "identifier": "schemas.types.ConstructorDescription",
      "description": {
        "overall": "The ConstructorDescription class is a Pydantic model used to represent the initialization method of a Python class. It captures a textual description of the constructor's purpose and a list of its parameters, where each parameter is further detailed by the ParameterDescription model.",
        "init_method": {
          "description": "Initializes a ConstructorDescription object. It takes a string description of the constructor and a list of ParameterDescription objects, each detailing a parameter of the constructor.",
          "parameters": [
            {
              "name": "description",
              "type": "str",
              "description": "A textual summary of the constructor's purpose."
            },
            {
              "name": "parameters",
              "type": "List[ParameterDescription]",
              "description": "A list of ParameterDescription objects, each detailing a parameter accepted by the constructor."
            }
          ]
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class depends on Pydantic's BaseModel for its structure and validation. It also utilizes typing.List for type hinting.",
          "instantiated_by": "This class is intended to be instantiated within systems that analyze and document Python classes, likely as part of a larger documentation generation or code analysis pipeline."
        }
      },
      "error": null
    },
    "schemas.types.ClassContext": {
      "identifier": "schemas.types.ClassContext",
      "description": {
        "overall": "The ClassContext model is a Pydantic BaseModel used to describe a class's external dependencies and its primary points of instantiation. It serves as a structured way to document where a class relies on other components and where instances of that class are created within a system.",
        "init_method": {
          "description": "Initializes the ClassContext model with information about the class's dependencies and instantiation points. It directly assigns the provided values to the corresponding attributes.",
          "parameters": [
            {
              "name": "dependencies",
              "type": "str",
              "description": "A string describing the external dependencies of the class."
            },
            {
              "name": "instantiated_by",
              "type": "str",
              "description": "A string describing where the class is instantiated within the system."
            }
          ]
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class does not define any external dependencies within its own code, but it is designed to describe the dependencies of other classes.",
          "instantiated_by": "This class is likely instantiated as part of a larger system for documenting code, possibly within a documentation generation tool or a code analysis framework."
        }
      },
      "error": null
    },
    "schemas.types.ClassDescription": {
      "identifier": "schemas.types.ClassDescription",
      "description": {
        "overall": "The ClassDescription class serves as a comprehensive data structure for holding the detailed analysis of a Python class. It encapsulates information about the class's overall purpose, its initialization method, a list of its individual methods, and its usage context within a larger system.",
        "init_method": {
          "description": "The __init__ method for ClassDescription initializes a new instance of the class with specific details about another class's analysis. It takes arguments for the overall description, the constructor's details, a list of analyzed methods, and the class's usage context.",
          "parameters": [
            {
              "name": "overall",
              "type": "str",
              "description": "A string providing a high-level summary of the class's purpose and responsibilities."
            },
            {
              "name": "init_method",
              "type": "ConstructorDescription",
              "description": "An object containing the analysis of the class's constructor (__init__ method), including its description and parameters."
            },
            {
              "name": "methods",
              "type": "List[FunctionAnalysis]",
              "description": "A list where each element is a FunctionAnalysis object, detailing the analysis of a specific method within the class."
            },
            {
              "name": "usage_context",
              "type": "ClassContext",
              "description": "An object detailing how the class is used, including its external dependencies and where it is instantiated."
            }
          ]
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class does not appear to have direct external code dependencies beyond the Pydantic BaseModel and typing modules it inherits from and uses.",
          "instantiated_by": "This class is intended to be instantiated by systems that perform code analysis and require a structured way to represent the findings for a given Python class."
        }
      },
      "error": null
    },
    "schemas.types.ClassAnalysis": {
      "identifier": "schemas.types.ClassAnalysis",
      "description": {
        "overall": "The ClassAnalysis model represents the comprehensive analysis of a Python class, structured for machine readability. It includes the class identifier, a detailed description encompassing its overall purpose, constructor, methods, and usage context, and an optional error field for reporting analysis issues.",
        "init_method": {
          "description": "Initializes the ClassAnalysis model with the class identifier, a detailed description object, and an optional error field. The identifier is a string representing the class name, and the description is a ClassDescription object containing the analysis results.",
          "parameters": [
            {
              "name": "identifier",
              "type": "str",
              "description": "The name of the class being analyzed."
            },
            {
              "name": "description",
              "type": "ClassDescription",
              "description": "An object containing the detailed analysis of the class, including its overall purpose, constructor, methods, and usage context."
            },
            {
              "name": "error",
              "type": "Optional[str]",
              "description": "An optional string field to report any errors encountered during the analysis of the class. Defaults to None."
            }
          ]
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class does not appear to have any external dependencies beyond Pydantic's BaseModel.",
          "instantiated_by": "This class is intended to be instantiated by the documentation generation system as part of its analysis process."
        }
      },
      "error": null
    },
    "schemas.types.CallInfo": {
      "identifier": "schemas.types.CallInfo",
      "description": {
        "overall": "The CallInfo class is a Pydantic BaseModel used to represent detailed information about a specific call event within a system. It captures the source file, the calling function or method name, the mode of the call (e.g., 'method', 'function', 'module'), and the line number where the call occurred. This structure is particularly useful for logging and analyzing relationships between different parts of the codebase, such as tracking which functions are calling a particular piece of code or where a class instance is being created.",
        "init_method": {
          "description": "Initializes a CallInfo object with details about a specific call event. It takes the file path, function name, call mode, and line number as arguments and assigns them to corresponding attributes.",
          "parameters": [
            {
              "name": "file",
              "type": "str",
              "description": "The path to the file where the call originated."
            },
            {
              "name": "function",
              "type": "str",
              "description": "The name of the function or method that made the call."
            },
            {
              "name": "mode",
              "type": "str",
              "description": "The type of call, such as 'method', 'function', or 'module'."
            },
            {
              "name": "line",
              "type": "int",
              "description": "The line number in the source file where the call occurred."
            }
          ]
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class depends on Pydantic's BaseModel for data validation and structure.",
          "instantiated_by": "This class is intended to be instantiated by systems that analyze code relationships, such as 'called_by' and 'instantiated_by' lists within other data structures."
        }
      },
      "error": null
    },
    "schemas.types.FunctionContextInput": {
      "identifier": "schemas.types.FunctionContextInput",
      "description": {
        "overall": "The FunctionContextInput class is a Pydantic model designed to structure contextual information for analyzing a function. It primarily holds lists of strings representing functions or methods called by the target function and a list of CallInfo objects detailing where the target function is called from.",
        "init_method": {
          "description": "Initializes the FunctionContextInput model with lists of calls and called_by information. This constructor is automatically generated by Pydantic based on the class attributes.",
          "parameters": [
            {
              "name": "calls",
              "type": "List[str]",
              "description": "A list of strings, where each string represents a function or method called by the analyzed function."
            },
            {
              "name": "called_by",
              "type": "List[CallInfo]",
              "description": "A list of CallInfo objects, where each object details a call site that invokes the analyzed function."
            }
          ]
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class depends on Pydantic's BaseModel for its structure and validation. It also utilizes List from typing and CallInfo (though CallInfo is not defined in the provided source code, it's expected to be a defined type).",
          "instantiated_by": "This class is intended to be instantiated wherever structured context for function analysis is required, likely within other analysis or documentation generation tools. Specific instantiation points are not detailed in the provided source."
        }
      },
      "error": null
    },
    "schemas.types.FunctionAnalysisInput": {
      "identifier": "schemas.types.FunctionAnalysisInput",
      "description": {
        "overall": "The FunctionAnalysisInput class is a Pydantic model designed to encapsulate all necessary information required for analyzing a Python function. It serves as a structured input for a documentation generation system, ensuring that all relevant details like the function's identifier, source code, import statements, and contextual information are provided in a standardized format.",
        "init_method": {
          "description": "Initializes the FunctionAnalysisInput model with all the required fields for function analysis. It takes the mode, identifier, source code, a list of import statements, and a FunctionContextInput object as arguments to define the scope and details of the function to be analyzed.",
          "parameters": [
            {
              "name": "mode",
              "type": "Literal[\"function_analysis\"]",
              "description": "Specifies the analysis mode, which must be 'function_analysis' for this input type."
            },
            {
              "name": "identifier",
              "type": "str",
              "description": "The unique name or identifier of the function being analyzed."
            },
            {
              "name": "source_code",
              "type": "str",
              "description": "The raw source code of the function."
            },
            {
              "name": "imports",
              "type": "List[str]",
              "description": "A list of import statements relevant to the source code file where the function is defined."
            },
            {
              "name": "context",
              "type": "FunctionContextInput",
              "description": "An object containing contextual information about the function, such as its dependencies and call relationships."
            }
          ]
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class does not appear to have external functional dependencies beyond Pydantic's BaseModel and typing module.",
          "instantiated_by": "This class is intended to be instantiated by systems that require structured input for function analysis, likely within a larger documentation generation pipeline."
        }
      },
      "error": null
    },
    "schemas.types.MethodContextInput": {
      "identifier": "schemas.types.MethodContextInput",
      "description": {
        "overall": "The MethodContextInput class is a Pydantic model designed to structure contextual information about a class's methods. It inherits from pydantic.BaseModel, ensuring data validation. This class is primarily used to hold details such as the method's identifier, lists of other methods or functions it calls and is called by, its arguments, and an optional docstring.",
        "init_method": {
          "description": "Initializes the MethodContextInput model with specific attributes related to a method's context. It takes an identifier, lists of calls and callers, a list of arguments, and an optional docstring.",
          "parameters": [
            {
              "name": "identifier",
              "type": "str",
              "description": "The unique name or identifier of the method."
            },
            {
              "name": "calls",
              "type": "List[str]",
              "description": "A list of strings representing other methods, classes, or functions that this method calls."
            },
            {
              "name": "called_by",
              "type": "List[CallInfo]",
              "description": "A list of CallInfo objects indicating which methods or functions call this method."
            },
            {
              "name": "args",
              "type": "List[str]",
              "description": "A list of strings representing the arguments accepted by the method."
            },
            {
              "name": "docstring",
              "type": "Optional[str]",
              "description": "An optional string containing the documentation string (docstring) of the method."
            }
          ]
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class depends on pydantic.BaseModel for its structure and validation. It also utilizes typing.List and typing.Optional for type hinting.",
          "instantiated_by": "This class is intended to be instantiated wherever structured context for a method's details is required, likely within a larger documentation generation or code analysis system."
        }
      },
      "error": null
    },
    "schemas.types.ClassContextInput": {
      "identifier": "schemas.types.ClassContextInput",
      "description": {
        "overall": "The ClassContextInput class is a Pydantic model designed to hold structured contextual information for analyzing a Python class. It aggregates details about the class's dependencies, where it is instantiated, and the context of its methods.",
        "init_method": {
          "description": "Initializes a ClassContextInput object with lists of dependencies, instantiation information, and method contexts. This model is likely used for data transfer or validation within a larger system that analyzes Python code.",
          "parameters": [
            {
              "name": "dependencies",
              "type": "List[str]",
              "description": "A list of strings representing external dependencies of the class being analyzed."
            },
            {
              "name": "instantiated_by",
              "type": "List[CallInfo]",
              "description": "A list of CallInfo objects detailing where instances of the class are created."
            },
            {
              "name": "method_context",
              "type": "List[MethodContextInput]",
              "description": "A list of MethodContextInput objects, each providing context for a specific method within the class."
            }
          ]
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class does not appear to have any external code dependencies beyond the Pydantic BaseModel and typing modules it inherits from.",
          "instantiated_by": "This class is not instantiated by any other code within the provided context; it is likely used as a data structure for input or configuration."
        }
      },
      "error": null
    },
    "schemas.types.ClassAnalysisInput": {
      "identifier": "schemas.types.ClassAnalysisInput",
      "description": {
        "overall": "The ClassAnalysisInput class is a Pydantic model designed to define the structure of input data required for a class analysis process. It specifies the mode of operation, the identifier of the class to be analyzed, its source code, a list of relevant imports, and a context object containing further details about dependencies and instantiation.",
        "init_method": {
          "description": "Initializes the ClassAnalysisInput model with all the necessary fields for class analysis. It takes the mode, identifier, source code, imports, and context as arguments, validating them according to Pydantic's BaseModel rules.",
          "parameters": [
            {
              "name": "mode",
              "type": "Literal[\"class_analysis\"]",
              "description": "Specifies the analysis mode, which must be 'class_analysis'."
            },
            {
              "name": "identifier",
              "type": "str",
              "description": "The name or identifier of the class to be analyzed."
            },
            {
              "name": "source_code",
              "type": "str",
              "description": "The raw source code of the class definition."
            },
            {
              "name": "imports",
              "type": "List[str]",
              "description": "A list of import statements relevant to the source code."
            },
            {
              "name": "context",
              "type": "ClassContextInput",
              "description": "An object containing contextual information about the class, such as dependencies and instantiation points."
            }
          ]
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class does not have any external functional dependencies explicitly listed.",
          "instantiated_by": "This class is not explicitly shown to be instantiated by any other components within the provided context."
        }
      },
      "error": null
    }
  }
}