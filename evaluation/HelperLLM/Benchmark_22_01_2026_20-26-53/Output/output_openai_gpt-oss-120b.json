{
  "functions": {
    "backend.AST_Schema.path_to_module": {
      "identifier": "backend.AST_Schema.path_to_module",
      "description": {
        "overall": "The function `path_to_module` converts a filesystem file path into a dotted Python module path. It first attempts to compute the path relative to a given project root, falling back to the file's basename if the relative computation fails. The function then removes a trailing `.py` extension and replaces OS-specific path separators with dots to form a module-like string. If the resulting path ends with `.__init__`, that suffix is stripped, yielding the importable module name. The resulting module path string is returned to the caller.",
        "parameters": [
          {
            "name": "filepath",
            "type": "str",
            "description": "The absolute or relative path to the Python file whose module path should be derived."
          },
          {
            "name": "project_root",
            "type": "str",
            "description": "The root directory of the project, used to compute a path relative to it."
          }
        ],
        "returns": [
          {
            "name": "module_path",
            "type": "str",
            "description": "A dotted module path corresponding to the provided file path."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "No other functions are listed as callers of this function."
        }
      },
      "error": null
    },
    "backend.File_Dependency.build_file_dependency_graph": {
      "identifier": "backend.File_Dependency.build_file_dependency_graph",
      "description": {
        "overall": "The function builds a directed graph that represents file import dependencies for a given source file. It starts by creating an empty NetworkX DiGraph, then instantiates a FileDependencyGraph visitor with the target filename and repository root. The visitor traverses the provided AST, collecting a mapping of callers to their imported modules. The function iterates over this mapping, adds each caller and callee as nodes, and creates edges from callers to their respective callees. Finally, the populated graph is returned.",
        "parameters": [
          {
            "name": "filename",
            "type": "str",
            "description": "The name of the source file for which the dependency graph is being constructed."
          },
          {
            "name": "tree",
            "type": "AST",
            "description": "The abstract syntax tree (AST) of the source file."
          },
          {
            "name": "repo_root",
            "type": "str",
            "description": "The root directory of the repository containing the source file."
          }
        ],
        "returns": [
          {
            "name": "graph",
            "type": "nx.DiGraph",
            "description": "A directed graph where nodes are files/modules and edges represent import relationships."
          }
        ],
        "usage_context": {
          "calls": "This function calls backend.File_Dependency.FileDependencyGraph.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "backend.File_Dependency.build_repository_graph": {
      "identifier": "backend.File_Dependency.build_repository_graph",
      "description": {
        "overall": "The function builds a repository\u2011wide dependency graph for Python files in a given Git repository. It first retrieves all files from the repository and filters out non\u2011Python files. For each Python file, it extracts the module name, parses its AST, and delegates to `backend.File_Dependency.build_file_dependency_graph` to obtain a per\u2011file dependency graph. Nodes and edges from each file graph are merged into a single global directed graph, which is then returned.",
        "parameters": [
          {
            "name": "repository",
            "type": "GitRepository",
            "description": "A GitRepository instance representing the repository to analyze."
          }
        ],
        "returns": [
          {
            "name": "",
            "type": "nx.DiGraph",
            "description": "A directed graph where nodes represent symbols (functions, classes, etc.) and edges represent dependency relationships across the repository."
          }
        ],
        "usage_context": {
          "calls": "This function calls backend.File_Dependency.build_file_dependency_graph.",
          "called_by": "No functions call this function."
        }
      },
      "error": null
    },
    "backend.File_Dependency.get_all_temp_files": {
      "identifier": "backend.File_Dependency.get_all_temp_files",
      "description": {
        "overall": "The function searches a given directory and all of its sub\u2011directories for Python source files. It first resolves the supplied directory string to an absolute Path object. Using a recursive glob it collects every file whose name ends with \".py\" and converts each file path to be relative to the root directory. Finally, it returns the list of these relative Path objects.",
        "parameters": [
          {
            "name": "directory",
            "type": "str",
            "description": "The directory path to search for Python files."
          }
        ],
        "returns": [
          {
            "name": "",
            "type": "list[Path]",
            "description": "A list of Path objects representing the Python files found under the given directory, expressed relative to the directory root."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "backend.HelperLLM.main_orchestrator": {
      "identifier": "backend.HelperLLM.main_orchestrator",
      "description": {
        "overall": "The `main_orchestrator` function serves as a dummy data and processing driver for testing the LLMHelper class. It constructs `FunctionAnalysisInput` objects for three example functions (`add_item`, `check_stock`, `generate_report`) and validates them against the corresponding Pydantic models. It also creates pre\u2011filled `FunctionAnalysis` and `ClassAnalysisInput` objects, assembles them into input lists, and invokes `llm_helper.generate_for_functions` to obtain generated documentation. The resulting documentation objects are collected into a dictionary, logged, and finally printed as a formatted JSON string. Throughout, the function relies on imported modules such as `json`, `logging`, and the custom schema definitions.",
        "parameters": [],
        "returns": [],
        "usage_context": {
          "calls": "This function calls backend.HelperLLM.LLMHelper, schemas.types.ClassAnalysisInput, and schemas.types.ClassContextInput.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "backend.callgraph.make_safe_dot": {
      "identifier": "backend.callgraph.make_safe_dot",
      "description": {
        "overall": "The function `make_safe_dot` generates a DOT file representation of a NetworkX directed graph with sanitized node identifiers. It first creates a copy of the input graph and builds a mapping from each original node to a new identifier of the form `n{i}`. The graph is relabeled using this mapping, and the original node names are stored in a node attribute called \"label\". Finally, the function writes the transformed graph to the specified output path using NetworkX's `write_dot` utility.",
        "parameters": [
          {
            "name": "graph",
            "type": "nx.DiGraph",
            "description": "The directed graph to be converted into a safe DOT representation."
          },
          {
            "name": "out_path",
            "type": "str",
            "description": "Filesystem path where the resulting DOT file will be written."
          }
        ],
        "returns": [],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "backend.callgraph.build_filtered_callgraph": {
      "identifier": "backend.callgraph.build_filtered_callgraph",
      "description": {
        "overall": "The function build_filtered_callgraph constructs a call graph for a given Git repository and filters it to include only functions defined within the repository itself. It retrieves all files from the repository, parses each Python file into an abstract syntax tree (AST), and uses a CallGraph visitor to collect the set of functions defined in each file. After gathering all functions, it builds a global directed graph, adding edges only when both the caller and callee are among the repository's own functions. Finally, the filtered directed graph is returned.",
        "parameters": [
          {
            "name": "repo",
            "type": "GitRepository",
            "description": "A GitRepository object representing the repository whose source files are to be analyzed."
          }
        ],
        "returns": [
          {
            "name": "",
            "type": "nx.DiGraph",
            "description": "A NetworkX directed graph containing edges between functions that are defined in the repository and call each other."
          }
        ],
        "usage_context": {
          "calls": "This function calls backend.callgraph.CallGraph.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "backend.converter.wrap_cdata": {
      "identifier": "backend.converter.wrap_cdata",
      "description": {
        "overall": "The function wrap_cdata takes a single argument named content and returns a new string where the original content is wrapped inside CDATA tags. It constructs the result using an f-string that places the opening <![CDATA[ marker, a newline, the content, another newline, and the closing ]]> marker. No additional processing, validation, or external calls are performed. The function is pure and deterministic, always returning the formatted string.",
        "parameters": [
          {
            "name": "content",
            "type": "str",
            "description": "The text to be wrapped inside CDATA tags."
          }
        ],
        "returns": [
          {
            "name": "",
            "type": "str",
            "description": "A string containing the original content enclosed in CDATA tags, with newline characters after the opening tag and before the closing tag."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "It is not called by any other functions."
        }
      },
      "error": null
    },
    "backend.converter.extract_output_content": {
      "identifier": "backend.converter.extract_output_content",
      "description": {
        "overall": "The function iterates over a collection of notebook output objects and extracts textual content or image placeholders. For outputs that contain display data, it attempts to locate an image in PNG format first and, if absent, in JPEG format, delegating the Base64 decoding to an inner helper. When an image is successfully processed, a placeholder XML tag referencing the image index is added to the result list; otherwise, plain text is used. Stream\u2011type outputs contribute their raw text, and error outputs contribute a formatted error message. Finally, the function returns a list of the gathered snippets.",
        "parameters": [
          {
            "name": "outputs",
            "type": "Iterable[Any]",
            "description": "A sequence of output objects (e.g., nbformat NotebookNode) that may contain display data, stream text, or error information."
          },
          {
            "name": "image_list",
            "type": "list",
            "description": "A mutable list that will be populated with dictionaries describing extracted images (mime_type and Base64 data)."
          }
        ],
        "returns": [
          {
            "name": "extracted_xml_snippets",
            "type": "list of str",
            "description": "A list containing either plain text strings, XML image placeholders, or formatted error messages extracted from the provided outputs."
          }
        ],
        "usage_context": {
          "calls": "This function calls backend.converter.process_image.",
          "called_by": "No functions are listed as callers of this function."
        }
      },
      "error": null
    },
    "backend.converter.process_image": {
      "identifier": "backend.converter.process_image",
      "description": {
        "overall": "The `process_image` function takes a MIME type string and attempts to retrieve a corresponding base\u201164\u2011encoded image from a global `data` mapping. If the MIME type is present, it strips newline characters from the stored string, records the image and its MIME type in a global `image_list`, and computes the index of the newly added entry. It then returns an XML\u2011like placeholder tag containing the index and MIME type, which can be used later to embed the image. If an exception occurs while handling the image data, the function returns an error tag with the exception message; if the MIME type is not found, it returns `None`.",
        "parameters": [
          {
            "name": "mime_type",
            "type": "str",
            "description": "MIME type identifier of the image to process."
          }
        ],
        "returns": [
          {
            "name": "placeholder",
            "type": "str",
            "description": "Placeholder XML tag with the image index and MIME type when processing succeeds."
          },
          {
            "name": "error_tag",
            "type": "str",
            "description": "Error XML tag containing the exception message if decoding fails."
          },
          {
            "name": "none",
            "type": "None",
            "description": "Returned when the provided MIME type is not present in the data mapping."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "No functions are listed as callers of this function."
        }
      },
      "error": null
    },
    "backend.converter.convert_notebook_to_xml": {
      "identifier": "backend.converter.convert_notebook_to_xml",
      "description": {
        "overall": "The function converts a Jupyter notebook, provided as raw file content, into an XML representation. It first attempts to parse the content using nbformat, handling JSON parsing errors gracefully. For each cell in the notebook, it generates XML fragments: markdown cells are wrapped directly, code cells are wrapped in CDATA sections, and any output data is extracted, optionally wrapped, and added as separate output cells. Finally, it concatenates all XML fragments and returns the combined XML string together with a list of any images extracted from the notebook outputs.",
        "parameters": [
          {
            "name": "file_content",
            "type": "str",
            "description": "The raw content of a notebook file as a string."
          }
        ],
        "returns": [
          {
            "name": "xml_string",
            "type": "str",
            "description": "A single XML document representing the notebook, with each cell and output encoded as XML elements."
          },
          {
            "name": "extracted_images",
            "type": "list",
            "description": "A list of image data extracted from cell outputs (e.g., base64\u2011encoded images)."
          }
        ],
        "usage_context": {
          "calls": "This function calls backend.converter.extract_output_content and backend.converter.wrap_cdata.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "backend.converter.process_repo_notebooks": {
      "identifier": "backend.converter.process_repo_notebooks",
      "description": {
        "overall": "The function `process_repo_notebooks` scans a collection of repository files to identify Jupyter notebook files. It filters the input list for entries whose `path` ends with `.ipynb`. For each notebook, it logs the processing step and invokes `backend.converter.convert_notebook_to_xml` to obtain an XML representation and any extracted images. The results are stored in a dictionary keyed by the notebook's path, with each value containing the XML output and the list of images. Finally, the dictionary of results is returned to the caller.",
        "parameters": [
          {
            "name": "repo_files",
            "type": "list",
            "description": "A collection of file objects from the repository; each object is expected to have `path` and `content` attributes."
          }
        ],
        "returns": [
          {
            "name": "results",
            "type": "dict",
            "description": "A dictionary mapping notebook file paths to a dictionary with keys `xml` (the converted XML string) and `images` (the extracted images)."
          }
        ],
        "usage_context": {
          "calls": "This function calls backend.converter.convert_notebook_to_xml.",
          "called_by": "No functions call this function."
        }
      },
      "error": null
    },
    "backend.main.create_savings_chart": {
      "identifier": "backend.main.create_savings_chart",
      "description": {
        "overall": "The function creates a bar chart that compares two token counts, one from JSON and one from TOON, and visualizes the percentage of savings. It builds the chart using Matplotlib, setting custom colors, labels, and a title that includes the savings percentage formatted to two decimal places. Numeric values are displayed above each bar for clarity, and the chart is saved to a specified file path before the figure is closed. No value is returned; the side effect is the creation of an image file on disk.",
        "parameters": [
          {
            "name": "json_tokens",
            "type": "int",
            "description": "The number of tokens counted for the JSON representation."
          },
          {
            "name": "toon_tokens",
            "type": "int",
            "description": "The number of tokens counted for the TOON representation."
          },
          {
            "name": "savings_percent",
            "type": "float",
            "description": "The percentage of token savings, used in the chart title."
          },
          {
            "name": "output_path",
            "type": "str",
            "description": "Filesystem path where the generated chart image will be saved."
          }
        ],
        "returns": [],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "backend.main.calculate_net_time": {
      "identifier": "backend.main.calculate_net_time",
      "description": {
        "overall": "The function calculates the effective elapsed time between a start and end timestamp, subtracting any artificial sleep periods that are introduced to respect rate\u2011limit constraints. It first computes the raw duration, then checks whether the provided model name indicates a Gemini model; if not, it returns the raw duration unchanged. For Gemini models it determines the number of batches required for the total items, derives the number of sleep intervals (one less than the number of batches), and subtracts the cumulative sleep time (61 seconds per interval) from the raw duration. Finally, it ensures the resulting net time is not negative before returning it.",
        "parameters": [
          {
            "name": "start_time",
            "type": "int or float",
            "description": "The starting timestamp (in seconds or a comparable numeric unit)."
          },
          {
            "name": "end_time",
            "type": "int or float",
            "description": "The ending timestamp (in the same unit as start_time)."
          },
          {
            "name": "total_items",
            "type": "int",
            "description": "The total number of items to be processed."
          },
          {
            "name": "batch_size",
            "type": "int",
            "description": "The maximum number of items that can be processed in a single batch."
          },
          {
            "name": "model_name",
            "type": "str",
            "description": "The name of the model; sleep time is only subtracted when it starts with \"gemini-\"."
          }
        ],
        "returns": [
          {
            "name": "",
            "type": "int or float",
            "description": "The net elapsed time after accounting for rate\u2011limit sleep periods, guaranteed to be zero or positive."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "No other functions are documented as calling this function."
        }
      },
      "error": null
    },
    "backend.main.main_workflow": {
      "identifier": "backend.main.main_workflow",
      "description": {
        "overall": "The `main_workflow` function orchestrates a complete analysis pipeline for a software repository provided via a user\u2011supplied URL. It extracts the repository URL from the input, clones the repository, gathers basic project information, builds an abstract syntax tree (AST) and relationship graph, and enriches the AST with those relationships. The enriched data is then fed to a Helper LLM that generates documentation for each function and class, after which a Main LLM creates a final report summarising the entire project. Finally, the function returns the generated report together with a set of execution metrics.",
        "parameters": [
          {
            "name": "input",
            "type": "Any",
            "description": "The raw user input string that should contain a GitHub repository URL."
          },
          {
            "name": "api_keys",
            "type": "dict",
            "description": "A dictionary mapping service names (e.g., \"gemini\", \"gpt\", \"scadsllm\") to their respective API keys."
          },
          {
            "name": "model_names",
            "type": "dict",
            "description": "A dictionary specifying which model identifiers to use for the helper and main LLMs."
          },
          {
            "name": "status_callback",
            "type": "Any",
            "description": "An optional callable that receives status messages for UI updates; if omitted, status is only logged."
          }
        ],
        "returns": [
          {
            "name": "result",
            "type": "dict",
            "description": "A dictionary with two keys: `report`, containing the final markdown report string, and `metrics`, containing timing and token\u2011usage statistics."
          }
        ],
        "usage_context": {
          "calls": "This function calls backend.AST_Schema.ASTAnalyzer, backend.AST_Schema.ASTAnalyzer.analyze_repository, backend.AST_Schema.ASTAnalyzer.merge_relationship_data, backend.HelperLLM.LLMHelper, backend.HelperLLM.LLMHelper.generate_for_classes, backend.HelperLLM.LLMHelper.generate_for_functions, backend.MainLLM.MainLLM, backend.MainLLM.MainLLM.call_llm, backend.basic_info.ProjektInfoExtractor, backend.basic_info.ProjektInfoExtractor.extrahiere_info, backend.getRepo.GitRepository, backend.main.calculate_net_time, backend.main.create_savings_chart, backend.main.update_status, backend.relationship_analyzer.ProjectAnalyzer, backend.relationship_analyzer.ProjectAnalyzer.analyze, backend.relationship_analyzer.ProjectAnalyzer.get_raw_relationships, schemas.types.ClassAnalysisInput, schemas.types.ClassContextInput, schemas.types.FunctionAnalysisInput, schemas.types.FunctionContextInput, and schemas.types.MethodContextInput.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "backend.main.update_status": {
      "identifier": "backend.main.update_status",
      "description": {
        "overall": "The `update_status` function forwards a status message to a registered callback and records the same message in the application log. It first checks whether a global `status_callback` callable is defined; if so, it invokes this callback with the provided message. Regardless of the callback's presence, the function then logs the message at the INFO level using the standard `logging` module. This design allows optional external handling of status updates while always preserving a record in the log.",
        "parameters": [
          {
            "name": "msg",
            "type": "str",
            "description": "The status message to be propagated to the callback (if any) and logged."
          }
        ],
        "returns": [],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "backend.main.notebook_workflow": {
      "identifier": "backend.main.notebook_workflow",
      "description": {
        "overall": "The `notebook_workflow` function orchestrates the end\u2011to\u2011end analysis of Jupyter notebooks contained in a GitHub repository. It extracts a repository URL from the free\u2011form `input`, clones the repository, converts notebook files to XML and image data, and gathers basic project information. For each notebook it builds a Gemini\u2011compatible payload, invokes a language model via `MainLLM` to generate a textual report, and aggregates all reports into a single markdown document that is written to the `result` directory. Finally it records execution metrics such as elapsed time and returns both the combined report and the metrics dictionary.",
        "parameters": [
          {
            "name": "input",
            "type": "str",
            "description": "A free\u2011form string that should contain a GitHub repository URL; the function extracts the URL from this text."
          },
          {
            "name": "api_keys",
            "type": "dict",
            "description": "A mapping of service identifiers (e.g., \"gpt\", \"gemini\", \"scadsllm\", \"ollama\") to their corresponding API keys and optional base URLs."
          },
          {
            "name": "model",
            "type": "str",
            "description": "The name of the language\u2011model to use; determines which API key and base URL are selected."
          },
          {
            "name": "status_callback",
            "type": "Callable[[str], Any] | None",
            "description": "An optional callable that receives status messages for real\u2011time UI updates; if omitted, status messages are only logged."
          }
        ],
        "returns": [
          {
            "name": "result",
            "type": "dict",
            "description": "A dictionary with two keys: `report` (a markdown string containing the concatenated notebook analyses) and `metrics` (a dictionary of timing and model information)."
          }
        ],
        "usage_context": {
          "calls": "This function calls backend.MainLLM.MainLLM, backend.MainLLM.MainLLM.call_llm, backend.basic_info.ProjektInfoExtractor, backend.basic_info.ProjektInfoExtractor.extrahiere_info, backend.converter.process_repo_notebooks, backend.getRepo.GitRepository, backend.main.gemini_payload, and backend.main.update_status.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "backend.main.gemini_payload": {
      "identifier": "backend.main.gemini_payload",
      "description": {
        "overall": "The function builds a Gemini API payload that mixes textual context with inline images extracted from an XML document. It first serialises basic information and the notebook path into a JSON string, then creates an initial text block containing that context. By scanning the XML for <IMAGE_PLACEHOLDER> tags, it appends preceding text as separate text blocks and replaces each placeholder with an image_url block that embeds the image data as a base64 data URI. After processing all placeholders, any remaining text is added and the complete list of content blocks is returned.",
        "parameters": [
          {
            "name": "basic_info",
            "type": "dict",
            "description": "A dictionary (or JSON\u2011serialisable object) containing basic information to be included in the payload."
          },
          {
            "name": "nb_path",
            "type": "str",
            "description": "The file system path of the current notebook, added to the introductory JSON."
          },
          {
            "name": "xml_content",
            "type": "str",
            "description": "A string containing the notebook XML with <IMAGE_PLACEHOLDER> tags indicating where images should be inserted."
          },
          {
            "name": "images",
            "type": "list",
            "description": "A list of dictionaries, each holding image data under the key 'data' as a base64\u2011encoded string."
          }
        ],
        "returns": [
          {
            "name": "payload_content",
            "type": "list",
            "description": "A list of dictionaries representing Gemini payload elements; each element is either a text block or an image_url block with a data URI."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "backend.relationship_analyzer.path_to_module": {
      "identifier": "backend.relationship_analyzer.path_to_module",
      "description": {
        "overall": "The function converts a filesystem path to a dotted Python module import path relative to a given project root. It first attempts to compute the relative path using `os.path.relpath`; if that fails, it falls back to the file's basename. The `.py` extension is stripped, path separators are replaced with dots, and a trailing `.__init__` segment is removed to yield the final module name. The resulting string is returned.",
        "parameters": [
          {
            "name": "filepath",
            "type": "str",
            "description": "The absolute or relative path to the Python file that should be translated into a module path."
          },
          {
            "name": "project_root",
            "type": "str",
            "description": "The root directory of the project against which `filepath` is made relative."
          }
        ],
        "returns": [
          {
            "name": "module_path",
            "type": "str",
            "description": "The dotted Python module path derived from the given file path."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "No functions are listed as callers of this function."
        }
      },
      "error": null
    },
    "database.db.encrypt_text": {
      "identifier": "database.db.encrypt_text",
      "description": {
        "overall": "The `encrypt_text` function takes a string and returns an encrypted version of it. It first checks whether the input text is falsy or whether a global `cipher_suite` object is unavailable; in those cases it returns the original text unchanged. If both are present, it strips whitespace from the text, encodes it to bytes, encrypts it using the `cipher_suite.encrypt` method, and decodes the resulting bytes back to a string. The function relies on the `cryptography.fernet.Fernet` instance referenced by `cipher_suite` which is expected to be defined elsewhere.",
        "parameters": [
          {
            "name": "text",
            "type": "str",
            "description": "The text string to be encrypted."
          }
        ],
        "returns": [
          {
            "name": "",
            "type": "str",
            "description": "The encrypted representation of the input text, or the original text if the input is falsy or `cipher_suite` is unavailable."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "No functions are listed as callers of this function."
        }
      },
      "error": null
    },
    "database.db.decrypt_text": {
      "identifier": "database.db.decrypt_text",
      "description": {
        "overall": "The function `decrypt_text` takes a string that is expected to contain encrypted data. It first checks whether the input text is falsy or whether a global `cipher_suite` object is unavailable; in those cases it returns the original text unchanged. If the checks pass, it strips whitespace, encodes the string to bytes, and attempts to decrypt it using `cipher_suite.decrypt`. The decrypted bytes are decoded back to a string and returned. If any exception occurs during decryption, the function falls back to returning the original input text.",
        "parameters": [
          {
            "name": "text",
            "type": "str",
            "description": "The encrypted text to be decrypted."
          }
        ],
        "returns": [
          {
            "name": "",
            "type": "str",
            "description": "The decrypted string if decryption succeeds, otherwise the original input text."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.insert_user": {
      "identifier": "database.db.insert_user",
      "description": {
        "overall": "The function `insert_user` constructs a user document for storage in a MongoDB collection. It receives a username, a display name, and a plain\u2011text password, hashes the password using `stauth.Hasher.hash`, and populates additional fields with empty strings. The document is then inserted into the `dbusers` collection via `insert_one`, and the function returns the identifier of the newly created record. This enables callers to reference the inserted user later.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The unique identifier for the user, used as the document's `_id` field."
          },
          {
            "name": "name",
            "type": "str",
            "description": "The display name of the user."
          },
          {
            "name": "password",
            "type": "str",
            "description": "The user's plain\u2011text password, which will be hashed before storage."
          }
        ],
        "returns": [
          {
            "name": "inserted_id",
            "type": "ObjectId",
            "description": "The identifier assigned by MongoDB to the newly inserted user document."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions in the provided context."
        }
      },
      "error": null
    },
    "database.db.fetch_all_users": {
      "identifier": "database.db.fetch_all_users",
      "description": {
        "overall": "The function `fetch_all_users` retrieves every user record from the database. It accesses the `dbusers` collection and invokes its `find` method to obtain a cursor over all documents. The cursor is immediately converted into a Python list, materializing all user entries in memory. Finally, the list of user documents is returned to the caller.",
        "parameters": [],
        "returns": [
          {
            "name": "",
            "type": "list",
            "description": "A list containing all user documents retrieved from the `dbusers` collection."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.fetch_user": {
      "identifier": "database.db.fetch_user",
      "description": {
        "overall": "The function `fetch_user` retrieves a user record from a MongoDB collection. It accepts a single argument, `username`, which is expected to be a string. Inside the function, it queries the `dbusers` collection for a document whose `_id` field matches the provided username. The result of this query is returned directly to the caller.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username used as the `_id` key to look up the user document in the database."
          }
        ],
        "returns": [
          {
            "name": "user_document",
            "type": "dict or None",
            "description": "A dictionary representing the user document if found, otherwise `None` when no matching record exists."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "No functions are documented as calling this function."
        }
      },
      "error": null
    },
    "database.db.update_user_name": {
      "identifier": "database.db.update_user_name",
      "description": {
        "overall": "The function `update_user_name` updates the `name` field of a user document in the MongoDB collection `dbusers`. It locates the document by matching the `_id` field with the provided `username`. The update operation uses MongoDB's `$set` operator to replace the existing name with `new_name`. After performing the update, the function returns the count of documents that were modified.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The identifier of the user document to update; it is matched against the `_id` field in the collection."
          },
          {
            "name": "new_name",
            "type": "str",
            "description": "The new name value that will be set in the `name` field of the matched user document."
          }
        ],
        "returns": [
          {
            "name": "modified_count",
            "type": "int",
            "description": "The number of documents that were modified by the update operation (typically 0 or 1)."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.update_gemini_key": {
      "identifier": "database.db.update_gemini_key",
      "description": {
        "overall": "The function updates a user's stored Gemini API key in the MongoDB database. It first removes surrounding whitespace from the provided key and encrypts it using the `encrypt_text` helper. Then it performs an `update_one` operation on the `dbusers` collection, matching the document whose `_id` equals the supplied username and setting the `gemini_api_key` field to the encrypted value. Finally, it returns the number of documents that were modified by the update.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username that identifies the user record to be updated."
          },
          {
            "name": "gemini_api_key",
            "type": "str",
            "description": "The raw Gemini API key that will be encrypted and stored for the user."
          }
        ],
        "returns": [
          {
            "name": "modified_count",
            "type": "int",
            "description": "The count of documents that were modified by the update operation."
          }
        ],
        "usage_context": {
          "calls": "This function calls database.db.encrypt_text.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.update_gpt_key": {
      "identifier": "database.db.update_gpt_key",
      "description": {
        "overall": "The function updates a stored GPT API key for a specific user in the database. It first removes any surrounding whitespace from the provided key and encrypts it using the encrypt_text helper. Then it executes a MongoDB update_one operation on the dbusers collection, setting the encrypted key for the document whose _id matches the given username. Finally, it returns the number of documents that were modified by the update operation.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The identifier of the user whose GPT API key should be updated."
          },
          {
            "name": "gpt_api_key",
            "type": "str",
            "description": "The raw GPT API key to be encrypted and stored for the user."
          }
        ],
        "returns": [
          {
            "name": "modified_count",
            "type": "int",
            "description": "The number of documents that were modified by the MongoDB update operation."
          }
        ],
        "usage_context": {
          "calls": "This function calls database.db.encrypt_text.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.update_ollama_url": {
      "identifier": "database.db.update_ollama_url",
      "description": {
        "overall": "The function updates a user's record in the MongoDB collection `dbusers` by setting the `ollama_base_url` field to a cleaned version of the provided URL. It identifies the document to update using the `username` as the `_id` field. The update operation uses MongoDB's `update_one` with the `$set` operator. Finally, it returns the number of documents that were modified by the operation.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The identifier of the user whose document is being updated; used as the `_id` field in the query."
          },
          {
            "name": "ollama_base_url",
            "type": "str",
            "description": "The new base URL for the Ollama service to store in the user's record; whitespace is stripped before saving."
          }
        ],
        "returns": [
          {
            "name": "modified_count",
            "type": "int",
            "description": "The number of documents that were modified by the update operation."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.update_opensrc_key": {
      "identifier": "database.db.update_opensrc_key",
      "description": {
        "overall": "The function encrypts the provided Open Source API key after removing surrounding whitespace. It then updates the MongoDB collection `dbusers`, locating the document whose `_id` matches the given username and setting its `opensrc_api_key` field to the encrypted value. The update operation uses MongoDB's `$set` operator. Finally, the function returns the number of documents that were modified by the update.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The identifier of the user whose record is being updated."
          },
          {
            "name": "opensrc_api_key",
            "type": "str",
            "description": "The Open Source API key to store for the user; it will be stripped of whitespace and encrypted before storage."
          }
        ],
        "returns": [
          {
            "name": "modified_count",
            "type": "int",
            "description": "The count of documents that were modified by the update operation."
          }
        ],
        "usage_context": {
          "calls": "This function calls database.db.encrypt_text.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.update_opensrc_url": {
      "identifier": "database.db.update_opensrc_url",
      "description": {
        "overall": "The function updates a user's record in the MongoDB collection `dbusers` by setting the `opensrc_base_url` field to a cleaned version of the provided URL. It constructs a filter using the supplied `username` as the document identifier and applies a `$set` operation with the stripped `opensrc_base_url`. After performing the update, it returns the number of documents that were modified. This allows callers to know whether the update succeeded and how many records were affected.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The unique identifier of the user whose record is to be updated."
          },
          {
            "name": "opensrc_base_url",
            "type": "str",
            "description": "The new base URL for the user's open-source repository, which will be stripped of surrounding whitespace before storage."
          }
        ],
        "returns": [
          {
            "name": "modified_count",
            "type": "int",
            "description": "The count of documents that were modified by the update operation."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.fetch_gemini_key": {
      "identifier": "database.db.fetch_gemini_key",
      "description": {
        "overall": "The function fetch_gemini_key retrieves a Gemini API key for a specified username from a MongoDB collection. It queries the `dbusers` collection for a document whose `_id` matches the provided username, projecting only the `gemini_api_key` field. If a matching document is found, the function extracts and returns the `gemini_api_key` value. If no document exists, it returns `None`.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username (used as the document `_id`) whose Gemini API key should be fetched from the database."
          }
        ],
        "returns": [
          {
            "name": "gemini_api_key",
            "type": "Optional[str]",
            "description": "The Gemini API key associated with the given username, or `None` if the user does not exist or the key is not stored."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "No functions are listed as callers of this function."
        }
      },
      "error": null
    },
    "database.db.fetch_ollama_url": {
      "identifier": "database.db.fetch_ollama_url",
      "description": {
        "overall": "The function fetch_ollama_url retrieves the Ollama base URL associated with a given username from a MongoDB collection. It queries the `dbusers` collection for a document whose `_id` matches the provided username, projecting only the `ollama_base_url` field. If a matching document is found, the function returns the value of `ollama_base_url`; otherwise it returns `None`. This provides a simple lookup utility for obtaining a user's Ollama service endpoint.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The identifier of the user whose Ollama base URL should be fetched."
          }
        ],
        "returns": [
          {
            "name": "",
            "type": "Optional[str]",
            "description": "The Ollama base URL string if the user exists and the field is present; otherwise `None`."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "It is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.fetch_gpt_key": {
      "identifier": "database.db.fetch_gpt_key",
      "description": {
        "overall": "The function fetch_gpt_key retrieves a stored GPT API key for a given username from a MongoDB collection. It queries the dbusers collection for a document whose _id matches the supplied username, projecting only the gpt_api_key field. If a matching document is found, the function extracts the gpt_api_key value; otherwise it returns None. This provides a simple lookup utility for accessing a user's GPT credentials.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The identifier of the user whose GPT API key should be fetched."
          }
        ],
        "returns": [
          {
            "name": "gpt_api_key",
            "type": "str or None",
            "description": "The GPT API key associated with the user if it exists; otherwise None."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.fetch_opensrc_key": {
      "identifier": "database.db.fetch_opensrc_key",
      "description": {
        "overall": "The function fetch_opensrc_key retrieves an OpenSRC API key from a MongoDB collection for a given user. It performs a find_one query on the dbusers collection, filtering by the provided username and projecting only the opensrc_api_key field. If a matching document is found, the function extracts the key from the result; otherwise it returns None. This allows callers to obtain a stored API credential without exposing other user data.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The identifier of the user whose OpenSRC API key should be fetched."
          }
        ],
        "returns": [
          {
            "name": "opensrc_api_key",
            "type": "Optional[Any]",
            "description": "The OpenSRC API key associated with the user, or None if the user does not exist or the key is absent."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "No functions are documented as calling this function."
        }
      },
      "error": null
    },
    "database.db.fetch_opensrc_url": {
      "identifier": "database.db.fetch_opensrc_url",
      "description": {
        "overall": "The function `fetch_opensrc_url` retrieves the Open Source base URL for a given username from the MongoDB collection `dbusers`. It performs a `find_one` query filtering on the `_id` field and projects only the `opensrc_base_url` field. If a matching document is found, it extracts the URL; otherwise it returns `None`. This provides a simple lookup utility for user\u2011specific Open Source URLs.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The identifier of the user whose Open Source base URL should be fetched."
          }
        ],
        "returns": [
          {
            "name": "opensrc_base_url",
            "type": "Optional[str]",
            "description": "The Open Source base URL associated with the user, or `None` if the user does not exist or the field is missing."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions in the provided context."
        }
      },
      "error": null
    },
    "database.db.delete_user": {
      "identifier": "database.db.delete_user",
      "description": {
        "overall": "The function `delete_user` removes a user document from the `dbusers` collection based on the provided username. It constructs a query that matches the `_id` field to the given username and invokes MongoDB's `delete_one` method. The result of the deletion operation is accessed via the `deleted_count` attribute, which indicates how many documents were removed. Finally, the function returns this count to the caller.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The identifier (username) of the user to be deleted from the database."
          }
        ],
        "returns": [
          {
            "name": "deleted_count",
            "type": "int",
            "description": "The number of documents deleted (0 if no matching user was found, 1 if the user was successfully removed)."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "No functions are documented as calling this function."
        }
      },
      "error": null
    },
    "database.db.get_decrypted_api_keys": {
      "identifier": "database.db.get_decrypted_api_keys",
      "description": {
        "overall": "The function retrieves a user's stored API credentials from a MongoDB collection and returns them in plaintext form. It first queries the collection for a document matching the provided username. If the user document is not found, it returns a pair of None values. For each credential field, it extracts the stored value, decrypts it when necessary, and assembles the results into a tuple. The function therefore acts as a secure accessor for encrypted API keys and related URLs.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The unique identifier of the user whose API keys are to be fetched from the database."
          }
        ],
        "returns": [
          {
            "name": "gemini_plain",
            "type": "str",
            "description": "Decrypted Gemini API key; empty string if not present."
          },
          {
            "name": "ollama_plain",
            "type": "str",
            "description": "Ollama base URL stored for the user; empty string if not present."
          },
          {
            "name": "gpt_plain",
            "type": "str",
            "description": "Decrypted GPT API key; empty string if not present."
          },
          {
            "name": "opensrc_plain",
            "type": "str",
            "description": "Decrypted Open-source API key; empty string if not present."
          },
          {
            "name": "opensrc_url",
            "type": "str",
            "description": "Open-source base URL stored for the user; empty string if not present."
          }
        ],
        "usage_context": {
          "calls": "This function calls database.db.decrypt_text.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.insert_chat": {
      "identifier": "database.db.insert_chat",
      "description": {
        "overall": "The function `insert_chat` creates a new chat record for a given user. It generates a unique identifier using `uuid.uuid4()` and captures the current timestamp with `datetime.now()`. The constructed chat dictionary is then inserted into the `dbchats` collection via `insert_one`. Finally, the function returns the identifier of the newly inserted document.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The name of the user who owns the chat."
          },
          {
            "name": "chat_name",
            "type": "str",
            "description": "The display name of the chat to be created."
          }
        ],
        "returns": [
          {
            "name": "inserted_id",
            "type": "Any",
            "description": "The identifier (`ObjectId`) assigned by MongoDB to the newly inserted chat document."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "No other functions are listed as callers of this function."
        }
      },
      "error": null
    },
    "database.db.fetch_chats_by_user": {
      "identifier": "database.db.fetch_chats_by_user",
      "description": {
        "overall": "The function `fetch_chats_by_user` retrieves all chat records associated with a specific user from the MongoDB collection `dbchats`. It filters documents where the `username` field matches the provided username, sorts the results by the `created_at` timestamp in ascending order, and converts the cursor to a Python list. The resulting list of chat documents is then returned to the caller. This operation enables callers to obtain a chronological view of a user's chats.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username of the user whose chats should be fetched."
          }
        ],
        "returns": [
          {
            "name": "chats",
            "type": "list",
            "description": "A list of chat documents (typically dictionaries) belonging to the specified user, ordered by creation time."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "No functions are documented as calling this function."
        }
      },
      "error": null
    },
    "database.db.check_chat_exists": {
      "identifier": "database.db.check_chat_exists",
      "description": {
        "overall": "The function determines whether a chat with a specific name exists for a given user in the MongoDB collection `dbchats`. It constructs a query dictionary containing the `username` and `chat_name` values and passes this to `dbchats.find_one`. The result of `find_one` is compared to `None`; if a document is found the expression evaluates to `True`, otherwise `False`. The implementation consists of a single return statement that encapsulates the entire check.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username associated with the chat to be looked up."
          },
          {
            "name": "chat_name",
            "type": "str",
            "description": "The name of the chat whose existence is being verified."
          }
        ],
        "returns": [
          {
            "name": "",
            "type": "bool",
            "description": "True if a matching chat document exists in `dbchats`, otherwise False."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.rename_chat_fully": {
      "identifier": "database.db.rename_chat_fully",
      "description": {
        "overall": "The function rename_chat_fully renames a chat identified by a username and its current name to a new name. It updates the chat entry in the dbchats collection and then updates all related exchange messages in the dbexchanges collection to reflect the new chat name. The updates are performed using MongoDB update operations. Finally, it returns the number of chat documents that were modified.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username associated with the chat to be renamed."
          },
          {
            "name": "old_name",
            "type": "str",
            "description": "The current name of the chat that will be changed."
          },
          {
            "name": "new_name",
            "type": "str",
            "description": "The new name to assign to the chat and its exchanges."
          }
        ],
        "returns": [
          {
            "name": "",
            "type": "int",
            "description": "The count of chat documents that were modified by the update operation."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.insert_exchange": {
      "identifier": "database.db.insert_exchange",
      "description": {
        "overall": "The function `insert_exchange` creates a new exchange record containing the provided question, answer, feedback, and related metadata, then stores it in a MongoDB collection. It generates a unique identifier using `uuid.uuid4()` and builds a dictionary that includes all arguments together with a creation timestamp. The dictionary is inserted into the `dbexchanges` collection with `insert_one`. If the insertion succeeds, the generated identifier is returned; otherwise the function logs the error and returns `None`.",
        "parameters": [
          {
            "name": "question",
            "type": "str",
            "description": "The text of the user's question."
          },
          {
            "name": "answer",
            "type": "str",
            "description": "The generated answer to the question."
          },
          {
            "name": "feedback",
            "type": "str",
            "description": "Feedback associated with the exchange."
          },
          {
            "name": "username",
            "type": "str",
            "description": "The username of the participant."
          },
          {
            "name": "chat_name",
            "type": "str",
            "description": "The name of the chat session."
          },
          {
            "name": "helper_used",
            "type": "str",
            "description": "Identifier of any helper model used (default empty)."
          },
          {
            "name": "main_used",
            "type": "str",
            "description": "Identifier of the main model used (default empty)."
          },
          {
            "name": "total_time",
            "type": "str",
            "description": "Total time taken for the exchange (default empty)."
          },
          {
            "name": "helper_time",
            "type": "str",
            "description": "Time spent using the helper model (default empty)."
          },
          {
            "name": "main_time",
            "type": "str",
            "description": "Time spent using the main model (default empty)."
          },
          {
            "name": "json_tokens",
            "type": "int",
            "description": "Number of JSON tokens used (default 0)."
          },
          {
            "name": "toon_tokens",
            "type": "int",
            "description": "Number of token units for the toon model (default 0)."
          },
          {
            "name": "savings_percent",
            "type": "float",
            "description": "Percentage of token savings achieved (default 0.0)."
          }
        ],
        "returns": [
          {
            "name": "new_id",
            "type": "str",
            "description": "The UUID string of the newly inserted exchange when insertion succeeds."
          },
          {
            "name": "None",
            "type": "None",
            "description": "Returned when an exception occurs during database insertion."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "No functions are listed as callers of this function."
        }
      },
      "error": null
    },
    "database.db.fetch_exchanges_by_user": {
      "identifier": "database.db.fetch_exchanges_by_user",
      "description": {
        "overall": "The function `fetch_exchanges_by_user` retrieves exchange records associated with a specific username from the MongoDB collection `dbexchanges`. It constructs a query filtering documents where the `username` field matches the provided argument. The resulting cursor is sorted in ascending order by the `created_at` timestamp to ensure chronological ordering, then converted into a Python list. Finally, the list of exchange documents is returned to the caller.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username whose exchange records should be fetched."
          }
        ],
        "returns": [
          {
            "name": "exchanges",
            "type": "list",
            "description": "A list containing the exchange documents for the given user, ordered by creation time."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not referenced by any other functions in the provided context."
        }
      },
      "error": null
    },
    "database.db.fetch_exchanges_by_chat": {
      "identifier": "database.db.fetch_exchanges_by_chat",
      "description": {
        "overall": "The function `fetch_exchanges_by_chat` retrieves exchange records from the MongoDB collection `dbexchanges` for a specific user and chat. It builds a query using the provided `username` and `chat_name`, executes the query, and sorts the results by the `created_at` field in ascending order. The resulting cursor is converted to a Python list. Finally, the list of exchanges is returned to the caller.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username to filter exchanges."
          },
          {
            "name": "chat_name",
            "type": "str",
            "description": "The name of the chat whose exchanges are to be fetched."
          }
        ],
        "returns": [
          {
            "name": "exchanges",
            "type": "list",
            "description": "A list of exchange records matching the given username and chat name, sorted by creation time."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "No functions are listed as calling this function."
        }
      },
      "error": null
    },
    "database.db.update_exchange_feedback": {
      "identifier": "database.db.update_exchange_feedback",
      "description": {
        "overall": "The function updates the feedback value for a specific exchange record in the MongoDB collection `dbexchanges`. It builds a filter using the provided `exchange_id` and sets the `feedback` field to the supplied integer value. The update is performed with `update_one`, and the function captures the operation result. Finally, it returns the number of documents that were modified by the update.",
        "parameters": [
          {
            "name": "exchange_id",
            "type": "Any",
            "description": "The identifier of the exchange document to be updated (e.g., a MongoDB ObjectId or string key)."
          },
          {
            "name": "feedback",
            "type": "int",
            "description": "The integer feedback value to store in the exchange document."
          }
        ],
        "returns": [
          {
            "name": "modified_count",
            "type": "int",
            "description": "The number of documents that were modified by the update operation."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.update_exchange_feedback_message": {
      "identifier": "database.db.update_exchange_feedback_message",
      "description": {
        "overall": "The function updates the `feedback_message` field of a specific exchange document in the database. It receives an exchange identifier and the new feedback message as arguments. It performs a MongoDB `update_one` operation on the `dbexchanges` collection, matching the document by its `_id` and setting the `feedback_message` field. The function returns the count of modified documents, allowing the caller to know whether the update succeeded.",
        "parameters": [
          {
            "name": "exchange_id",
            "type": "Any",
            "description": "Identifier of the exchange document to be updated."
          },
          {
            "name": "feedback_message",
            "type": "str",
            "description": "The new feedback message to set for the exchange."
          }
        ],
        "returns": [
          {
            "name": "modified_count",
            "type": "int",
            "description": "Number of documents modified by the update operation."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.delete_exchange_by_id": {
      "identifier": "database.db.delete_exchange_by_id",
      "description": {
        "overall": "The function deletes a single exchange document from the MongoDB collection `dbexchanges` whose `_id` matches the supplied `exchange_id`. It constructs a filter dictionary with the `_id` field, calls the `delete_one` method on the collection, and captures the operation result. Finally, it returns the `deleted_count` attribute of the result, indicating how many documents were removed. This provides a simple way to remove an exchange by its identifier and know whether the deletion succeeded.",
        "parameters": [
          {
            "name": "exchange_id",
            "type": "str",
            "description": "The identifier of the exchange document to be removed; it is matched against the `_id` field in the collection."
          }
        ],
        "returns": [
          {
            "name": "deleted_count",
            "type": "int",
            "description": "The number of documents deleted (0 if no matching document was found, 1 if the document was successfully removed)."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.delete_full_chat": {
      "identifier": "database.db.delete_full_chat",
      "description": {
        "overall": "The function removes all exchange records associated with a specific chat for a given user, then deletes the chat entry itself from the chat list. It performs the deletions using MongoDB collection operations and returns the number of chat documents that were removed. This ensures consistency between the frontend representation of chats and the backend data store. The implementation consists of a delete_many call on the exchanges collection followed by a delete_one call on the chats collection.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username identifying the owner of the chat to be deleted."
          },
          {
            "name": "chat_name",
            "type": "str",
            "description": "The name of the chat whose exchanges and record should be removed."
          }
        ],
        "returns": [
          {
            "name": "deleted_count",
            "type": "int",
            "description": "The number of chat documents deleted (typically 0 if the chat did not exist, or 1 if it was successfully removed)."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "No other functions call this function."
        }
      },
      "error": null
    },
    "frontend.frontend.clean_names": {
      "identifier": "frontend.frontend.clean_names",
      "description": {
        "overall": "The function `clean_names` takes a collection of model identifier strings and returns a new list containing only the final segment of each identifier. It assumes that each model string uses the forward\u2011slash character (`/`) as a delimiter. Internally, it iterates over the input list with a list comprehension, splits each string on `/`, and selects the last element of the resulting list. The resulting list of cleaned names is returned to the caller.",
        "parameters": [
          {
            "name": "model_list",
            "type": "List[str]",
            "description": "A list of model identifier strings that may contain path\u2011like components separated by '/'."
          }
        ],
        "returns": [
          {
            "name": "",
            "type": "List[str]",
            "description": "A list containing the last segment of each input string, effectively the cleaned model names."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "No other functions are shown to call this function."
        }
      },
      "error": null
    },
    "frontend.frontend.get_filtered_models": {
      "identifier": "frontend.frontend.get_filtered_models",
      "description": {
        "overall": "The function filters a list of model identifiers according to a selected category. It first retrieves the keyword list associated with the given category from the global CATEGORY_KEYWORDS mapping. If the keyword list contains the special token \"STANDARD\", it returns only those models that also appear in the global STANDARD_MODELS collection. Otherwise it builds a filtered list by keeping models whose names contain any of the category keywords (case\u2011insensitive). If no models match, the original source list is returned unchanged.",
        "parameters": [
          {
            "name": "source_list",
            "type": "list[str]",
            "description": "A list of model name strings that should be filtered."
          },
          {
            "name": "category_name",
            "type": "str",
            "description": "The name of the category whose keywords are used for filtering."
          }
        ],
        "returns": [
          {
            "name": "",
            "type": "list[str]",
            "description": "A list of model names that match the category criteria, or the original source list if no matches were found."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "No other functions are recorded as calling this function."
        }
      },
      "error": null
    },
    "frontend.frontend.save_gemini_cb": {
      "identifier": "frontend.frontend.save_gemini_cb",
      "description": {
        "overall": "The `save_gemini_cb` function retrieves a Gemini key from the Streamlit session state, and if a key is present, it updates the stored key in the database, clears the session entry, and displays a success toast. It operates without any input parameters and does not return a value.",
        "parameters": [],
        "returns": [],
        "usage_context": {
          "calls": "This function calls database.db.update_gemini_key.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "frontend.frontend.save_ollama_cb": {
      "identifier": "frontend.frontend.save_ollama_cb",
      "description": {
        "overall": "The function retrieves a potential Ollama URL from Streamlit's session state using the key \"in_ollama_url\". If a non\u2011empty URL is found, it updates the stored Ollama URL for the current user by calling `database.db.update_ollama_url` with the username from session state and the new URL. After successfully updating, it displays a toast notification confirming the save. The function does not return any value.",
        "parameters": [],
        "returns": [],
        "usage_context": {
          "calls": "This function calls database.db.update_ollama_url.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "frontend.frontend.load_data_from_db": {
      "identifier": "frontend.frontend.load_data_from_db",
      "description": {
        "overall": "The function load_data_from_db loads a user's chat and exchange data from the database into Streamlit's session state. It first checks whether the data for the given username has already been loaded, and if not, it clears any existing chat data. It retrieves defined chats via db.fetch_chats_by_user and initializes empty exchange lists for each chat. It then fetches exchanges via db.fetch_exchanges_by_user, ensures each exchange is placed under the correct chat (creating placeholder chats if necessary), and normalizes missing feedback values to NaN. If no chats exist after loading, it creates a default chat in the database and sets it as the active chat; otherwise it ensures an active chat is selected.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username whose chats and exchanges should be loaded from the database."
          }
        ],
        "returns": [],
        "usage_context": {
          "calls": "This function calls database.db.fetch_chats_by_user, database.db.fetch_exchanges_by_user, and database.db.insert_chat.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "frontend.frontend.handle_feedback_change": {
      "identifier": "frontend.frontend.handle_feedback_change",
      "description": {
        "overall": "The function `handle_feedback_change` updates the feedback information for a given exchange record. It accepts an exchange dictionary `ex` and a new feedback value `val`. First, it assigns the new value to the `\"feedback\"` key of the dictionary. Then it persists the change by invoking `database.db.update_exchange_feedback` with the exchange's `_id` and the new feedback value. Finally, it triggers a Streamlit rerun with `st.rerun()` to refresh the UI.",
        "parameters": [
          {
            "name": "ex",
            "type": "dict",
            "description": "A dictionary representing an exchange; it should contain at least the keys \"_id\" and \"feedback\"."
          },
          {
            "name": "val",
            "type": "Any",
            "description": "The new feedback value to be stored in the exchange."
          }
        ],
        "returns": [],
        "usage_context": {
          "calls": "This function calls database.db.update_exchange_feedback.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "frontend.frontend.handle_delete_exchange": {
      "identifier": "frontend.frontend.handle_delete_exchange",
      "description": {
        "overall": "The function removes a specific exchange from persistent storage and from the current Streamlit session state, then forces the app to refresh. It first deletes the exchange in the database by calling `db.delete_exchange_by_id` with the exchange's `_id`. Afterwards it checks whether the provided chat name exists in `st.session_state.chats` and, if so, whether the exchange is listed under that chat's `\"exchanges\"`. If the exchange is present, it is removed from the list. Finally, `st.rerun()` is invoked to trigger a rerun of the Streamlit script.",
        "parameters": [
          {
            "name": "chat_name",
            "type": "str",
            "description": "The identifier of the chat whose exchanges are being managed."
          },
          {
            "name": "ex",
            "type": "dict",
            "description": "A dictionary representing the exchange to delete; it must contain an \"_id\" key used for database deletion."
          }
        ],
        "returns": [],
        "usage_context": {
          "calls": "This function calls database.db.delete_exchange_by_id.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "frontend.frontend.handle_delete_chat": {
      "identifier": "frontend.frontend.handle_delete_chat",
      "description": {
        "overall": "The function handle_delete_chat removes a specific chat for a given user. It first deletes the full chat record from the database via db.delete_full_chat. It then removes the chat from Streamlit's session state and updates the active chat; if no chats remain, it creates a new empty chat named \"Chat 1\" in the database and session state. Finally, it triggers a Streamlit rerun to refresh the UI. The implementation relies on the global db and st objects.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The identifier of the user whose chat is being deleted."
          },
          {
            "name": "chat_name",
            "type": "str",
            "description": "The name of the chat to delete."
          }
        ],
        "returns": [],
        "usage_context": {
          "calls": "This function calls database.db.delete_full_chat and database.db.insert_chat.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "frontend.frontend.extract_repo_name": {
      "identifier": "frontend.frontend.extract_repo_name",
      "description": {
        "overall": "The function searches the provided text for a URL using a regular expression. If a URL is found, it parses the URL to obtain its path component. It then extracts the last segment of the path, removes a trailing \".git\" suffix if present, and returns this segment as the repository name. If no URL or no path segment is found, the function returns None.",
        "parameters": [
          {
            "name": "text",
            "type": "str",
            "description": "The input string that may contain a repository URL."
          }
        ],
        "returns": [
          {
            "name": "",
            "type": "Optional[str]",
            "description": "The extracted repository name without the \".git\" suffix, or None if no valid URL is found."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "frontend.frontend.stream_text_generator": {
      "identifier": "frontend.frontend.stream_text_generator",
      "description": {
        "overall": "The function `stream_text_generator` takes a single string argument and produces a generator that yields the text word by word. It splits the input on spaces, appends a trailing space to each word, and yields the result. After yielding each word, it pauses briefly using `time.sleep(0.01)` to simulate a streaming delay. This design enables incremental consumption of the text, useful for real\u2011time display scenarios.",
        "parameters": [
          {
            "name": "text",
            "type": "str",
            "description": "The input text to be split into individual words."
          }
        ],
        "returns": [
          {
            "name": "",
            "type": "generator",
            "description": "Yields each word from the input text followed by a space, with a short 0.01\u2011second pause between yields."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "frontend.frontend.render_text_with_mermaid": {
      "identifier": "frontend.frontend.render_text_with_mermaid",
      "description": {
        "overall": "The function `render_text_with_mermaid` takes a markdown string and optionally streams its textual parts. It first checks for an empty input and returns early if none is provided. The markdown is split into alternating plain text and mermaid diagram sections using a regular expression. Plain text sections are either streamed via `st.write_stream` or displayed with `st.markdown` based on the `should_stream` flag, while mermaid sections are rendered with `st_mermaid`; if rendering fails, the diagram source is shown as a code block.",
        "parameters": [
          {
            "name": "markdown_text",
            "type": "str",
            "description": "The markdown content that may contain mermaid code blocks."
          },
          {
            "name": "should_stream",
            "type": "bool",
            "description": "Flag indicating whether plain text parts should be streamed (True) or rendered normally (False)."
          }
        ],
        "returns": [],
        "usage_context": {
          "calls": "This function calls frontend.frontend.stream_text_generator.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "frontend.frontend.render_exchange": {
      "identifier": "frontend.frontend.render_exchange",
      "description": {
        "overall": "The `render_exchange` function displays a single exchange (question and answer) within a Streamlit chat interface. It first shows the user's question, then renders the assistant's answer inside a container that includes a toolbar with feedback buttons, a comment pop\u2011over, a download button, and a delete button. Depending on whether the answer starts with an error indicator, it either shows the normal toolbar or an error message with a delete option. Finally, it renders the answer content (including possible Mermaid diagrams) inside a scrollable container. The function interacts with the database and other frontend helpers to record feedback and handle deletion.",
        "parameters": [
          {
            "name": "ex",
            "type": "Any",
            "description": "A dictionary representing the exchange, expected to contain keys such as \"question\", \"answer\", \"feedback\", \"feedback_message\", and \"_id\"."
          },
          {
            "name": "current_chat_name",
            "type": "Any",
            "description": "The name of the chat session to which this exchange belongs, used when handling deletion."
          }
        ],
        "returns": [],
        "usage_context": {
          "calls": "This function calls database.db.update_exchange_feedback_message, frontend.frontend.handle_delete_exchange, frontend.frontend.handle_feedback_change, and frontend.frontend.render_text_with_mermaid.",
          "called_by": "No functions are listed as calling this function."
        }
      },
      "error": null
    }
  },
  "classes": {
    "backend.AST_Schema.ASTVisitor": {
      "identifier": "backend.AST_Schema.ASTVisitor",
      "description": {
        "overall": "The **ASTVisitor** class walks a Python abstract syntax tree (AST) to collect structural information about a source file. It records import statements, class definitions, and function definitions into a unified ``schema`` dictionary. While traversing, it computes the fully\u2011qualified module path of the file using the external ``path_to_module`` helper and maintains a temporary ``_current_class`` context when visiting class bodies. The resulting schema can later be used for downstream analysis such as documentation generation or code indexing.",
        "init_method": {
          "description": "Initializes the visitor with the source code, its file location, and the project root. It computes the module path, prepares an empty schema structure for imports, functions, and classes, and sets up a placeholder for the class currently being visited.",
          "parameters": [
            {
              "name": "source_code",
              "type": "str",
              "description": "The raw Python source code that will be parsed into an AST."
            },
            {
              "name": "file_path",
              "type": "str",
              "description": "Filesystem path to the source file being analysed."
            },
            {
              "name": "project_root",
              "type": "str",
              "description": "Root directory of the project; used together with ``file_path`` to derive the module's import path."
            }
          ]
        },
        "methods": [
          {
            "identifier": "visit_Import",
            "description": {
              "overall": "Processes ``import`` statements encountered in the AST. For each alias in the statement, it records the imported module name into the ``schema['imports']`` list. After updating the schema, it continues the generic AST traversal to visit any child nodes. The method does not return a value.",
              "parameters": [
                {
                  "name": "self",
                  "type": "ASTVisitor",
                  "description": "The instance of the visitor."
                },
                {
                  "name": "node",
                  "type": "ast.Import",
                  "description": "The AST node representing an ``import`` statement."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "The method does not call any other functions.",
                "called_by": "No other methods are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_ImportFrom",
            "description": {
              "overall": "Handles ``from ... import`` statements in the AST. It constructs a fully\u2011qualified import string ``{module}.{name}`` for each alias and appends it to ``schema['imports']``. The generic visitor is then invoked to continue traversal. The method returns nothing.",
              "parameters": [
                {
                  "name": "self",
                  "type": "ASTVisitor",
                  "description": "The instance of the visitor."
                },
                {
                  "name": "node",
                  "type": "ast.ImportFrom",
                  "description": "The AST node representing a ``from ... import`` statement."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "The method does not call any other functions.",
                "called_by": "No other methods are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_ClassDef",
            "description": {
              "overall": "Visits a class definition node in the AST. It builds a unique identifier for the class using the computed ``module_path`` and the class name, then creates a ``class_info`` dictionary containing metadata such as source code, line numbers, and an empty context placeholder. This dictionary is appended to ``schema['classes']`` and stored in ``_current_class`` while the generic visitor processes the class body. After the body is visited, ``_current_class`` is cleared. The method does not return a value.",
              "parameters": [
                {
                  "name": "self",
                  "type": "ASTVisitor",
                  "description": "The instance of the visitor."
                },
                {
                  "name": "node",
                  "type": "ast.ClassDef",
                  "description": "The AST node representing a class definition."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "The method does not call any other functions.",
                "called_by": "No other methods are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_FunctionDef",
            "description": {
              "overall": "Processes a function definition node. If the visitor is currently inside a class (``_current_class`` is set), it records method metadata (identifier, name, arguments, docstring, line numbers) into the class's ``context['method_context']`` list. Otherwise, it creates a top\u2011level function description and adds it to ``schema['functions']``. In both cases, the generic visitor is called to walk the function body. The method returns nothing.",
              "parameters": [
                {
                  "name": "self",
                  "type": "ASTVisitor",
                  "description": "The instance of the visitor."
                },
                {
                  "name": "node",
                  "type": "ast.FunctionDef",
                  "description": "The AST node representing a function definition."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "The method does not call any other functions.",
                "called_by": "No other methods are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_AsyncFunctionDef",
            "description": {
              "overall": "Handles asynchronous function definitions by delegating to ``visit_FunctionDef``. This ensures that async functions are recorded in the same way as regular functions. No additional processing is performed, and the method does not return a value.",
              "parameters": [
                {
                  "name": "self",
                  "type": "ASTVisitor",
                  "description": "The instance of the visitor."
                },
                {
                  "name": "node",
                  "type": "ast.AsyncFunctionDef",
                  "description": "The AST node representing an async function definition."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "The method calls ``visit_FunctionDef`` to process the async function.",
                "called_by": "No other methods are recorded as calling this method."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "The class depends on the function ``path_to_module`` from ``backend.AST_Schema``.",
          "instantiated_by": "No known locations instantiate this class."
        }
      },
      "error": null
    },
    "backend.AST_Schema.ASTAnalyzer": {
      "identifier": "backend.AST_Schema.ASTAnalyzer",
      "description": {
        "overall": "The **ASTAnalyzer** class orchestrates the extraction and enrichment of an abstract\u2011syntax\u2011tree (AST) based schema for a Python code repository. It first walks each Python file with an `ASTVisitor` to collect imports, functions, and classes, assembling this information into a nested dictionary (`full_schema`). Afterwards, it merges external relationship data (outgoing and incoming calls) into the schema, annotating each function and class with call\u2011sites, instantiation sites, and inferred dependencies. By combining structural parsing with relationship mapping, the class provides a comprehensive view of code entities and their interactions within a repository.",
        "init_method": {
          "description": "The constructor of **ASTAnalyzer** performs no initialization work; it simply exists as a placeholder and does not set any instance attributes.",
          "parameters": []
        },
        "methods": [
          {
            "identifier": "merge_relationship_data",
            "description": {
              "overall": "`merge_relationship_data` enriches an existing schema with call\u2011relationship information. It extracts outgoing and incoming call maps from the supplied `raw_relationships` dictionary. For each file and each function in the schema it adds a `calls` list (outgoing) and a `called_by` list (incoming). For each class it records which functions instantiate the class and computes a list of external dependencies based on method calls that do not belong to the same class. Finally, it returns the updated schema dictionary.",
              "parameters": [
                {
                  "name": "full_schema",
                  "type": "dict",
                  "description": "A dictionary representing the current AST\u2011based schema of the repository, structured by file paths."
                },
                {
                  "name": "raw_relationships",
                  "type": "dict",
                  "description": "A dictionary containing two keys, `outgoing` and `incoming`, each mapping entity identifiers to lists of call targets."
                }
              ],
              "returns": [
                {
                  "name": "merged_schema",
                  "type": "dict",
                  "description": "The input `full_schema` dictionary now populated with `calls`, `called_by`, `instantiated_by`, and `dependencies` information."
                }
              ],
              "usage_context": {
                "calls": "This method does not call any other functions or classes.",
                "called_by": "No other functions are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "analyze_repository",
            "description": {
              "overall": "`analyze_repository` builds a complete AST\u2011based schema for a list of repository files. It first determines the common project root and then iterates over each supplied file, skipping non\u2011Python files or empty contents. For each Python file it parses the source with `ast.parse` and walks the tree using an `ASTVisitor`, which extracts imports, functions, and classes into a structured schema. The method aggregates these per\u2011file schemas into a single `full_schema` dictionary and returns it, handling syntax errors gracefully by printing a warning.",
              "parameters": [
                {
                  "name": "files",
                  "type": "list",
                  "description": "A list of file objects, each exposing `path` and `content` attributes representing repository files."
                },
                {
                  "name": "repo",
                  "type": "GitRepository",
                  "description": "An instance representing the Git repository; currently not used directly in the method logic."
                }
              ],
              "returns": [
                {
                  "name": "full_schema",
                  "type": "dict",
                  "description": "A dictionary mapping file paths to their extracted AST node information."
                }
              ],
              "usage_context": {
                "calls": "It calls the `ASTVisitor` class from `backend.AST_Schema` to traverse the parsed AST of each file.",
                "called_by": "No other functions are recorded as calling this method."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "ASTAnalyzer depends on the `ASTVisitor` component from `backend.AST_Schema` to collect AST node information.",
          "instantiated_by": "No other components are recorded as directly instantiating ASTAnalyzer."
        }
      },
      "error": null
    },
    "backend.File_Dependency.FileDependencyGraph": {
      "identifier": "backend.File_Dependency.FileDependencyGraph",
      "description": {
        "overall": "FileDependencyGraph builds a lightweight import\u2011dependency map for a single Python file inside a repository. It walks the AST of the file, records which modules or symbols are imported, and resolves relative imports to concrete module names using helper functions from the backend.File_Dependency package. The collected information is stored in the class\u2011level dictionary `import_dependencies`, keyed by the filename. This enables later stages of the analysis pipeline to understand file\u2011level coupling without executing the code.",
        "init_method": {
          "description": "The constructor stores the target filename and the repository root path that the graph will analyse. These values are later used to locate the file on disk and to resolve relative import statements.",
          "parameters": [
            {
              "name": "filename",
              "type": "str",
              "description": "The name of the Python file (without path) whose imports are to be analysed."
            },
            {
              "name": "repo_root",
              "type": "Any",
              "description": "Root directory of the repository; used to locate files when resolving imports."
            }
          ]
        },
        "methods": [
          {
            "identifier": "_resolve_module_name",
            "description": {
              "overall": "Resolves relative import statements of the form `from .. import name1, name2` to concrete module or symbol names that actually exist in the repository. It first gathers all temporary files in the repository, finds the file that matches the current filename, and then walks up the directory hierarchy according to the import's level depth. For each imported name it checks whether a corresponding module file or an `__init__.py` that exports the symbol exists, using the helper functions `module_file_exists` and `init_exports_symbol`. If no names can be resolved, an ImportError is raised. The function finally returns a sorted list of unique resolved names.",
              "parameters": [
                {
                  "name": "self",
                  "type": "FileDependencyGraph",
                  "description": "Instance of the class."
                },
                {
                  "name": "node",
                  "type": "ImportFrom",
                  "description": "AST node representing a relative import statement."
                }
              ],
              "returns": [
                {
                  "name": "",
                  "type": "list[str]",
                  "description": "A list of resolved module or symbol names that exist relative to the current file."
                }
              ],
              "usage_context": {
                "calls": "It calls `backend.File_Dependency.get_all_temp_files`, `backend.File_Dependency.init_exports_symbol`, and `backend.File_Dependency.module_file_exists` to locate files and verify module or symbol existence.",
                "called_by": "No other methods in this class are recorded as calling `_resolve_module_name`."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_Import",
            "description": {
              "overall": "Handles generic `import` statements encountered during AST traversal. For each alias in the import node it ensures the class\u2011level `import_dependencies` dictionary contains a set for the current file and then adds either the provided `base_name` or the alias name to that set. After processing all aliases it continues the generic AST visit. This method populates the dependency map with direct import targets.",
              "parameters": [
                {
                  "name": "self",
                  "type": "FileDependencyGraph",
                  "description": "Instance of the class."
                },
                {
                  "name": "node",
                  "type": "Import | ImportFrom",
                  "description": "AST node representing an import statement."
                },
                {
                  "name": "base_name",
                  "type": "str | None",
                  "description": "Optional explicit base module name to record instead of the alias name."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method does not call any external functions.",
                "called_by": "It is invoked directly by `visit_ImportFrom` when processing absolute imports."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_ImportFrom",
            "description": {
              "overall": "Processes `from ... import ...` statements. If the import has an explicit module path, it extracts the last component of that path and forwards the node to `visit_Import` with that component as the base name. For relative imports (no module path), it attempts to resolve the module name using the private `_resolve_module_name` method; each resolved base name is then passed to `visit_Import`. Errors during resolution are caught and reported via a printed message. Finally, it continues the generic AST traversal.",
              "parameters": [
                {
                  "name": "self",
                  "type": "FileDependencyGraph",
                  "description": "Instance of the class."
                },
                {
                  "name": "node",
                  "type": "ImportFrom",
                  "description": "AST node representing a `from ... import ...` statement."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "It calls the internal method `_resolve_module_name` when handling relative imports.",
                "called_by": "No other methods in this class are recorded as calling `visit_ImportFrom`."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "The class relies on three external helper functions: `backend.File_Dependency.get_all_temp_files`, `backend.File_Dependency.init_exports_symbol`, and `backend.File_Dependency.module_file_exists`.",
          "instantiated_by": "There are currently no recorded locations where `FileDependencyGraph` is instantiated."
        }
      },
      "error": null
    },
    "backend.HelperLLM.LLMHelper": {
      "identifier": "backend.HelperLLM.LLMHelper",
      "description": {
        "overall": "LLMHelper centralises interaction with a large language model (LLM) for the purpose of generating documentation for functions and classes. It loads system prompts from external files, selects an appropriate LLM provider based on the requested model name, and configures a batch size that matches the capabilities of the chosen model. The class then creates two specialised LLM wrappers \u2013 one for function\u2011level analysis and one for class\u2011level analysis \u2013 both configured to emit JSON\u2011schema compliant output. Public methods expose batch\u2011processing APIs that serialise input models, invoke the LLM in controlled batches, handle rate\u2011limit waiting and errors, and return validated documentation objects.",
        "init_method": {
          "description": "The constructor validates the provided API key, reads the function and class system prompts from the given file paths, determines the appropriate LLM implementation (Gemini, OpenAI, a custom SCADSLLM endpoint, or Ollama) based on the model name, configures a batch size appropriate for that model, and creates structured\u2011output LLM wrappers for function and class analysis. It also stores the raw LLM instance and logs successful initialisation.",
          "parameters": [
            {
              "name": "api_key",
              "type": "str",
              "description": "API key required to authenticate with the selected LLM provider."
            },
            {
              "name": "function_prompt_path",
              "type": "str",
              "description": "Filesystem path to the text file containing the system prompt used for function documentation generation."
            },
            {
              "name": "class_prompt_path",
              "type": "str",
              "description": "Filesystem path to the text file containing the system prompt used for class documentation generation."
            },
            {
              "name": "model_name",
              "type": "str",
              "description": "Identifier of the LLM model to use; defaults to \"gemini-2.0-flash-lite\"."
            },
            {
              "name": "base_url",
              "type": "str | None",
              "description": "Optional base URL for custom LLM endpoints (e.g., Ollama); if omitted, a default URL is used."
            }
          ]
        },
        "methods": [
          {
            "identifier": "_configure_batch_settings",
            "description": {
              "overall": "This private helper method determines the optimal batch size for API calls based on the selected model name. It contains a series of conditional branches that assign a specific integer to `self.batch_size` for known Gemini, Llama, GPT, and custom model identifiers. For models that match a generic pattern (containing a '/' or certain keywords) it falls back to a large batch size of 500. If the model name is not recognised, it logs a warning and conservatively sets the batch size to 2. The method does not return a value; it only mutates the instance state.",
              "parameters": [
                {
                  "name": "model_name",
                  "type": "str",
                  "description": "The name of the LLM model for which a batch size should be configured."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method does not call any other functions.",
                "called_by": "It is invoked by the class constructor to set the initial batch size."
              }
            },
            "error": null
          },
          {
            "identifier": "generate_for_functions",
            "description": {
              "overall": "Generates documentation for a batch of functions by sending structured prompts to the LLM. It first serialises each `FunctionAnalysisInput` into a JSON payload and pairs it with the pre\u2011loaded function system prompt to build a list of conversations. The conversations are processed in chunks of `self.batch_size`; each chunk is sent to `self.function_llm.batch` with a concurrency configuration matching the batch size. Successful results are accumulated, while any exception during a batch call results in `None` placeholders for that chunk. Between batches the method optionally sleeps to respect rate\u2011limit constraints, and finally returns a list containing either `FunctionAnalysis` objects or `None` for each input.",
              "parameters": [
                {
                  "name": "function_inputs",
                  "type": "List[FunctionAnalysisInput]",
                  "description": "A list of input models describing the functions for which documentation should be generated."
                }
              ],
              "returns": [
                {
                  "name": "validated_functions",
                  "type": "List[Optional[FunctionAnalysis]]",
                  "description": "A list where each element is either a `FunctionAnalysis` result from the LLM or `None` if the corresponding batch failed."
                }
              ],
              "usage_context": {
                "calls": "The method does not call any other user\u2011defined functions; it uses standard library utilities and the `self.function_llm` wrapper.",
                "called_by": "No external callers are recorded in the provided context."
              }
            },
            "error": null
          },
          {
            "identifier": "generate_for_classes",
            "description": {
              "overall": "Generates documentation for a batch of classes using the same batching logic as `generate_for_functions`, but with the class\u2011specific system prompt and LLM wrapper. It serialises each `ClassAnalysisInput` to JSON, builds conversations, processes them in batches of `self.batch_size` via `self.class_llm.batch`, and handles errors by inserting `None` placeholders. Rate\u2011limit waiting is applied between batches, and the accumulated list of `ClassAnalysis` results (or `None` values) is returned.",
              "parameters": [
                {
                  "name": "class_inputs",
                  "type": "List[ClassAnalysisInput]",
                  "description": "A list of input models describing the classes for which documentation should be generated."
                }
              ],
              "returns": [
                {
                  "name": "validated_classes",
                  "type": "List[Optional[ClassAnalysis]]",
                  "description": "A list where each element is either a `ClassAnalysis` result from the LLM or `None` if the corresponding batch failed."
                }
              ],
              "usage_context": {
                "calls": "The method does not call any other user\u2011defined functions; it uses standard library utilities and the `self.class_llm` wrapper.",
                "called_by": "No external callers are recorded in the provided context."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "The class does not have external dependencies recorded in the provided context.",
          "instantiated_by": "No information about where this class is instantiated is provided."
        }
      },
      "error": null
    },
    "backend.MainLLM.MainLLM": {
      "identifier": "backend.MainLLM.MainLLM",
      "description": {
        "overall": "The **MainLLM** class provides a unified interface for interacting with a variety of large language\u2011model back\u2011ends (Google Gemini, OpenAI\u2011compatible APIs, Ollama, or a custom SCADSLLM endpoint). It loads a system\u2011prompt from a file, validates the supplied API key, selects the appropriate chat model implementation based on the `model_name` argument, and stores the configured client in `self.llm`. Two public methods are offered: `call_llm` for a single synchronous request and `stream_llm` for a streaming response, both of which automatically prepend the system prompt and handle errors while logging activity.",
        "init_method": {
          "description": "Initialises the MainLLM instance by verifying the provided API key, reading the system prompt from the given file, selecting the correct chat\u2011model wrapper (Google Gemini, OpenAI\u2011compatible, or Ollama) according to the `model_name`, and storing the configured client in `self.llm`. Logging statements record successful initialisation and any configuration issues.",
          "parameters": [
            {
              "name": "api_key",
              "type": "str",
              "description": "API key required by the underlying LLM provider; the constructor raises a ValueError if it is falsy."
            },
            {
              "name": "prompt_file_path",
              "type": "str",
              "description": "Path to a UTF\u20118 encoded file containing the system prompt that will be sent to the LLM on every call."
            },
            {
              "name": "model_name",
              "type": "str",
              "description": "Identifier of the model to use (e.g., \"gemini-2.5-pro\", \"gpt-4\", or a custom model name). Defaults to \"gemini-2.5-pro\"."
            },
            {
              "name": "base_url",
              "type": "str | None",
              "description": "Optional base URL for custom endpoints; used when `model_name` does not match a known provider and no SCADSLLM_URL is set."
            }
          ]
        },
        "methods": [
          {
            "identifier": "call_llm",
            "description": {
              "overall": "The `call_llm` method sends a user\u2011provided text to the configured language model and returns the model's response as a plain string. It builds a message list consisting of the previously loaded system prompt (`SystemMessage`) and the user's input (`HumanMessage`). The method then invokes `self.llm.invoke(messages)` and extracts the `content` attribute from the response object. If any exception occurs during the call, it logs the error and returns `None` instead of propagating the exception.",
              "parameters": [
                {
                  "name": "user_input",
                  "type": "str",
                  "description": "The text supplied by the user that should be processed by the language model."
                }
              ],
              "returns": [
                {
                  "name": "response_content",
                  "type": "str | None",
                  "description": "The content returned by the LLM on success, or `None` if an error was encountered."
                }
              ],
              "usage_context": {
                "calls": "This method does not call any other functions or methods.",
                "called_by": "No other functions or methods are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "stream_llm",
            "description": {
              "overall": "The `stream_llm` method provides a streaming interface to the configured language model. Like `call_llm`, it constructs a message list with the system prompt and the user's input, but instead of a single invoke it calls `self.llm.stream(messages)`. The method iterates over the returned iterator, yielding each chunk's `content` attribute to the caller, which allows incremental processing of the model's output. If an exception is raised during streaming, an error message is logged and yielded as a single string indicating the failure.",
              "parameters": [
                {
                  "name": "user_input",
                  "type": "str",
                  "description": "The text supplied by the user that should be streamed from the language model."
                }
              ],
              "returns": [
                {
                  "name": "streamed_chunks",
                  "type": "Generator[str, None, None]",
                  "description": "A generator yielding each piece of the model's response as a string; on error it yields a formatted error message."
                }
              ],
              "usage_context": {
                "calls": "This method does not call any other functions or methods.",
                "called_by": "No other functions or methods are recorded as calling this method."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "The class does not list any external dependencies in the provided context.",
          "instantiated_by": "No instantiation sites are recorded in the provided context."
        }
      },
      "error": null
    },
    "backend.basic_info.ProjektInfoExtractor": {
      "identifier": "backend.basic_info.ProjektInfoExtractor",
      "description": {
        "overall": "ProjektInfoExtractor ist eine Hilfsklasse, die grundlegende Metadaten eines Software\u2011Projekts aus typischen Projektdateien (README, pyproject.toml, requirements.txt) extrahiert und in einer strukturierten Dictionary\u2011Struktur bereitstellt. Sie sucht die relevanten Dateien, parst deren Inhalt, f\u00fcllt Platzhalter\u2011Eintr\u00e4ge mit gefundenen Informationen und erzeugt bei Bedarf Fallback\u2011Werte (z.\u202fB. aus der Repository\u2011URL). Die Klasse dient als zentrale Quelle f\u00fcr Projekt\u2011\u00dcbersicht und Installations\u2011Hinweise, die von anderen Komponenten weiterverarbeitet werden k\u00f6nnen.",
        "init_method": {
          "description": "Der Konstruktor initialisiert ein Konstante\u2011String\u2011Platzhalter\u2011Token (`INFO_NICHT_GEFUNDEN`) und legt ein verschachteltes `info`\u2011Dictionary an, das sp\u00e4ter mit Projekt\u2011\u00dcbersicht\u2011 und Installations\u2011Daten gef\u00fcllt wird. Es werden keine Eingabeparameter erwartet.",
          "parameters": []
        },
        "methods": [
          {
            "identifier": "_clean_content",
            "description": {
              "overall": "Entfernt Null\u2011Byte\u2011Zeichen (\\x00) aus einem \u00fcbergebenen Text, um Encoding\u2011Probleme zu beheben. Gibt bei leerem Eingabewert sofort einen leeren String zur\u00fcck. Die Bereinigung erfolgt durch Aufruf von `str.replace`. Die Methode ist rein funktional und hat keine Seiteneffekte.",
              "parameters": [
                {
                  "name": "content",
                  "type": "str",
                  "description": "Der zu bereinigende Text, der potenziell Null\u2011Byte\u2011Zeichen enth\u00e4lt."
                }
              ],
              "returns": [
                {
                  "name": "cleaned_content",
                  "type": "str",
                  "description": "Der Eingabetext ohne Null\u2011Byte\u2011Zeichen; ist leer, wenn die Eingabe leer war."
                }
              ],
              "usage_context": {
                "calls": "Der Methode sind laut Kontext keine weiteren Funktionen oder Methoden bekannt.",
                "called_by": "Kein Aufrufer ist im bereitgestellten Kontext verzeichnet."
              }
            },
            "error": null
          },
          {
            "identifier": "_finde_datei",
            "description": {
              "overall": "Durchsucht eine Liste von Datei\u2011Objekten nach dem ersten Objekt, dessen Pfad mit einem der angegebenen Muster (case\u2011insensitiv) endet. Gibt das gefundene Datei\u2011Objekt zur\u00fcck oder `None`, wenn kein Treffer vorliegt. Die Suche erfolgt in einer verschachtelten Schleife \u00fcber Dateien und Muster.",
              "parameters": [
                {
                  "name": "patterns",
                  "type": "List[str]",
                  "description": "Liste von Dateinamen\u2011Endungen bzw. Mustern, nach denen gesucht werden soll."
                },
                {
                  "name": "dateien",
                  "type": "List[Any]",
                  "description": "Liste von Datei\u2011Objekten; jedes Objekt muss ein Attribut `path` besitzen."
                }
              ],
              "returns": [
                {
                  "name": "found_file",
                  "type": "Optional[Any]",
                  "description": "Das erste Datei\u2011Objekt, dessen Pfad zu einem Muster passt, oder `None` wenn kein Treffer gefunden wurde."
                }
              ],
              "usage_context": {
                "calls": "Der Methode sind laut Kontext keine weiteren Aufrufe bekannt.",
                "called_by": "Kein Aufrufer ist im bereitgestellten Kontext verzeichnet."
              }
            },
            "error": null
          },
          {
            "identifier": "_extrahiere_sektion_aus_markdown",
            "description": {
              "overall": "Extrahiert den Text einer Markdown\u2011Sektion, die durch eine \u00dcberschrift der Ebene 2 (`##`) gekennzeichnet ist und zu einem der \u00fcbergebenen Schl\u00fcsselw\u00f6rter passt. Baut ein regul\u00e4res Ausdruck\u2011Pattern aus den Schl\u00fcsselw\u00f6rtern, sucht nach dem entsprechenden Header und gibt den nachfolgenden Text bis zum n\u00e4chsten Header oder Dateiende zur\u00fcck. Liefert `None`, wenn keine passende Sektion gefunden wird.",
              "parameters": [
                {
                  "name": "inhalt",
                  "type": "str",
                  "description": "Der gesamte Markdown\u2011Text, aus dem die Sektion extrahiert werden soll."
                },
                {
                  "name": "keywords",
                  "type": "List[str]",
                  "description": "Liste von m\u00f6glichen \u00dcberschriften\u2011Bezeichnungen, die als Treffer gelten."
                }
              ],
              "returns": [
                {
                  "name": "section_text",
                  "type": "Optional[str]",
                  "description": "Der gefundene Abschnittstext ohne f\u00fchrende/trailing Leerzeichen, oder `None` wenn kein Abschnitt gefunden wurde."
                }
              ],
              "usage_context": {
                "calls": "Der Methode sind laut Kontext keine weiteren Aufrufe bekannt.",
                "called_by": "Kein Aufrufer ist im bereitgestellten Kontext verzeichnet."
              }
            },
            "error": null
          },
          {
            "identifier": "_parse_readme",
            "description": {
              "overall": "Analysiert den Inhalt einer README\u2011Datei und f\u00fcllt das interne `info`\u2011Dictionary mit Titel, Beschreibung, Schl\u00fcssel\u2011Features, Tech\u2011Stack, aktuellem Status sowie Installations\u2011 und Schnellstart\u2011Anleitungen. Nutzt `_clean_content` zur Vorverarbeitung und `_extrahiere_sektion_aus_markdown` f\u00fcr die einzelnen Abschnitte. Setzt Werte nur, wenn sie bislang noch nicht durch andere Quellen belegt sind.",
              "parameters": [
                {
                  "name": "inhalt",
                  "type": "str",
                  "description": "Rohinhalt der README\u2011Datei."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "Der Methode sind laut Kontext keine Aufrufe verzeichnet, obwohl sie intern `_clean_content` und `_extrahiere_sektion_aus_markdown` verwendet.",
                "called_by": "Kein Aufrufer ist im bereitgestellten Kontext verzeichnet."
              }
            },
            "error": null
          },
          {
            "identifier": "_parse_toml",
            "description": {
              "overall": "Parst den Inhalt einer `pyproject.toml`\u2011Datei, extrahiert Projekt\u2011Name, Beschreibung und Abh\u00e4ngigkeiten und speichert sie im `info`\u2011Dictionary. Vor dem Parsen wird der Inhalt mit `_clean_content` bereinigt. Bei fehlender `tomllib`\u2011Bibliothek wird eine Warnung ausgegeben; bei Syntax\u2011Fehlern wird ebenfalls eine Warnung angezeigt.",
              "parameters": [
                {
                  "name": "inhalt",
                  "type": "str",
                  "description": "Der rohe Textinhalt der `pyproject.toml`\u2011Datei."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "Der Methode sind laut Kontext keine Aufrufe verzeichnet, obwohl sie intern `_clean_content` nutzt.",
                "called_by": "Kein Aufrufer ist im bereitgestellten Kontext verzeichnet."
              }
            },
            "error": null
          },
          {
            "identifier": "_parse_requirements",
            "description": {
              "overall": "Verarbeitet den Inhalt einer `requirements.txt`\u2011Datei, entfernt Kommentare und leere Zeilen und speichert die gefundene Liste von Abh\u00e4ngigkeiten im `info`\u2011Dictionary, sofern dort noch keine Abh\u00e4ngigkeiten aus einer TOML\u2011Datei hinterlegt sind. Der Text wird vorher mit `_clean_content` bereinigt.",
              "parameters": [
                {
                  "name": "inhalt",
                  "type": "str",
                  "description": "Der rohe Textinhalt der `requirements.txt`\u2011Datei."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "Der Methode sind laut Kontext keine Aufrufe verzeichnet, obwohl sie intern `_clean_content` verwendet.",
                "called_by": "Kein Aufrufer ist im bereitgestellten Kontext verzeichnet."
              }
            },
            "error": null
          },
          {
            "identifier": "extrahiere_info",
            "description": {
              "overall": "Steuert den gesamten Extraktions\u2011Workflow: Sie sucht nach README, pyproject.toml und requirements.txt mittels `_finde_datei`, parst die gefundenen Dateien in einer definierten Priorit\u00e4tsreihenfolge (TOML \u2192 Requirements \u2192 README) und normalisiert die gesammelten Abh\u00e4ngigkeiten zu einer Aufz\u00e4hlungsliste. Falls kein Titel gefunden wurde, leitet sie diesen aus der Repository\u2011URL ab. Abschlie\u00dfend gibt sie das vollst\u00e4ndig bef\u00fcllte `info`\u2011Dictionary zur\u00fcck.",
              "parameters": [
                {
                  "name": "dateien",
                  "type": "List[Any]",
                  "description": "Liste von Datei\u2011Objekten, die mindestens ein Attribut `path` und `content` besitzen."
                },
                {
                  "name": "repo_url",
                  "type": "str",
                  "description": "URL des Git\u2011Repositories; wird verwendet, um einen Titel abzuleiten, falls keiner gefunden wurde."
                }
              ],
              "returns": [
                {
                  "name": "info",
                  "type": "Dict[str, Any]",
                  "description": "Strukturiertes Dictionary mit Projekt\u2011\u00dcbersicht und Installations\u2011Informationen."
                }
              ],
              "usage_context": {
                "calls": "Der Methode sind laut Kontext keine Aufrufe verzeichnet, obwohl sie intern `_finde_datei`, `_parse_toml`, `_parse_requirements`, `_parse_readme` und Standard\u2011Bibliotheksfunktionen nutzt.",
                "called_by": "Kein Aufrufer ist im bereitgestellten Kontext verzeichnet."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "Es liegen keine externen Abh\u00e4ngigkeiten f\u00fcr diese Klasse vor.",
          "instantiated_by": "Die Klasse wird in den bereitgestellten Kontextdaten an keiner Stelle instanziiert."
        }
      },
      "error": null
    },
    "backend.callgraph.CallGraph": {
      "identifier": "backend.callgraph.CallGraph",
      "description": {
        "overall": "The **CallGraph** class is a concrete implementation of ``ast.NodeVisitor`` that walks through the abstract syntax tree of a Python source file and builds a directed call graph of all functions, methods and their relationships. It records imports, class definitions and resolves callee names to fully\u2011qualified identifiers that include the originating file, class (if any) and function name. The resulting graph is stored in a ``networkx.DiGraph`` together with auxiliary mappings that allow later analysis of call dependencies across the module.",
        "init_method": {
          "description": "Initialises a new ``CallGraph`` for a specific source file. The constructor stores the filename, prepares internal state for tracking the current function and class while creating containers for local definitions, import mappings, the graph structure and edge collections.",
          "parameters": [
            {
              "name": "filename",
              "type": "str",
              "description": "The path or name of the Python file that will be analysed."
            }
          ]
        },
        "methods": [
          {
            "identifier": "_recursive_call",
            "description": {
              "overall": "Recursively extracts the dotted name components from an ``ast.Call`` node. It walks down the AST, handling ``ast.Call`` (by recursing into ``node.func``), ``ast.Name`` (returning the identifier) and ``ast.Attribute`` (building a list of attribute names). The result is a list of strings representing the hierarchical name parts, e.g. ``['pkg', 'mod', 'Class', 'method']``. If the node type is not recognised, an empty list is returned.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.AST",
                  "description": "The AST node representing a function call or name that should be decomposed into its constituent parts."
                }
              ],
              "returns": [
                {
                  "name": "",
                  "type": "list[str]",
                  "description": "A list of name components extracted from the node, ordered from the outermost to the innermost element."
                }
              ],
              "usage_context": {
                "calls": "This method does not call any other functions.",
                "called_by": "No other functions are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "_resolve_all_callee_names",
            "description": {
              "overall": "Converts a collection of name\u2011step lists (as produced by ``_recursive_call``) into fully qualified callee identifiers. For each list it first checks whether the simple name or a dotted variant exists in the ``local_defs`` mapping, then looks up possible import aliases via ``import_mapping``. If no mapping is found it falls back to constructing a name that includes the current filename and, when inside a class, the class name. The method returns a list of resolved callee strings ready to be added to the call graph.",
              "parameters": [
                {
                  "name": "callee_nodes",
                  "type": "list[list[str]]",
                  "description": "A list where each element is a list of name components representing a potential callee."
                }
              ],
              "returns": [
                {
                  "name": "",
                  "type": "list[str]",
                  "description": "A list of fully qualified callee names resolved according to local definitions, imports and the current file context."
                }
              ],
              "usage_context": {
                "calls": "This method does not call any other functions.",
                "called_by": "No other functions are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "_make_full_name",
            "description": {
              "overall": "Creates a fully qualified identifier string for a function or method based on the stored filename, an optional class name and a base name. If a class name is supplied the format is ``{filename}::{class_name}::{basename}``; otherwise it is ``{filename}::{basename}``. This helper is used when registering functions in the internal mappings and the call graph.",
              "parameters": [
                {
                  "name": "basename",
                  "type": "str",
                  "description": "The simple name of the function or method."
                },
                {
                  "name": "class_name",
                  "type": "str | None",
                  "description": "The name of the enclosing class, if the function is a method; otherwise ``None``."
                }
              ],
              "returns": [
                {
                  "name": "",
                  "type": "str",
                  "description": "A fully qualified name in the form ``filename::[class_name::]basename``."
                }
              ],
              "usage_context": {
                "calls": "This method does not call any other functions.",
                "called_by": "No other functions are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "_current_caller",
            "description": {
              "overall": "Determines the identifier of the function currently being visited. If ``self.current_function`` is set, it returns that value; otherwise it falls back to a placeholder that includes the filename or a generic ``<global-scope>`` token. This identifier is used as the source node when recording call edges.",
              "parameters": [
                {
                  "name": "self",
                  "type": "CallGraph",
                  "description": "The instance of the CallGraph visitor."
                }
              ],
              "returns": [
                {
                  "name": "",
                  "type": "str",
                  "description": "The identifier of the current caller context."
                }
              ],
              "usage_context": {
                "calls": "This method does not call any other functions.",
                "called_by": "No other functions are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_Import",
            "description": {
              "overall": "Handles ``import`` statements encountered during the AST walk. For each alias it records a mapping from the imported name (or its ``as`` alias) to the original module name in ``self.import_mapping``. After updating the mapping it continues the generic visitation of child nodes.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.Import",
                  "description": "The AST node representing an ``import`` statement."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls ``self.generic_visit`` to continue traversing child nodes.",
                "called_by": "No other functions are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_ImportFrom",
            "description": {
              "overall": "Processes ``from ... import ...`` statements. It extracts the originating module (using the last component of the dotted module path) and stores a mapping from each imported name (or its alias) to that module name in ``self.import_mapping``. No further traversal is required beyond the generic visit.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.ImportFrom",
                  "description": "The AST node representing a ``from ... import`` statement."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls ``self.generic_visit`` to continue traversing child nodes.",
                "called_by": "No other functions are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_ClassDef",
            "description": {
              "overall": "Visits a class definition node. It saves the current class name, updates ``self.current_class`` while recursively visiting the class body, and restores the previous class context after traversal. This enables proper name resolution for methods defined inside the class.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.ClassDef",
                  "description": "The AST node representing a class definition."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls ``self.generic_visit`` to walk the class body.",
                "called_by": "No other functions are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_FunctionDef",
            "description": {
              "overall": "Handles a regular function or method definition. It builds a fully qualified name using ``_make_full_name`` (including the enclosing class if present) and stores it in ``self.local_defs`` for later resolution. The function name is also added to ``self.graph`` as a node, the visitor state ``self.current_function`` is updated while traversing the function body, and finally the function is added to ``self.function_set``. After processing, the previous function context is restored.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.FunctionDef",
                  "description": "The AST node representing a function or method definition."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls ``self._make_full_name`` and ``self.generic_visit`` during its execution.",
                "called_by": "No other functions are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_AsyncFunctionDef",
            "description": {
              "overall": "Treats an ``async def`` function the same way as a regular function by delegating to ``visit_FunctionDef``. This ensures that asynchronous functions are also added to the call graph with the same handling logic.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.AsyncFunctionDef",
                  "description": "The AST node representing an asynchronous function definition."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls ``self.visit_FunctionDef`` to reuse the standard function handling logic.",
                "called_by": "No other functions are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_Call",
            "description": {
              "overall": "Processes a function call expression. It determines the current caller identifier, extracts the callee name components via ``_recursive_call``, resolves them to fully qualified names with ``_resolve_all_callee_names``, and records an edge from the caller to each resolved callee in ``self.edges``. The method then continues generic visitation of the call's arguments.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.Call",
                  "description": "The AST node representing a function call."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls ``self._current_caller``, ``self._recursive_call``, ``self._resolve_all_callee_names`` and ``self.generic_visit``.",
                "called_by": "No other functions are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_If",
            "description": {
              "overall": "Visits an ``if`` statement. If the test condition is a comparison that checks ``__name__`` (i.e., the typical ``if __name__ == '__main__'`` guard), it temporarily sets ``self.current_function`` to ``<main_block>`` while traversing the block, then restores the previous context. For all other ``if`` statements it simply continues generic visitation.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.If",
                  "description": "The AST node representing an ``if`` statement."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls ``self.generic_visit`` to walk the body of the ``if`` statement.",
                "called_by": "No other functions are recorded as calling this method."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "The class does not have external dependencies beyond the imports listed (standard library ``ast`` and third\u2011party ``networkx``).",
          "instantiated_by": "No instantiation sites are provided in the supplied context."
        }
      },
      "error": null
    },
    "backend.getRepo.RepoFile": {
      "identifier": "backend.getRepo.RepoFile",
      "description": {
        "overall": "The **RepoFile** class models a single file inside a Git repository. It lazily loads the underlying Git blob, its decoded text content, and its size only when those properties are accessed, which avoids unnecessary I/O. In addition to basic accessors, it provides helper utilities for a readable representation, a simple word\u2011count analysis, and conversion of the file\u2019s metadata (and optionally its content) into a plain dictionary.",
        "init_method": {
          "description": "The constructor stores the repository\u2011relative path of the file and the commit tree from which the file originates. It also prepares internal placeholders for the Git blob, the decoded content, and the file size, all of which are loaded lazily on first access.",
          "parameters": [
            {
              "name": "file_path",
              "type": "str",
              "description": "Der Pfad zur Datei innerhalb des Repositories."
            },
            {
              "name": "commit_tree",
              "type": "git.Tree",
              "description": "Das Tree\u2011Objekt des Commits, aus dem die Datei stammt."
            }
          ]
        },
        "methods": [
          {
            "identifier": "blob",
            "description": {
              "overall": "The **blob** property lazily retrieves the Git blob object that corresponds to the file path from the stored commit tree. If the blob has not been fetched yet, it attempts to index the tree with the path; a missing entry raises a **FileNotFoundError**. Once retrieved, the blob is cached in the private attribute ``_blob`` for subsequent accesses. This property enables other methods to obtain raw binary data, size, and other blob metadata without repeatedly querying the repository.",
              "parameters": [
                {
                  "name": "self",
                  "type": "RepoFile",
                  "description": "The instance on which the property is accessed."
                }
              ],
              "returns": [
                {
                  "name": "blob",
                  "type": "git.Blob",
                  "description": "The Git blob object representing the file's contents."
                }
              ],
              "usage_context": {
                "calls": "This method does not call any other functions.",
                "called_by": "No other functions are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "content",
            "description": {
              "overall": "The **content** property provides the decoded text of the file. On first access it reads the raw data stream from the lazily\u2011loaded blob, decodes it as UTF\u20118 while ignoring errors, and caches the resulting string in ``_content``. Subsequent accesses return the cached string, avoiding repeated I/O and decoding. This makes the property suitable for read\u2011only text processing tasks.",
              "parameters": [
                {
                  "name": "self",
                  "type": "RepoFile",
                  "description": "The instance on which the property is accessed."
                }
              ],
              "returns": [
                {
                  "name": "content",
                  "type": "str",
                  "description": "The decoded UTF\u20118 content of the file."
                }
              ],
              "usage_context": {
                "calls": "This method does not call any other functions.",
                "called_by": "No other functions are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "size",
            "description": {
              "overall": "The **size** property returns the size of the file in bytes. It lazily accesses the underlying blob's ``size`` attribute, caches the integer in ``_size``, and reuses the cached value on subsequent calls. This provides a cheap way to obtain file length without loading the full content.",
              "parameters": [
                {
                  "name": "self",
                  "type": "RepoFile",
                  "description": "The instance on which the property is accessed."
                }
              ],
              "returns": [
                {
                  "name": "size",
                  "type": "int",
                  "description": "The size of the file in bytes."
                }
              ],
              "usage_context": {
                "calls": "This method does not call any other functions.",
                "called_by": "No other functions are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "analyze_word_count",
            "description": {
              "overall": "The **analyze_word_count** method demonstrates a simple analysis routine: it splits the lazily loaded text content into whitespace\u2011separated tokens and returns the count of those tokens. This provides a quick word\u2011count metric for the file's content and showcases how other analyses could be built on top of the ``content`` property.",
              "parameters": [
                {
                  "name": "self",
                  "type": "RepoFile",
                  "description": "The instance whose content is to be analyzed."
                }
              ],
              "returns": [
                {
                  "name": "word_count",
                  "type": "int",
                  "description": "The number of words found in the file's content."
                }
              ],
              "usage_context": {
                "calls": "This method does not call any other functions.",
                "called_by": "No other functions are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "__repr__",
            "description": {
              "overall": "The **__repr__** method returns a concise, developer\u2011friendly string that identifies the ``RepoFile`` instance by its path. This representation is useful for debugging and logging, as it clearly shows which repository file an object corresponds to.",
              "parameters": [
                {
                  "name": "self",
                  "type": "RepoFile",
                  "description": "The instance to represent."
                }
              ],
              "returns": [
                {
                  "name": "repr_str",
                  "type": "str",
                  "description": "A string of the form ``<RepoFile(path='...')>``."
                }
              ],
              "usage_context": {
                "calls": "This method does not call any other functions.",
                "called_by": "No other functions are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "to_dict",
            "description": {
              "overall": "The **to_dict** method serializes the file's metadata into a plain Python dictionary. It always includes the file's path, base name, size, and a fixed type value of ``\"file\"``. When the optional ``include_content`` flag is set to ``True``, the decoded file content is also added under the ``\"content\"`` key. This method is handy for converting ``RepoFile`` objects into JSON\u2011serializable structures for APIs or storage.",
              "parameters": [
                {
                  "name": "self",
                  "type": "RepoFile",
                  "description": "The instance to serialize."
                },
                {
                  "name": "include_content",
                  "type": "bool",
                  "description": "If ``True``, the file's decoded content is added to the output dictionary."
                }
              ],
              "returns": [
                {
                  "name": "data",
                  "type": "dict",
                  "description": "A dictionary containing the file's metadata and optionally its content."
                }
              ],
              "usage_context": {
                "calls": "This method does not call any other functions.",
                "called_by": "No other functions are recorded as calling this method."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "The class does not have external dependencies listed.",
          "instantiated_by": "No instantiation sites are recorded for this class."
        }
      },
      "error": null
    },
    "backend.getRepo.GitRepository": {
      "identifier": "backend.getRepo.GitRepository",
      "description": {
        "overall": "The **GitRepository** class encapsulates the lifecycle of a remote Git repository for the backend. It clones the repository into a temporary directory, exposes the list of files as `RepoFile` objects, and can build a hierarchical representation of the repository\u2019s file tree. The class also implements the context\u2011manager protocol so it can be used with a `with` statement, ensuring the temporary directory is cleaned up automatically. Its responsibilities are limited to repository access, file enumeration, and cleanup, delegating actual file content handling to the `RepoFile` helper.",
        "init_method": {
          "description": "The constructor receives a repository URL, creates a temporary directory, and attempts to clone the remote repository into that directory. Upon successful cloning it stores references to the repository object, the latest commit, and the commit tree, while also preparing an empty list for later file objects.",
          "parameters": [
            {
              "name": "repo_url",
              "type": "str",
              "description": "The HTTPS (or SSH) URL of the Git repository to be cloned."
            }
          ]
        },
        "methods": [
          {
            "identifier": "get_all_files",
            "description": {
              "overall": "`get_all_files` enumerates every file tracked in the cloned repository by invoking `git ls-files`. It splits the output into individual paths, creates a `RepoFile` instance for each path using the commit tree, and stores the resulting objects in the instance attribute `self.files`. The method then returns the populated list of `RepoFile` objects. This provides callers with a convenient collection of file representations that can later be inspected for content or metadata.",
              "parameters": [
                {
                  "name": "self",
                  "type": "GitRepository",
                  "description": "The instance on which the method operates."
                }
              ],
              "returns": [
                {
                  "name": "files",
                  "type": "list[RepoFile]",
                  "description": "A list of `RepoFile` instances, each representing a file in the repository."
                }
              ],
              "usage_context": {
                "calls": "This method calls the `RepoFile` class to wrap each file path into an object.",
                "called_by": "No other functions are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "close",
            "description": {
              "overall": "`close` is responsible for cleaning up the temporary directory created during initialization. If the temporary directory path is still stored, it prints a message indicating the deletion and then clears the `self.temp_dir` reference. The actual removal of the directory\u2019s contents is left to the operating system when the temporary directory object is garbage\u2011collected. This method is also invoked automatically by the context\u2011manager exit routine.",
              "parameters": [
                {
                  "name": "self",
                  "type": "GitRepository",
                  "description": "The instance on which the method operates."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method does not call any external functions.",
                "called_by": "It is called by the `__exit__` method and may also be invoked manually."
              }
            },
            "error": null
          },
          {
            "identifier": "__enter__",
            "description": {
              "overall": "`__enter__` implements the entry part of the context\u2011manager protocol. It simply returns the repository instance itself, allowing the caller to use the object within a `with` block. No additional setup is performed because the constructor already performed cloning and initialization.",
              "parameters": [
                {
                  "name": "self",
                  "type": "GitRepository",
                  "description": "The instance being entered."
                }
              ],
              "returns": [
                {
                  "name": "self",
                  "type": "GitRepository",
                  "description": "The repository instance, enabling attribute access inside the `with` block."
                }
              ],
              "usage_context": {
                "calls": "This method does not call any external functions.",
                "called_by": "It is invoked automatically when the class is used in a `with` statement."
              }
            },
            "error": null
          },
          {
            "identifier": "__exit__",
            "description": {
              "overall": "`__exit__` implements the exit part of the context\u2011manager protocol. Regardless of whether an exception occurred, it calls `self.close()` to ensure the temporary directory is cleaned up. The method accepts the standard exception information parameters but does not use them, allowing normal suppression behavior.",
              "parameters": [
                {
                  "name": "self",
                  "type": "GitRepository",
                  "description": "The instance being exited."
                },
                {
                  "name": "exc_type",
                  "type": "type | None",
                  "description": "The exception type, if an exception was raised inside the `with` block."
                },
                {
                  "name": "exc_val",
                  "type": "BaseException | None",
                  "description": "The exception instance raised inside the `with` block."
                },
                {
                  "name": "exc_tb",
                  "type": "TracebackType | None",
                  "description": "The traceback object associated with the exception."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls `close` to perform cleanup.",
                "called_by": "It is invoked automatically when exiting a `with` block that uses the class."
              }
            },
            "error": null
          },
          {
            "identifier": "get_file_tree",
            "description": {
              "overall": "`get_file_tree` builds a nested dictionary representing the directory structure of the repository. If the file list has not yet been populated, it first calls `self.get_all_files()` to retrieve all `RepoFile` objects. It then iterates over each file, splitting its path into components and constructing intermediate directory nodes as needed, finally inserting each file\u2019s dictionary representation (optionally including its content) as a leaf node. The resulting tree starts with a root node named \"root\" and mirrors the repository\u2019s folder hierarchy.",
              "parameters": [
                {
                  "name": "self",
                  "type": "GitRepository",
                  "description": "The instance on which the method operates."
                },
                {
                  "name": "include_content",
                  "type": "bool",
                  "description": "If true, the file dictionaries will contain the file\u2019s content; otherwise only metadata is included."
                }
              ],
              "returns": [
                {
                  "name": "tree",
                  "type": "dict",
                  "description": "A nested dictionary representing the repository\u2019s directory tree, with each node containing `name`, `type`, and `children`."
                }
              ],
              "usage_context": {
                "calls": "This method calls `get_all_files` when the file list is empty.",
                "called_by": "No other functions are recorded as calling this method."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "The class depends on the external `RepoFile` helper from `backend.getRepo.RepoFile` to represent individual files.",
          "instantiated_by": "No instantiation points were provided in the context."
        }
      },
      "error": null
    },
    "backend.relationship_analyzer.ProjectAnalyzer": {
      "identifier": "backend.relationship_analyzer.ProjectAnalyzer",
      "description": {
        "overall": "ProjectAnalyzer walks a Python project directory, parses each source file into an AST, collects definitions of functions, classes, and methods, and then resolves call relationships between them. It builds a call\u2011graph where each callee is mapped to a list of caller information, and can expose the raw outgoing and incoming relationships as simple dictionaries. The class hides the details of filesystem traversal, AST handling, and call\u2011resolution behind a small public API (analyze and get_raw_relationships). It is intended to be used as a reusable component for static analysis of code\u2011base relationships.",
        "init_method": {
          "description": "The constructor stores the absolute path of the project root and initializes internal data structures for definitions, the call graph, cached ASTs, and a set of directory names to ignore during traversal.",
          "parameters": [
            {
              "name": "project_root",
              "type": "str",
              "description": "Root directory of the project to be analyzed."
            }
          ]
        },
        "methods": [
          {
            "identifier": "analyze",
            "description": {
              "overall": "The analyze method orchestrates the full analysis workflow. It first discovers all Python files under the project root, then iterates over those files to collect definitions of functions, classes, and methods. A second pass resolves call relationships for each file, populating the internal call_graph. After processing, it clears the cached ASTs to free memory and finally returns the constructed call graph.",
              "parameters": [],
              "returns": [
                {
                  "name": "",
                  "type": "defaultdict(list)",
                  "description": "A mapping from callee identifiers to a list of caller information dictionaries."
                }
              ],
              "usage_context": {
                "calls": "This method does not call any other methods directly.",
                "called_by": "No recorded callers for this method."
              }
            },
            "error": null
          },
          {
            "identifier": "get_raw_relationships",
            "description": {
              "overall": "get_raw_relationships transforms the internal call graph into two dictionaries that describe outgoing and incoming relationships. It iterates over each callee and its list of caller info, populating sets of outgoing edges (caller \u2192 callee) and incoming edges (callee \u2190 caller). The sets are then converted to sorted lists for deterministic output. Finally, it returns a dictionary containing both the outgoing and incoming relationship mappings.",
              "parameters": [],
              "returns": [
                {
                  "name": "",
                  "type": "dict",
                  "description": "A dictionary with keys \"outgoing\" and \"incoming\", each mapping identifiers to sorted lists of related identifiers."
                }
              ],
              "usage_context": {
                "calls": "This method does not call any other methods.",
                "called_by": "No recorded callers for this method."
              }
            },
            "error": null
          },
          {
            "identifier": "_find_py_files",
            "description": {
              "overall": "_find_py_files walks the project directory tree starting at the stored project_root. It filters out any directories listed in the ignore_dirs set to avoid processing virtual environments, version\u2011control metadata, and build artefacts. For each file that ends with \".py\", it records the absolute path. The method returns the collected list of Python file paths.",
              "parameters": [],
              "returns": [
                {
                  "name": "",
                  "type": "list[str]",
                  "description": "A list of absolute file paths for all discovered Python source files."
                }
              ],
              "usage_context": {
                "calls": "This method does not call any other methods.",
                "called_by": "No recorded callers for this method."
              }
            },
            "error": null
          },
          {
            "identifier": "_collect_definitions",
            "description": {
              "overall": "_collect_definitions reads a Python source file, parses it into an abstract syntax tree (AST), and stores the tree for later use. It determines the module path for the file using the external helper path_to_module. It then walks the AST to locate function, class, and method definitions, recording their fully\u2011qualified names, file location, line number, and type (function, method, or class) in the definitions dictionary. Any errors encountered while reading or parsing the file are logged, and a None placeholder is stored for that file's AST.",
              "parameters": [
                {
                  "name": "filepath",
                  "type": "str",
                  "description": "Absolute path to the Python source file to be processed."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls backend.relationship_analyzer.path_to_module to compute the module path for the given file.",
                "called_by": "No recorded callers for this method."
              }
            },
            "error": null
          },
          {
            "identifier": "_get_parent",
            "description": {
              "overall": "_get_parent searches the AST for the immediate parent node of a given node. It walks the entire tree, examining each node's children until it finds the child that matches the target node, then returns that parent. If no parent is found, it returns None. This helper is used to distinguish whether a function definition belongs to a class (method) or is a top\u2011level function.",
              "parameters": [
                {
                  "name": "tree",
                  "type": "ast.AST",
                  "description": "The root AST node of a parsed Python file."
                },
                {
                  "name": "node",
                  "type": "ast.AST",
                  "description": "The AST node whose parent is being sought."
                }
              ],
              "returns": [
                {
                  "name": "",
                  "type": "ast.AST or None",
                  "description": "The parent node of the supplied node, or None if not found."
                }
              ],
              "usage_context": {
                "calls": "This method does not call any other methods.",
                "called_by": "No recorded callers for this method."
              }
            },
            "error": null
          },
          {
            "identifier": "_resolve_calls",
            "description": {
              "overall": "_resolve_calls retrieves the previously stored AST for a given file and, if present, creates a CallResolverVisitor instance (from backend.relationship_analyzer) to walk the tree. The visitor collects call relationships, which are then merged into the class's call_graph dictionary. Errors during visitation are caught and logged, ensuring the analysis continues for other files.",
              "parameters": [
                {
                  "name": "filepath",
                  "type": "str",
                  "description": "Absolute path to the Python source file whose calls are to be resolved."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls backend.relationship_analyzer.CallResolverVisitor to perform the AST visitation and call extraction.",
                "called_by": "No recorded callers for this method."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "The class depends on CallResolverVisitor and path_to_module from backend.relationship_analyzer.",
          "instantiated_by": "No recorded locations instantiate this class."
        }
      },
      "error": null
    },
    "backend.relationship_analyzer.CallResolverVisitor": {
      "identifier": "backend.relationship_analyzer.CallResolverVisitor",
      "description": {
        "overall": "The **CallResolverVisitor** walks a Python abstract syntax tree (AST) to discover where functions, methods, and class constructors are invoked within a module. It resolves imported names, tracks variable assignments that instantiate known classes, and records each call with contextual metadata such as the caller's fully\u2011qualified name, file, line number, and caller type (module, function, method, or local function). All discovered relationships are stored in a ``defaultdict(list)`` called ``calls`` keyed by the callee's qualified pathname, enabling later analysis of call graphs across the project.",
        "init_method": {
          "description": "The constructor stores the path of the file being analysed, computes its module pathname via ``path_to_module``, and records the supplied definitions mapping. It also initialises several bookkeeping structures \u2013 a scope dictionary for import resolution, an instance\u2011type map for variable\u2011to\u2011class tracking, placeholders for the current caller and class names, and a ``defaultdict(list)`` to accumulate call information.",
          "parameters": [
            {
              "name": "filepath",
              "type": "str",
              "description": "Absolute or relative path to the source file whose AST is being visited."
            },
            {
              "name": "project_root",
              "type": "str",
              "description": "Root directory of the project; used together with ``filepath`` to compute the module's dotted path."
            },
            {
              "name": "definitions",
              "type": "dict",
              "description": "Mapping of fully\u2011qualified names (functions, classes, etc.) that are considered known call targets."
            }
          ]
        },
        "methods": [
          {
            "identifier": "visit_ClassDef",
            "description": {
              "overall": "When the visitor encounters a ``ClassDef`` node, it temporarily records the class name in ``self.current_class_name`` so that any nested functions can be identified as methods. It then recursively visits the class body via ``generic_visit`` to process inner definitions and calls. After the traversal, the original class context is restored. This method does not invoke any external helpers.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.ClassDef",
                  "description": "The AST node representing the class definition."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method does not call any other functions.",
                "called_by": "No recorded functions or methods call ``visit_ClassDef``."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_FunctionDef",
            "description": {
              "overall": "For each ``FunctionDef`` node, the visitor builds a fully\u2011qualified identifier that includes the module path, optional class name, and the function name. This identifier is stored in ``self.current_caller_name`` so that subsequent ``Call`` nodes can be attributed to the correct caller. The method then walks the function body with ``generic_visit`` and finally restores the previous caller context. No external functions are invoked.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.FunctionDef",
                  "description": "The AST node representing the function or method definition."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method does not call any other functions.",
                "called_by": "No recorded functions or methods call ``visit_FunctionDef``."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_Call",
            "description": {
              "overall": "When a ``Call`` node is visited, the method attempts to resolve the callee's fully\u2011qualified name using the private helper ``_resolve_call_qname``. If the name is found in the supplied ``definitions`` mapping, the visitor determines the caller type (module, function, method, or local function) based on the current context. It then creates a ``caller_info`` dictionary containing the source file, line number, caller identifier, and caller type, and appends this information to ``self.calls`` under the callee's pathname. Finally, it continues traversing any child nodes.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.Call",
                  "description": "The AST node representing the function or method call."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls the private helper ``_resolve_call_qname`` to resolve the callee name.",
                "called_by": "No recorded functions or methods call ``visit_Call`` directly; it is invoked automatically by the ``ast.NodeVisitor`` traversal."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_Import",
            "description": {
              "overall": "For each ``Import`` statement, the visitor records the imported module names in ``self.scope``. It maps the alias (or the original name if no alias is provided) to the fully\u2011qualified module name, enabling later name resolution. After updating the scope, it proceeds with a generic visit of the node's children.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.Import",
                  "description": "The AST node representing an ``import`` statement."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method does not call any other functions.",
                "called_by": "No recorded functions or methods call ``visit_Import`` directly; it is invoked automatically by the ``ast.NodeVisitor`` traversal."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_ImportFrom",
            "description": {
              "overall": "When processing a ``ImportFrom`` node, the visitor resolves relative imports by adjusting the current module path according to ``node.level``. It then records each imported name (or its alias) in ``self.scope`` with a fully\u2011qualified pathname that includes the originating module. This enables later resolution of names used in calls or attribute accesses. The method finishes by recursively visiting any child nodes.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.ImportFrom",
                  "description": "The AST node representing a ``from ... import ...`` statement."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method does not call any other functions.",
                "called_by": "No recorded functions or methods call ``visit_ImportFrom`` directly; it is invoked automatically by the ``ast.NodeVisitor`` traversal."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_Assign",
            "description": {
              "overall": "During an ``Assign`` node visit, the method checks whether the right\u2011hand side is a call to a name that resolves to a known class (via ``self.scope`` and ``self.definitions``). If so, it records the variable name on the left\u2011hand side in ``self.instance_types`` with the qualified class pathname. This mapping later assists ``_resolve_call_qname`` in resolving method calls on instance variables. The visitor then continues the generic traversal.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.Assign",
                  "description": "The AST node representing an assignment statement."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method does not call any other functions.",
                "called_by": "No recorded functions or methods call ``visit_Assign`` directly; it is invoked automatically by the ``ast.NodeVisitor`` traversal."
              }
            },
            "error": null
          },
          {
            "identifier": "_resolve_call_qname",
            "description": {
              "overall": "This private helper attempts to translate a function/method AST node into its fully\u2011qualified dotted name. For simple ``Name`` nodes it first looks up the name in ``self.scope`` and then falls back to a module\u2011local lookup. For ``Attribute`` nodes where the base is a ``Name``, it resolves either an instance variable (using ``self.instance_types``) or a module name (using ``self.scope``) and appends the attribute. If resolution fails, ``None`` is returned.",
              "parameters": [
                {
                  "name": "func_node",
                  "type": "ast.AST",
                  "description": "The AST node representing the function part of a call expression (either ``Name`` or ``Attribute``)."
                }
              ],
              "returns": [
                {
                  "name": "qualified_name",
                  "type": "str or None",
                  "description": "The fully\u2011qualified dotted pathname of the callable if it could be resolved; otherwise ``None``."
                }
              ],
              "usage_context": {
                "calls": "This method is called by ``visit_Call`` to resolve the callee's name.",
                "called_by": "No other methods directly call ``_resolve_call_qname`` besides ``visit_Call``."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "This class depends on the function ``backend.relationship_analyzer.path_to_module`` for converting file paths to module names.",
          "instantiated_by": "No recorded locations instantiate this class."
        }
      },
      "error": null
    },
    "schemas.types.ParameterDescription": {
      "identifier": "schemas.types.ParameterDescription",
      "description": {
        "overall": "ParameterDescription is a lightweight Pydantic model that encapsulates metadata for a single function parameter. It stores the parameter's name, its type annotation (as a string), and a human\u2011readable description. By inheriting from `pydantic.BaseModel`, it gains validation, serialization, and convenient construction of instances using the defined fields.",
        "init_method": {
          "description": "The class relies on the default initializer generated by `pydantic.BaseModel`, which accepts the three declared fields (`name`, `type`, `description`) as keyword arguments and assigns them to the instance.",
          "parameters": []
        },
        "methods": [],
        "usage_context": {
          "dependencies": "No external runtime dependencies are referenced beyond the imports required for the Pydantic base class.",
          "instantiated_by": "No instantiation sites were provided in the context."
        }
      },
      "error": null
    },
    "schemas.types.ReturnDescription": {
      "identifier": "schemas.types.ReturnDescription",
      "description": {
        "overall": "ReturnDescription is a Pydantic model that encapsulates metadata about a function's return value. It stores the return's name, its type as a string, and a textual description. This structured representation can be used in documentation generation or type analysis.",
        "init_method": {
          "description": "The class relies on Pydantic's BaseModel to generate an initializer that accepts the defined fields. No explicit __init__ method is defined in the source code.",
          "parameters": []
        },
        "methods": [],
        "usage_context": {
          "dependencies": "The class has no external runtime dependencies beyond the imported modules.",
          "instantiated_by": "No locations were identified where ReturnDescription is instantiated."
        }
      },
      "error": null
    },
    "schemas.types.UsageContext": {
      "identifier": "schemas.types.UsageContext",
      "description": {
        "overall": "UsageContext is a lightweight Pydantic model that captures the calling context of a function. It stores two string attributes \u2013 `calls`, indicating which function(s) are being called, and `called_by`, indicating which function(s) invoke the target function. By leveraging Pydantic's BaseModel, it provides validation and easy serialization of this contextual information.",
        "init_method": {
          "description": "The class does not define an explicit `__init__`; Pydantic generates one automatically that accepts the model fields as keyword arguments.",
          "parameters": []
        },
        "methods": [],
        "usage_context": {
          "dependencies": "The class does not rely on any external modules beyond the imported Pydantic and typing utilities.",
          "instantiated_by": "No locations in the provided context instantiate this class."
        }
      },
      "error": null
    },
    "schemas.types.FunctionDescription": {
      "identifier": "schemas.types.FunctionDescription",
      "description": {
        "overall": "FunctionDescription is a Pydantic model that encapsulates a comprehensive analysis of a function, including a textual overall description, a list of parameter descriptions, a list of return descriptions, and contextual usage information.",
        "init_method": {
          "description": "The class relies on Pydantic's BaseModel for initialization; no custom __init__ method is defined, so instance attributes correspond directly to the declared fields (overall, parameters, returns, usage_context).",
          "parameters": []
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class does not depend on any external modules beyond the imports listed.",
          "instantiated_by": "No parts of the provided codebase instantiate this class."
        }
      },
      "error": null
    },
    "schemas.types.FunctionAnalysis": {
      "identifier": "schemas.types.FunctionAnalysis",
      "description": {
        "overall": "FunctionAnalysis is a Pydantic model that represents the complete JSON schema for a function analysis. It stores the function identifier, a nested FunctionDescription object describing the function, and an optional error message. The model is used to serialize and validate function analysis data throughout the system.",
        "init_method": {
          "description": "The class inherits Pydantic's BaseModel and does not define a custom __init__ method; initialization is handled by the BaseModel constructor.",
          "parameters": []
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class does not rely on any external runtime dependencies beyond the standard typing imports and Pydantic.",
          "instantiated_by": "No instantiation sites are provided in the supplied context."
        }
      },
      "error": null
    },
    "schemas.types.ConstructorDescription": {
      "identifier": "schemas.types.ConstructorDescription",
      "description": {
        "overall": "The **ConstructorDescription** class is a Pydantic model that captures metadata about a class's ``__init__`` method. It stores a textual description of the constructor and a list of parameter specifications, each represented by a ``ParameterDescription`` model. The class provides a structured way to document constructor signatures for downstream tooling or documentation generation.",
        "init_method": {
          "description": "The class does not define its own ``__init__`` method; it relies on the default initializer provided by ``pydantic.BaseModel`` which accepts the declared fields as keyword arguments.",
          "parameters": []
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class has no external dependencies.",
          "instantiated_by": "No information about where this class is instantiated."
        }
      },
      "error": null
    },
    "schemas.types.ClassContext": {
      "identifier": "schemas.types.ClassContext",
      "description": {
        "overall": "ClassContext is a lightweight Pydantic model that captures two pieces of metadata about a class: its external dependencies and the locations where it is instantiated. The model stores these values as simple string fields, allowing downstream code to record free\u2011form descriptions or serialized lists. Because it inherits from BaseModel, it benefits from Pydantic's validation and serialization features without requiring custom logic. This class serves as a structured container for documenting how a class interacts with the rest of the system.",
        "init_method": {
          "description": "ClassContext relies on the default initializer provided by Pydantic's BaseModel. The generated __init__ accepts the two declared fields, `dependencies` and `instantiated_by`, and assigns them to the instance. No custom initialization logic is defined.",
          "parameters": []
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class has no external dependencies recorded in the provided context.",
          "instantiated_by": "There are no known locations where this class is instantiated according to the provided context."
        }
      },
      "error": null
    },
    "schemas.types.ClassDescription": {
      "identifier": "schemas.types.ClassDescription",
      "description": {
        "overall": "ClassDescription is a Pydantic model that encapsulates the full analysis of a Python class, including its overall textual description, constructor details, analyses of each method, and the context in which the class is used.",
        "init_method": {
          "description": "The class relies on Pydantic's autogenerated __init__, which accepts values for the four declared fields: overall, init_method, methods, and usage_context.",
          "parameters": []
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class does not depend on any external components.",
          "instantiated_by": "No other code instantiates this class in the provided context."
        }
      },
      "error": null
    },
    "schemas.types.ClassAnalysis": {
      "identifier": "schemas.types.ClassAnalysis",
      "description": {
        "overall": "ClassAnalysis is a Pydantic model that defines the schema for representing a full analysis of a Python class, including its identifier, a detailed description, and any error information. It serves as the top\u2011level container that other components can serialize to JSON. By leveraging BaseModel, it automatically provides validation and serialization capabilities. The model is intended to be used throughout the documentation generation pipeline to convey structured class\u2011analysis data.",
        "init_method": {
          "description": "The class inherits from pydantic.BaseModel and uses the default initializer provided by BaseModel, which accepts values for the defined fields.",
          "parameters": [
            {
              "name": "identifier",
              "type": "str",
              "description": "A string representing the unique name of the class being described."
            },
            {
              "name": "description",
              "type": "ClassDescription",
              "description": "An instance of ClassDescription containing detailed information about the class."
            },
            {
              "name": "error",
              "type": "Optional[str]",
              "description": "An optional error message; defaults to None if no error occurred."
            }
          ]
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class does not have any external runtime dependencies beyond the imports listed (typing and pydantic).",
          "instantiated_by": "No information is provided about where instances of this class are created."
        }
      },
      "error": null
    },
    "schemas.types.CallInfo": {
      "identifier": "schemas.types.CallInfo",
      "description": {
        "overall": "CallInfo is a lightweight data model that captures details of a single call event identified by the relationship analyzer. It stores the source file name, the calling function's name, the call mode (e.g., method, function, module), and the line number where the call occurs. By inheriting from **pydantic.BaseModel**, it gains automatic validation, parsing, and serialization of its fields. The model is used in the `called_by` and `instantiated_by` collections to trace how functions and classes interact within the system.",
        "init_method": {
          "description": "The class relies on the automatically generated initializer provided by **pydantic.BaseModel**, which accepts the defined fields (`file`, `function`, `mode`, `line`) as keyword arguments and validates their types.",
          "parameters": []
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class does not depend on any external runtime components beyond the imported modules listed in the file.",
          "instantiated_by": "No information is provided about where or how this class is instantiated."
        }
      },
      "error": null
    },
    "schemas.types.FunctionContextInput": {
      "identifier": "schemas.types.FunctionContextInput",
      "description": {
        "overall": "FunctionContextInput is a Pydantic model that encapsulates contextual information for analyzing a function. It stores a list of call names (`calls`) and a list of `CallInfo` objects (`called_by`) that describe where the function is invoked. The class provides a structured container that can be passed to analysis utilities to understand a function's relationships within the codebase.",
        "init_method": {
          "description": "The class relies on Pydantic's autogenerated `__init__` method, which accepts the defined fields as arguments and assigns them to instance attributes. No custom constructor is defined in the source code.",
          "parameters": []
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class does not depend on any external modules beyond the imports listed (typing and pydantic).",
          "instantiated_by": "No locations where this class is instantiated were provided in the context."
        }
      },
      "error": null
    },
    "schemas.types.FunctionAnalysisInput": {
      "identifier": "schemas.types.FunctionAnalysisInput",
      "description": {
        "overall": "The `FunctionAnalysisInput` class is a Pydantic model that defines the required input schema for generating a `FunctionAnalysis` object. It captures the analysis mode, a unique identifier, the raw source code to be analyzed, a list of import statements, and a contextual description of the function environment. By inheriting from `BaseModel`, it gains automatic validation and serialization of these fields.",
        "init_method": {
          "description": "The class does not define an explicit `__init__` method; it relies on the default initializer provided by `pydantic.BaseModel`, which assigns the declared fields from the supplied data.",
          "parameters": []
        },
        "methods": [],
        "usage_context": {
          "dependencies": "The class does not depend on any external modules beyond those listed in its imports.",
          "instantiated_by": "No instantiation sites were provided in the context."
        }
      },
      "error": null
    },
    "schemas.types.MethodContextInput": {
      "identifier": "schemas.types.MethodContextInput",
      "description": {
        "overall": "MethodContextInput is a Pydantic model that provides a structured container for contextual information about a class's methods. It stores the method's identifier, a list of calls made by the method, information about callers, the argument names, and an optional docstring. This enables downstream tooling to reason about method relationships and documentation in a uniform way.",
        "init_method": {
          "description": "The class inherits from Pydantic's BaseModel, so its initialization is handled by the BaseModel constructor which accepts the defined fields as keyword arguments. No custom __init__ is defined, therefore the model can be instantiated by passing values for identifier, calls, called_by, args, and optionally docstring.",
          "parameters": []
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class does not have external dependencies.",
          "instantiated_by": "No information about where this class is instantiated is provided."
        }
      },
      "error": null
    },
    "schemas.types.ClassContextInput": {
      "identifier": "schemas.types.ClassContextInput",
      "description": {
        "overall": "ClassContextInput is a Pydantic model that encapsulates the contextual information needed to analyze another class. It stores a list of dependency names, a list of CallInfo objects describing where the class is instantiated, and a list of MethodContextInput objects providing details for each method such as its identifier, calls, and callers. This structured representation enables downstream tools to understand class relationships and usage patterns.",
        "init_method": {
          "description": "The class relies on Pydantic's autogenerated __init__, which accepts values for the declared fields: dependencies, instantiated_by, and method_context.",
          "parameters": []
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class has no external dependencies.",
          "instantiated_by": "No instantiation sites are recorded for this class."
        }
      },
      "error": null
    },
    "schemas.types.ClassAnalysisInput": {
      "identifier": "schemas.types.ClassAnalysisInput",
      "description": {
        "overall": "ClassAnalysisInput is a Pydantic model that defines the required input structure for generating a ClassAnalysis object. It contains fields for the operation mode (restricted to the literal string \"class_analysis\"), the target class identifier, the raw source code, a list of import statements, and a context object describing dependencies and instantiation sites. By inheriting from BaseModel, it gains automatic validation, parsing, and serialization of these fields, ensuring that downstream processing receives well\u2011formed data.",
        "init_method": {
          "description": "The class relies on the default Pydantic BaseModel initializer, which accepts the defined fields as keyword arguments and performs validation.",
          "parameters": []
        },
        "methods": [],
        "usage_context": {
          "dependencies": "The class does not have any external runtime dependencies beyond the imports listed in the file.",
          "instantiated_by": "There are no recorded locations where this class is instantiated."
        }
      },
      "error": null
    }
  }
}