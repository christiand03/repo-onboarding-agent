{
  "functions": {
    "backend.AST_Schema.path_to_module": {
      "identifier": "backend.AST_Schema.path_to_module",
      "description": {
        "overall": "The function `path_to_module` converts a filesystem path into a Python dotted module import path. It first attempts to compute a path relative to the provided project root using `os.path.relpath`; if that raises a `ValueError`, it falls back to using the file's basename. The function then removes a trailing `.py` extension, replaces OS-specific path separators with dots, and strips a trailing `.__init__` segment to handle package initializers. The resulting string is returned as the module path.",
        "parameters": [
          {
            "name": "filepath",
            "type": "str",
            "description": "The file system path that should be transformed into a module path."
          },
          {
            "name": "project_root",
            "type": "str",
            "description": "The root directory of the project used to compute a relative path."
          }
        ],
        "returns": [
          {
            "name": "",
            "type": "str",
            "description": "The dotted module path derived from the given file path."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not documented as being called by any other functions."
        }
      },
      "error": null
    },
    "backend.File_Dependency.build_file_dependency_graph": {
      "identifier": "backend.File_Dependency.build_file_dependency_graph",
      "description": {
        "overall": "The function builds a directed graph that represents file import dependencies for a given source file. It creates an empty NetworkX DiGraph, instantiates a FileDependencyGraph visitor with the filename and repository root, and walks the provided AST. After the visitor collects import relationships, the function adds each caller and its callee nodes to the graph and creates edges from callers to callees. Finally, the populated dependency graph is returned.",
        "parameters": [
          {
            "name": "filename",
            "type": "str",
            "description": "The name of the source file whose dependencies are being analyzed."
          },
          {
            "name": "tree",
            "type": "AST",
            "description": "The abstract syntax tree (AST) of the source file."
          },
          {
            "name": "repo_root",
            "type": "str",
            "description": "The root directory of the repository containing the source file."
          }
        ],
        "returns": [
          {
            "name": "graph",
            "type": "nx.DiGraph",
            "description": "A directed graph where nodes are files and edges represent import dependencies."
          }
        ],
        "usage_context": {
          "calls": "This function calls backend.File_Dependency.FileDependencyGraph.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "backend.File_Dependency.build_repository_graph": {
      "identifier": "backend.File_Dependency.build_repository_graph",
      "description": {
        "overall": "The function builds a repository\u2011wide dependency graph for a given Git repository. It retrieves all files from the repository, filters for Python source files, and parses each file's content into an abstract syntax tree. For each Python file it invokes backend.File_Dependency.build_file_dependency_graph to obtain a per\u2011file call graph, then merges all nodes and edges into a single directed graph. Finally, it returns the aggregated networkx.DiGraph representing cross\u2011file dependencies.",
        "parameters": [
          {
            "name": "repository",
            "type": "GitRepository",
            "description": "The GitRepository instance representing the source code repository to analyze; it provides get_all_files() and a temp_dir attribute."
          }
        ],
        "returns": [
          {
            "name": "global_graph",
            "type": "nx.DiGraph",
            "description": "A directed graph (networkx.DiGraph) where nodes are code entities and edges represent dependency relationships across the repository."
          }
        ],
        "usage_context": {
          "calls": "This function calls backend.File_Dependency.build_file_dependency_graph.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "backend.File_Dependency.get_all_temp_files": {
      "identifier": "backend.File_Dependency.get_all_temp_files",
      "description": {
        "overall": "The function `get_all_temp_files` scans a given directory for Python source files and returns their paths relative to the directory root. It first resolves the absolute path of the provided directory using `Path`. It then recursively searches for files matching the pattern \"*.py\" with `rglob`, converting each found path to a relative path. Finally, it returns a list containing these relative `Path` objects.",
        "parameters": [
          {
            "name": "directory",
            "type": "str",
            "description": "The path to the directory that should be searched for Python files."
          }
        ],
        "returns": [
          {
            "name": "",
            "type": "list[Path]",
            "description": "A list of `Path` objects representing the relative paths of all `.py` files found under the given directory."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "backend.HelperLLM.main_orchestrator": {
      "identifier": "backend.HelperLLM.main_orchestrator",
      "description": {
        "overall": "The function constructs dummy data and a processing loop to test the LLMHelper class. It creates example FunctionAnalysisInput objects for three inventory\u2011related methods, builds corresponding FunctionAnalysis objects, and defines a ClassAnalysisInput for the InventoryManager class. It then invokes an LLMHelper instance to generate documentation for the functions, aggregates the results into a final documentation dictionary, and prints the JSON representation. This orchestration demonstrates how the helper utilities can be used to produce structured documentation from code snippets. The function operates entirely as a self\u2011contained script without returning a value.",
        "parameters": [],
        "returns": [],
        "usage_context": {
          "calls": "This function calls backend.HelperLLM.LLMHelper, schemas.types.ClassAnalysisInput, and schemas.types.ClassContextInput.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "backend.callgraph.make_safe_dot": {
      "identifier": "backend.callgraph.make_safe_dot",
      "description": {
        "overall": "The function takes a NetworkX directed graph and an output file path, creates a copy of the graph, and relabels all nodes to simple identifiers (n0, n1, ...). It records the original node names as a \"label\" attribute on each new node. The relabeled graph is then written to a DOT file using NetworkX's pydot writer. This process produces a DOT representation that is safe for tools that may not handle arbitrary node identifiers.",
        "parameters": [
          {
            "name": "graph",
            "type": "nx.DiGraph",
            "description": "The input directed graph to be processed."
          },
          {
            "name": "out_path",
            "type": "str",
            "description": "The filesystem path where the DOT file will be written."
          }
        ],
        "returns": [],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "backend.callgraph.build_filtered_callgraph": {
      "identifier": "backend.callgraph.build_filtered_callgraph",
      "description": {
        "overall": "The function `build_filtered_callgraph` constructs a call graph for a given repository. It iterates over all Python files in the repository, parses each file's abstract syntax tree, and collects the set of functions defined within the project using the `CallGraph` visitor. Afterwards it builds a global directed graph where edges represent calls between these own functions, adding only edges where both caller and callee belong to the previously collected set. The resulting `networkx.DiGraph` contains only self\u2011written functions and their internal call relationships, which is returned to the caller.",
        "parameters": [
          {
            "name": "repo",
            "type": "GitRepository",
            "description": "A repository object providing access to the project's files via `get_all_files()`."
          }
        ],
        "returns": [
          {
            "name": "global_graph",
            "type": "nx.DiGraph",
            "description": "A directed graph containing only calls between functions defined in the repository."
          }
        ],
        "usage_context": {
          "calls": "This function calls backend.callgraph.CallGraph.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "backend.converter.wrap_cdata": {
      "identifier": "backend.converter.wrap_cdata",
      "description": {
        "overall": "The `wrap_cdata` function accepts a single argument `content`. It creates an XML CDATA section by surrounding the provided content with `<![CDATA[` and `]]>` tags, inserting newline characters before and after the content. The function returns the resulting string. No external functions or modules are invoked, and the implementation is a straightforward one\u2011liner using an f\u2011string.",
        "parameters": [
          {
            "name": "content",
            "type": "str",
            "description": "The text or data to be wrapped inside CDATA tags."
          }
        ],
        "returns": [
          {
            "name": "",
            "type": "str",
            "description": "A string containing the original content enclosed in CDATA tags."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "backend.converter.extract_output_content": {
      "identifier": "backend.converter.extract_output_content",
      "description": {
        "overall": "The function iterates over a collection of notebook output objects and extracts their textual representation or a placeholder for embedded images. For display-type outputs it checks for PNG or JPEG image data, decodes the Base64 string, records the image in the supplied image list, and inserts an XML placeholder referencing the image index. If no image is found, it falls back to plain text content. Stream outputs are appended directly, and error outputs are formatted as \"ename: evalue\" strings. Finally, a list containing all extracted strings and placeholders is returned.",
        "parameters": [
          {
            "name": "outputs",
            "type": "Iterable[Any]",
            "description": "A sequence of output objects (e.g., nbformat outputs) to be processed."
          },
          {
            "name": "image_list",
            "type": "list",
            "description": "A mutable list that will be populated with dictionaries describing extracted images."
          }
        ],
        "returns": [
          {
            "name": "extracted_xml_snippets",
            "type": "list[str]",
            "description": "A list of text strings or XML placeholders representing the extracted content."
          }
        ],
        "usage_context": {
          "calls": "This function calls backend.converter.process_image.",
          "called_by": "No functions are listed as callers of this function."
        }
      },
      "error": null
    },
    "backend.converter.process_image": {
      "identifier": "backend.converter.process_image",
      "description": {
        "overall": "The function `process_image` examines a given MIME type and, if corresponding image data exists, prepares a placeholder tag for inclusion elsewhere. It retrieves the base64\u2011encoded image string from a global `data` mapping, removes newline characters, and records the image information in a global `image_list`. It then returns a formatted placeholder string containing the image index and MIME type. If an exception occurs while processing, it returns an error string; otherwise, if the MIME type is not present, it returns `None`.",
        "parameters": [
          {
            "name": "mime_type",
            "type": "str",
            "description": "The MIME type of the image to be processed (e.g., 'image/png')."
          }
        ],
        "returns": [
          {
            "name": "",
            "type": "str",
            "description": "A placeholder tag string of the form `<IMAGE_PLACEHOLDER index=\"...\" mime=\"...\"/>` when processing succeeds."
          },
          {
            "name": "",
            "type": "str",
            "description": "An error string wrapped in `<ERROR>` tags if an exception is raised during processing."
          },
          {
            "name": "",
            "type": "None",
            "description": "None is returned when the provided MIME type is not found in the data mapping."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "No functions are listed as callers of this function."
        }
      },
      "error": null
    },
    "backend.converter.convert_notebook_to_xml": {
      "identifier": "backend.converter.convert_notebook_to_xml",
      "description": {
        "overall": "The function converts the raw JSON content of a Jupyter notebook into an XML representation while extracting any embedded images. It first attempts to parse the supplied content using nbformat; if parsing fails, it returns an error XML element and an empty image list. For each cell in the notebook, it creates a <CELL> XML element, handling markdown cells directly and wrapping code cell source in CDATA. If a code cell contains outputs, the function extracts the output content, wraps it in CDATA, and adds it as an output cell. Finally, it joins all XML parts with double newlines and returns the combined XML string together with the list of extracted images.",
        "parameters": [
          {
            "name": "file_content",
            "type": "str",
            "description": "The raw content of a notebook file, expected to be a JSON string representing a Jupyter notebook."
          }
        ],
        "returns": [
          {
            "name": "",
            "type": "tuple",
            "description": "A tuple where the first element is an XML string representing the notebook, and the second element is a list of extracted images."
          }
        ],
        "usage_context": {
          "calls": "This function calls backend.converter.extract_output_content and backend.converter.wrap_cdata.",
          "called_by": "It is not called by any other functions."
        }
      },
      "error": null
    },
    "backend.converter.process_repo_notebooks": {
      "identifier": "backend.converter.process_repo_notebooks",
      "description": {
        "overall": "The function processes a collection of repository files to identify Jupyter notebooks. It filters the provided list for files whose path ends with '.ipynb'. For each notebook, it logs the processing step and invokes backend.converter.convert_notebook_to_xml on the notebook's content to obtain XML output and extracted images. The results are stored in a dictionary keyed by the notebook's path, with each entry containing the XML and images. Finally, the dictionary of results is returned.",
        "parameters": [
          {
            "name": "repo_files",
            "type": "Iterable",
            "description": "A collection of file objects from the repository, each expected to have 'path' and 'content' attributes."
          }
        ],
        "returns": [
          {
            "name": "results",
            "type": "dict",
            "description": "A dictionary mapping notebook file paths to a dictionary containing the generated XML string under the key 'xml' and any extracted images under the key 'images'."
          }
        ],
        "usage_context": {
          "calls": "This function calls backend.converter.convert_notebook_to_xml.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "backend.main.create_savings_chart": {
      "identifier": "backend.main.create_savings_chart",
      "description": {
        "overall": "The function creates a bar chart that visualizes a comparison between two token counts, JSON tokens and TOON tokens. It labels the bars, assigns distinct colors, and sizes the figure for readability. The chart title incorporates the percentage of savings provided, and each bar is annotated with its exact token count. Finally, the chart is saved to the specified file path and the plotting resources are released.",
        "parameters": [
          {
            "name": "json_tokens",
            "type": "int or float",
            "description": "The number of tokens counted for the JSON format."
          },
          {
            "name": "toon_tokens",
            "type": "int or float",
            "description": "The number of tokens counted for the TOON format."
          },
          {
            "name": "savings_percent",
            "type": "float",
            "description": "The percentage of token savings, displayed in the chart title."
          },
          {
            "name": "output_path",
            "type": "str",
            "description": "File system path where the generated chart image will be saved."
          }
        ],
        "returns": [],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "backend.main.calculate_net_time": {
      "identifier": "backend.main.calculate_net_time",
      "description": {
        "overall": "The function calculate_net_time computes the effective elapsed time between a start and end timestamp, subtracting any artificial sleep periods that may have been introduced to respect rate limits. It first determines the total duration by subtracting start_time from end_time. If the model name does not begin with \"gemini-\", it returns the raw duration unchanged. For Gemini models, it calculates the number of batches needed for total_items given batch_size, assumes a 61\u2011second sleep between batches, and subtracts the accumulated sleep time from the total duration, ensuring the result is not negative. The function also handles edge cases where there are no items, returning zero.",
        "parameters": [
          {
            "name": "start_time",
            "type": "int or float",
            "description": "Timestamp marking the beginning of the operation."
          },
          {
            "name": "end_time",
            "type": "int or float",
            "description": "Timestamp marking the end of the operation."
          },
          {
            "name": "total_items",
            "type": "int",
            "description": "Total number of items to be processed."
          },
          {
            "name": "batch_size",
            "type": "int",
            "description": "Number of items processed per batch."
          },
          {
            "name": "model_name",
            "type": "str",
            "description": "Name of the model, used to decide whether rate\u2011limit sleep should be accounted for."
          }
        ],
        "returns": [
          {
            "name": "",
            "type": "int or float",
            "description": "Net elapsed time after subtracting estimated sleep time; never negative."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "No other functions are documented as calling this function."
        }
      },
      "error": null
    },
    "backend.main.main_workflow": {
      "identifier": "backend.main.main_workflow",
      "description": {
        "overall": "The function `main_workflow` orchestrates the end\u2011to\u2011end analysis of a software repository provided via user input. It selects appropriate API keys and model identifiers, clones the repository, extracts basic project information, builds a file tree, performs relationship and AST analyses, and then uses a helper LLM to generate documentation for all functions and classes. The enriched AST schema and documentation are combined into an input for a main LLM, which produces a final markdown report and token\u2011savings statistics. Finally, the function saves the report and optional charts, computes timing and model metrics, and returns the report together with a metrics dictionary.",
        "parameters": [
          {
            "name": "input",
            "type": "Any",
            "description": "The raw user input string, expected to contain a GitHub repository URL."
          },
          {
            "name": "api_keys",
            "type": "dict",
            "description": "Dictionary mapping service names (e.g., \"gemini\", \"gpt\", \"scadsllm\", \"ollama\") to their respective API keys or base URLs."
          },
          {
            "name": "model_names",
            "type": "dict",
            "description": "Dictionary specifying the model identifiers for the helper and main LLMs under the keys \"helper\" and \"main\"."
          },
          {
            "name": "status_callback",
            "type": "Callable[[str], None] | None",
            "description": "Optional callable that receives status messages for UI updates; if omitted, status is only logged."
          }
        ],
        "returns": [
          {
            "name": "result",
            "type": "dict",
            "description": "A dictionary containing the generated report string under the key \"report\" and a metrics dictionary under the key \"metrics\"."
          }
        ],
        "usage_context": {
          "calls": "This function calls backend.AST_Schema.ASTAnalyzer, backend.AST_Schema.ASTAnalyzer.analyze_repository, backend.AST_Schema.ASTAnalyzer.merge_relationship_data, backend.HelperLLM.LLMHelper, backend.HelperLLM.LLMHelper.generate_for_classes, backend.HelperLLM.LLMHelper.generate_for_functions, backend.MainLLM.MainLLM, backend.MainLLM.MainLLM.call_llm, backend.basic_info.ProjektInfoExtractor, backend.basic_info.ProjektInfoExtractor.extrahiere_info, backend.getRepo.GitRepository, backend.main.calculate_net_time, backend.main.create_savings_chart, backend.main.update_status, backend.relationship_analyzer.ProjectAnalyzer, backend.relationship_analyzer.ProjectAnalyzer.analyze, backend.relationship_analyzer.ProjectAnalyzer.get_raw_relationships, schemas.types.ClassAnalysisInput, schemas.types.ClassContextInput, schemas.types.FunctionAnalysisInput, schemas.types.FunctionContextInput, and schemas.types.MethodContextInput.",
          "called_by": "No other functions call this function."
        }
      },
      "error": null
    },
    "backend.main.update_status": {
      "identifier": "backend.main.update_status",
      "description": {
        "overall": "The `update_status` function is responsible for handling status messages within the backend. It accepts a single argument `msg` representing the status information. If a global `status_callback` is defined and truthy, the function forwards the message to this callback. Regardless of the callback, it records the message using the standard `logging` module at the INFO level.",
        "parameters": [
          {
            "name": "msg",
            "type": "Any",
            "description": "The message to be passed to the optional status callback and logged."
          }
        ],
        "returns": [],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "backend.main.notebook_workflow": {
      "identifier": "backend.main.notebook_workflow",
      "description": {
        "overall": "The function orchestrates the analysis of Jupyter notebooks contained in a GitHub repository by using a language model. It first extracts a repository URL from the provided input string, clones the repository, and processes the notebook files into XML and image data. Basic project information is extracted, and a payload is built for the selected LLM which is then called for each notebook to generate an individual report. All notebook reports are concatenated, saved to a timestamped markdown file, and timing/usage metrics are collected. Finally, the function returns the combined report and the metrics dictionary.",
        "parameters": [
          {
            "name": "input",
            "type": "str",
            "description": "Raw user input that should contain a GitHub repository URL."
          },
          {
            "name": "api_keys",
            "type": "dict",
            "description": "Mapping of model identifiers to their respective API keys and optional base URLs."
          },
          {
            "name": "model",
            "type": "str",
            "description": "Name of the language model to use (e.g., \"gpt-4\", \"gemini-pro\", etc.)."
          },
          {
            "name": "status_callback",
            "type": "callable | None",
            "description": "Optional callback function that receives status messages for UI updates; if None, status messages are only logged."
          }
        ],
        "returns": [
          {
            "name": "report",
            "type": "str",
            "description": "The concatenated markdown report generated from all processed notebooks."
          },
          {
            "name": "metrics",
            "type": "dict",
            "description": "Dictionary containing timing information and model usage statistics for the workflow."
          }
        ],
        "usage_context": {
          "calls": "This function calls backend.MainLLM.MainLLM, backend.MainLLM.MainLLM.call_llm, backend.basic_info.ProjektInfoExtractor, backend.basic_info.ProjektInfoExtractor.extrahiere_info, backend.converter.process_repo_notebooks, backend.getRepo.GitRepository, backend.main.gemini_payload, and backend.main.update_status.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "backend.main.gemini_payload": {
      "identifier": "backend.main.gemini_payload",
      "description": {
        "overall": "The function `gemini_payload` constructs a payload for the Gemini API by first embedding basic notebook information as JSON text. It then parses the provided XML content, splitting it into text segments and image placeholders. For each placeholder it inserts an image block with a base64\u2011encoded data URL using the corresponding entry from the `images` list. Finally, it appends any remaining text and returns the assembled list of content blocks.",
        "parameters": [
          {
            "name": "basic_info",
            "type": "dict",
            "description": "A dictionary containing basic information about the notebook or project, which will be included in the introductory JSON segment."
          },
          {
            "name": "nb_path",
            "type": "str",
            "description": "The file system path to the current notebook, inserted into the introductory JSON."
          },
          {
            "name": "xml_content",
            "type": "str",
            "description": "A string representation of the notebook's XML structure, potentially containing `<IMAGE_PLACEHOLDER>` tags that indicate where images should be inserted."
          },
          {
            "name": "images",
            "type": "list[dict]",
            "description": "A list where each element is a dictionary with a `'data'` key holding a base64\u2011encoded image string. The index of the list corresponds to the placeholder index in the XML."
          }
        ],
        "returns": [
          {
            "name": "payload_content",
            "type": "list[dict]",
            "description": "A list of dictionaries representing the payload. Each dictionary has a `'type'` key of either `'text'` or `'image_url'` and the associated content."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "backend.relationship_analyzer.path_to_module": {
      "identifier": "backend.relationship_analyzer.path_to_module",
      "description": {
        "overall": "The function converts a filesystem path to a dotted Python module path relative to a given project root. It first attempts to compute a relative path using `os.path.relpath`; if that fails, it falls back to using the basename of the file. The function strips a trailing `.py` extension and replaces path separators with dots to form the module path. If the resulting path ends with `.__init__`, that suffix is removed so that the package name is returned. The final module path string is returned.",
        "parameters": [
          {
            "name": "filepath",
            "type": "str",
            "description": "The absolute or relative path to the Python file whose module name is to be derived."
          },
          {
            "name": "project_root",
            "type": "str",
            "description": "The root directory of the project against which the relative module path is calculated."
          }
        ],
        "returns": [
          {
            "name": "",
            "type": "str",
            "description": "A dotted module path corresponding to the given file, with any trailing `.__init__` removed."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.encrypt_text": {
      "identifier": "database.db.encrypt_text",
      "description": {
        "overall": "The `encrypt_text` function takes a string and returns an encrypted representation of it. It first checks whether the input text is falsy or whether the global `cipher_suite` is unavailable; in those cases it returns the original text unchanged. When encryption is possible, it strips whitespace from the text, encodes it to bytes, encrypts it using the `cipher_suite`, and decodes the resulting bytes back to a string. The function relies on a globally defined `cipher_suite`, presumably an instance of `cryptography.fernet.Fernet`.",
        "parameters": [
          {
            "name": "text",
            "type": "str",
            "description": "The plaintext string to be encrypted."
          }
        ],
        "returns": [
          {
            "name": "",
            "type": "str",
            "description": "The encrypted text as a string, or the original input if encryption could not be performed."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not documented as being called by any other functions."
        }
      },
      "error": null
    },
    "database.db.decrypt_text": {
      "identifier": "database.db.decrypt_text",
      "description": {
        "overall": "The function `decrypt_text` attempts to decrypt a provided string using a globally defined `cipher_suite` (likely a Fernet instance). If the input string is empty or the `cipher_suite` is unavailable, it returns the original string unchanged. It trims whitespace, encodes the string to bytes, decrypts it, and decodes the result back to a string. Any exception raised during decryption is caught, and the original input string is returned.",
        "parameters": [
          {
            "name": "text",
            "type": "str",
            "description": "The text to be decrypted; expected to be an encrypted string."
          }
        ],
        "returns": [
          {
            "name": "result",
            "type": "str",
            "description": "The decrypted string if decryption succeeds; otherwise the original input string."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.insert_user": {
      "identifier": "database.db.insert_user",
      "description": {
        "overall": "The function creates a user document containing the provided username, name, and a hashed version of the password, along with placeholder fields for various API keys. It uses `stauth.Hasher.hash` to securely hash the plaintext password. The constructed document is then inserted into the `dbusers` collection via `insert_one`. Finally, the function returns the identifier of the newly inserted document.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The unique identifier for the user, stored as the document's `_id`."
          },
          {
            "name": "name",
            "type": "str",
            "description": "The display name of the user."
          },
          {
            "name": "password",
            "type": "str",
            "description": "The plaintext password which will be hashed before storage."
          }
        ],
        "returns": [
          {
            "name": "inserted_id",
            "type": "ObjectId",
            "description": "The identifier of the document that was inserted into the `dbusers` collection."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "No functions are documented as calling this function."
        }
      },
      "error": null
    },
    "database.db.fetch_all_users": {
      "identifier": "database.db.fetch_all_users",
      "description": {
        "overall": "The function fetch_all_users retrieves all user records from the database. It accesses the MongoDB collection `dbusers` and invokes its `find` method to obtain a cursor over all documents. The cursor is converted to a Python list, which is then returned to the caller. No input parameters are required, and the function performs no additional processing.",
        "parameters": [],
        "returns": [
          {
            "name": "users",
            "type": "list",
            "description": "A list of user documents retrieved from the dbusers collection."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions in the provided context."
        }
      },
      "error": null
    },
    "database.db.fetch_user": {
      "identifier": "database.db.fetch_user",
      "description": {
        "overall": "The function `fetch_user` retrieves a user record from the `dbusers` collection based on a provided username. It accepts a single argument, `username`, which is expected to be a string representing the user's identifier. Internally, it constructs a query dictionary with the `_id` field set to the given username and passes this query to the `find_one` method of the `dbusers` collection. The result of this database lookup is returned directly to the caller.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username (or user identifier) used to look up the corresponding document in the `dbusers` collection."
          }
        ],
        "returns": [
          {
            "name": "user_document",
            "type": "dict | None",
            "description": "The document representing the user if found, otherwise `None`."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions in the provided context."
        }
      },
      "error": null
    },
    "database.db.update_user_name": {
      "identifier": "database.db.update_user_name",
      "description": {
        "overall": "The function `update_user_name` updates the name field of a user document stored in a MongoDB collection. It locates the document by matching the `_id` field with the provided `username`. The update is performed with the `$set` operator, assigning `new_name` to the `name` field. After the operation, the function returns the number of documents that were modified. This allows the caller to know whether the update succeeded.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The identifier of the user in the database, used as the value for the `_id` field in the query filter."
          },
          {
            "name": "new_name",
            "type": "str",
            "description": "The new name value that will be written to the user's `name` field."
          }
        ],
        "returns": [
          {
            "name": "modified_count",
            "type": "int",
            "description": "The number of documents whose `name` field was modified by the update operation."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions in the provided context."
        }
      },
      "error": null
    },
    "database.db.update_gemini_key": {
      "identifier": "database.db.update_gemini_key",
      "description": {
        "overall": "The function updates a user's stored Gemini API key in the database. It trims whitespace from the provided key and encrypts it using the encrypt_text helper. It then performs a MongoDB update_one operation on the dbusers collection, setting the encrypted key for the document identified by the username. Finally, it returns the count of modified documents.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The identifier of the user whose record is being updated (used as the document _id)."
          },
          {
            "name": "gemini_api_key",
            "type": "str",
            "description": "The Gemini API key to store for the user."
          }
        ],
        "returns": [
          {
            "name": "modified_count",
            "type": "int",
            "description": "The number of documents that were modified by the update operation."
          }
        ],
        "usage_context": {
          "calls": "This function calls database.db.encrypt_text.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.update_gpt_key": {
      "identifier": "database.db.update_gpt_key",
      "description": {
        "overall": "The function `update_gpt_key` updates a user's stored GPT API key in the database. It accepts a username and a raw API key string as inputs. The API key is stripped of surrounding whitespace, encrypted via `encrypt_text`, and then written to the `dbusers` collection using an `update_one` operation that sets the `gpt_api_key` field. The function returns the `modified_count` from the update result, indicating how many documents were altered.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The identifier of the user whose GPT API key should be updated."
          },
          {
            "name": "gpt_api_key",
            "type": "str",
            "description": "The new GPT API key provided as a plain\u2011text string."
          }
        ],
        "returns": [
          {
            "name": "modified_count",
            "type": "int",
            "description": "The number of documents that were modified by the update operation."
          }
        ],
        "usage_context": {
          "calls": "This function calls database.db.encrypt_text.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.update_ollama_url": {
      "identifier": "database.db.update_ollama_url",
      "description": {
        "overall": "The function updates the `ollama_base_url` field for a specific user in the `dbusers` MongoDB collection. It builds a filter using the provided `username` and sets the `ollama_base_url` to the stripped version of the supplied URL. The update is performed with `update_one`, which modifies at most one matching document. Finally, the function returns the count of documents that were actually modified.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The identifier of the user whose record should be updated."
          },
          {
            "name": "ollama_base_url",
            "type": "str",
            "description": "The new base URL for Ollama; whitespace is stripped before storing."
          }
        ],
        "returns": [
          {
            "name": "modified_count",
            "type": "int",
            "description": "Number of documents that were modified by the update operation."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "No functions are listed as callers of this function."
        }
      },
      "error": null
    },
    "database.db.update_opensrc_key": {
      "identifier": "database.db.update_opensrc_key",
      "description": {
        "overall": "The function `update_opensrc_key` updates a user's Open Source API key in the database. It first strips whitespace from the provided key and encrypts it using the `encrypt_text` helper. The encrypted key is then stored in the `dbusers` collection by updating the document whose `_id` matches the given username. Finally, the function returns the count of modified documents, indicating whether the update succeeded.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The identifier of the user whose record will be updated (used as the document `_id`)."
          },
          {
            "name": "opensrc_api_key",
            "type": "str",
            "description": "The Open Source API key to be encrypted and stored for the user."
          }
        ],
        "returns": [
          {
            "name": "modified_count",
            "type": "int",
            "description": "The number of documents that were modified by the update operation."
          }
        ],
        "usage_context": {
          "calls": "This function calls database.db.encrypt_text.",
          "called_by": "No functions call this function."
        }
      },
      "error": null
    },
    "database.db.update_opensrc_url": {
      "identifier": "database.db.update_opensrc_url",
      "description": {
        "overall": "The function `update_opensrc_url` updates the stored Open Source base URL for a given user in the database. It accepts the user's identifier (`username`) and the new URL (`opensrc_base_url`) as string arguments. Inside, it calls the `update_one` method on the `dbusers` collection, targeting the document whose `_id` matches `username` and setting the `opensrc_base_url` field to the stripped version of the provided URL. The result of the update operation is stored in `result`. Finally, the function returns `result.modified_count`, indicating how many documents were modified (typically 0 or 1).",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The identifier of the user whose record should be updated."
          },
          {
            "name": "opensrc_base_url",
            "type": "str",
            "description": "The new Open Source base URL to store for the user; surrounding whitespace is removed before saving."
          }
        ],
        "returns": [
          {
            "name": "modified_count",
            "type": "int",
            "description": "The number of documents that were modified by the update operation (0 if no matching user, 1 if the update succeeded)."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.fetch_gemini_key": {
      "identifier": "database.db.fetch_gemini_key",
      "description": {
        "overall": "The function `fetch_gemini_key` retrieves a Gemini API key associated with a given username from a MongoDB collection. It queries the `dbusers` collection for a document whose `_id` matches the provided username, projecting only the `gemini_api_key` field. If a matching document is found, the function extracts the `gemini_api_key` value; otherwise, it returns `None`. This allows callers to obtain the stored API key or determine that none exists for the user.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username (used as the document `_id`) for which the Gemini API key should be fetched."
          }
        ],
        "returns": [
          {
            "name": "gemini_api_key",
            "type": "Optional[str]",
            "description": "The Gemini API key string if the user exists and the key is stored; otherwise `None`."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.fetch_ollama_url": {
      "identifier": "database.db.fetch_ollama_url",
      "description": {
        "overall": "The function fetch_ollama_url retrieves the Ollama base URL for a given user from a MongoDB collection named `dbusers`. It performs a `find_one` query using the provided `username` as the document identifier, requesting only the `ollama_base_url` field while excluding the `_id`. The result of the query is stored in the variable `user`. Finally, the function returns the `ollama_base_url` value if a matching document exists, otherwise it returns `None`.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The identifier of the user whose Ollama base URL should be fetched."
          }
        ],
        "returns": [
          {
            "name": "ollama_base_url",
            "type": "Optional[str]",
            "description": "The Ollama base URL associated with the user, or `None` if the user is not found."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "No other functions are listed as callers of this function."
        }
      },
      "error": null
    },
    "database.db.fetch_gpt_key": {
      "identifier": "database.db.fetch_gpt_key",
      "description": {
        "overall": "The function fetch_gpt_key retrieves the GPT API key associated with a given username from the MongoDB collection `dbusers`. It queries the collection for a document whose `_id` matches the provided username, projecting only the `gpt_api_key` field. If a matching document is found, it returns the value of `gpt_api_key`; otherwise, it returns `None`. The function therefore provides a simple lookup utility for user\u2011specific API credentials.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username used as the document identifier (`_id`) to locate the user's record in the database."
          }
        ],
        "returns": [
          {
            "name": "",
            "type": "Optional[str]",
            "description": "The GPT API key string if the user exists and has a key, otherwise `None`."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "No functions are documented as calling this function."
        }
      },
      "error": null
    },
    "database.db.fetch_opensrc_key": {
      "identifier": "database.db.fetch_opensrc_key",
      "description": {
        "overall": "The function fetch_opensrc_key retrieves an Open Source API key associated with a given username from a MongoDB collection. It queries the `dbusers` collection for a document whose `_id` matches the provided username, projecting only the `opensrc_api_key` field. If a matching document is found, the function extracts the `opensrc_api_key` value; otherwise it returns None. This allows callers to obtain a stored API key without exposing other user data.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The identifier of the user whose Open Source API key should be fetched."
          }
        ],
        "returns": [
          {
            "name": "opensrc_api_key",
            "type": "str",
            "description": "The Open Source API key associated with the user, or None if the user does not exist or the key is not present."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not referenced by any other functions in the provided context."
        }
      },
      "error": null
    },
    "database.db.fetch_opensrc_url": {
      "identifier": "database.db.fetch_opensrc_url",
      "description": {
        "overall": "The function fetches the Open Source base URL associated with a given username from a MongoDB collection. It queries the `dbusers` collection for a document whose `_id` matches the provided username, requesting only the `opensrc_base_url` field. If a matching document is found, the function extracts the `opensrc_base_url` value; otherwise it returns `None`. The implementation relies on MongoDB's `find_one` method and a conditional expression to handle the absent\u2011user case.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The identifier of the user whose Open Source base URL should be retrieved."
          }
        ],
        "returns": [
          {
            "name": "",
            "type": "Optional[str]",
            "description": "The `opensrc_base_url` string for the specified user, or `None` if the user does not exist in the database."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.delete_user": {
      "identifier": "database.db.delete_user",
      "description": {
        "overall": "The function `delete_user` removes a user record from the database based on a supplied username. It constructs a query that matches the `_id` field to the provided username and forwards this query to the `delete_one` method of the `dbusers` collection. The result of the deletion operation is accessed via the `deleted_count` attribute, which indicates how many documents were removed. Finally, the function returns this count to the caller, allowing the caller to know whether a user was actually deleted.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username (used as the document's `_id`) of the user to be deleted from the database."
          }
        ],
        "returns": [
          {
            "name": "",
            "type": "int",
            "description": "The number of documents deleted (0 if no matching user was found, 1 if the user was successfully removed)."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.get_decrypted_api_keys": {
      "identifier": "database.db.get_decrypted_api_keys",
      "description": {
        "overall": "The function retrieves a user document from the MongoDB collection `dbusers` using the provided username. If the user does not exist, it returns a pair of `None` values. When a user is found, it extracts encrypted API keys and URLs from the document, decrypts the keys using the `decrypt_text` helper, and collects the plain values. Finally, it returns a tuple containing the decrypted Gemini, Ollama base URL, GPT, Open\u2011Source API keys, and the Open\u2011Source base URL.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The identifier of the user whose API keys are to be fetched from the database."
          }
        ],
        "returns": [
          {
            "name": "not_found",
            "type": "Tuple[None, None]",
            "description": "Returned when no user document matches the given username."
          },
          {
            "name": "api_keys_and_urls",
            "type": "Tuple[Optional[str], Optional[str], Optional[str], Optional[str], Optional[str]]",
            "description": "A tuple containing the decrypted Gemini API key, Ollama base URL, GPT API key, Open\u2011Source API key, and Open\u2011Source base URL for the found user."
          }
        ],
        "usage_context": {
          "calls": "This function calls database.db.decrypt_text.",
          "called_by": "No functions are listed as calling this function."
        }
      },
      "error": null
    },
    "database.db.insert_chat": {
      "identifier": "database.db.insert_chat",
      "description": {
        "overall": "The function `insert_chat` creates a new chat entry in the database. It builds a dictionary containing a unique identifier, the supplied username, the chat name, and a creation timestamp. The dictionary is inserted into the `dbchats` collection via `insert_one`. The function returns the identifier of the inserted document so that callers can reference the newly created chat.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username associated with the chat."
          },
          {
            "name": "chat_name",
            "type": "str",
            "description": "The name of the chat to be created."
          }
        ],
        "returns": [
          {
            "name": "inserted_id",
            "type": "Any",
            "description": "The identifier of the newly inserted chat document."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "No functions are listed as callers of this function."
        }
      },
      "error": null
    },
    "database.db.fetch_chats_by_user": {
      "identifier": "database.db.fetch_chats_by_user",
      "description": {
        "overall": "The function fetch_chats_by_user retrieves all chat records for a specified user from the database. It accepts a single argument, username, which is a string identifying the user. Inside, it queries the MongoDB collection dbchats for documents where the \"username\" field matches the provided value. The results are sorted by the \"created_at\" field in ascending order and converted to a list. The list of chat documents is then returned to the caller.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username of the user whose chats are to be retrieved."
          }
        ],
        "returns": [
          {
            "name": "",
            "type": "list",
            "description": "A list of chat documents associated with the given username, ordered by creation time."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not referenced by any other functions in the provided context."
        }
      },
      "error": null
    },
    "database.db.check_chat_exists": {
      "identifier": "database.db.check_chat_exists",
      "description": {
        "overall": "The function `check_chat_exists` determines whether a chat with a given name exists for a specific user. It queries the `dbchats` collection using the provided `username` and `chat_name` as filter criteria. The result of the query is evaluated to a boolean indicating presence or absence. The function returns `True` if a matching document is found, otherwise `False`.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username associated with the chat to be looked up."
          },
          {
            "name": "chat_name",
            "type": "str",
            "description": "The name of the chat whose existence is being checked."
          }
        ],
        "returns": [
          {
            "name": "",
            "type": "bool",
            "description": "True if a chat matching the given username and chat_name exists in the database; otherwise False."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.rename_chat_fully": {
      "identifier": "database.db.rename_chat_fully",
      "description": {
        "overall": "This function renames a chat for a given user and updates all related exchange records to reflect the new chat name. It first updates the chat document in the `dbchats` collection by matching the username and the old chat name, setting the `chat_name` field to the new value. Afterwards it updates every exchange document in the `dbexchanges` collection that belongs to the same user and chat, also setting their `chat_name` to the new name. Finally it returns the number of chat documents that were modified as reported by the MongoDB update operation.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username of the owner of the chat."
          },
          {
            "name": "old_name",
            "type": "str",
            "description": "The current name of the chat to be renamed."
          },
          {
            "name": "new_name",
            "type": "str",
            "description": "The desired new name for the chat."
          }
        ],
        "returns": [
          {
            "name": "modified_count",
            "type": "int",
            "description": "The number of chat documents that were modified by the update operation."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "No functions are listed as calling this function."
        }
      },
      "error": null
    },
    "database.db.insert_exchange": {
      "identifier": "database.db.insert_exchange",
      "description": {
        "overall": "The function `insert_exchange` creates a new exchange record and stores it in a MongoDB collection. It generates a unique identifier using `uuid.uuid4()` and assembles a dictionary containing the provided question, answer, feedback, user information, timing metrics, token counts, and a timestamp. The assembled record is then inserted into the `dbexchanges` collection. If the insertion succeeds, the function returns the generated identifier; otherwise it logs the error and returns `None`.",
        "parameters": [
          {
            "name": "question",
            "type": "str",
            "description": "The question text to be stored in the exchange record."
          },
          {
            "name": "answer",
            "type": "str",
            "description": "The answer text corresponding to the question."
          },
          {
            "name": "feedback",
            "type": "str",
            "description": "Feedback associated with the exchange."
          },
          {
            "name": "username",
            "type": "str",
            "description": "The username of the user who performed the exchange."
          },
          {
            "name": "chat_name",
            "type": "str",
            "description": "The name of the chat session where the exchange occurred."
          },
          {
            "name": "helper_used",
            "type": "str",
            "description": "Optional name of the helper model used; defaults to an empty string."
          },
          {
            "name": "main_used",
            "type": "str",
            "description": "Optional name of the main model used; defaults to an empty string."
          },
          {
            "name": "total_time",
            "type": "str",
            "description": "Optional total processing time as a string; defaults to an empty string."
          },
          {
            "name": "helper_time",
            "type": "str",
            "description": "Optional helper processing time as a string; defaults to an empty string."
          },
          {
            "name": "main_time",
            "type": "str",
            "description": "Optional main processing time as a string; defaults to an empty string."
          },
          {
            "name": "json_tokens",
            "type": "int",
            "description": "Number of JSON tokens used; defaults to 0."
          },
          {
            "name": "toon_tokens",
            "type": "int",
            "description": "Number of Toon tokens used; defaults to 0."
          },
          {
            "name": "savings_percent",
            "type": "float",
            "description": "Percentage of token savings; defaults to 0.0."
          }
        ],
        "returns": [
          {
            "name": "new_id",
            "type": "str or None",
            "description": "The UUID string of the inserted exchange on success, or `None` if an error occurs during insertion."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions in the provided context."
        }
      },
      "error": null
    },
    "database.db.fetch_exchanges_by_user": {
      "identifier": "database.db.fetch_exchanges_by_user",
      "description": {
        "overall": "The function fetch_exchanges_by_user retrieves exchange records for a specific user from the MongoDB collection named dbexchanges. It filters documents where the \"username\" field matches the provided username argument. The resulting cursor is sorted by the \"created_at\" timestamp in ascending order to ensure chronological display. Finally, the sorted cursor is materialized into a Python list and returned to the caller.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username whose exchange records should be fetched from the database."
          }
        ],
        "returns": [
          {
            "name": "exchanges",
            "type": "list",
            "description": "A list of exchange documents belonging to the given user, ordered by their creation timestamp (oldest first)."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "No functions are documented as calling this function."
        }
      },
      "error": null
    },
    "database.db.fetch_exchanges_by_chat": {
      "identifier": "database.db.fetch_exchanges_by_chat",
      "description": {
        "overall": "The function fetch_exchanges_by_chat retrieves chat exchange records from a MongoDB collection. It accepts a username and a chat name, both as strings, and uses them to query the `dbexchanges` collection. The query results are sorted by the `created_at` field in ascending order. The matching documents are collected into a list, which is then returned to the caller.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username identifying the owner of the chat."
          },
          {
            "name": "chat_name",
            "type": "str",
            "description": "The name of the chat whose exchanges are to be fetched."
          }
        ],
        "returns": [
          {
            "name": "",
            "type": "list",
            "description": "A list of exchange documents matching the given username and chat name, ordered by creation time."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "No functions are documented as calling this function."
        }
      },
      "error": null
    },
    "database.db.update_exchange_feedback": {
      "identifier": "database.db.update_exchange_feedback",
      "description": {
        "overall": "The function updates the feedback value for a specific exchange record in the MongoDB collection `dbexchanges`. It builds a filter using the provided `exchange_id` and applies an update operation that sets the `feedback` field to the supplied integer. The MongoDB `update_one` method is used, which modifies at most one matching document. Finally, the function returns the count of documents that were actually modified by the operation.",
        "parameters": [
          {
            "name": "exchange_id",
            "type": "Any",
            "description": "The unique identifier of the exchange document to be updated."
          },
          {
            "name": "feedback",
            "type": "int",
            "description": "The integer feedback value to store in the exchange document."
          }
        ],
        "returns": [
          {
            "name": "modified_count",
            "type": "int",
            "description": "The number of documents that were modified by the update operation (typically 0 or 1)."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "No functions are listed as callers of this function."
        }
      },
      "error": null
    },
    "database.db.update_exchange_feedback_message": {
      "identifier": "database.db.update_exchange_feedback_message",
      "description": {
        "overall": "The function update_exchange_feedback_message updates the feedback_message field of a specific exchange document in the database. It receives an exchange identifier and a new feedback message string. Using the dbexchanges collection, it performs an update_one operation that sets the feedback_message field to the provided value for the document whose _id matches exchange_id. The function then returns the number of documents that were modified as an integer. This allows callers to know whether the update was successful.",
        "parameters": [
          {
            "name": "exchange_id",
            "type": "Any",
            "description": "The identifier of the exchange document whose feedback_message should be updated."
          },
          {
            "name": "feedback_message",
            "type": "str",
            "description": "The new feedback message to store in the exchange document."
          }
        ],
        "returns": [
          {
            "name": "",
            "type": "int",
            "description": "The count of documents that were modified by the update operation."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.delete_exchange_by_id": {
      "identifier": "database.db.delete_exchange_by_id",
      "description": {
        "overall": "The function deletes an exchange document from the MongoDB collection `dbexchanges` using the provided identifier. It builds a filter with the `_id` field set to `exchange_id` and invokes `delete_one` on the collection. The result of the deletion operation is stored in `result`. Finally, the function returns the `deleted_count` attribute, indicating how many documents were removed (typically 0 or 1). This serves as a thin wrapper around the MongoDB delete operation.",
        "parameters": [
          {
            "name": "exchange_id",
            "type": "str",
            "description": "The unique identifier of the exchange document to be removed."
          }
        ],
        "returns": [
          {
            "name": "deleted_count",
            "type": "int",
            "description": "The number of documents deleted by the operation (0 if none were found, 1 if the document was removed)."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.delete_full_chat": {
      "identifier": "database.db.delete_full_chat",
      "description": {
        "overall": "The function removes a chat and all of its related exchange records from the database. It first deletes every exchange document that matches the provided username and chat name using the `dbexchanges.delete_many` operation. Afterwards it deletes the chat document itself via `dbchats.delete_one`. Finally, it returns the count of deleted chat documents, indicating whether the chat was successfully removed.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username associated with the chat to be deleted."
          },
          {
            "name": "chat_name",
            "type": "str",
            "description": "The name of the chat that should be removed."
          }
        ],
        "returns": [
          {
            "name": "deleted_count",
            "type": "int",
            "description": "The number of chat documents deleted (0 if none were found, 1 if the chat was removed)."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "No functions are documented as calling this function."
        }
      },
      "error": null
    },
    "frontend.frontend.clean_names": {
      "identifier": "frontend.frontend.clean_names",
      "description": {
        "overall": "The function `clean_names` processes a collection of model identifiers. It iterates over each element in the provided `model_list` and extracts the substring after the last '/' character. The extraction is performed using the `split` method and a list comprehension. The resulting list of cleaned names is returned to the caller.",
        "parameters": [
          {
            "name": "model_list",
            "type": "list",
            "description": "A list of model name strings, each potentially containing path components separated by '/'."
          }
        ],
        "returns": [
          {
            "name": "",
            "type": "list",
            "description": "A list of strings containing only the final component of each input model name after splitting by '/'."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "frontend.frontend.get_filtered_models": {
      "identifier": "frontend.frontend.get_filtered_models",
      "description": {
        "overall": "The function filters a list of model identifiers based on a selected category. It retrieves a list of keywords for the given category from the global CATEGORY_KEYWORDS mapping. If the keyword list contains the special token \"STANDARD\", the function returns only those models that are also present in the predefined STANDARD_MODELS collection. Otherwise, it builds a new list containing models whose lowercase names contain any of the retrieved keywords. If no models match the keywords, the original source list is returned unchanged.",
        "parameters": [
          {
            "name": "source_list",
            "type": "list",
            "description": "A list of model identifiers (typically strings) that should be filtered."
          },
          {
            "name": "category_name",
            "type": "str",
            "description": "The name of the category whose associated keywords are used for filtering."
          }
        ],
        "returns": [
          {
            "name": "filtered_models",
            "type": "list",
            "description": "A list of models that match the category criteria, or the original source_list if no matches are found."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "frontend.frontend.save_gemini_cb": {
      "identifier": "frontend.frontend.save_gemini_cb",
      "description": {
        "overall": "The function `save_gemini_cb` retrieves a Gemini API key from the Streamlit session state. If a key is present, it updates the stored key for the current user in the database via `db.update_gemini_key`. After successfully saving, it clears the input field in the session state. Finally, it shows a toast notification confirming the successful save.",
        "parameters": [],
        "returns": [],
        "usage_context": {
          "calls": "This function calls database.db.update_gemini_key.",
          "called_by": "No functions call this function."
        }
      },
      "error": null
    },
    "frontend.frontend.save_ollama_cb": {
      "identifier": "frontend.frontend.save_ollama_cb",
      "description": {
        "overall": "The function `save_ollama_cb` retrieves a potential Ollama service URL from Streamlit's session state. If a non\u2011empty URL is present, it updates the stored Ollama URL for the current user in the database. After successfully updating, it displays a toast notification confirming the save. The function performs no explicit return.",
        "parameters": [],
        "returns": [],
        "usage_context": {
          "calls": "This function calls database.db.update_ollama_url.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "frontend.frontend.load_data_from_db": {
      "identifier": "frontend.frontend.load_data_from_db",
      "description": {
        "overall": "The function load_data_from_db retrieves a user's chat history and associated exchanges from the database and stores them in Streamlit's session state. It first checks whether the data for the given username has already been loaded; if not, it clears the current chats and loads defined chats followed by their exchanges. Missing chats referenced by exchanges are created on the fly, and feedback fields without values are set to NaN. If the user has no chats, a default chat is inserted into the database and set as active; otherwise an active chat is selected from the loaded chats. Finally, the loaded_user flag is updated to prevent redundant loading.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username whose chats and exchanges are to be loaded from the database."
          }
        ],
        "returns": [],
        "usage_context": {
          "calls": "This function calls database.db.fetch_chats_by_user, database.db.fetch_exchanges_by_user, and database.db.insert_chat.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "frontend.frontend.handle_feedback_change": {
      "identifier": "frontend.frontend.handle_feedback_change",
      "description": {
        "overall": "The function updates the feedback value of a given exchange object, persists the change to the database, and then triggers a Streamlit rerun to refresh the UI. It directly mutates the provided exchange dictionary by setting its \"feedback\" key to the new value. Afterwards it calls a database helper to store the updated feedback using the exchange's identifier. Finally, it invokes Streamlit's rerun mechanism to reflect the change immediately.",
        "parameters": [
          {
            "name": "ex",
            "type": "dict",
            "description": "A dictionary representing an exchange; it must contain at least the keys \"_id\" and \"feedback\"."
          },
          {
            "name": "val",
            "type": "Any",
            "description": "The new feedback value to assign to the exchange."
          }
        ],
        "returns": [],
        "usage_context": {
          "calls": "This function calls database.db.update_exchange_feedback.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "frontend.frontend.handle_delete_exchange": {
      "identifier": "frontend.frontend.handle_delete_exchange",
      "description": {
        "overall": "The function handle_delete_exchange removes a specific exchange from both the persistent database and the in\u2011memory chat state. It receives the chat identifier and an exchange object, extracts the exchange's unique identifier, and invokes database.db.delete_exchange_by_id to delete the record. It then checks whether the chat exists in Streamlit's session_state and, if the exchange is present in the chat's exchanges list, removes it from that list. Finally, it triggers a Streamlit rerun to refresh the UI.",
        "parameters": [
          {
            "name": "chat_name",
            "type": "str",
            "description": "The name of the chat from which the exchange should be removed."
          },
          {
            "name": "ex",
            "type": "dict",
            "description": "A dictionary representing the exchange to delete; expected to contain an \"_id\" key identifying it in the database."
          }
        ],
        "returns": [],
        "usage_context": {
          "calls": "This function calls database.db.delete_exchange_by_id.",
          "called_by": "No functions are listed as callers of this function."
        }
      },
      "error": null
    },
    "frontend.frontend.handle_delete_chat": {
      "identifier": "frontend.frontend.handle_delete_chat",
      "description": {
        "overall": "The function handle_delete_chat removes a specific chat for a given user from the database and updates the Streamlit session state accordingly. It first calls db.delete_full_chat to delete the chat records. It then removes the chat entry from st.session_state.chats if present. Depending on whether any chats remain, it either selects the first remaining chat as active or creates a new empty chat named \"Chat 1\", inserting it into the database and initializing its session state. Finally, it triggers a Streamlit rerun to refresh the UI.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The identifier of the user whose chat is being deleted."
          },
          {
            "name": "chat_name",
            "type": "str",
            "description": "The name of the chat to delete."
          }
        ],
        "returns": [],
        "usage_context": {
          "calls": "This function calls database.db.delete_full_chat and database.db.insert_chat.",
          "called_by": "No functions are listed as calling this function."
        }
      },
      "error": null
    },
    "frontend.frontend.extract_repo_name": {
      "identifier": "frontend.frontend.extract_repo_name",
      "description": {
        "overall": "The function `extract_repo_name` extracts a repository name from a block of text that may contain a URL. It first searches the text for an HTTP or HTTPS URL using a regular expression. If a URL is found, it parses the URL, trims leading and trailing slashes from the path, and takes the last segment as the repository name. If the name ends with the suffix \".git\", that suffix is removed before the name is returned. If no URL or no path segment is present, the function returns `None`.",
        "parameters": [
          {
            "name": "text",
            "type": "str",
            "description": "A string that may contain a repository URL from which the repository name should be extracted."
          }
        ],
        "returns": [
          {
            "name": "",
            "type": "str | None",
            "description": "The extracted repository name without a trailing \".git\" suffix, or `None` if no suitable URL is found."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "frontend.frontend.stream_text_generator": {
      "identifier": "frontend.frontend.stream_text_generator",
      "description": {
        "overall": "The function `stream_text_generator` takes a single string argument and produces a stream of its constituent words. It splits the input text on spaces and iterates over each resulting word. For each word, it yields the word followed by a trailing space and then pauses briefly using `time.sleep`. This creates a generator that can be consumed to simulate a typing effect or incremental display of text.",
        "parameters": [
          {
            "name": "text",
            "type": "str",
            "description": "The input text to be split into words."
          }
        ],
        "returns": [
          {
            "name": "generator",
            "type": "Generator[str, None, None]",
            "description": "A generator that yields each word from the input text followed by a space, with a short delay between yields."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any documented functions."
        }
      },
      "error": null
    },
    "frontend.frontend.render_text_with_mermaid": {
      "identifier": "frontend.frontend.render_text_with_mermaid",
      "description": {
        "overall": "The function `render_text_with_mermaid` takes a markdown string and optionally streams its content. It first checks whether the provided markdown text is empty and returns early if it is. The function then splits the markdown into alternating parts of regular text and mermaid diagram blocks using a regular\u2011expression split. Regular text parts are rendered in Streamlit as markdown, either directly or via a streaming writer when `should_stream` is True. Mermaid parts are rendered with `st_mermaid`; if that fails, the mermaid source is shown as a code block.",
        "parameters": [
          {
            "name": "markdown_text",
            "type": "str",
            "description": "The markdown content to be processed, which may include regular text and mermaid diagram blocks."
          },
          {
            "name": "should_stream",
            "type": "bool",
            "description": "Flag indicating whether the markdown text should be streamed to the UI using `st.write_stream`; defaults to False."
          }
        ],
        "returns": [],
        "usage_context": {
          "calls": "This function calls frontend.frontend.stream_text_generator.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "frontend.frontend.render_exchange": {
      "identifier": "frontend.frontend.render_exchange",
      "description": {
        "overall": "The function `render_exchange` displays a single exchange (question and answer) within a Streamlit chat interface. It first writes the user's question, then opens an assistant message container where it shows the answer, detects error messages, and provides a toolbar with interactive UI elements such as feedback buttons, a comment pop\u2011over, a download button, and a delete button. The toolbar is arranged horizontally on the right side of the container, and the appearance of the feedback buttons adapts based on the stored feedback state in the exchange dictionary. User interactions trigger helper functions that update feedback in the database, save comment text, or delete the exchange, and the answer content is rendered with Mermaid support inside a scrollable container. The function does not return any value.",
        "parameters": [
          {
            "name": "ex",
            "type": "dict",
            "description": "A dictionary representing a single exchange, containing keys such as \"question\", \"answer\", \"_id\", \"feedback\", \"feedback_message\", etc."
          },
          {
            "name": "current_chat_name",
            "type": "str",
            "description": "The name of the chat session to which the exchange belongs."
          }
        ],
        "returns": [],
        "usage_context": {
          "calls": "This function calls database.db.update_exchange_feedback_message, frontend.frontend.handle_delete_exchange, frontend.frontend.handle_feedback_change, and frontend.frontend.render_text_with_mermaid.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    }
  },
  "classes": {
    "backend.AST_Schema.ASTVisitor": {
      "identifier": "backend.AST_Schema.ASTVisitor",
      "description": {
        "overall": "ASTVisitor is an AST node visitor that walks a Python source file and builds a lightweight schema describing the module's imports, functions, and classes. It records the module path using the external `path_to_module` helper, stores collected information in a nested dictionary, and tracks the currently visited class to capture method metadata. The visitor provides dedicated handlers for import statements, class definitions, and function definitions, delegating to the generic visitor for deeper traversal.",
        "init_method": {
          "description": "The constructor stores the raw source code, the file's path, and the project root, then computes the module's dotted path using `path_to_module`. It also initializes an empty schema dictionary to collect imports, functions, and classes, and prepares a placeholder for the class currently being visited.",
          "parameters": [
            {
              "name": "source_code",
              "type": "str",
              "description": "The full text of the Python source file that will be parsed."
            },
            {
              "name": "file_path",
              "type": "str",
              "description": "The filesystem path to the source file."
            },
            {
              "name": "project_root",
              "type": "str",
              "description": "The root directory of the project, used to resolve the module's dotted name."
            }
          ]
        },
        "methods": [
          {
            "identifier": "backend.AST_Schema.ASTVisitor.visit_Import",
            "description": {
              "overall": "This method processes `import` statements encountered in the AST. It iterates over each alias in the node's `names` list and appends the imported module name to the `schema[\"imports\"]` collection. After recording the imports, it calls `generic_visit` to continue traversing any child nodes of the import statement. The method does not return a value.",
              "parameters": [
                {
                  "name": "self",
                  "type": "ASTVisitor",
                  "description": "The visitor instance."
                },
                {
                  "name": "node",
                  "type": "ast.Import",
                  "description": "The AST node representing an `import` statement."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "The method does not call any other functions or methods.",
                "called_by": "No recorded callers for this method."
              }
            },
            "error": null
          },
          {
            "identifier": "backend.AST_Schema.ASTVisitor.visit_ImportFrom",
            "description": {
              "overall": "This method handles `from ... import ...` statements. For each alias in the node's `names`, it constructs a fully\u2011qualified import string combining the module name and the alias, then appends it to `schema[\"imports\"]`. It finally invokes `generic_visit` to walk any nested nodes. The method returns nothing.",
              "parameters": [
                {
                  "name": "self",
                  "type": "ASTVisitor",
                  "description": "The visitor instance."
                },
                {
                  "name": "node",
                  "type": "ast.ImportFrom",
                  "description": "The AST node representing a `from ... import ...` statement."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "The method does not call any other functions or methods.",
                "called_by": "No recorded callers for this method."
              }
            },
            "error": null
          },
          {
            "identifier": "backend.AST_Schema.ASTVisitor.visit_ClassDef",
            "description": {
              "overall": "When a class definition node is visited, this method builds a unique identifier for the class by combining the module path with the class name. It creates a `class_info` dictionary containing analysis metadata such as the identifier, name, docstring, source segment, and line numbers, and appends it to `schema[\"classes\"]`. The method also sets `_current_class` to this dictionary so that subsequent function visits can be recorded as methods of the class, then delegates to `generic_visit` to process the class body, and finally resets `_current_class` to `None`.",
              "parameters": [
                {
                  "name": "self",
                  "type": "ASTVisitor",
                  "description": "The visitor instance."
                },
                {
                  "name": "node",
                  "type": "ast.ClassDef",
                  "description": "The AST node representing a class definition."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "The method does not call any external functions; it only uses built\u2011in `ast` utilities and the visitor's own attributes.",
                "called_by": "No recorded callers for this method."
              }
            },
            "error": null
          },
          {
            "identifier": "backend.AST_Schema.ASTVisitor.visit_FunctionDef",
            "description": {
              "overall": "This method processes function definition nodes. If the visitor is currently inside a class (`_current_class` is set), it creates a `method_context_info` entry describing the method and adds it to the class's `context[\"method_context\"]` list. Otherwise, it builds a top\u2011level `func_info` dictionary with metadata and appends it to `schema[\"functions\"]`. After recording the appropriate information, it calls `generic_visit` to traverse the function body. The method returns nothing.",
              "parameters": [
                {
                  "name": "self",
                  "type": "ASTVisitor",
                  "description": "The visitor instance."
                },
                {
                  "name": "node",
                  "type": "ast.FunctionDef",
                  "description": "The AST node representing a function definition."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "The method does not call any other functions or methods directly.",
                "called_by": "No recorded callers for this method."
              }
            },
            "error": null
          },
          {
            "identifier": "backend.AST_Schema.ASTVisitor.visit_AsyncFunctionDef",
            "description": {
              "overall": "This method handles asynchronous function definitions by delegating to `visit_FunctionDef`, thereby reusing the same logic for recording async functions as regular functions. It receives an `ast.AsyncFunctionDef` node and forwards it unchanged. No additional processing is performed, and the method returns nothing.",
              "parameters": [
                {
                  "name": "self",
                  "type": "ASTVisitor",
                  "description": "The visitor instance."
                },
                {
                  "name": "node",
                  "type": "ast.AsyncFunctionDef",
                  "description": "The AST node representing an async function definition."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "The method calls `visit_FunctionDef` to handle the node.",
                "called_by": "No recorded callers for this method."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "The class depends on the external helper `backend.AST_Schema.path_to_module` to translate file paths into module identifiers.",
          "instantiated_by": "There are no recorded locations in the provided context that instantiate this class."
        }
      },
      "error": null
    },
    "backend.AST_Schema.ASTAnalyzer": {
      "identifier": "backend.AST_Schema.ASTAnalyzer",
      "description": {
        "overall": "The **ASTAnalyzer** class is responsible for constructing a full abstract\u2011syntax\u2011tree (AST) schema for a Python code base. It iterates over a collection of source files, uses an **ASTVisitor** to extract imports, functions, and classes, and then enriches that schema with call\u2011relationship information (outgoing, incoming) and class\u2011level dependencies. The resulting nested dictionary can be used downstream for code\u2011graph analysis or dependency visualisation.",
        "init_method": {
          "description": "The constructor creates an instance of **ASTAnalyzer** but performs no additional initialisation; it simply provides a placeholder for future state.",
          "parameters": [
            {
              "name": "self",
              "type": "ASTAnalyzer",
              "description": "Reference to the newly created instance."
            }
          ]
        },
        "methods": [
          {
            "identifier": "merge_relationship_data",
            "description": {
              "overall": "This method merges raw call\u2011relationship data into an existing schema produced by **ASTVisitor**. It extracts outgoing and incoming call mappings from the supplied ``raw_relationships`` dictionary, then walks every file entry in ``full_schema``. For each function it records the list of functions it calls and the list of functions that call it. For each class it records which other functions instantiate the class and builds a set of cross\u2011method dependencies, finally storing the sorted list under the class\u2019s ``dependencies`` key. The enriched schema is returned for further processing.",
              "parameters": [
                {
                  "name": "full_schema",
                  "type": "dict",
                  "description": "A nested dictionary representing the AST information for all analysed files."
                },
                {
                  "name": "raw_relationships",
                  "type": "dict",
                  "description": "Dictionary containing ``outgoing`` and ``incoming`` call mappings keyed by function or method identifiers."
                }
              ],
              "returns": [
                {
                  "name": "full_schema",
                  "type": "dict",
                  "description": "The same schema dictionary, now enriched with call and dependency context."
                }
              ],
              "usage_context": {
                "calls": "The method does not invoke any external functions or classes directly.",
                "called_by": "No other methods in the provided source call ``merge_relationship_data``."
              }
            },
            "error": null
          },
          {
            "identifier": "analyze_repository",
            "description": {
              "overall": "This method builds the initial AST schema for a repository. It receives a list of file objects and a ``GitRepository`` instance, determines the project root, and iterates over each Python file. For each file it parses the source with ``ast.parse`` and creates an ``ASTVisitor`` (passing the source code, file path, and project root) to walk the tree and collect imports, functions, and classes. The visitor\u2019s ``schema`` is stored under the file\u2019s entry in ``full_schema``. Files that cannot be parsed are reported via a warning message. The completed ``full_schema`` dictionary is returned.",
              "parameters": [
                {
                  "name": "files",
                  "type": "list",
                  "description": "A list of file objects, each exposing ``path`` and ``content`` attributes."
                },
                {
                  "name": "repo",
                  "type": "GitRepository",
                  "description": "An object representing the Git repository; currently only used for contextual purposes."
                }
              ],
              "returns": [
                {
                  "name": "full_schema",
                  "type": "dict",
                  "description": "Dictionary containing the AST information for every parsed Python file."
                }
              ],
              "usage_context": {
                "calls": "It calls the ``ASTVisitor`` class to traverse each file's abstract syntax tree.",
                "called_by": "No other methods in the provided source call ``analyze_repository``."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "ASTAnalyzer depends on the ``ASTVisitor`` class (from ``backend.AST_Schema``) to extract AST nodes from source files.",
          "instantiated_by": "The provided context does not list any component that instantiates ``ASTAnalyzer``."
        }
      },
      "error": null
    },
    "backend.File_Dependency.FileDependencyGraph": {
      "identifier": "backend.File_Dependency.FileDependencyGraph",
      "description": {
        "overall": "The **FileDependencyGraph** class walks the abstract syntax tree of a Python file and records which other modules or symbols the file imports. It resolves both absolute and relative import statements, handling package ``__init__`` exports and verifying the existence of target modules within the repository. Resolved dependencies are stored in a class\u2011level ``import_dependencies`` dictionary keyed by the analysed file name, enabling later construction of a full file\u2011level dependency graph for the repository.",
        "init_method": {
          "description": "The constructor stores the name of the file to be analysed and the root directory of the repository, preparing the instance for subsequent AST traversal and dependency collection.",
          "parameters": [
            {
              "name": "filename",
              "type": "str",
              "description": "The path (relative or absolute) of the Python file whose imports are to be analysed."
            },
            {
              "name": "repo_root",
              "type": "Any",
              "description": "The root directory of the repository containing the file; used to locate other files during import resolution."
            }
          ]
        },
        "methods": [
          {
            "identifier": "_resolve_module_name",
            "description": {
              "overall": "This method resolves relative ``from .. import name`` statements to concrete module or symbol names that exist in the repository. It determines the import's level, gathers candidate files that match the current file, and walks up the directory hierarchy to the appropriate base directory. Two helper functions \u2013 ``module_file_exists`` and ``init_exports_symbol`` \u2013 are used to check for a matching ``.py`` file or an exported symbol in a package's ``__init__.py``. Valid names are collected, deduplicated, sorted and returned; if none can be resolved an ``ImportError`` is raised.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ImportFrom",
                  "description": "AST node representing the relative import statement to be resolved."
                }
              ],
              "returns": [
                {
                  "name": "resolved_names",
                  "type": "list[str]",
                  "description": "Sorted list of module or symbol names that were successfully resolved from the relative import."
                }
              ],
              "usage_context": {
                "calls": "It calls the external functions ``backend.File_Dependency.get_all_temp_files``, ``backend.File_Dependency.init_exports_symbol`` and ``backend.File_Dependency.module_file_exists`` to locate files and verify exports.",
                "called_by": "It is invoked by the ``visit_ImportFrom`` method when handling relative imports that lack an explicit module name."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_Import",
            "description": {
              "overall": "The method processes generic import statements (both ``import`` and ``from ... import``) by iterating over each alias in the node. It ensures that the class\u2011level ``import_dependencies`` dictionary has an entry for the current file and then adds either the supplied ``base_name`` or the alias's name to the set of dependencies for that file. After updating the mapping it continues the AST traversal by calling ``generic_visit``. This records direct import relationships for later graph construction.",
              "parameters": [
                {
                  "name": "node",
                  "type": "Import | ImportFrom",
                  "description": "AST node representing the import statement being visited."
                },
                {
                  "name": "base_name",
                  "type": "str | None",
                  "description": "Optional base module name to record instead of the alias name; used for relative imports."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "It calls ``generic_visit`` to continue walking the AST after recording dependencies.",
                "called_by": "It is called by ``visit_ImportFrom`` for both absolute imports (with a derived base name) and relative imports (after name resolution)."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_ImportFrom",
            "description": {
              "overall": "This method handles ``ImportFrom`` nodes, distinguishing between absolute imports that specify a module and relative imports that do not. For absolute imports it extracts the last component of the module path and forwards the node to ``visit_Import`` with that base name. For relative imports it attempts to resolve the module names using ``_resolve_module_name``; each resolved base name is then passed to ``visit_Import``. If resolution fails an informative message is printed. Finally, it calls ``generic_visit`` to continue traversing the AST. This integrates relative import resolution into the overall dependency collection process.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ImportFrom",
                  "description": "AST node representing a ``from ... import`` statement."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "It calls ``_resolve_module_name`` (when the import has no explicit module) and ``visit_Import`` to record the resolved dependencies, then ``generic_visit`` to continue traversal.",
                "called_by": "No other methods in the class call ``visit_ImportFrom`` directly."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "The class relies on the functions ``get_all_temp_files``, ``init_exports_symbol`` and ``module_file_exists`` from the ``backend.File_Dependency`` module.",
          "instantiated_by": "No external code in the provided context directly instantiates this class."
        }
      },
      "error": null
    },
    "backend.HelperLLM.LLMHelper": {
      "identifier": "backend.HelperLLM.LLMHelper",
      "description": {
        "overall": "LLMHelper is a utility class that abstracts interaction with multiple large\u2011language\u2011model back\u2011ends (Google Gemini, OpenAI, Ollama and custom endpoints). It loads system prompts for function\u2011 and class\u2011level documentation, configures a model\u2011specific batch size, creates structured LLM wrappers for the FunctionAnalysis and ClassAnalysis schemas, and provides batch\u2011processing methods that generate and validate documentation for collections of functions or classes while handling rate\u2011limit delays and errors.",
        "init_method": {
          "description": "The constructor validates the provided API key, reads the function and class system\u2011prompt files, selects and configures an appropriate LLM client based on the model name, determines the batch size for that model, and creates structured\u2011output LLM wrappers for function and class analysis.",
          "parameters": [
            {
              "name": "api_key",
              "type": "str",
              "description": "API key used to authenticate with the selected LLM provider."
            },
            {
              "name": "function_prompt_path",
              "type": "str",
              "description": "Filesystem path to the text file containing the system prompt for function documentation."
            },
            {
              "name": "class_prompt_path",
              "type": "str",
              "description": "Filesystem path to the text file containing the system prompt for class documentation."
            },
            {
              "name": "model_name",
              "type": "str",
              "description": "Identifier of the LLM model to use (e.g., \"gemini-2.0-flash-lite\"). Defaults to \"gemini-2.0-flash-lite\"."
            },
            {
              "name": "base_url",
              "type": "str | None",
              "description": "Optional base URL for custom LLM APIs; used when the model does not match built\u2011in providers."
            }
          ]
        },
        "methods": [
          {
            "identifier": "_configure_batch_settings",
            "description": {
              "overall": "Sets the instance attribute `batch_size` based on the supplied model name. It contains a series of conditional branches that map known model identifiers to optimal batch sizes, falling back to a conservative default of 2 for unknown models. The method also logs a warning when the model is not recognized. No value is returned.",
              "parameters": [
                {
                  "name": "model_name",
                  "type": "str",
                  "description": "The name of the LLM model for which batch size should be configured."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method does not call any other functions or methods.",
                "called_by": "No other methods are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "generate_for_functions",
            "description": {
              "overall": "Generates documentation for a list of functions by converting each `FunctionAnalysisInput` into a JSON payload, pairing it with the function system prompt, and sending the conversations to the LLM in batches. It respects the configured `batch_size`, logs progress, handles exceptions by inserting `None` placeholders, and waits between batches to obey rate limits. The method returns a list of `FunctionAnalysis` objects (or `None` for failed items).",
              "parameters": [
                {
                  "name": "function_inputs",
                  "type": "List[FunctionAnalysisInput]",
                  "description": "A list of input models describing the functions to be documented."
                }
              ],
              "returns": [
                {
                  "name": "result",
                  "type": "List[Optional[FunctionAnalysis]]",
                  "description": "A list containing the LLM\u2011generated `FunctionAnalysis` objects for each input, or `None` where a call failed."
                }
              ],
              "usage_context": {
                "calls": "This method does not call any other functions or methods directly (it uses standard library utilities such as `json.dumps`, `time.sleep`, and the LLM wrapper's `batch` method).",
                "called_by": "No other methods are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "generate_for_classes",
            "description": {
              "overall": "Generates documentation for a list of classes in the same batch\u2011processing fashion as `generate_for_functions`. It serialises each `ClassAnalysisInput` to JSON, pairs it with the class system prompt, and invokes the LLM's structured\u2011output wrapper for class analysis. Errors are caught, logged, and result in `None` placeholders, while rate\u2011limit pauses are observed between batches. The method returns a list of `ClassAnalysis` objects (or `None` for failures).",
              "parameters": [
                {
                  "name": "class_inputs",
                  "type": "List[ClassAnalysisInput]",
                  "description": "A list of input models describing the classes to be documented."
                }
              ],
              "returns": [
                {
                  "name": "result",
                  "type": "List[Optional[ClassAnalysis]]",
                  "description": "A list containing the LLM\u2011generated `ClassAnalysis` objects for each input, or `None` where a call failed."
                }
              ],
              "usage_context": {
                "calls": "This method does not call any other functions or methods directly (it uses standard library utilities such as `json.dumps`, `time.sleep`, and the LLM wrapper's `batch` method).",
                "called_by": "No other methods are recorded as calling this method."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "The class does not have any external dependencies recorded in the provided context.",
          "instantiated_by": "No locations are recorded where this class is instantiated."
        }
      },
      "error": null
    },
    "backend.MainLLM.MainLLM": {
      "identifier": "backend.MainLLM.MainLLM",
      "description": {
        "overall": "The **MainLLM** class is a thin wrapper that abstracts interaction with different large language\u2011model providers (Google Gemini, OpenAI\u2011compatible APIs, and Ollama). It loads a system\u2011prompt from a file, selects the appropriate LangChain chat model based on the supplied `model_name`, and exposes two convenience methods \u2013 `call_llm` for a single synchronous request and `stream_llm` for a streaming response. By handling model\u2011specific initialisation and error logging internally, it offers a uniform interface for the rest of the application.",
        "init_method": {
          "description": "Initialises a MainLLM instance by reading a system prompt file, storing the chosen model name, and constructing a LangChain chat model (`ChatGoogleGenerativeAI`, `ChatOpenAI`, or `ChatOllama`) appropriate for the supplied `model_name`. It also validates the presence of an API key and, when required, a custom SCADSLLM URL.",
          "parameters": [
            {
              "name": "api_key",
              "type": "str",
              "description": "API key required by the underlying LLM provider."
            },
            {
              "name": "prompt_file_path",
              "type": "str",
              "description": "Path to a UTF\u20118 text file containing the system prompt that will be sent with every request."
            },
            {
              "name": "model_name",
              "type": "str",
              "description": "Identifier of the LLM model to use (e.g., \"gemini-2.5-pro\", \"gpt-4\", or an Ollama model name). Defaults to \"gemini-2.5-pro\"."
            },
            {
              "name": "base_url",
              "type": "str | None",
              "description": "Optional base URL for custom endpoints (used when `model_name` does not match built\u2011in providers)."
            }
          ]
        },
        "methods": [
          {
            "identifier": "call_llm",
            "description": {
              "overall": "Builds a message list consisting of the stored system prompt and the supplied user input, then invokes the configured LLM synchronously via `self.llm.invoke`. If the call succeeds, the method returns the textual content of the LLM's response; otherwise it logs the exception and returns `None`.",
              "parameters": [
                {
                  "name": "self",
                  "type": "MainLLM",
                  "description": "Reference to the current MainLLM instance."
                },
                {
                  "name": "user_input",
                  "type": "str",
                  "description": "The user's query or instruction to be sent to the LLM."
                }
              ],
              "returns": [
                {
                  "name": "response_content",
                  "type": "str | None",
                  "description": "The content returned by the LLM on success, or `None` if an error occurred."
                }
              ],
              "usage_context": {
                "calls": "This method does not call any other functions.",
                "called_by": "No other functions are shown to call this method."
              }
            },
            "error": null
          },
          {
            "identifier": "stream_llm",
            "description": {
              "overall": "Creates the same message list as `call_llm` but uses the streaming interface `self.llm.stream`. It yields each chunk's content as it arrives, allowing the caller to process a partial response in real time. If an exception occurs, an error message string is yielded instead of raising.",
              "parameters": [
                {
                  "name": "self",
                  "type": "MainLLM",
                  "description": "Reference to the current MainLLM instance."
                },
                {
                  "name": "user_input",
                  "type": "str",
                  "description": "The user's query or instruction to be streamed to the LLM."
                }
              ],
              "returns": [
                {
                  "name": "stream",
                  "type": "Iterator[str]",
                  "description": "An iterator yielding pieces of the LLM's response as strings, or an error message string if the call fails."
                }
              ],
              "usage_context": {
                "calls": "This method does not call any other functions.",
                "called_by": "No other functions are shown to call this method."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "The class does not declare any external runtime dependencies beyond the imported modules.",
          "instantiated_by": "No instantiation sites are provided in the current context."
        }
      },
      "error": null
    },
    "backend.basic_info.ProjektInfoExtractor": {
      "identifier": "backend.basic_info.ProjektInfoExtractor",
      "description": {
        "overall": "ProjektInfoExtractor orchestrates the extraction of basic project metadata from common repository files such as README, pyproject.toml and requirements.txt. It builds a structured `info` dictionary containing a project overview (title, description, status, key features, tech stack) and installation details (dependencies, setup instructions, quick\u2011start guide). Helper methods clean raw file contents, locate files by pattern, and parse specific formats, while the main `extrahiere_info` method coordinates the workflow and returns the populated information. The class therefore provides a reusable abstraction for quickly summarising a Python project's essential documentation.",
        "init_method": {
          "description": "The constructor creates a placeholder string `INFO_NICHT_GEFUNDEN` and initialises the `info` attribute with a nested dictionary that contains sections for project overview and installation, each pre\u2011filled with the placeholder value. No external parameters are required.",
          "parameters": []
        },
        "methods": [
          {
            "identifier": "_clean_content",
            "description": {
              "overall": "Removes null\u2011byte characters from a string, handling empty input gracefully. It first checks whether the supplied `content` is falsy and returns an empty string in that case. Otherwise it replaces all occurrences of the null byte (`\\x00`) with an empty string and returns the cleaned result. This preprocessing step protects downstream parsers from encoding artefacts.",
              "parameters": [
                {
                  "name": "self",
                  "type": "ProjektInfoExtractor",
                  "description": "Instance reference."
                },
                {
                  "name": "content",
                  "type": "str",
                  "description": "The raw text that may contain null\u2011byte characters."
                }
              ],
              "returns": [
                {
                  "name": "cleaned_content",
                  "type": "str",
                  "description": "The input text with all null\u2011byte characters removed, or an empty string if the input was falsy."
                }
              ],
              "usage_context": {
                "calls": "This method does not call any other functions.",
                "called_by": "No other functions are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "_finde_datei",
            "description": {
              "overall": "Searches through a collection of file objects to locate one whose path matches any of the supplied filename patterns, using a case\u2011insensitive comparison. It iterates over each file and, for each file, over each pattern, returning the first matching file object. If no file matches, the method returns `None`. This helper abstracts the file\u2011discovery logic needed by the extractor.",
              "parameters": [
                {
                  "name": "self",
                  "type": "ProjektInfoExtractor",
                  "description": "Instance reference."
                },
                {
                  "name": "patterns",
                  "type": "List[str]",
                  "description": "A list of filename patterns (e.g., \"readme.md\") to match against."
                },
                {
                  "name": "dateien",
                  "type": "List[Any]",
                  "description": "A list of file objects, each expected to have a `path` attribute."
                }
              ],
              "returns": [
                {
                  "name": "found_file",
                  "type": "Optional[Any]",
                  "description": "The first file object whose path matches one of the patterns, or `None` if no match is found."
                }
              ],
              "usage_context": {
                "calls": "This method does not call any other functions.",
                "called_by": "No other functions are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "_extrahiere_sektion_aus_markdown",
            "description": {
              "overall": "Extracts the markdown section that follows a level\u20112 heading (`##`) matching any of the supplied keywords. It builds a regular\u2011expression pattern that joins the keywords with an OR operator, searches the content, and captures all text until the next heading of the same level or the end of the document. The captured block is stripped of surrounding whitespace and returned. If the heading is not present, the method returns `None`.",
              "parameters": [
                {
                  "name": "self",
                  "type": "ProjektInfoExtractor",
                  "description": "Instance reference."
                },
                {
                  "name": "inhalt",
                  "type": "str",
                  "description": "The full markdown text to search within."
                },
                {
                  "name": "keywords",
                  "type": "List[str]",
                  "description": "A list of possible heading titles that identify the desired section."
                }
              ],
              "returns": [
                {
                  "name": "section_text",
                  "type": "Optional[str]",
                  "description": "The extracted section content without the heading, or `None` if no matching heading is found."
                }
              ],
              "usage_context": {
                "calls": "This method does not call any other functions.",
                "called_by": "No other functions are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "_parse_readme",
            "description": {
              "overall": "Parses the content of a README file to populate various fields of the `info` structure. After cleaning the raw content, it extracts the title using a regex that matches the first top\u2011level heading, then attempts to capture a brief description following the title. It further extracts key features, tech stack, current status, setup instructions, and quick\u2011start guide by delegating to `_extrahiere_sektion_aus_markdown` with appropriate keyword lists. Each discovered piece of information is stored in the corresponding nested dictionary entry, leaving placeholders where data is missing.",
              "parameters": [
                {
                  "name": "self",
                  "type": "ProjektInfoExtractor",
                  "description": "Instance reference."
                },
                {
                  "name": "inhalt",
                  "type": "str",
                  "description": "The raw text of the README file."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method does not call any other functions.",
                "called_by": "No other functions are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "_parse_toml",
            "description": {
              "overall": "Parses a `pyproject.toml` file to obtain project metadata and dependency information. The method first cleans the raw content, then checks whether the `tomllib` module is available; if not, it prints a warning and aborts. When available, it loads the TOML data, extracts the `project` table, and copies the `name`, `description`, and `dependencies` fields into the appropriate locations of the `info` dictionary. Any parsing errors are caught and reported via a warning message.",
              "parameters": [
                {
                  "name": "self",
                  "type": "ProjektInfoExtractor",
                  "description": "Instance reference."
                },
                {
                  "name": "inhalt",
                  "type": "str",
                  "description": "The raw text of the pyproject.toml file."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method does not call any other functions.",
                "called_by": "No other functions are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "_parse_requirements",
            "description": {
              "overall": "Parses a `requirements.txt` file to collect a list of dependency specifications. After cleaning the content, it splits the text into lines, removes empty lines and comment lines, and builds a list of stripped dependency strings. The list is stored in the `info[\"installation\"][\"dependencies\"]` field only if that field has not already been populated by the TOML parser. This ensures that TOML\u2011provided dependencies take precedence.",
              "parameters": [
                {
                  "name": "self",
                  "type": "ProjektInfoExtractor",
                  "description": "Instance reference."
                },
                {
                  "name": "inhalt",
                  "type": "str",
                  "description": "The raw text of the requirements.txt file."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method does not call any other functions.",
                "called_by": "No other functions are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "extrahiere_info",
            "description": {
              "overall": "Coordinates the overall extraction process for a repository. It first locates the README, pyproject.toml, and requirements.txt files using `_finde_datei`. The files are then parsed in order of priority: TOML first (to obtain canonical metadata), followed by requirements (to fill missing dependencies), and finally README (to extract human\u2011readable project information). After parsing, the method normalises the dependencies field into a formatted bullet\u2011list string and, if a repository URL is supplied, derives a fallback project title from the URL when no title has been found. The fully populated `info` dictionary is returned to the caller.",
              "parameters": [
                {
                  "name": "self",
                  "type": "ProjektInfoExtractor",
                  "description": "Instance reference."
                },
                {
                  "name": "dateien",
                  "type": "List[Any]",
                  "description": "A list of file objects representing the repository's files; each object should have `path` and `content` attributes."
                },
                {
                  "name": "repo_url",
                  "type": "str",
                  "description": "The URL of the repository, used to derive a fallback title if necessary."
                }
              ],
              "returns": [
                {
                  "name": "info",
                  "type": "Dict[str, Any]",
                  "description": "A dictionary containing the extracted project overview and installation information."
                }
              ],
              "usage_context": {
                "calls": "This method does not call any other functions.",
                "called_by": "No other functions are recorded as calling this method."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "The class does not have any external dependencies listed.",
          "instantiated_by": "No locations are recorded as instantiating this class."
        }
      },
      "error": null
    },
    "backend.callgraph.CallGraph": {
      "identifier": "backend.callgraph.CallGraph",
      "description": {
        "overall": "CallGraph is an AST visitor that builds a directed call graph for a single Python source file. It records imports, class and function definitions, and resolves call relationships to fully\u2011qualified names, storing the results in a NetworkX DiGraph and auxiliary edge dictionaries. The class therefore provides a reusable abstraction for static analysis of call relationships within a module.",
        "init_method": {
          "description": "The constructor stores the filename of the module to be analysed and initialises the internal state required for graph construction. It creates containers for the current traversal context, a mapping of local definitions, import aliases, a NetworkX directed graph, and structures for tracking edges and discovered functions.",
          "parameters": [
            {
              "name": "filename",
              "type": "str",
              "description": "Path or name of the Python source file that will be visited to build the call graph."
            }
          ]
        },
        "methods": [
          {
            "identifier": "_recursive_call",
            "description": {
              "overall": "This helper method extracts the dotted name components from an AST Call node. It walks the node recursively, handling Call, Name, and Attribute nodes, and returns a list of identifier strings representing the call target. For a simple name it returns a one\u2011element list, while for attribute chains it builds the sequence from the base object outward. If the node type is not recognised, it returns an empty list. The method is used by the visitor when processing Call nodes to obtain the raw name parts before resolution.",
              "parameters": [
                {
                  "name": "node",
                  "type": "Any",
                  "description": "An AST node that is expected to be a Call, Name, or Attribute representing a function invocation."
                }
              ],
              "returns": [
                {
                  "name": "",
                  "type": "list[str]",
                  "description": "A list of name components (e.g., ['pkg', 'mod', 'Class', 'method'])."
                }
              ],
              "usage_context": {
                "calls": "This method does not call any other methods.",
                "called_by": "No other methods are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "_resolve_all_callee_names",
            "description": {
              "overall": "This method receives a list of name\u2011component lists (as produced by _recursive_call) and resolves each to a fully qualified identifier. It first checks whether the simple or dotted name matches a locally defined symbol, then looks up import aliases, and finally falls back to constructing a module\u2011relative name using the current file and class context. Resolved names are returned as strings, using a \"::\" separator for module paths. The method ensures that calls are mapped to the correct definition regardless of import style or local scope.",
              "parameters": [
                {
                  "name": "callee_nodes",
                  "type": "list[list[str]]",
                  "description": "A list where each element is a list of name components representing a potential callee."
                }
              ],
              "returns": [
                {
                  "name": "",
                  "type": "list[str]",
                  "description": "A list of resolved fully\u2011qualified callee names."
                }
              ],
              "usage_context": {
                "calls": "This method does not call any other methods.",
                "called_by": "No other methods are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "_make_full_name",
            "description": {
              "overall": "Constructs a fully qualified name string for a function or method based on the filename, optional class name, and a base identifier. If a class name is supplied, the format is \"filename::ClassName::basename\"; otherwise it is \"filename::basename\". This utility is used when registering definitions during the AST walk to keep a consistent naming scheme across the graph.",
              "parameters": [
                {
                  "name": "basename",
                  "type": "str",
                  "description": "The simple name of the function or method."
                },
                {
                  "name": "class_name",
                  "type": "str | None",
                  "description": "Optional name of the enclosing class; if None the name is treated as a top\u2011level function."
                }
              ],
              "returns": [
                {
                  "name": "",
                  "type": "str",
                  "description": "A fully qualified identifier in the form \"filename::[ClassName::]basename\"."
                }
              ],
              "usage_context": {
                "calls": "This method does not call any other methods.",
                "called_by": "No other methods are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "_current_caller",
            "description": {
              "overall": "Determines the identifier of the function currently being visited. If a function context is active it returns that identifier; otherwise it falls back to a placeholder representing the module or global scope. This value is used as the source node when recording edges for call relationships.",
              "parameters": [
                {
                  "name": "self",
                  "type": "Any",
                  "description": "The CallGraph instance."
                }
              ],
              "returns": [
                {
                  "name": "",
                  "type": "str",
                  "description": "The identifier of the current caller or a placeholder such as \"<filename>\" or \"<global-scope>\"."
                }
              ],
              "usage_context": {
                "calls": "This method does not call any other methods.",
                "called_by": "No other methods are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_Import",
            "description": {
              "overall": "Handles import statements by populating the import_mapping dictionary with alias\u2011to\u2011module relationships. For each alias in the import, the original module name is stored under the alias name (or the module name itself if no alias is used). After updating the mapping, the generic visitor continues traversal of child nodes. This enables later resolution of imported symbols when building the call graph.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.Import",
                  "description": "The AST node representing an import statement."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method does not call any other methods.",
                "called_by": "No other methods are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_ImportFrom",
            "description": {
              "overall": "Processes \"from ... import ...\" statements, extracting the originating module's short name and mapping each imported name (or its alias) to that module. The mapping is stored in import_mapping for later name resolution. No further custom processing is performed beyond delegating to the generic visitor.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.ImportFrom",
                  "description": "The AST node representing a from\u2011import statement."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method does not call any other methods.",
                "called_by": "No other methods are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_ClassDef",
            "description": {
              "overall": "Tracks entry into a class definition by saving the previous class context, setting the current_class attribute to the new class name, and then visiting the class body. After processing the body, it restores the prior class context. This allows the visitor to correctly qualify methods defined inside classes.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.ClassDef",
                  "description": "The AST node representing a class definition."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method does not call any other methods.",
                "called_by": "No other methods are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_FunctionDef",
            "description": {
              "overall": "Handles function (or method) definitions by constructing a fully qualified name using _make_full_name, storing it in local_defs for later lookup, and adding the node to the graph. It also updates the current_function context while recursively visiting the function body. After traversal, the function identifier is added to function_set and the previous function context is restored.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.FunctionDef",
                  "description": "The AST node representing a function or method definition."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method does not call any other methods.",
                "called_by": "No other methods are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_AsyncFunctionDef",
            "description": {
              "overall": "Treats asynchronous function definitions identically to regular functions by delegating to visit_FunctionDef. This ensures that async functions are also recorded in the call graph with the same handling logic.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.AsyncFunctionDef",
                  "description": "The AST node representing an async function definition."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method does not call any other methods.",
                "called_by": "No other methods are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_Call",
            "description": {
              "overall": "Processes a function call expression by determining the current caller, extracting the raw name parts via _recursive_call, and resolving them to fully qualified callee names with _resolve_all_callee_names. It then records an edge from the caller to each resolved callee in the edges dictionary. Finally, it continues generic traversal of the call node's children.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.Call",
                  "description": "The AST node representing a function call."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls the helper methods _current_caller, _recursive_call, and _resolve_all_callee_names.",
                "called_by": "No other methods are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_If",
            "description": {
              "overall": "Special\u2011cases an if\u2011statement that checks \"if __name__ == '__main__'\" by temporarily setting the current function context to \"<main_block>\" so that any calls inside the block are attributed to the module's entry point. For all other if statements it simply performs a generic visit of the node. This handling allows the graph to capture calls made when the module is executed as a script.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.If",
                  "description": "The AST node representing an if statement."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method does not call any other methods.",
                "called_by": "No other methods are recorded as calling this method."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "The class does not rely on external dependencies beyond the imported modules listed in the file.",
          "instantiated_by": "No instantiation sites are provided in the context."
        }
      },
      "error": null
    },
    "backend.getRepo.RepoFile": {
      "identifier": "backend.getRepo.RepoFile",
      "description": {
        "overall": "RepoFile represents a single file inside a Git repository. It lazily loads the underlying Git blob, its decoded text content, and its size only when those properties are accessed, which avoids unnecessary I/O. The class also offers a small example analysis method to count words in the file, a custom string representation, and a helper to serialize its metadata (and optionally its content) to a dictionary. Together these capabilities make RepoFile a convenient abstraction for working with repository files without loading everything up\u2011front.",
        "init_method": {
          "description": "The constructor stores the relative path of the file within the repository and the commit tree from which the file originates. It also initializes internal placeholders for the blob object, the decoded content, and the file size; these placeholders are populated lazily when the corresponding properties are accessed.",
          "parameters": [
            {
              "name": "file_path",
              "type": "str",
              "description": "The path to the file inside the repository."
            },
            {
              "name": "commit_tree",
              "type": "git.Tree",
              "description": "The Tree object of the commit that contains the file."
            }
          ]
        },
        "methods": [
          {
            "identifier": "blob",
            "description": {
              "overall": "The `blob` property lazily retrieves the Git blob object that corresponds to the file path stored in the instance. On first access it looks up the blob in the stored commit tree using the file path; if the path is not present a `FileNotFoundError` is raised. The retrieved blob is cached in the private `_blob` attribute so subsequent accesses are fast. This property provides direct access to low\u2011level Git data such as the raw bytes and size of the file.",
              "parameters": [],
              "returns": [
                {
                  "name": "blob",
                  "type": "git.Blob",
                  "description": "The Git blob object representing the file."
                }
              ],
              "usage_context": {
                "calls": "This method does not call any other functions.",
                "called_by": "No other functions are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "content",
            "description": {
              "overall": "The `content` property returns the decoded text content of the file. It accesses the `blob` property to obtain the raw data stream, reads all bytes, and decodes them as UTF\u20118 while ignoring decoding errors. The result is cached in the private `_content` attribute so the file is read only once. If the file is binary or contains non\u2011UTF\u20118 data, the undecodable bytes are silently dropped.",
              "parameters": [],
              "returns": [
                {
                  "name": "content",
                  "type": "str",
                  "description": "The UTF\u20118 decoded text of the file."
                }
              ],
              "usage_context": {
                "calls": "This method does not call any other functions.",
                "called_by": "No other functions are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "size",
            "description": {
              "overall": "The `size` property provides the size of the file in bytes. It lazily obtains the size from the underlying Git blob (via the `blob` property) and stores it in the private `_size` attribute for future accesses. This avoids repeated look\u2011ups of the blob metadata. The returned value is an integer representing the number of bytes the file occupies in the repository.",
              "parameters": [],
              "returns": [
                {
                  "name": "size",
                  "type": "int",
                  "description": "The size of the file in bytes."
                }
              ],
              "usage_context": {
                "calls": "This method does not call any other functions.",
                "called_by": "No other functions are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "analyze_word_count",
            "description": {
              "overall": "`analyze_word_count` is a simple example analysis method that counts how many words are present in the file's text content. It accesses the `content` property to obtain the decoded string, splits the string on whitespace, and returns the length of the resulting list. This gives a quick metric of the file's word count without any external dependencies. The method is useful for demonstration or lightweight analytics.",
              "parameters": [],
              "returns": [
                {
                  "name": "word_count",
                  "type": "int",
                  "description": "The number of words in the file content."
                }
              ],
              "usage_context": {
                "calls": "This method does not call any other functions.",
                "called_by": "No other functions are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "__repr__",
            "description": {
              "overall": "`__repr__` returns a concise string representation of the `RepoFile` instance that includes the file path. This representation is intended for debugging and logging, making it easy to identify which repository file an object refers to. The method formats the string as `<RepoFile(path='...')>` using the stored `self.path` attribute.",
              "parameters": [],
              "returns": [
                {
                  "name": "repr_str",
                  "type": "str",
                  "description": "A string representation of the RepoFile instance."
                }
              ],
              "usage_context": {
                "calls": "This method does not call any other functions.",
                "called_by": "No other functions are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "to_dict",
            "description": {
              "overall": "`to_dict` serializes the file's metadata into a plain Python dictionary. The dictionary always contains the file's path, its base name (derived via `os.path.basename`), its size in bytes, and a static type field set to \"file\". If the optional argument `include_content` is true, the method also adds the decoded file content under the key \"content\". This method is useful for converting the object into JSON\u2011serializable structures for APIs or storage.",
              "parameters": [
                {
                  "name": "include_content",
                  "type": "bool",
                  "description": "If true, the file's decoded content is added to the output dictionary."
                }
              ],
              "returns": [
                {
                  "name": "data",
                  "type": "dict",
                  "description": "A dictionary containing the file's metadata (and optionally its content)."
                }
              ],
              "usage_context": {
                "calls": "This method does not call any other functions.",
                "called_by": "No other functions are recorded as calling this method."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "The class does not have external dependencies beyond the standard imports listed (tempfile, git, logging, os).",
          "instantiated_by": "No instantiation sites are provided in the context."
        }
      },
      "error": null
    },
    "backend.getRepo.GitRepository": {
      "identifier": "backend.getRepo.GitRepository",
      "description": {
        "overall": "GitRepository manages a Git repository by cloning it into a temporary directory, exposing the repository's files as RepoFile objects, and providing utilities to retrieve a flat list of files or a hierarchical file\u2011tree representation. It also implements the context\u2011manager protocol so that resources are automatically cleaned up when the object is used inside a `with` block. The class abstracts away the low\u2011level Git operations and temporary\u2011directory handling, offering a simple API for higher\u2011level code to work with repository contents.",
        "init_method": {
          "description": "The constructor clones the supplied repository URL into a newly created temporary directory. It stores the URL, the temporary directory path, and the Repo object, and prepares placeholders for the list of files and commit information.",
          "parameters": [
            {
              "name": "repo_url",
              "type": "str",
              "description": "URL of the Git repository to clone."
            }
          ]
        },
        "methods": [
          {
            "identifier": "get_all_files",
            "description": {
              "overall": "This method retrieves all file paths tracked in the cloned repository using Git's `ls-files` command. It splits the output into individual paths, creates a `RepoFile` object for each non\u2011empty path using the repository's commit tree, stores the resulting list in `self.files`, and returns this list. The created `RepoFile` instances give callers access to file content and metadata, and caching the list enables subsequent operations to avoid repeated Git queries.",
              "parameters": [
                {
                  "name": "self",
                  "type": "GitRepository",
                  "description": "The instance on which the method is called."
                }
              ],
              "returns": [
                {
                  "name": "files",
                  "type": "list[RepoFile]",
                  "description": "A list of `RepoFile` objects representing every file in the repository."
                }
              ],
              "usage_context": {
                "calls": "It creates `RepoFile` objects for each file path retrieved from the repository.",
                "called_by": "No other methods are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "close",
            "description": {
              "overall": "The `close` method removes the temporary directory that was created for the cloned repository. If a temporary directory exists, it prints a message indicating its removal and then clears the `temp_dir` attribute, allowing the operating system to reclaim the space. This method is used to clean up resources when the repository is no longer needed.",
              "parameters": [
                {
                  "name": "self",
                  "type": "GitRepository",
                  "description": "The instance on which the method is called."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "It does not call any other functions.",
                "called_by": "No other methods are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "__enter__",
            "description": {
              "overall": "Implements the context\u2011manager entry protocol by returning the `GitRepository` instance itself, allowing it to be used within a `with` statement.",
              "parameters": [
                {
                  "name": "self",
                  "type": "GitRepository",
                  "description": "The instance on which the method is called."
                }
              ],
              "returns": [
                {
                  "name": "self",
                  "type": "GitRepository",
                  "description": "The repository instance, enabling further operations inside the `with` block."
                }
              ],
              "usage_context": {
                "calls": "It does not call any other functions.",
                "called_by": "No other methods are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "__exit__",
            "description": {
              "overall": "Implements the context\u2011manager exit protocol. Regardless of whether an exception occurred, it invokes `self.close()` to clean up the temporary directory and release resources.",
              "parameters": [
                {
                  "name": "self",
                  "type": "GitRepository",
                  "description": "The instance on which the method is called."
                },
                {
                  "name": "exc_type",
                  "type": "type | None",
                  "description": "The exception type, if an exception was raised inside the `with` block."
                },
                {
                  "name": "exc_val",
                  "type": "BaseException | None",
                  "description": "The exception instance raised inside the `with` block."
                },
                {
                  "name": "exc_tb",
                  "type": "TracebackType | None",
                  "description": "The traceback object associated with the exception."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "It calls the `close` method to clean up resources.",
                "called_by": "No other methods are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "get_file_tree",
            "description": {
              "overall": "This method builds a hierarchical representation of the repository's files as a nested dictionary tree. If the file list has not yet been populated, it first calls `get_all_files` to retrieve all `RepoFile` objects. It then iterates over each file, splitting its path into directory components and creating intermediate directory nodes as needed. Each file is added to the appropriate location in the tree using the `RepoFile.to_dict` method, optionally including the file's content. The resulting tree dictionary is returned to the caller.",
              "parameters": [
                {
                  "name": "self",
                  "type": "GitRepository",
                  "description": "The instance on which the method is called."
                },
                {
                  "name": "include_content",
                  "type": "bool",
                  "description": "If True, the file content is included in each leaf node; otherwise only metadata is stored."
                }
              ],
              "returns": [
                {
                  "name": "tree",
                  "type": "dict",
                  "description": "A nested dictionary representing the directory hierarchy of the repository, where each leaf node is a file dictionary produced by `RepoFile.to_dict`."
                }
              ],
              "usage_context": {
                "calls": "It internally calls `get_all_files` when the file list is empty.",
                "called_by": "No other methods are recorded as calling this method."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "The class depends on the `RepoFile` class from `backend.getRepo` to represent individual files within the repository.",
          "instantiated_by": "No specific instantiation sites are provided in the current context."
        }
      },
      "error": null
    },
    "backend.relationship_analyzer.ProjectAnalyzer": {
      "identifier": "backend.relationship_analyzer.ProjectAnalyzer",
      "description": {
        "overall": "ProjectAnalyzer scans a Python project directory, discovers all Python source files, collects definitions of functions, classes, and methods, resolves call relationships between them, and produces both a detailed call\u2011graph and a simplified mapping of outgoing and incoming relationships. It orchestrates the analysis via its public methods while relying on helper utilities such as `path_to_module` and `CallResolverVisitor`.",
        "init_method": {
          "description": "The constructor receives the path to a project's root directory, resolves it to an absolute path, and initializes the internal data structures required for analysis: a dictionary for storing definitions, a `defaultdict(list)` for the call graph, a cache for parsed ASTs, and a set of directory names that should be ignored during file discovery.",
          "parameters": [
            {
              "name": "project_root",
              "type": "str",
              "description": "Path to the root of the Python project that will be analyzed."
            }
          ]
        },
        "methods": [
          {
            "identifier": "analyze",
            "description": {
              "overall": "The `analyze` method orchestrates the full analysis of the project. It first discovers all Python files under the project root, then iterates over each file to collect definitions of functions, classes, and methods, and subsequently resolves call relationships between them. After processing, it clears the cached ASTs to free memory and returns the constructed call graph mapping each callee to a list of caller information dictionaries.",
              "parameters": [],
              "returns": [
                {
                  "name": "call_graph",
                  "type": "defaultdict(list)",
                  "description": "A mapping from callee identifiers to lists of dictionaries containing caller information."
                }
              ],
              "usage_context": {
                "calls": "This method does not call any other functions or methods.",
                "called_by": "No other functions or methods are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "get_raw_relationships",
            "description": {
              "overall": "The `get_raw_relationships` method transforms the internal call graph into a pair of dictionaries representing outgoing and incoming relationships. It iterates over each callee and its associated callers, populating sets for outgoing calls (from caller to callee) and incoming calls (from callee to callers). The sets are then converted to sorted lists and returned in a dictionary.",
              "parameters": [],
              "returns": [
                {
                  "name": "relationships",
                  "type": "dict",
                  "description": "Dictionary with keys \"outgoing\" and \"incoming\" mapping identifiers to sorted lists of related identifiers."
                }
              ],
              "usage_context": {
                "calls": "This method does not call any other functions or methods.",
                "called_by": "No other functions or methods are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "_find_py_files",
            "description": {
              "overall": "The `_find_py_files` private method walks the project directory tree, skipping directories listed in `ignore_dirs`, and collects the absolute paths of all files ending with `.py`. It returns the list of discovered Python file paths.",
              "parameters": [],
              "returns": [
                {
                  "name": "py_files",
                  "type": "list[str]",
                  "description": "A list containing the absolute paths of all Python files found under the project root."
                }
              ],
              "usage_context": {
                "calls": "This method does not call any other functions or methods.",
                "called_by": "No other functions or methods are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "_collect_definitions",
            "description": {
              "overall": "The `_collect_definitions` method reads a Python file, parses its source into an AST, and records definitions of functions, classes, and methods. It stores the AST in a cache, computes the module path using `path_to_module`, and populates the `definitions` dictionary with metadata such as file location, line number, and type (function, method, or class). Errors encountered during processing are logged.",
              "parameters": [
                {
                  "name": "filepath",
                  "type": "str",
                  "description": "Absolute path to the Python file whose definitions are to be collected."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls backend.relationship_analyzer.path_to_module.",
                "called_by": "No other functions or methods are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "_get_parent",
            "description": {
              "overall": "The `_get_parent` helper traverses the AST to find and return the immediate parent node of a given node, or `None` if no parent is found.",
              "parameters": [
                {
                  "name": "tree",
                  "type": "ast.AST",
                  "description": "The abstract syntax tree that contains the node."
                },
                {
                  "name": "node",
                  "type": "ast.AST",
                  "description": "The AST node whose parent is being sought."
                }
              ],
              "returns": [
                {
                  "name": "parent",
                  "type": "ast.AST | None",
                  "description": "The parent node of the supplied node, or `None` if the node has no parent."
                }
              ],
              "usage_context": {
                "calls": "This method does not call any other functions or methods.",
                "called_by": "No other functions or methods are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "_resolve_calls",
            "description": {
              "overall": "The `_resolve_calls` method retrieves the cached AST for a file, creates a `CallResolverVisitor` with the file path, project root, and definitions, visits the AST to collect call information, and merges the results into the class's `call_graph`. Errors during this process are logged.",
              "parameters": [
                {
                  "name": "filepath",
                  "type": "str",
                  "description": "Absolute path to the Python file whose call relationships are to be resolved."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls backend.relationship_analyzer.CallResolverVisitor.",
                "called_by": "No other functions or methods are recorded as calling this method."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "ProjectAnalyzer depends on backend.relationship_analyzer.CallResolverVisitor and backend.relationship_analyzer.path_to_module.",
          "instantiated_by": "There are no recorded locations where this class is instantiated."
        }
      },
      "error": null
    },
    "backend.relationship_analyzer.CallResolverVisitor": {
      "identifier": "backend.relationship_analyzer.CallResolverVisitor",
      "description": {
        "overall": "The **CallResolverVisitor** walks a Python abstract syntax tree (AST) to build a mapping of which callables (functions, methods, classes) are invoked by which locations in the source code. It tracks the current module, class, and function context, resolves imported names and instance types, and records each call site (file, line, caller identifier, and caller type) in a ``defaultdict(list)`` called ``calls``. The visitor relies on a pre\u2011computed ``definitions`` dictionary and a helper ``path_to_module`` function to resolve qualified names. This information can be used to construct a call graph for the whole project.",
        "init_method": {
          "description": "The constructor stores the path of the file being analysed, computes its module path, and initialises several bookkeeping structures used during the AST walk. It records the provided definitions dictionary, creates empty scopes for imports and instance types, sets the initial caller context to the module itself, and prepares a ``defaultdict`` to collect call information.",
          "parameters": [
            {
              "name": "filepath",
              "type": "str",
              "description": "Path to the source file that will be visited."
            },
            {
              "name": "project_root",
              "type": "str",
              "description": "Root directory of the project; used together with ``filepath`` to compute the module path."
            },
            {
              "name": "definitions",
              "type": "dict",
              "description": "Mapping of qualified names to definition objects that the visitor uses to verify whether a resolved name is a known definition."
            }
          ]
        },
        "methods": [
          {
            "identifier": "visit_ClassDef",
            "description": {
              "overall": "This method is invoked for each ``ast.ClassDef`` node encountered during the traversal. It saves the previous ``current_class_name`` value, updates it to the name of the class being visited, and then recursively visits all child nodes of the class definition. After processing the class body, it restores the original class context. The method does not return a value.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.ClassDef",
                  "description": "The AST node representing a class definition."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method does not call any other functions.",
                "called_by": "No other functions are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_FunctionDef",
            "description": {
              "overall": "When a function or method definition is visited, this method builds a fully\u2011qualified identifier for the callable based on the current module and class context. It temporarily replaces ``current_caller_name`` with this identifier, walks the function body, and finally restores the previous caller name. This enables later call sites to be linked back to the correct function or method. The method returns ``None``.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.FunctionDef",
                  "description": "The AST node representing a function or method definition."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method does not call any other functions.",
                "called_by": "No other functions are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_Call",
            "description": {
              "overall": "For each ``ast.Call`` node, the visitor attempts to resolve the fully\u2011qualified name of the callee using ``_resolve_call_qname``. If the callee is found in the supplied ``definitions`` dictionary, the method determines the caller type (module, function, method, or local function) based on the current context, builds a caller information dictionary, and appends it to the ``calls`` mapping under the callee's qualified name. The method then continues traversing any child nodes of the call expression. No explicit return value is produced.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.Call",
                  "description": "The AST node representing a function or method call."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method does not call any other functions.",
                "called_by": "No other functions are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_Import",
            "description": {
              "overall": "When an ``import`` statement is encountered, this method records each imported name (or its alias) in the ``scope`` dictionary, mapping it to the original module name. This allows later name resolution to map short identifiers to fully\u2011qualified module paths. After updating the scope, the method recursively visits any remaining child nodes of the import statement. The method returns ``None``.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.Import",
                  "description": "The AST node representing an import statement."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method does not call any other functions.",
                "called_by": "No other functions are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_ImportFrom",
            "description": {
              "overall": "For ``from ... import ...`` statements, this method constructs the full module path for each imported name, taking relative import levels into account, and stores the mapping in ``scope``. It correctly handles aliasing via ``as`` and updates the visitor's name resolution table. After processing all aliases, it continues traversing any child nodes. No value is returned.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.ImportFrom",
                  "description": "The AST node representing a from\u2011import statement."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method does not call any other functions.",
                "called_by": "No other functions are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_Assign",
            "description": {
              "overall": "When an assignment statement is visited, the method checks whether the right\u2011hand side is a call to a class constructor whose name is known in the current ``scope``. If so, it records the variable name on the left\u2011hand side in ``instance_types`` with the qualified class name, enabling later attribute calls to be resolved to the correct class. The method then proceeds with the generic visit of the assignment node. It does not return a value.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.Assign",
                  "description": "The AST node representing an assignment statement."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method does not call any other functions.",
                "called_by": "No other functions are recorded as calling this method."
              }
            },
            "error": null
          },
          {
            "identifier": "_resolve_call_qname",
            "description": {
              "overall": "This helper method attempts to determine the fully\u2011qualified name of a callable represented by ``func_node``. It handles three cases: a simple name (looking it up in ``scope`` or constructing a module\u2011local name), an attribute access on a known instance (using ``instance_types``), and an attribute access on a known imported module (using ``scope``). If resolution succeeds, the qualified name is returned; otherwise ``None`` is returned. The method does not raise exceptions and returns a string or ``None``.",
              "parameters": [
                {
                  "name": "func_node",
                  "type": "ast.AST",
                  "description": "The AST node representing the function part of a call expression (either ``ast.Name`` or ``ast.Attribute``)."
                }
              ],
              "returns": [
                {
                  "name": "qualified_name",
                  "type": "str or None",
                  "description": "The fully\u2011qualified name of the callable if it could be resolved, otherwise ``None``."
                }
              ],
              "usage_context": {
                "calls": "This method does not call any other functions.",
                "called_by": "No other functions are recorded as calling this method."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "It depends on the function ``backend.relationship_analyzer.path_to_module`` for converting file paths to module names.",
          "instantiated_by": "No instantiation sites are provided in the context."
        }
      },
      "error": null
    },
    "schemas.types.ParameterDescription": {
      "identifier": "schemas.types.ParameterDescription",
      "description": {
        "overall": "The **ParameterDescription** class is a lightweight Pydantic model that encapsulates metadata for a single function parameter. It stores the parameter's name, its type (as a string), and a human\u2011readable description. By inheriting from `BaseModel`, it gains validation, serialization, and convenient dict\u2011conversion capabilities, making it suitable for documentation\u2011generation pipelines.",
        "init_method": {
          "description": "The class relies on Pydantic's autogenerated `__init__`, which accepts the three declared fields (`name`, `type`, `description`) as keyword arguments and assigns them to the instance.",
          "parameters": [
            {
              "name": "name",
              "type": "str",
              "description": "The identifier of the function parameter."
            },
            {
              "name": "type",
              "type": "str",
              "description": "A string representation of the parameter's type."
            },
            {
              "name": "description",
              "type": "str",
              "description": "A human\u2011readable explanation of what the parameter represents."
            }
          ]
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class does not depend on any external modules beyond the imported `pydantic.BaseModel`.",
          "instantiated_by": "No instantiation sites are provided in the current context."
        }
      },
      "error": null
    },
    "schemas.types.ReturnDescription": {
      "identifier": "schemas.types.ReturnDescription",
      "description": {
        "overall": "ReturnDescription is a lightweight Pydantic model that encapsulates metadata about a function's return value. It stores the return variable's name, its type as a string, and a human\u2011readable description. The class provides a structured way to convey return\u2011value information throughout the codebase.",
        "init_method": {
          "description": "The class relies on Pydantic's autogenerated __init__ to initialise the three fields: name, type, and description. No custom constructor is defined.",
          "parameters": []
        },
        "methods": [],
        "usage_context": {
          "dependencies": "The class does not depend on any external runtime dependencies beyond the imported modules (typing and pydantic).",
          "instantiated_by": "No instantiation sites were provided in the context."
        }
      },
      "error": null
    },
    "schemas.types.UsageContext": {
      "identifier": "schemas.types.UsageContext",
      "description": {
        "overall": "The `UsageContext` class is a simple Pydantic data model that captures the calling context of a function. It stores two string fields: `calls`, which records the functions that are called, and `called_by`, which records the functions that invoke the current function. By inheriting from `BaseModel`, it gains validation and serialization capabilities without requiring explicit method implementations.",
        "init_method": {
          "description": "The class inherits the autogenerated `__init__` from `pydantic.BaseModel`, which accepts the two defined fields (`calls` and `called_by`) as keyword arguments and assigns them to instance attributes.",
          "parameters": [
            {
              "name": "calls",
              "type": "str",
              "description": "A string describing the functions that are called by the target function."
            },
            {
              "name": "called_by",
              "type": "str",
              "description": "A string describing the functions that call the target function."
            }
          ]
        },
        "methods": [],
        "usage_context": {
          "dependencies": "The class does not have any external dependencies beyond the imported modules.",
          "instantiated_by": "There is no information provided about where this class is instantiated."
        }
      },
      "error": null
    },
    "schemas.types.FunctionDescription": {
      "identifier": "schemas.types.FunctionDescription",
      "description": {
        "overall": "FunctionDescription is a Pydantic model that encapsulates a comprehensive analysis of a function, including a free\u2011form overall description, a list of its parameters, a list of its return values, and contextual usage information. It provides a structured container for conveying both the signature and the purpose of a function within a larger system.",
        "init_method": {
          "description": "The class does not define a custom __init__ method and therefore relies on the default initializer provided by Pydantic's BaseModel.",
          "parameters": []
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class does not have any runtime dependencies beyond the standard typing imports and the Pydantic BaseModel it inherits from.",
          "instantiated_by": "No instantiation sites are reported in the provided context."
        }
      },
      "error": null
    },
    "schemas.types.FunctionAnalysis": {
      "identifier": "schemas.types.FunctionAnalysis",
      "description": {
        "overall": "The **FunctionAnalysis** class is a Pydantic model that defines the top\u2011level schema for representing the analysis of a function. It stores the function's unique identifier, a detailed description encapsulated in a **FunctionDescription** object, and an optional error message indicating any problems encountered during analysis. By inheriting from **BaseModel**, it gains automatic data validation, serialization, and a generated ``__init__`` method.",
        "init_method": {
          "description": "The class relies on Pydantic's autogenerated ``__init__`` method, which accepts values for the declared fields and performs type validation.",
          "parameters": []
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class does not depend on any external modules beyond the standard typing utilities and Pydantic's BaseModel.",
          "instantiated_by": "No instantiation sites are provided in the current context."
        }
      },
      "error": null
    },
    "schemas.types.ConstructorDescription": {
      "identifier": "schemas.types.ConstructorDescription",
      "description": {
        "overall": "The `ConstructorDescription` class is a Pydantic model that encapsulates metadata about a class's `__init__` method. It stores a textual description of the constructor and a list of `ParameterDescription` objects that detail each parameter. This abstraction allows other parts of the system to programmatically access constructor documentation.",
        "init_method": {
          "description": "This model does not define its own `__init__` method; it relies on the default initializer provided by `pydantic.BaseModel`. The class fields `description` and `parameters` are populated via the BaseModel constructor, representing the constructor's documentation and its parameters respectively.",
          "parameters": []
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class does not depend on any external modules beyond its imports.",
          "instantiated_by": "No information is provided about where this class is instantiated."
        }
      },
      "error": null
    },
    "schemas.types.ClassContext": {
      "identifier": "schemas.types.ClassContext",
      "description": {
        "overall": "ClassContext is a lightweight Pydantic model that records a class's external dependencies and the locations where the class is instantiated. It provides a structured, type\u2011checked container for two string attributes \u2013 `dependencies` and `instantiated_by` \u2013 enabling downstream code to query this metadata in a uniform way.",
        "init_method": {
          "description": "The class relies on Pydantic's autogenerated `__init__`, which accepts the two declared fields as keyword arguments and stores them as instance attributes.",
          "parameters": []
        },
        "methods": [],
        "usage_context": {
          "dependencies": "No external dependencies are listed for this class in the provided context.",
          "instantiated_by": "No instantiation sites are listed for this class in the provided context."
        }
      },
      "error": null
    },
    "schemas.types.ClassDescription": {
      "identifier": "schemas.types.ClassDescription",
      "description": {
        "overall": "ClassDescription is a Pydantic model that serves as a container for the full analysis of another class. It stores a free\u2011form textual summary of the class purpose (`overall`), a structured description of the constructor (`init_method`), a list of analyses for each method defined in the target class (`methods`), and contextual information about external dependencies and instantiation sites (`usage_context`).",
        "init_method": {
          "description": "The class does not define an explicit __init__ method; it relies on the default constructor provided by pydantic.BaseModel, which accepts the declared fields as keyword arguments and performs validation.",
          "parameters": []
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class does not depend on any external modules or packages beyond the imports required for its own definition.",
          "instantiated_by": "No locations in the provided context instantiate this class."
        }
      },
      "error": null
    },
    "schemas.types.ClassAnalysis": {
      "identifier": "schemas.types.ClassAnalysis",
      "description": {
        "overall": "ClassAnalysis is a Pydantic BaseModel that defines the JSON schema for representing the analysis of a Python class. It holds the class identifier, a detailed description of its constructor and methods, and an optional error field for reporting analysis problems.",
        "init_method": {
          "description": "The class inherits its initializer from pydantic.BaseModel; no custom __init__ is defined.",
          "parameters": []
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class does not rely on any external runtime dependencies beyond the imports listed in the source file.",
          "instantiated_by": "No instantiation locations are provided in the context."
        }
      },
      "error": null
    },
    "schemas.types.CallInfo": {
      "identifier": "schemas.types.CallInfo",
      "description": {
        "overall": "CallInfo is a Pydantic model that encapsulates information about a single call event captured by the relationship analyzer. It stores the source file, the name of the calling function, the call mode (e.g., method, function, module), and the line number where the call occurs. This structured representation is used in the `called_by` and `instantiated_by` collections to track dependencies between code elements.",
        "init_method": {
          "description": "The class relies on Pydantic's autogenerated initializer, which assigns the provided values to the instance attributes `file`, `function`, `mode`, and `line`.",
          "parameters": []
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class does not depend on any external modules beyond the imported ones.",
          "instantiated_by": "No code locations are recorded as instantiating this class."
        }
      },
      "error": null
    },
    "schemas.types.FunctionContextInput": {
      "identifier": "schemas.types.FunctionContextInput",
      "description": {
        "overall": "FunctionContextInput is a Pydantic model that encapsulates the contextual information needed to analyze a function. It stores a list of function names that the target function calls (`calls`) and a list of `CallInfo` objects describing where the target function is invoked (`called_by`). This structured data enables downstream analysis tools to understand call relationships and build call graphs.",
        "init_method": {
          "description": "The class relies on Pydantic's autogenerated initializer, which accepts the fields `calls` and `called_by` as optional inputs and assigns them to the instance attributes.",
          "parameters": []
        },
        "methods": [],
        "usage_context": {
          "dependencies": "The class does not depend on any external modules beyond the imports already listed.",
          "instantiated_by": "There is no recorded location where this class is instantiated."
        }
      },
      "error": null
    },
    "schemas.types.FunctionAnalysisInput": {
      "identifier": "schemas.types.FunctionAnalysisInput",
      "description": {
        "overall": "FunctionAnalysisInput is a Pydantic model that defines the required input schema for generating a FunctionAnalysis object. It captures the analysis mode, the identifier of the target function, its source code, any import statements, and a context object containing additional information. By inheriting from BaseModel it gains validation, serialization, and an automatically generated initializer for these fields. This model serves as a structured contract for downstream analysis components.",
        "init_method": {
          "description": "Pydantic automatically creates an __init__ method that accepts the model fields as arguments and assigns them to the instance.",
          "parameters": [
            {
              "name": "mode",
              "type": "Literal[\"function_analysis\"]",
              "description": "Specifies the operation mode; must be the literal string \"function_analysis\"."
            },
            {
              "name": "identifier",
              "type": "str",
              "description": "The name of the function or method to be analyzed."
            },
            {
              "name": "source_code",
              "type": "str",
              "description": "The raw source code of the target function or method."
            },
            {
              "name": "imports",
              "type": "List[str]",
              "description": "A list of import statements required by the source code."
            },
            {
              "name": "context",
              "type": "FunctionContextInput",
              "description": "Additional contextual information needed for the analysis."
            }
          ]
        },
        "methods": [],
        "usage_context": {
          "dependencies": "The class relies only on standard typing utilities and the Pydantic library; no additional external dependencies are declared.",
          "instantiated_by": "No instantiation sites are provided in the current context."
        }
      },
      "error": null
    },
    "schemas.types.MethodContextInput": {
      "identifier": "schemas.types.MethodContextInput",
      "description": {
        "overall": "MethodContextInput is a Pydantic data model that encapsulates structured information about a class's methods. It stores the method identifier, a list of calls made by the method, information about callers, the argument names, and an optional docstring. The model serves as a lightweight container for method\u2011level metadata used elsewhere in the system.",
        "init_method": {
          "description": "The class relies on Pydantic's autogenerated __init__ method, which initializes the model fields based on the provided arguments.",
          "parameters": []
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class does not depend on any external modules beyond the imports already listed.",
          "instantiated_by": "There are no recorded locations where this class is instantiated."
        }
      },
      "error": null
    },
    "schemas.types.ClassContextInput": {
      "identifier": "schemas.types.ClassContextInput",
      "description": {
        "overall": "ClassContextInput is a Pydantic model that encapsulates the contextual information needed to analyze another class. It stores a list of dependency names, a list of CallInfo objects describing where the class is instantiated, and a list of MethodContextInput objects providing per\u2011method call relationships.",
        "init_method": {
          "description": "The class relies on Pydantic's autogenerated __init__, which accepts the defined fields as keyword arguments.",
          "parameters": []
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class does not declare any external dependencies.",
          "instantiated_by": "No instantiation sites are recorded for this class."
        }
      },
      "error": null
    },
    "schemas.types.ClassAnalysisInput": {
      "identifier": "schemas.types.ClassAnalysisInput",
      "description": {
        "overall": "ClassAnalysisInput is a Pydantic model that defines the required input schema for generating a ClassAnalysis object. It captures the analysis mode, a unique identifier for the target class, the raw source code of that class, a list of import statements, and a context object describing dependencies and instantiation sites. By inheriting from BaseModel, it benefits from automatic validation and serialization of these fields.",
        "init_method": {
          "description": "The class relies on the autogenerated __init__ method provided by Pydantic's BaseModel, which accepts values for each declared field and stores them as instance attributes.",
          "parameters": [
            {
              "name": "mode",
              "type": "Literal[\"class_analysis\"]",
              "description": "A literal string that must be \"class_analysis\", indicating the type of analysis to perform."
            },
            {
              "name": "identifier",
              "type": "str",
              "description": "The name of the class that will be analyzed."
            },
            {
              "name": "source_code",
              "type": "str",
              "description": "The raw source code of the target class."
            },
            {
              "name": "imports",
              "type": "List[str]",
              "description": "A list of import statements extracted from the source file."
            },
            {
              "name": "context",
              "type": "ClassContextInput",
              "description": "An object containing additional context such as dependencies, instantiation sites, and method\u2011level call information."
            }
          ]
        },
        "methods": [],
        "usage_context": {
          "dependencies": "The class does not declare any external dependencies.",
          "instantiated_by": "No information is provided about where this class is instantiated."
        }
      },
      "error": null
    }
  }
}