{
  "functions": {
    "backend.AST_Schema.path_to_module": {
      "identifier": "backend.AST_Schema.path_to_module",
      "description": {
        "overall": "This function converts a given file path into a Python module path relative to a specified project root. It first calculates the relative path and handles potential `ValueError` by falling back to the base filename. It then removes the '.py' extension if present and replaces the operating system's path separator with dots to form a module path. Special handling is included for '__init__.py' files, returning the parent module path.",
        "parameters": [
          {
            "name": "filepath",
            "type": "str",
            "description": "The absolute or relative path to the file."
          },
          {
            "name": "project_root",
            "type": "str",
            "description": "The root directory of the project from which the relative path is calculated."
          }
        ],
        "returns": [
          {
            "name": "module_path",
            "type": "str",
            "description": "The calculated Python module path string."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is called by no other functions."
        }
      },
      "error": null
    },
    "backend.File_Dependency.build_file_dependency_graph": {
      "identifier": "backend.File_Dependency.build_file_dependency_graph",
      "description": {
        "overall": "This function constructs a directed graph representing file dependencies within a Python project. It takes a filename, an Abstract Syntax Tree (AST) of the file, and the repository root as input. The function initializes a graph and uses a visitor pattern to traverse the AST, identifying import dependencies. It then populates the graph with nodes representing the files and adds edges to show the import relationships. The resulting graph is returned.",
        "parameters": [
          {
            "name": "filename",
            "type": "str",
            "description": "The name of the file being analyzed."
          },
          {
            "name": "tree",
            "type": "AST",
            "description": "The Abstract Syntax Tree (AST) of the file."
          },
          {
            "name": "repo_root",
            "type": "str",
            "description": "The root directory of the repository."
          }
        ],
        "returns": [
          {
            "name": "graph",
            "type": "nx.DiGraph",
            "description": "A directed graph representing the file dependencies."
          }
        ],
        "usage_context": {
          "calls": "This function calls backend.File_Dependency.FileDependencyGraph.",
          "called_by": "This function is not called by any other function within the provided context."
        }
      },
      "error": null
    },
    "backend.File_Dependency.build_repository_graph": {
      "identifier": "backend.File_Dependency.build_repository_graph",
      "description": {
        "overall": "This function constructs a directed graph representing file dependencies within a Git repository. It iterates through all Python files in the repository, parses their content to build individual file dependency graphs, and then merges these into a single global graph. The function focuses on Python files, ignoring others, and uses the `build_file_dependency_graph` helper to create subgraphs for each file. The final graph represents relationships between different components (likely functions or classes) across the entire repository.",
        "parameters": [
          {
            "name": "repository",
            "type": "GitRepository",
            "description": "An object representing the Git repository, providing access to its files and temporary directory."
          }
        ],
        "returns": [
          {
            "name": "global_graph",
            "type": "nx.DiGraph",
            "description": "A NetworkX directed graph object representing the aggregated dependencies across all Python files in the repository."
          }
        ],
        "usage_context": {
          "calls": "This function calls backend.File_Dependency.build_file_dependency_graph.",
          "called_by": "This function is not called by any other functions within the provided context."
        }
      },
      "error": null
    },
    "backend.File_Dependency.get_all_temp_files": {
      "identifier": "backend.File_Dependency.get_all_temp_files",
      "description": {
        "overall": "This function identifies and returns a list of all Python files within a specified directory and its subdirectories. It resolves the root directory path and then uses `rglob` to find all files ending with '.py'. The function returns the relative paths of these files with respect to the root directory.",
        "parameters": [
          {
            "name": "directory",
            "type": "str",
            "description": "The path to the directory to search for Python files."
          }
        ],
        "returns": [
          {
            "name": "all_files",
            "type": "list[Path]",
            "description": "A list of Path objects, where each Path represents the relative path of a Python file found in the directory."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "backend.HelperLLM.main_orchestrator": {
      "identifier": "backend.HelperLLM.main_orchestrator",
      "description": {
        "overall": "This function serves as a dummy orchestrator for testing the LLMHelper class and its documentation generation capabilities. It defines pre-computed analysis data for several inventory management functions ('add_item', 'check_stock', 'generate_report') and a class ('InventoryManager'). It then instantiates an LLMHelper, processes the predefined function analyses, and aggregates the results into a final JSON structure. The primary goal is to simulate the input and output flow for generating documentation for classes and their methods.",
        "parameters": [],
        "returns": [],
        "usage_context": {
          "calls": "backend.HelperLLM.LLMHelper, schemas.types.ClassAnalysisInput, schemas.types.ClassContextInput",
          "called_by": "This function is not called by any other function."
        }
      },
      "error": null
    },
    "backend.callgraph.make_safe_dot": {
      "identifier": "backend.callgraph.make_safe_dot",
      "description": {
        "overall": "This function takes a NetworkX directed graph and an output path as input. It creates a copy of the graph and relabels its nodes to ensure they are safe for DOT format, which is used for graph visualization. It then assigns the original node names as labels to these new nodes and writes the modified graph to a DOT file at the specified output path.",
        "parameters": [
          {
            "name": "graph",
            "type": "nx.DiGraph",
            "description": "The input directed graph from the NetworkX library."
          },
          {
            "name": "out_path",
            "type": "str",
            "description": "The file path where the DOT representation of the graph will be saved."
          }
        ],
        "returns": [],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is called by no other functions."
        }
      },
      "error": null
    },
    "backend.callgraph.build_filtered_callgraph": {
      "identifier": "backend.callgraph.build_filtered_callgraph",
      "description": {
        "overall": "This function constructs a global call graph for a given Git repository and then filters it to include only functions defined within the repository itself. It iterates through all Python files, parses their Abstract Syntax Trees (ASTs), and uses a `CallGraph` visitor to identify functions and their calls. The function first collects all functions defined in the repository and then builds a directed graph (`nx.DiGraph`) by adding edges only between functions that are both defined within the repository. This results in a call graph representing the internal dependencies of the project.",
        "parameters": [
          {
            "name": "repo",
            "type": "GitRepository",
            "description": "An object representing the Git repository to analyze, providing access to its files."
          }
        ],
        "returns": [
          {
            "name": "global_graph",
            "type": "nx.DiGraph",
            "description": "A NetworkX directed graph representing the filtered call graph, containing only edges between functions defined within the repository."
          }
        ],
        "usage_context": {
          "calls": "This function calls backend.callgraph.CallGraph.",
          "called_by": "This function is not called by any other functions within the provided context."
        }
      },
      "error": null
    },
    "backend.converter.wrap_cdata": {
      "identifier": "backend.converter.wrap_cdata",
      "description": {
        "overall": "This function takes a string `content` as input and returns a new string where the input content is wrapped within XML CDATA (Character Data) tags. The CDATA tags are formatted as '<![CDATA[\\n{content}\\n]]>', ensuring that the content inside is treated as raw character data by XML parsers. This is useful for embedding content that might otherwise be interpreted as markup, such as HTML or script code, within an XML document.",
        "parameters": [
          {
            "name": "content",
            "type": "string",
            "description": "The string content to be wrapped within CDATA tags."
          }
        ],
        "returns": [
          {
            "name": "wrapped_content",
            "type": "string",
            "description": "The input content enclosed within CDATA tags."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "backend.converter.extract_output_content": {
      "identifier": "backend.converter.extract_output_content",
      "description": {
        "overall": "This function iterates through a list of outputs, processing different output types to extract relevant content. It specifically handles 'display_data' and 'execute_result' types by decoding Base64 encoded images into a list of image data and inserting image placeholders into the output. For other data types, it extracts plain text or stream content. Error outputs are also captured and formatted.",
        "parameters": [
          {
            "name": "outputs",
            "type": "list",
            "description": "A list of output objects, each potentially containing data, type, and other metadata."
          },
          {
            "name": "image_list",
            "type": "list",
            "description": "A list used to store image data, where each image is represented as a dictionary with 'mime_type' and 'data'."
          }
        ],
        "returns": [
          {
            "name": "extracted_xml_snippets",
            "type": "list",
            "description": "A list containing extracted text content, image placeholders, or error messages."
          }
        ],
        "usage_context": {
          "calls": "This function calls backend.converter.process_image.",
          "called_by": "This function is not called by any other function."
        }
      },
      "error": null
    },
    "backend.converter.process_image": {
      "identifier": "backend.converter.process_image",
      "description": {
        "overall": "This function processes an image based on its MIME type. It checks if the MIME type exists in a global `data` dictionary. If found, it attempts to decode a base64 string associated with that MIME type, cleans up newline characters, and appends the image data to a global `image_list`. It then returns an HTML-like placeholder string with the image's index and MIME type. If any error occurs during decoding or if the MIME type is not found, it returns an error message or None, respectively.",
        "parameters": [
          {
            "name": "mime_type",
            "type": "str",
            "description": "The MIME type of the image to be processed."
          }
        ],
        "returns": [
          {
            "name": "placeholder_or_error",
            "type": "str",
            "description": "A string representing an image placeholder with its index and MIME type if successful, or an error message if decoding fails. Returns None if the mime_type is not found in the data."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "backend.converter.convert_notebook_to_xml": {
      "identifier": "backend.converter.convert_notebook_to_xml",
      "description": {
        "overall": "This function takes the content of a Jupyter notebook as a string and converts it into an XML representation. It iterates through each cell of the notebook, distinguishing between markdown and code cells. For markdown cells, it directly includes the source content within a 'markdown' CELL tag. For code cells, it wraps the source code in CDATA and includes it within a 'code' CELL tag. It also processes the outputs of code cells, extracting relevant content and wrapping it in CDATA within an 'output' CELL tag if any content exists. The function handles potential JSON parsing errors by returning an error message and an empty list. It returns the generated XML string and a list of extracted image data.",
        "parameters": [
          {
            "name": "file_content",
            "type": "str",
            "description": "A string containing the raw content of the Jupyter notebook file."
          }
        ],
        "returns": [
          {
            "name": "xml_string",
            "type": "str",
            "description": "A string representing the XML representation of the notebook, or an error message if parsing fails."
          },
          {
            "name": "extracted_images",
            "type": "list",
            "description": "A list containing extracted image data from the notebook outputs."
          }
        ],
        "usage_context": {
          "calls": "This function calls backend.converter.extract_output_content and backend.converter.wrap_cdata.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "backend.converter.process_repo_notebooks": {
      "identifier": "backend.converter.process_repo_notebooks",
      "description": {
        "overall": "This function iterates through a list of repository files, identifies Jupyter notebooks (.ipynb), and converts them into an XML format along with any associated images. It logs the number of notebooks found and the processing of each individual notebook. The function aggregates the conversion results for each notebook, storing the XML output and image data, and returns a dictionary where keys are notebook file paths and values are dictionaries containing the 'xml' and 'images'.",
        "parameters": [
          {
            "name": "repo_files",
            "type": "List[FileObject]",
            "description": "A list of file objects, where each object is expected to have 'path' and 'content' attributes."
          }
        ],
        "returns": [
          {
            "name": "results",
            "type": "Dict[str, Dict[str, Any]]",
            "description": "A dictionary mapping notebook file paths to their converted XML content and extracted images."
          }
        ],
        "usage_context": {
          "calls": "This function calls backend.converter.convert_notebook_to_xml.",
          "called_by": "This function is not called by any other functions within the provided context."
        }
      },
      "error": null
    },
    "backend.main.create_savings_chart": {
      "identifier": "backend.main.create_savings_chart",
      "description": {
        "overall": "This function generates a bar chart to visualize the comparison of JSON and TOON tokens, indicating the percentage of savings. It takes the token counts for both formats, the calculated savings percentage, and the desired output path as input. The chart includes labels for 'JSON' and 'TOON', corresponding token values, and a title reflecting the savings percentage. It also displays the exact token counts above each bar and saves the generated chart to the specified file path, closing the plot afterwards to free up resources.",
        "parameters": [
          {
            "name": "json_tokens",
            "type": "int",
            "description": "The number of tokens in the JSON format."
          },
          {
            "name": "toon_tokens",
            "type": "int",
            "description": "The number of tokens in the TOON format."
          },
          {
            "name": "savings_percent",
            "type": "float",
            "description": "The percentage of savings achieved by using the TOON format compared to JSON."
          },
          {
            "name": "output_path",
            "type": "str",
            "description": "The file path where the generated chart image will be saved."
          }
        ],
        "returns": [],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is called by no other functions."
        }
      },
      "error": null
    },
    "backend.main.calculate_net_time": {
      "identifier": "backend.main.calculate_net_time",
      "description": {
        "overall": "This function calculates the net processing time by subtracting estimated sleep times from the total duration. It first determines the total duration by subtracting the start time from the end time. If the model name does not start with 'gemini-', it returns the total duration directly. For 'gemini-' models, it calculates the number of batches based on total items and batch size, then estimates the total sleep time. Finally, it subtracts the total sleep time from the total duration, ensuring the net time is not negative.",
        "parameters": [
          {
            "name": "start_time",
            "type": "Any",
            "description": "The start timestamp of the operation."
          },
          {
            "name": "end_time",
            "type": "Any",
            "description": "The end timestamp of the operation."
          },
          {
            "name": "total_items",
            "type": "int",
            "description": "The total number of items processed."
          },
          {
            "name": "batch_size",
            "type": "int",
            "description": "The size of each batch."
          },
          {
            "name": "model_name",
            "type": "str",
            "description": "The name of the model being used."
          }
        ],
        "returns": [
          {
            "name": "net_time",
            "type": "int",
            "description": "The calculated net processing time after subtracting sleep times, or 0 if total_items is 0, or the total_duration if the model_name does not start with 'gemini-'."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "backend.main.main_workflow": {
      "identifier": "backend.main.main_workflow",
      "description": {
        "overall": "The `main_workflow` function orchestrates a comprehensive analysis of a given GitHub repository. It begins by extracting API keys and model names, then clones the repository and extracts its files. Subsequently, it performs several analysis steps: extracting basic project information, constructing a file tree, analyzing code relationships (calls and instantiations), and generating an Abstract Syntax Tree (AST). The AST is then enriched with the relationship data. The function prepares inputs for a 'Helper LLM' to analyze individual functions and classes within the repository, generating documentation for them. Finally, it prepares input for a 'Main LLM' with the aggregated analysis results and generates a final report, along with metrics on execution time and token usage.",
        "parameters": [
          {
            "name": "input",
            "type": "Any",
            "description": "The primary input, expected to contain a repository URL."
          },
          {
            "name": "api_keys",
            "type": "dict",
            "description": "A dictionary containing API keys for various services like Gemini, OpenAI, and ScadsLLM, as well as base URLs for services like Ollama."
          },
          {
            "name": "model_names",
            "type": "dict",
            "description": "A dictionary specifying the model names to be used for different tasks, such as 'helper' and 'main' models."
          },
          {
            "name": "status_callback",
            "type": "Optional[Callable]",
            "description": "An optional callback function to report the status of the workflow's progress."
          }
        ],
        "returns": [
          {
            "name": "report",
            "type": "str",
            "description": "The final generated report summarizing the analysis of the repository."
          },
          {
            "name": "metrics",
            "type": "dict",
            "description": "A dictionary containing performance metrics such as execution times for helper and main LLM calls, model names used, and token usage statistics."
          }
        ],
        "usage_context": {
          "calls": "This function calls backend.AST_Schema.ASTAnalyzer, backend.AST_Schema.ASTAnalyzer.analyze_repository, backend.AST_Schema.ASTAnalyzer.merge_relationship_data, backend.HelperLLM.LLMHelper, backend.HelperLLM.LLMHelper.generate_for_classes, backend.HelperLLM.LLMHelper.generate_for_functions, backend.MainLLM.MainLLM, backend.MainLLM.MainLLM.call_llm, backend.basic_info.ProjektInfoExtractor, backend.basic_info.ProjektInfoExtractor.extrahiere_info, backend.getRepo.GitRepository, backend.main.calculate_net_time, backend.main.create_savings_chart, backend.main.update_status, backend.relationship_analyzer.ProjectAnalyzer, backend.relationship_analyzer.ProjectAnalyzer.analyze, backend.relationship_analyzer.ProjectAnalyzer.get_raw_relationships, schemas.types.ClassAnalysisInput, schemas.types.ClassContextInput, schemas.types.FunctionAnalysisInput, schemas.types.FunctionContextInput, and schemas.types.MethodContextInput.",
          "called_by": "This function is not called by any other functions within the provided context."
        }
      },
      "error": null
    },
    "backend.main.update_status": {
      "identifier": "backend.main.update_status",
      "description": {
        "overall": "This function is responsible for updating the status message of a process. It first checks if a callback function `status_callback` is defined and, if so, calls it with the provided message. Subsequently, it logs the message using the `logging.info` function. This ensures that the status is both communicated externally via the callback and recorded internally for monitoring.",
        "parameters": [
          {
            "name": "msg",
            "type": "Any",
            "description": "The status message to be displayed or logged. The type is inferred as 'Any' due to the lack of explicit type hinting."
          }
        ],
        "returns": [],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is called by no other functions."
        }
      },
      "error": null
    },
    "backend.main.notebook_workflow": {
      "identifier": "backend.main.notebook_workflow",
      "description": {
        "overall": "This function orchestrates a workflow for analyzing GitHub repositories containing Jupyter notebooks. It clones a repository, extracts project information, processes notebooks into an XML format with embedded images, and then uses a language model (specified by the 'model' parameter) to generate a report for each notebook. The function handles API key selection based on the model type and provides status updates throughout the process. Finally, it concatenates individual notebook reports into a single final report, saves it to a file, and returns the report along with processing metrics.",
        "parameters": [
          {
            "name": "input",
            "type": "str",
            "description": "The input string, expected to contain a GitHub repository URL."
          },
          {
            "name": "api_keys",
            "type": "dict",
            "description": "A dictionary containing API keys for different language models (e.g., 'gpt', 'gemini', 'scadsllm', 'ollama')."
          },
          {
            "name": "model",
            "type": "str",
            "description": "The name or identifier of the language model to be used for report generation."
          },
          {
            "name": "status_callback",
            "type": "Optional[Callable]",
            "description": "An optional callback function to report status updates during the workflow."
          }
        ],
        "returns": [
          {
            "name": "report",
            "type": "str",
            "description": "The concatenated final report generated from all processed notebooks."
          },
          {
            "name": "metrics",
            "type": "dict",
            "description": "A dictionary containing performance metrics for the workflow execution."
          }
        ],
        "usage_context": {
          "calls": "This function calls backend.MainLLM.MainLLM, backend.MainLLM.MainLLM.call_llm, backend.basic_info.ProjektInfoExtractor, backend.basic_info.ProjektInfoExtractor.extrahiere_info, backend.converter.process_repo_notebooks, backend.getRepo.GitRepository, backend.main.gemini_payload, and backend.main.update_status.",
          "called_by": "This function is not called by any other functions within the provided context."
        }
      },
      "error": null
    },
    "backend.main.gemini_payload": {
      "identifier": "backend.main.gemini_payload",
      "description": {
        "overall": "This function constructs a payload for the Gemini API, designed to process and present information including basic project details, notebook paths, XML content, and images. It serializes basic information and the notebook path into a JSON string. The function then iterates through the XML content, identifying image placeholders. For each placeholder, it extracts image data from a provided list of images, converts it to a base64 string, and appends it to the payload as an image URL. Text segments between image placeholders are also included as text elements in the payload. Finally, any remaining text in the XML content after the last image placeholder is appended.",
        "parameters": [
          {
            "name": "basic_info",
            "type": "any",
            "description": "A dictionary or object containing basic information about the project."
          },
          {
            "name": "nb_path",
            "type": "str",
            "description": "The file path to the current notebook."
          },
          {
            "name": "xml_content",
            "type": "str",
            "description": "A string containing the XML representation of the notebook structure."
          },
          {
            "name": "images",
            "type": "list",
            "description": "A list of dictionaries, where each dictionary contains image data, including a 'data' key with a base64 encoded string."
          }
        ],
        "returns": [
          {
            "name": "payload_content",
            "type": "list",
            "description": "A list of dictionaries, where each dictionary represents a part of the Gemini API payload. Each item has a 'type' ('text' or 'image_url') and corresponding content."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is called by no other functions."
        }
      },
      "error": null
    },
    "backend.relationship_analyzer.path_to_module": {
      "identifier": "backend.relationship_analyzer.path_to_module",
      "description": {
        "overall": "This function converts a given file path into a Python module path relative to a specified project root. It first calculates the relative path from the project root to the file. If the file is a Python file (ends with '.py'), the extension is removed. It then replaces the operating system's path separator with dots to form a module path. Special handling is included for '__init__.py' files, where the '__init__' part is removed from the module path.",
        "parameters": [
          {
            "name": "filepath",
            "type": "str",
            "description": "The absolute or relative path to the file."
          },
          {
            "name": "project_root",
            "type": "str",
            "description": "The root directory of the project."
          }
        ],
        "returns": [
          {
            "name": "module_path",
            "type": "str",
            "description": "The calculated Python module path."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.encrypt_text": {
      "identifier": "database.db.encrypt_text",
      "description": {
        "overall": "This function encrypts a given string using a pre-configured cipher suite. It first checks if the input text is empty or if the cipher suite is not initialized. If either condition is true, it returns the original text without modification. Otherwise, it strips leading/trailing whitespace from the text, encodes it into bytes, encrypts the bytes using the cipher suite, and then decodes the resulting encrypted bytes back into a string before returning it.",
        "parameters": [
          {
            "name": "text",
            "type": "str",
            "description": "The string to be encrypted."
          }
        ],
        "returns": [
          {
            "name": "encrypted_text",
            "type": "str",
            "description": "The encrypted string, or the original string if encryption could not be performed."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.decrypt_text": {
      "identifier": "database.db.decrypt_text",
      "description": {
        "overall": "This function, `decrypt_text`, is designed to decrypt a given string using a `cipher_suite`. It first checks if the input text or the `cipher_suite` is missing; if either is true, it returns the original text without attempting decryption. If both are present, it proceeds to decrypt the text. The decryption process involves stripping whitespace, encoding the text to bytes, performing the decryption, and then decoding the result back into a string. A `try-except` block is used to catch any potential exceptions during the decryption process, in which case the original text is returned.",
        "parameters": [
          {
            "name": "text",
            "type": "str",
            "description": "The encrypted string to be decrypted."
          }
        ],
        "returns": [
          {
            "name": "decrypted_text",
            "type": "str",
            "description": "The decrypted string. If decryption fails or if the input text/cipher_suite is missing, the original text is returned."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.insert_user": {
      "identifier": "database.db.insert_user",
      "description": {
        "overall": "This function inserts a new user record into the database. It constructs a user dictionary containing the username, name, and a hashed password. Additional fields for API keys and base URLs are initialized as empty strings. The function then uses `dbusers.insert_one()` to add this user data to the database and returns the unique identifier of the newly inserted document.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The unique username for the new user."
          },
          {
            "name": "name",
            "type": "str",
            "description": "The full name of the new user."
          },
          {
            "name": "password",
            "type": "str",
            "description": "The plain text password for the new user, which will be hashed."
          }
        ],
        "returns": [
          {
            "name": "inserted_id",
            "type": "Any",
            "description": "The unique identifier of the newly inserted user document in the database."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.fetch_all_users": {
      "identifier": "database.db.fetch_all_users",
      "description": {
        "overall": "This function retrieves all user records from the database. It interacts with a database collection named 'dbusers' and returns the entire set of documents found within it. The function is designed to fetch all user data without any filtering or specific selection criteria.",
        "parameters": [],
        "returns": [
          {
            "name": "user_list",
            "type": "list",
            "description": "A list containing all user documents fetched from the 'dbusers' collection."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.fetch_user": {
      "identifier": "database.db.fetch_user",
      "description": {
        "overall": "This function retrieves a user record from the database based on the provided username. It queries the `dbusers` collection for a document where the `_id` field matches the input username. The function is designed to fetch a single user document.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username of the user to fetch from the database."
          }
        ],
        "returns": [
          {
            "name": "user_document",
            "type": "Any",
            "description": "A dictionary representing the user document if found, otherwise None."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.update_user_name": {
      "identifier": "database.db.update_user_name",
      "description": {
        "overall": "This function updates the 'name' field for a user in the 'dbusers' collection. It takes the current username and the new name as input. The function uses MongoDB's `update_one` method to find the document with the matching `_id` (which is assumed to be the username) and sets the 'name' field to the `new_name`. It returns the count of documents that were modified.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The current username of the user to be updated. This is used as the `_id` to find the document."
          },
          {
            "name": "new_name",
            "type": "str",
            "description": "The new name to set for the user."
          }
        ],
        "returns": [
          {
            "name": "modified_count",
            "type": "int",
            "description": "The number of documents that were modified by the update operation. Typically 1 if the user was found and updated, 0 otherwise."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.update_gemini_key": {
      "identifier": "database.db.update_gemini_key",
      "description": {
        "overall": "This function updates the Gemini API key for a given user in the database. It first encrypts the provided API key using the `encrypt_text` function. Then, it updates a user document in the `dbusers` collection using MongoDB's `update_one` method, setting the `gemini_api_key` field to the encrypted value. The function returns the count of modified documents, indicating whether the update was successful.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username of the user whose Gemini API key needs to be updated."
          },
          {
            "name": "gemini_api_key",
            "type": "str",
            "description": "The new Gemini API key to be stored for the user."
          }
        ],
        "returns": [
          {
            "name": "modified_count",
            "type": "int",
            "description": "The number of documents that were modified in the database. Typically 1 if the update was successful, 0 otherwise."
          }
        ],
        "usage_context": {
          "calls": "This function calls database.db.encrypt_text.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.update_gpt_key": {
      "identifier": "database.db.update_gpt_key",
      "description": {
        "overall": "This function updates the GPT API key for a given user in the database. It first encrypts the provided API key using the `encrypt_text` function. Then, it uses `dbusers.update_one` to find the user by their username and set the `gpt_api_key` field to the encrypted value. The function returns the count of documents that were modified.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username of the user whose GPT API key needs to be updated."
          },
          {
            "name": "gpt_api_key",
            "type": "str",
            "description": "The new GPT API key to be set for the user."
          }
        ],
        "returns": [
          {
            "name": "modified_count",
            "type": "int",
            "description": "The number of documents that were modified in the database. Typically 1 if the update was successful."
          }
        ],
        "usage_context": {
          "calls": "This function calls database.db.encrypt_text.",
          "called_by": "This function is not called by any other functions within the provided context."
        }
      },
      "error": null
    },
    "database.db.update_ollama_url": {
      "identifier": "database.db.update_ollama_url",
      "description": {
        "overall": "This function updates the 'ollama_base_url' field for a specific user in the database. It takes a username and the new base URL as input. The function uses `dbusers.update_one` to find the user by their username (using the `_id` field) and sets the `ollama_base_url` to the provided URL after stripping any leading or trailing whitespace. It then returns the count of documents that were modified.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username of the user whose ollama_base_url needs to be updated."
          },
          {
            "name": "ollama_base_url",
            "type": "str",
            "description": "The new base URL for the Ollama service, which will be stripped of whitespace before being saved."
          }
        ],
        "returns": [
          {
            "name": "modified_count",
            "type": "int",
            "description": "An integer representing the number of documents that were modified in the database. Typically 1 if the update was successful, 0 otherwise."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.update_opensrc_key": {
      "identifier": "database.db.update_opensrc_key",
      "description": {
        "overall": "This function updates the 'opensrc_api_key' for a given username in the database. It first encrypts the provided API key using the `encrypt_text` function and then updates the corresponding user document in the `dbusers` collection. The function returns the count of modified documents, indicating whether the update was successful.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username of the user whose API key needs to be updated."
          },
          {
            "name": "opensrc_api_key",
            "type": "str",
            "description": "The new open-source API key to be set for the user."
          }
        ],
        "returns": [
          {
            "name": "modified_count",
            "type": "int",
            "description": "The number of documents that were modified in the database. Typically 1 if the update was successful, 0 otherwise."
          }
        ],
        "usage_context": {
          "calls": "This function calls database.db.encrypt_text.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.update_opensrc_url": {
      "identifier": "database.db.update_opensrc_url",
      "description": {
        "overall": "This function updates the 'opensrc_base_url' field for a given username in the database. It takes the username and the new URL as input. The function strips whitespace from the provided URL before updating the database record. It returns the count of documents that were modified.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username of the record to update."
          },
          {
            "name": "opensrc_base_url",
            "type": "str",
            "description": "The new base URL for the open-source repository."
          }
        ],
        "returns": [
          {
            "name": "modified_count",
            "type": "int",
            "description": "The number of documents modified in the database."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.fetch_gemini_key": {
      "identifier": "database.db.fetch_gemini_key",
      "description": {
        "overall": "This function retrieves the Gemini API key associated with a given username from the database. It queries the `dbusers` collection for a user document matching the provided username. If the user is found, it extracts and returns the `gemini_api_key`. If the user is not found, it returns None.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username of the user whose Gemini API key needs to be fetched."
          }
        ],
        "returns": [
          {
            "name": "gemini_api_key",
            "type": "str | None",
            "description": "The Gemini API key for the specified user, or None if the user is not found or has no key."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.fetch_ollama_url": {
      "identifier": "database.db.fetch_ollama_url",
      "description": {
        "overall": "This function retrieves the Ollama base URL associated with a given username from a database. It queries the database for a user document matching the provided username and extracts the 'ollama_base_url' field. If the user is found, their Ollama URL is returned; otherwise, None is returned.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username to look up in the database."
          }
        ],
        "returns": [
          {
            "name": "ollama_base_url",
            "type": "str | None",
            "description": "The Ollama base URL for the user, or None if the user is not found or has no URL configured."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.fetch_gpt_key": {
      "identifier": "database.db.fetch_gpt_key",
      "description": {
        "overall": "This function retrieves the GPT API key associated with a given username from the database. It queries the `dbusers` collection for a user document matching the provided username and specifically requests the `gpt_api_key` field, excluding the `_id` field. If a user document is found, it returns the value of the `gpt_api_key`. If no user is found, it returns None.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username of the user whose GPT API key needs to be fetched."
          }
        ],
        "returns": [
          {
            "name": "gpt_api_key",
            "type": "str | None",
            "description": "The GPT API key for the specified user, or None if the user is not found or has no key."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.fetch_opensrc_key": {
      "identifier": "database.db.fetch_opensrc_key",
      "description": {
        "overall": "This function retrieves the 'opensrc_api_key' for a given username from a database. It queries the database for a user document based on the provided username and specifically selects the 'opensrc_api_key' field while excluding the '_id' field. If the user is found, it returns the associated API key; otherwise, it returns None.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username of the user whose opensrc_api_key needs to be fetched."
          }
        ],
        "returns": [
          {
            "name": "opensrc_api_key",
            "type": "str | None",
            "description": "The opensrc_api_key associated with the username, or None if the user is not found or has no such key."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.fetch_opensrc_url": {
      "identifier": "database.db.fetch_opensrc_url",
      "description": {
        "overall": "This function retrieves the 'opensrc_base_url' for a given username from a database. It queries a collection named 'dbusers' for a document matching the provided username. If a user document is found, it attempts to extract and return the value associated with the 'opensrc_base_url' key. If the user is not found or the key is missing, it returns None.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username to query in the database."
          }
        ],
        "returns": [
          {
            "name": "opensrc_base_url",
            "type": "str | None",
            "description": "The 'opensrc_base_url' associated with the username, or None if the user is not found or the URL is not present."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other function."
        }
      },
      "error": null
    },
    "database.db.delete_user": {
      "identifier": "database.db.delete_user",
      "description": {
        "overall": "This function deletes a user from the database. It takes a username as input and returns the count of deleted documents. The function interacts with a database collection named 'dbusers' to perform the deletion operation.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username of the user to be deleted."
          }
        ],
        "returns": [
          {
            "name": "deleted_count",
            "type": "int",
            "description": "The number of documents that were deleted from the database. This is expected to be 1 if the user existed and was deleted, or 0 otherwise."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.get_decrypted_api_keys": {
      "identifier": "database.db.get_decrypted_api_keys",
      "description": {
        "overall": "This function retrieves and decrypts API keys and related base URLs for a given user from a database. It first fetches the user's record using their username. If the user is not found, it returns None for all values. Otherwise, it decrypts sensitive API keys (Gemini, GPT, Open Source) using an external `decrypt_text` function and retrieves non-sensitive information like the Ollama base URL and Open Source base URL. Finally, it returns all the decrypted API keys and base URLs.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username of the user whose API keys are to be retrieved."
          }
        ],
        "returns": [
          {
            "name": "gemini_plain",
            "type": "str",
            "description": "The decrypted Gemini API key."
          },
          {
            "name": "ollama_plain",
            "type": "str",
            "description": "The Ollama base URL."
          },
          {
            "name": "gpt_plain",
            "type": "str",
            "description": "The decrypted GPT API key."
          },
          {
            "name": "opensrc_plain",
            "type": "str",
            "description": "The decrypted Open Source API key."
          },
          {
            "name": "opensrc_url",
            "type": "str",
            "description": "The Open Source base URL."
          }
        ],
        "usage_context": {
          "calls": "This function calls database.db.decrypt_text.",
          "called_by": "This function is not called by any other function."
        }
      },
      "error": null
    },
    "database.db.insert_chat": {
      "identifier": "database.db.insert_chat",
      "description": {
        "overall": "This function creates a new chat entry in the database. It generates a unique ID, records the username and chat name, and timestamps the creation. The function then inserts this data into a collection named 'dbchats' and returns the ID of the newly inserted document.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username associated with the chat."
          },
          {
            "name": "chat_name",
            "type": "str",
            "description": "The name of the chat to be created."
          }
        ],
        "returns": [
          {
            "name": "inserted_id",
            "type": "Any",
            "description": "The unique identifier of the newly created chat document."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.fetch_chats_by_user": {
      "identifier": "database.db.fetch_chats_by_user",
      "description": {
        "overall": "This function retrieves all chats associated with a specific user from a database. It queries a collection named 'dbchats' for documents matching the provided username. The results are then sorted by their 'created_at' field in ascending order before being returned as a list. The function's purpose is to provide a user with their chat history.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username of the user whose chats are to be fetched."
          }
        ],
        "returns": [
          {
            "name": "chats",
            "type": "list",
            "description": "A list of chat documents associated with the specified user, sorted by creation time."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.check_chat_exists": {
      "identifier": "database.db.check_chat_exists",
      "description": {
        "overall": "This function checks if a specific chat exists for a given username in the database. It queries a collection (presumably 'dbchats') for a document matching both the provided username and chat name. The function returns a boolean value indicating whether a matching document was found.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username associated with the chat."
          },
          {
            "name": "chat_name",
            "type": "str",
            "description": "The name of the chat to check for."
          }
        ],
        "returns": [
          {
            "name": "chat_exists",
            "type": "bool",
            "description": "True if the chat exists for the given username, False otherwise."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.rename_chat_fully": {
      "identifier": "database.db.rename_chat_fully",
      "description": {
        "overall": "This function renames a chat and all associated exchanges in the database. It first updates the chat's name in the 'chats' collection and then updates the chat name for all related messages in the 'exchanges' collection. The function returns the count of modified documents in the 'chats' collection.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username associated with the chat."
          },
          {
            "name": "old_name",
            "type": "str",
            "description": "The current name of the chat to be renamed."
          },
          {
            "name": "new_name",
            "type": "str",
            "description": "The new name for the chat."
          }
        ],
        "returns": [
          {
            "name": "modified_count",
            "type": "int",
            "description": "The number of chat documents that were modified."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is called by no other functions."
        }
      },
      "error": null
    },
    "database.db.insert_exchange": {
      "identifier": "database.db.insert_exchange",
      "description": {
        "overall": "This function inserts a new exchange record into the database. It constructs a dictionary containing various details of an exchange, including question, answer, feedback, user information, usage statistics, and timestamps. It then attempts to insert this record into the 'dbexchanges' collection using `insert_one`. If the insertion is successful, it returns the unique ID of the new record; otherwise, it prints an error message and returns None.",
        "parameters": [
          {
            "name": "question",
            "type": "str",
            "description": "The user's question."
          },
          {
            "name": "answer",
            "type": "str",
            "description": "The answer provided to the question."
          },
          {
            "name": "feedback",
            "type": "str",
            "description": "User feedback on the answer."
          },
          {
            "name": "username",
            "type": "str",
            "description": "The username of the user making the exchange."
          },
          {
            "name": "chat_name",
            "type": "str",
            "description": "The name of the chat session."
          },
          {
            "name": "helper_used",
            "type": "str",
            "description": "Indicates if a helper was used (default: \"\")."
          },
          {
            "name": "main_used",
            "type": "str",
            "description": "Indicates if the main model was used (default: \"\")."
          },
          {
            "name": "total_time",
            "type": "str",
            "description": "Total time taken for the exchange (default: \"\")."
          },
          {
            "name": "helper_time",
            "type": "str",
            "description": "Time spent using the helper model (default: \"\")."
          },
          {
            "name": "main_time",
            "type": "str",
            "description": "Time spent using the main model (default: \"\")."
          },
          {
            "name": "json_tokens",
            "type": "int",
            "description": "Number of JSON tokens used (default: 0)."
          },
          {
            "name": "toon_tokens",
            "type": "int",
            "description": "Number of toon tokens used (default: 0)."
          },
          {
            "name": "savings_percent",
            "type": "float",
            "description": "Percentage of savings achieved (default: 0.0)."
          }
        ],
        "returns": [
          {
            "name": "new_id",
            "type": "str",
            "description": "The unique ID of the newly inserted exchange record, or None if an error occurred."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is called by no other functions."
        }
      },
      "error": null
    },
    "database.db.fetch_exchanges_by_user": {
      "identifier": "database.db.fetch_exchanges_by_user",
      "description": {
        "overall": "This function retrieves a list of exchanges associated with a specific username from a database. It queries a collection named 'dbexchanges' for documents matching the provided username. The retrieved exchanges are then sorted by their 'created_at' timestamp in ascending order before being returned as a list.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username to filter exchanges by."
          }
        ],
        "returns": [
          {
            "name": "exchanges",
            "type": "list",
            "description": "A list of exchange documents associated with the given username, sorted by creation time."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.fetch_exchanges_by_chat": {
      "identifier": "database.db.fetch_exchanges_by_chat",
      "description": {
        "overall": "This function retrieves a list of exchanges from a database collection based on the provided username and chat name. It queries the 'dbexchanges' collection, filters documents by 'username' and 'chat_name', sorts them by 'created_at' in ascending order, and returns the results as a list. The function is designed to fetch historical chat data.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username associated with the chat exchanges to be fetched."
          },
          {
            "name": "chat_name",
            "type": "str",
            "description": "The name of the chat from which to fetch exchanges."
          }
        ],
        "returns": [
          {
            "name": "exchanges",
            "type": "list",
            "description": "A list of exchange documents from the database, sorted by creation time."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.update_exchange_feedback": {
      "identifier": "database.db.update_exchange_feedback",
      "description": {
        "overall": "This function updates the feedback associated with a specific exchange in the database. It takes an exchange ID and a feedback integer as input. The function then uses the `dbexchanges.update_one` method to set the 'feedback' field for the document matching the provided `exchange_id`. Finally, it returns the count of documents that were modified by the update operation.",
        "parameters": [
          {
            "name": "exchange_id",
            "type": "Any",
            "description": "The unique identifier of the exchange to be updated."
          },
          {
            "name": "feedback",
            "type": "int",
            "description": "The integer value representing the feedback to be set for the exchange."
          }
        ],
        "returns": [
          {
            "name": "modified_count",
            "type": "int",
            "description": "The number of documents that were modified by the update operation. Typically 1 if the update was successful and the document existed, or 0 otherwise."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.update_exchange_feedback_message": {
      "identifier": "database.db.update_exchange_feedback_message",
      "description": {
        "overall": "This function updates the feedback message associated with a specific exchange in the database. It takes an exchange ID and a feedback message string as input. The function then uses the `dbexchanges.update_one` method to find the exchange by its ID and set the `feedback_message` field to the provided value. Finally, it returns the count of documents that were modified.",
        "parameters": [
          {
            "name": "exchange_id",
            "type": "Any",
            "description": "The unique identifier for the exchange to be updated."
          },
          {
            "name": "feedback_message",
            "type": "str",
            "description": "The new feedback message to be associated with the exchange."
          }
        ],
        "returns": [
          {
            "name": "modified_count",
            "type": "int",
            "description": "The number of documents that were modified in the database (expected to be 1 if successful)."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.delete_exchange_by_id": {
      "identifier": "database.db.delete_exchange_by_id",
      "description": {
        "overall": "This function deletes a single exchange record from the database based on its unique identifier. It interacts with a database collection named 'dbexchanges' to perform the deletion. The function returns the count of documents that were successfully deleted.",
        "parameters": [
          {
            "name": "exchange_id",
            "type": "str",
            "description": "The unique identifier of the exchange record to be deleted."
          }
        ],
        "returns": [
          {
            "name": "deleted_count",
            "type": "int",
            "description": "The number of documents that were deleted from the database. This is typically 1 if the exchange was found and deleted, or 0 if no matching exchange was found."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.delete_full_chat": {
      "identifier": "database.db.delete_full_chat",
      "description": {
        "overall": "This function deletes a specific chat and all associated exchanges from the database to ensure consistency between the frontend and backend. It first removes all messages within the specified chat and then deletes the chat itself from the chat list. The function aims to maintain data integrity by performing these operations atomically.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username associated with the chat to be deleted."
          },
          {
            "name": "chat_name",
            "type": "str",
            "description": "The name of the chat to be deleted."
          }
        ],
        "returns": [
          {
            "name": "deleted_count",
            "type": "int",
            "description": "The number of chat documents that were deleted."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "frontend.frontend.clean_names": {
      "identifier": "frontend.frontend.clean_names",
      "description": {
        "overall": "This function takes a list of strings, where each string is expected to be a path or identifier that includes a '/'. It processes each string by splitting it at the '/' character and extracting the last part. This is useful for cleaning up model names or paths to get just the final component. The function returns a new list containing these cleaned names.",
        "parameters": [
          {
            "name": "model_list",
            "type": "List[str]",
            "description": "A list of strings, where each string is an identifier or path that needs cleaning."
          }
        ],
        "returns": [
          {
            "name": "cleaned_names",
            "type": "List[str]",
            "description": "A new list containing the last component of each string from the input list after splitting by '/'."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "frontend.frontend.get_filtered_models": {
      "identifier": "frontend.frontend.get_filtered_models",
      "description": {
        "overall": "This function filters a list of models based on a specified category name. It retrieves keywords associated with the category from a `CATEGORY_KEYWORDS` mapping. If the category is 'STANDARD', it returns models present in both the input list and a `STANDARD_MODELS` list. Otherwise, it filters the input list to include models whose names contain any of the category's keywords (case-insensitive). If no models match the keywords, the original source list is returned.",
        "parameters": [
          {
            "name": "source_list",
            "type": "list",
            "description": "The original list of models to be filtered."
          },
          {
            "name": "category_name",
            "type": "str",
            "description": "The name of the category to filter by."
          }
        ],
        "returns": [
          {
            "name": "filtered_list",
            "type": "list",
            "description": "A list of models filtered by the specified category, or the original list if no matches are found or if the category is 'STANDARD' and matches are found."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is called by no other functions."
        }
      },
      "error": null
    },
    "frontend.frontend.save_gemini_cb": {
      "identifier": "frontend.frontend.save_gemini_cb",
      "description": {
        "overall": "This function is responsible for saving a Gemini API key provided by the user. It retrieves the new key from the Streamlit session state. If a key exists, it updates the user's Gemini key in the database using the `update_gemini_key` function. After a successful update, it clears the temporary key from the session state and displays a success message to the user using a toast notification.",
        "parameters": [],
        "returns": [],
        "usage_context": {
          "calls": "This function calls database.db.update_gemini_key.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "frontend.frontend.save_ollama_cb": {
      "identifier": "frontend.frontend.save_ollama_cb",
      "description": {
        "overall": "This function is a callback designed to save an Ollama URL. It retrieves a URL from the Streamlit session state, and if a URL is present, it updates the database with this new URL associated with the current user. Finally, it displays a confirmation toast message to the user indicating that the URL has been saved.",
        "parameters": [],
        "returns": [],
        "usage_context": {
          "calls": "This function calls database.db.update_ollama_url.",
          "called_by": "This function is not called by any other function."
        }
      },
      "error": null
    },
    "frontend.frontend.load_data_from_db": {
      "identifier": "frontend.frontend.load_data_from_db",
      "description": {
        "overall": "This function loads chat and exchange data from a database for a given username, ensuring consistency. It first loads predefined chats and then sorts associated exchanges into them. If no chats exist, it creates a default chat and inserts it into the database. It also manages the active chat session state, setting it to the first available chat if necessary or creating a new one if the user is new or data hasn't been loaded yet. This function is intended to be called at the beginning of a user session to populate the frontend with their data.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username for whom to load data."
          }
        ],
        "returns": [],
        "usage_context": {
          "calls": "This function calls database.db.fetch_chats_by_user, database.db.fetch_exchanges_by_user, and database.db.insert_chat.",
          "called_by": "This function is not called by any other function within the provided context."
        }
      },
      "error": null
    },
    "frontend.frontend.handle_feedback_change": {
      "identifier": "frontend.frontend.handle_feedback_change",
      "description": {
        "overall": "This function updates the feedback associated with an exchange and then triggers a rerun of the Streamlit application. It modifies a dictionary representing an exchange by setting its 'feedback' key to a new value. Subsequently, it calls a database function to persist this feedback change, associating it with the exchange's unique identifier. Finally, it instructs the Streamlit application to refresh its display to reflect the updated information.",
        "parameters": [
          {
            "name": "ex",
            "type": "dict",
            "description": "A dictionary representing an exchange, expected to contain at least an '_id' key for database updates."
          },
          {
            "name": "val",
            "type": "any",
            "description": "The new feedback value to be assigned to the exchange."
          }
        ],
        "returns": [],
        "usage_context": {
          "calls": "This function calls database.db.update_exchange_feedback.",
          "called_by": "This function is not called by any other functions within the provided context."
        }
      },
      "error": null
    },
    "frontend.frontend.handle_delete_exchange": {
      "identifier": "frontend.frontend.handle_delete_exchange",
      "description": {
        "overall": "This function handles the deletion of an exchange from the system. It first deletes the exchange from the database using its ID. Then, it checks if the chat associated with the exchange exists in the session state. If it does, and if the exchange is present in the list of exchanges for that chat, it removes the exchange from the list. Finally, it triggers a rerun of the Streamlit application to reflect the changes.",
        "parameters": [
          {
            "name": "chat_name",
            "type": "str",
            "description": "The name of the chat associated with the exchange to be deleted."
          },
          {
            "name": "ex",
            "type": "dict",
            "description": "A dictionary representing the exchange to be deleted, expected to contain an '_id' key."
          }
        ],
        "returns": [],
        "usage_context": {
          "calls": "This function calls database.db.delete_exchange_by_id.",
          "called_by": "This function is not called by any other function."
        }
      },
      "error": null
    },
    "frontend.frontend.handle_delete_chat": {
      "identifier": "frontend.frontend.handle_delete_chat",
      "description": {
        "overall": "This function handles the deletion of a chat for a given user. It first deletes the chat data from the database using `db.delete_full_chat`. Then, it cleans up the session state by removing the chat from `st.session_state.chats`. If there are remaining chats, it sets the first one as the active chat. If no chats remain, it creates a new default chat, inserts it into the database, initializes it in the session state, and sets it as the active chat. Finally, it reruns the Streamlit application to reflect the changes.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username of the user whose chat is to be deleted."
          },
          {
            "name": "chat_name",
            "type": "str",
            "description": "The name of the chat to be deleted."
          }
        ],
        "returns": [],
        "usage_context": {
          "calls": "This function calls database.db.delete_full_chat and database.db.insert_chat.",
          "called_by": "This function is not called by any other function."
        }
      },
      "error": null
    },
    "frontend.frontend.extract_repo_name": {
      "identifier": "frontend.frontend.extract_repo_name",
      "description": {
        "overall": "This function extracts a repository name from a given text, primarily by searching for a URL. It uses regular expressions to find a URL within the text. If a URL is found, it parses the URL to isolate the path component. The last part of the path is considered the repository name. It also handles cases where the repository name might end with '.git', removing that suffix. If no URL is found or if the extracted path does not yield a repository name, the function returns None.",
        "parameters": [
          {
            "name": "text",
            "type": "str",
            "description": "The input text which may contain a URL to a repository."
          }
        ],
        "returns": [
          {
            "name": "repo_name",
            "type": "str | None",
            "description": "The extracted repository name if a URL is found and parsed successfully, otherwise None."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is called by no other functions."
        }
      },
      "error": null
    },
    "frontend.frontend.stream_text_generator": {
      "identifier": "frontend.frontend.stream_text_generator",
      "description": {
        "overall": "This function takes a string of text as input and yields words from it one by one with a small delay. It splits the input text into words based on spaces and then yields each word followed by a space. A brief pause of 0.01 seconds is introduced after yielding each word. This is likely used for creating a streaming text effect in a user interface.",
        "parameters": [
          {
            "name": "text",
            "type": "str",
            "description": "The input text to be streamed."
          }
        ],
        "returns": [
          {
            "name": "word",
            "type": "str",
            "description": "A word from the input text, followed by a space."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "frontend.frontend.render_text_with_mermaid": {
      "identifier": "frontend.frontend.render_text_with_mermaid",
      "description": {
        "overall": "This function takes a markdown string and renders it, specifically handling mermaid code blocks. It splits the input text by mermaid code blocks (delimited by ```mermaid ... ```). For non-mermaid parts, it renders them as markdown, optionally streaming the output if `should_stream` is True. For mermaid code blocks, it attempts to render them using `st_mermaid`; if that fails, it falls back to rendering as a code block with the mermaid language specified.",
        "parameters": [
          {
            "name": "markdown_text",
            "type": "str",
            "description": "The input markdown text that may contain mermaid code blocks."
          },
          {
            "name": "should_stream",
            "type": "bool",
            "description": "A flag to indicate whether the non-mermaid text should be streamed. Defaults to False."
          }
        ],
        "returns": [],
        "usage_context": {
          "calls": "This function calls frontend.frontend.stream_text_generator.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "frontend.frontend.render_exchange": {
      "identifier": "frontend.frontend.render_exchange",
      "description": {
        "overall": "This function renders a chat exchange, displaying both the user's question and the assistant's answer. It handles displaying feedback options, download functionality, and deletion for the assistant's response. If the answer indicates an error, it displays an error message and a delete option. The function also supports rendering markdown content with Mermaid diagrams.",
        "parameters": [
          {
            "name": "ex",
            "type": "dict",
            "description": "A dictionary containing the exchange data, including 'question', 'answer', 'feedback', '_id', and potentially 'feedback_message'."
          },
          {
            "name": "current_chat_name",
            "type": "str",
            "description": "The name of the current chat session, used for deletion operations."
          }
        ],
        "returns": [],
        "usage_context": {
          "calls": "This function calls database.db.update_exchange_feedback_message, frontend.frontend.handle_delete_exchange, frontend.frontend.handle_feedback_change, and frontend.frontend.render_text_with_mermaid.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    }
  },
  "classes": {
    "backend.AST_Schema.ASTVisitor": {
      "identifier": "backend.AST_Schema.ASTVisitor",
      "description": {
        "overall": "The ASTVisitor class is designed to traverse an Abstract Syntax Tree (AST) generated from Python source code. It specifically focuses on identifying and extracting information about imports, classes, and functions defined within the code. The visitor pattern is employed to systematically process different node types in the AST, accumulating structured data about these code elements into a schema. This class is instrumental in parsing Python files to build a metadata representation of their structure.",
        "init_method": {
          "description": "Initializes the ASTVisitor with the source code, file path, and project root. It sets up instance variables to store this information and initializes an empty schema dictionary to hold extracted AST information. It also prepares a variable to track the current class being visited.",
          "parameters": [
            {
              "name": "source_code",
              "type": "str",
              "description": "The raw source code of the Python file being analyzed."
            },
            {
              "name": "file_path",
              "type": "str",
              "description": "The absolute path to the Python file being analyzed."
            },
            {
              "name": "project_root",
              "type": "str",
              "description": "The root directory of the project."
            }
          ]
        },
        "methods": [
          {
            "identifier": "visit_Import",
            "description": {
              "overall": "This method is called when an `import` statement is encountered in the AST. It iterates through the imported names and appends them to the 'imports' list within the schema. It then calls `generic_visit` to continue traversal down the AST.",
              "parameters": [
                {
                  "name": "self",
                  "type": "ASTVisitor",
                  "description": "The instance of the ASTVisitor."
                },
                {
                  "name": "node",
                  "type": "ast.AST",
                  "description": "The AST node representing an import statement."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls `generic_visit` to continue the AST traversal.",
                "called_by": "This method is called by the AST traversal mechanism when an import node is encountered."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_ImportFrom",
            "description": {
              "overall": "This method handles `from ... import ...` statements. It extracts the module and the specific names being imported, formatting them as `module.name` before adding them to the 'imports' list in the schema. It ensures the traversal continues by calling `generic_visit`.",
              "parameters": [
                {
                  "name": "self",
                  "type": "ASTVisitor",
                  "description": "The instance of the ASTVisitor."
                },
                {
                  "name": "node",
                  "type": "ast.AST",
                  "description": "The AST node representing a 'from import' statement."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls `generic_visit` to continue the AST traversal.",
                "called_by": "This method is called by the AST traversal mechanism when a 'from import' node is encountered."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_ClassDef",
            "description": {
              "overall": "This method is invoked when a class definition is found in the AST. It constructs a detailed dictionary (`class_info`) containing information about the class, such as its fully qualified identifier, name, docstring, source code segment, and line numbers. This information is appended to the 'classes' list in the schema, and the `_current_class` attribute is updated to store this class's information for subsequent method analysis. Finally, it continues the AST traversal and resets `_current_class` upon exiting the class definition.",
              "parameters": [
                {
                  "name": "self",
                  "type": "ASTVisitor",
                  "description": "The instance of the ASTVisitor."
                },
                {
                  "name": "node",
                  "type": "ast.AST",
                  "description": "The AST node representing a class definition."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls `ast.get_docstring` to retrieve the class docstring, `ast.get_source_segment` to get the source code of the class, and `generic_visit` to continue AST traversal.",
                "called_by": "This method is called by the AST traversal mechanism when a class definition node is encountered."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_FunctionDef",
            "description": {
              "overall": "This method handles the definition of functions and methods. If the visitor is currently inside a class (`self._current_class` is set), it treats the definition as a method, creating a `method_context_info` dictionary with its identifier, name, arguments, docstring, and line numbers, and appends it to the current class's context. If not inside a class, it's treated as a standalone function, and a `func_info` dictionary is created and added to the schema's 'functions' list. In both cases, it continues the AST traversal.",
              "parameters": [
                {
                  "name": "self",
                  "type": "ASTVisitor",
                  "description": "The instance of the ASTVisitor."
                },
                {
                  "name": "node",
                  "type": "ast.AST",
                  "description": "The AST node representing a function or method definition."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls `ast.get_docstring` to retrieve the function/method docstring, `ast.get_source_segment` to get the source code of the function/method, and `generic_visit` to continue AST traversal.",
                "called_by": "This method is called by the AST traversal mechanism when a function definition node is encountered."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_AsyncFunctionDef",
            "description": {
              "overall": "This method is an alias for `visit_FunctionDef` and is designed to handle asynchronous function definitions (`async def`). It ensures that asynchronous functions are processed identically to regular functions by simply calling the `visit_FunctionDef` method.",
              "parameters": [
                {
                  "name": "self",
                  "type": "ASTVisitor",
                  "description": "The instance of the ASTVisitor."
                },
                {
                  "name": "node",
                  "type": "ast.AST",
                  "description": "The AST node representing an asynchronous function definition."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls `self.visit_FunctionDef` to process the asynchronous function definition.",
                "called_by": "This method is called by the AST traversal mechanism when an asynchronous function definition node is encountered."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "This class depends on the `backend.AST_Schema.path_to_module` function for path manipulation.",
          "instantiated_by": "This class is not instantiated by any other code within the provided context."
        }
      },
      "error": null
    },
    "backend.AST_Schema.ASTAnalyzer": {
      "identifier": "backend.AST_Schema.ASTAnalyzer",
      "description": {
        "overall": "The ASTAnalyzer class is designed to process and enrich Abstract Syntax Tree (AST) data generated from a codebase. It takes raw schema information and relationship data (like function calls and class instantiations) and merges them to provide a more comprehensive understanding of the code structure. It also facilitates the analysis of an entire repository by parsing individual files and extracting AST information.",
        "init_method": {
          "description": "Initializes the ASTAnalyzer. Currently, this constructor does not perform any specific setup or attribute initialization.",
          "parameters": []
        },
        "methods": [
          {
            "identifier": "merge_relationship_data",
            "description": {
              "overall": "This method enriches a given schema dictionary with relationship data, such as outgoing calls and incoming calls for functions, and instantiation information for classes. It iterates through the files, functions, classes, and methods within the schema, populating their respective context fields with data from `outgoing_calls` and `incoming_calls`. It also calculates and stores dependencies for classes based on the methods they call.",
              "parameters": [
                {
                  "name": "full_schema",
                  "type": "dict",
                  "description": "A dictionary representing the complete schema of the codebase, including file structures and AST nodes."
                },
                {
                  "name": "raw_relationships",
                  "type": "dict",
                  "description": "A dictionary containing raw relationship data, expected to have 'outgoing' and 'incoming' keys for call and instantiation information."
                }
              ],
              "returns": [
                {
                  "name": "full_schema",
                  "type": "dict",
                  "description": "The modified full_schema dictionary, now enriched with relationship data."
                }
              ],
              "usage_context": {
                "calls": "This method retrieves data using .get() on dictionaries and iterates through nested structures. It does not explicitly call other methods or functions from external modules within its own logic.",
                "called_by": "This method is called by the 'analyze_repository' method to merge relationship data into the schema."
              }
            },
            "error": null
          },
          {
            "identifier": "analyze_repository",
            "description": {
              "overall": "This method orchestrates the analysis of an entire code repository. It takes a list of file objects and a GitRepository object, constructs a base schema, and then iterates through each Python file. For each file, it parses the content using Python's `ast` module and an `ASTVisitor` to extract AST information. It populates the schema with file-specific AST nodes and handles potential parsing errors.",
              "parameters": [
                {
                  "name": "files",
                  "type": "list",
                  "description": "A list of file objects, where each object is expected to have 'path' and 'content' attributes."
                },
                {
                  "name": "repo",
                  "type": "GitRepository",
                  "description": "An object representing the Git repository, though its methods are not directly used within this function's logic."
                }
              ],
              "returns": [
                {
                  "name": "full_schema",
                  "type": "dict",
                  "description": "A dictionary containing the aggregated AST schema for all processed Python files in the repository."
                }
              ],
              "usage_context": {
                "calls": "This method calls the ast.parse function to parse Python code into an AST, instantiates and uses an ASTVisitor, and uses os.path functions for path manipulation.",
                "called_by": "This method is called externally to initiate the repository analysis process."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "This class depends on the 'ast' module for parsing Python code, the 'os' module for path operations, and 'getRepo.GitRepository' for repository interaction. It also relies on 'backend.AST_Schema.ASTVisitor' for the core AST traversal and schema generation.",
          "instantiated_by": "This class is not instantiated by any other part of the code based on the provided context."
        }
      },
      "error": null
    },
    "backend.File_Dependency.FileDependencyGraph": {
      "identifier": "backend.File_Dependency.FileDependencyGraph",
      "description": {
        "overall": "The FileDependencyGraph class is designed to analyze Python source code and build a graph of file dependencies. It inherits from `ast.NodeVisitor` to traverse the Abstract Syntax Tree (AST) of Python files. The primary goal is to identify and resolve import statements, particularly relative imports, to map out how different files within a repository depend on each other. It stores these dependencies in a dictionary where keys are filenames and values are sets of imported module names.",
        "init_method": {
          "description": "Initializes the FileDependencyGraph with the filename being analyzed and the root directory of the repository. This context is crucial for resolving relative imports and understanding the scope of the dependency analysis.",
          "parameters": [
            {
              "name": "filename",
              "type": "str",
              "description": "The name of the Python file currently being processed."
            },
            {
              "name": "repo_root",
              "type": "str",
              "description": "The absolute path to the root directory of the repository."
            }
          ]
        },
        "methods": [
          {
            "identifier": "_resolve_module_name",
            "description": {
              "overall": "This method is responsible for resolving relative import statements (e.g., `from .. import module`) within a Python file. It determines the correct module path based on the current file's location and the specified import level. It searches for corresponding Python files or `__init__.py` files within the repository to identify the target module or symbol. If a resolution is not possible, it raises an `ImportError`.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ImportFrom",
                  "description": "The AST node representing the import statement."
                }
              ],
              "returns": [
                {
                  "name": "resolved",
                  "type": "list[str]",
                  "description": "A sorted list of strings representing the resolved module or symbol names."
                }
              ],
              "usage_context": {
                "calls": "This method calls `get_all_temp_files` to get a list of all files in the repository, and `init_exports_symbol` and `module_file_exists` to check for the existence and exportability of modules and symbols.",
                "called_by": "This method is called by `visit_ImportFrom` when a relative import needs to be resolved."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_Import",
            "description": {
              "overall": "This method is called when an `ast.Import` node is encountered during AST traversal. It processes the imported module names and adds them to the `import_dependencies` dictionary for the current file. If a `base_name` is provided (indicating a part of a larger import, typically from `visit_ImportFrom`), it's added; otherwise, the direct alias name is used.",
              "parameters": [
                {
                  "name": "node",
                  "type": "Import | ImportFrom",
                  "description": "The AST node representing the import statement."
                },
                {
                  "name": "base_name",
                  "type": "str | None",
                  "description": "An optional base name for the import, used for partial imports."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls `self.generic_visit(node)` to continue the AST traversal.",
                "called_by": "This method is called by `visit_ImportFrom` and potentially directly if an `ast.Import` node is visited."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_ImportFrom",
            "description": {
              "overall": "This method handles `ast.ImportFrom` nodes, which represent imports with a specific module source (e.g., `from module import name`). It extracts the base module name or, if it's a relative import, uses `_resolve_module_name` to find the actual module path. It then calls `visit_Import` to record the dependency.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ImportFrom",
                  "description": "The AST node representing the import-from statement."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls `_resolve_module_name` to handle relative imports and `self.visit_Import` to record the dependency. It also calls `self.generic_visit(node)` to continue the AST traversal.",
                "called_by": "This method is called when an `ast.ImportFrom` node is encountered during AST traversal."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "This class depends on several modules and functions for AST parsing, path manipulation, and file system operations, including `ast` module functions (`Assign`, `ClassDef`, `FunctionDef`, `Import`, `ImportFrom`, `Name`, `NodeVisitor`, `literal_eval`, `parse`, `walk`), `keyword.iskeyword`, `pathlib.Path`, and specific functions from `backend.File_Dependency` like `get_all_temp_files`, `init_exports_symbol`, and `module_file_exists`.",
          "instantiated_by": "The provided context does not specify where instances of this class are created."
        }
      },
      "error": null
    },
    "backend.HelperLLM.LLMHelper": {
      "identifier": "backend.HelperLLM.LLMHelper",
      "description": {
        "overall": "The LLMHelper class is designed to facilitate the generation and validation of documentation for code elements, specifically functions and classes, by interacting with large language models (LLMs). It centralizes the configuration of LLM clients (supporting Google Gemini, OpenAI, and Ollama), manages API key authentication, loads system prompts from files, and dynamically sets batch sizes based on the chosen model to optimize API calls. The class provides distinct methods for processing batches of function or class documentation requests, including error handling and rate-limiting delays.",
        "init_method": {
          "description": "Initializes the LLMHelper with necessary API credentials, prompt file paths, and LLM configuration. It reads system prompts for function and class documentation from specified files, sets up the LLM client based on the model name (supporting various providers like Gemini, OpenAI, and Ollama), and configures batch processing settings. It raises a ValueError if the API key is missing or if required environment variables for custom LLM endpoints are not set.",
          "parameters": [
            {
              "name": "api_key",
              "type": "str",
              "description": "The API key for authenticating with the LLM service."
            },
            {
              "name": "function_prompt_path",
              "type": "str",
              "description": "The file path to the system prompt used for generating function documentation."
            },
            {
              "name": "class_prompt_path",
              "type": "str",
              "description": "The file path to the system prompt used for generating class documentation."
            },
            {
              "name": "model_name",
              "type": "str",
              "description": "The name of the LLM model to use. Defaults to 'gemini-2.0-flash-lite'."
            },
            {
              "name": "base_url",
              "type": "str",
              "description": "An optional base URL for custom LLM endpoints, used if not using default providers or if OLLAMA_BASE_URL is not set."
            }
          ]
        },
        "methods": [
          {
            "identifier": "_configure_batch_settings",
            "description": {
              "overall": "Configures the batch size for API calls based on the specified LLM model name. It defines different batch sizes for various models, including Gemini and OpenAI variants, and sets a conservative default batch size for unknown models. This method helps optimize the number of requests sent in a single API call to manage rate limits and efficiency.",
              "parameters": [
                {
                  "name": "model_name",
                  "type": "str",
                  "description": "The name of the LLM model for which to configure batch settings."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method is called internally by the __init__ method to set the batch size.",
                "called_by": "This method is called by the __init__ method."
              }
            },
            "error": null
          },
          {
            "identifier": "generate_for_functions",
            "description": {
              "overall": "Generates and validates documentation for a list of function inputs using the configured LLM. It processes the inputs in batches according to the `batch_size` attribute, constructs conversation prompts with the system message and function input payload, and sends them to the LLM. The method handles potential exceptions during batch processing by logging errors and returning None for failed batches, ensuring the output list maintains the correct order. It also includes a delay between batches to respect API rate limits.",
              "parameters": [
                {
                  "name": "function_inputs",
                  "type": "List[FunctionAnalysisInput]",
                  "description": "A list of FunctionAnalysisInput objects, each containing the necessary information to generate documentation for a function."
                }
              ],
              "returns": [
                {
                  "name": "all_validated_functions",
                  "type": "List[Optional[FunctionAnalysis]]",
                  "description": "A list containing the generated and validated FunctionAnalysis objects, or None for any batches that failed."
                }
              ],
              "usage_context": {
                "calls": "This method calls `json.dumps` to serialize input data, constructs `SystemMessage` and `HumanMessage` objects for conversation, and uses the `batch` method of the `self.function_llm` object to interact with the LLM API. It also uses `time.sleep` for rate limiting.",
                "called_by": "This method is called to generate documentation for functions."
              }
            },
            "error": null
          },
          {
            "identifier": "generate_for_classes",
            "description": {
              "overall": "Generates and validates documentation for a list of class inputs using the configured LLM. Similar to `generate_for_functions`, it processes class inputs in batches, prepares conversation prompts with the system prompt and class input payload, and sends them to the LLM via the `self.class_llm.batch` method. It includes error handling for batch failures and implements a waiting period between batches to manage API rate limits, returning a list of validated `ClassAnalysis` objects or `None` for failed items.",
              "parameters": [
                {
                  "name": "class_inputs",
                  "type": "List[ClassAnalysisInput]",
                  "description": "A list of ClassAnalysisInput objects, each containing the necessary information to generate documentation for a class."
                }
              ],
              "returns": [
                {
                  "name": "all_validated_classes",
                  "type": "List[Optional[ClassAnalysis]]",
                  "description": "A list containing the generated and validated ClassAnalysis objects, or None for any batches that failed."
                }
              ],
              "usage_context": {
                "calls": "This method calls `json.dumps` to serialize input data, constructs `SystemMessage` and `HumanMessage` objects for conversation, and uses the `batch` method of the `self.class_llm` object to interact with the LLM API. It also uses `time.sleep` for rate limiting.",
                "called_by": "This method is called to generate documentation for classes."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "This class depends on several external libraries for LLM interaction and data handling, including `langchain-google-genai`, `langchain-ollama`, `langchain-openai`, `pydantic` for data validation, and standard Python libraries like `os`, `json`, `logging`, and `time`. It also relies on custom schema types like `FunctionAnalysis`, `ClassAnalysis`, `FunctionAnalysisInput`, and `ClassAnalysisInput`.",
          "instantiated_by": "This class is instantiated by other parts of the backend system that require LLM-based documentation generation capabilities for functions and classes."
        }
      },
      "error": null
    },
    "backend.MainLLM.MainLLM": {
      "identifier": "backend.MainLLM.MainLLM",
      "description": {
        "overall": "The MainLLM class is designed to interact with various Large Language Models (LLMs). It handles the initialization of different LLM clients based on provided model names and configurations, loads system prompts from files, and provides methods to invoke LLM calls and stream responses. This class acts as a central interface for LLM communication within the backend system.",
        "init_method": {
          "description": "Initializes the MainLLM class by validating the API key, loading the system prompt from a specified file, and setting up the appropriate LLM client based on the model name. It supports models from Google Generative AI, OpenAI (via SCADSLLM_URL), and Ollama, with default settings for temperature and fallback URLs.",
          "parameters": [
            {
              "name": "api_key",
              "type": "str",
              "description": "The API key required for authenticating with the LLM service."
            },
            {
              "name": "prompt_file_path",
              "type": "str",
              "description": "The file path to the system prompt that will be used for all LLM interactions."
            },
            {
              "name": "model_name",
              "type": "str",
              "description": "The name of the LLM model to use. Defaults to 'gemini-2.5-pro'."
            },
            {
              "name": "base_url",
              "type": "str",
              "description": "An optional base URL for custom LLM endpoints, used when not using default services like Google or Ollama. Defaults to None."
            }
          ]
        },
        "methods": [
          {
            "identifier": "call_llm",
            "description": {
              "overall": "This method sends a user's input along with the system prompt to the initialized LLM and returns the content of the LLM's response. It constructs the message list, invokes the LLM client, and handles potential exceptions during the call, logging any errors and returning None if an issue occurs.",
              "parameters": [
                {
                  "name": "user_input",
                  "type": "str",
                  "description": "The input string provided by the user to be processed by the LLM."
                }
              ],
              "returns": [
                {
                  "name": "response.content",
                  "type": "str",
                  "description": "The content of the LLM's response as a string, or None if an error occurred."
                }
              ],
              "usage_context": {
                "calls": "This method calls the 'invoke' method of the initialized LLM client, which is expected to be a Langchain LLM object.",
                "called_by": "This method is called to get a direct response from the LLM based on user input."
              }
            },
            "error": null
          },
          {
            "identifier": "stream_llm",
            "description": {
              "overall": "This method initiates a streaming call to the LLM, allowing for the response to be received in chunks. It constructs the message list with the system prompt and user input, then iterates over the stream iterator provided by the LLM client, yielding each chunk's content. Errors during the streaming process are logged, and an error message is yielded.",
              "parameters": [
                {
                  "name": "user_input",
                  "type": "str",
                  "description": "The input string provided by the user for which a streamed LLM response is requested."
                }
              ],
              "returns": [
                {
                  "name": "chunk.content",
                  "type": "str",
                  "description": "Yields chunks of the LLM's response content as they become available. In case of an error, it yields an error message string."
                }
              ],
              "usage_context": {
                "calls": "This method calls the 'stream' method of the initialized LLM client, which is expected to be a Langchain LLM object that supports streaming.",
                "called_by": "This method is called to receive a streaming response from the LLM, useful for real-time interactions."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "This class depends on several external libraries for LLM interaction, including langchain_google_genai, langchain_ollama, and langchain_openai, as well as standard libraries like 'os', 'logging', and 'sys'. It also relies on environment variables like SCADSLLM_URL and OLLAMA_BASE_URL for configuration.",
          "instantiated_by": "The context provided does not specify where this class is instantiated."
        }
      },
      "error": null
    },
    "backend.basic_info.ProjektInfoExtractor": {
      "identifier": "backend.basic_info.ProjektInfoExtractor",
      "description": {
        "overall": "The ProjektInfoExtractor class is designed to extract fundamental project information from common project files such as README, pyproject.toml, and requirements.txt. It initializes a structured dictionary to hold project overview and installation details, populating it by parsing these files. The class prioritizes information from pyproject.toml for dependencies and title, then falls back to requirements.txt for dependencies, and finally uses README for a broader range of project details like title, description, features, tech stack, status, and setup instructions. It also derives the project title from the repository URL if no other source provides it.",
        "init_method": {
          "description": "Initializes the ProjektInfoExtractor with a default structure for project information and a constant string for indicating missing information. The info dictionary is pre-populated with placeholders for project overview (title, description, status, key features, tech stack) and installation details (dependencies, setup instructions, quick start guide).",
          "parameters": []
        },
        "methods": [
          {
            "identifier": "_clean_content",
            "description": {
              "overall": "This method takes a string as input and removes any null bytes ('\\x00') from it. Null bytes can occur due to encoding issues, such as reading UTF-16 encoded files as UTF-8. The method ensures that the returned string is clean and free of these problematic characters, returning an empty string if the input is empty or None.",
              "parameters": [
                {
                  "name": "content",
                  "type": "str",
                  "description": "The string content to be cleaned."
                }
              ],
              "returns": [
                {
                  "name": "cleaned_content",
                  "type": "str",
                  "description": "The content string with null bytes removed."
                }
              ],
              "usage_context": {
                "calls": "This method is called by other internal parsing methods to clean file content before further processing.",
                "called_by": "This method is called by _parse_readme, _parse_toml, and _parse_requirements to clean their respective input content."
              }
            },
            "error": null
          },
          {
            "identifier": "_finde_datei",
            "description": {
              "overall": "This method searches through a list of file objects to find a file that matches one of the provided patterns. The search is case-insensitive and checks if the file's path ends with any of the specified patterns. It's useful for locating specific project files like README variants or configuration files within a collection of files.",
              "parameters": [
                {
                  "name": "patterns",
                  "type": "List[str]",
                  "description": "A list of file name patterns (e.g., 'readme.md') to search for."
                },
                {
                  "name": "dateien",
                  "type": "List[Any]",
                  "description": "A list of file objects, where each object is expected to have a 'path' attribute."
                }
              ],
              "returns": [
                {
                  "name": "datei",
                  "type": "Optional[Any]",
                  "description": "The first file object that matches any of the patterns, or None if no match is found."
                }
              ],
              "usage_context": {
                "calls": "This method iterates through provided file objects and patterns to find a match.",
                "called_by": "This method is called by extrahiere_info to locate specific project files like README, pyproject.toml, and requirements.txt."
              }
            },
            "error": null
          },
          {
            "identifier": "_extrahiere_sektion_aus_markdown",
            "description": {
              "overall": "This method extracts a specific section of text from a Markdown-formatted string. It looks for a section preceded by a level 2 heading ('##') that matches one of the provided keywords. The content following the heading, up to the next level 2 heading or the end of the file, is captured and returned after stripping leading/trailing whitespace. This is useful for parsing structured information within README files.",
              "parameters": [
                {
                  "name": "inhalt",
                  "type": "str",
                  "description": "The Markdown content to parse."
                },
                {
                  "name": "keywords",
                  "type": "List[str]",
                  "description": "A list of keywords that identify the desired section heading."
                }
              ],
              "returns": [
                {
                  "name": "section_content",
                  "type": "Optional[str]",
                  "description": "The extracted content of the section, or None if the section is not found."
                }
              ],
              "usage_context": {
                "calls": "This method uses regular expressions to find and extract content based on Markdown headings and keywords.",
                "called_by": "This method is called by _parse_readme to extract specific sections like 'Features', 'Tech Stack', 'Status', 'Installation', and 'Quick Start'."
              }
            },
            "error": null
          },
          {
            "identifier": "_parse_readme",
            "description": {
              "overall": "Parses the content of a README file to extract various project details and updates the class's internal info dictionary. It first cleans the content by removing null bytes. Then, it attempts to extract the project title from the main heading, followed by a general description. It uses the `_extrahiere_sektion_aus_markdown` method to find and populate fields for key features, tech stack, current status, setup instructions, and quick start guide. It prioritizes filling in missing information, meaning if a field is already populated (e.g., from pyproject.toml), it might not be overwritten unless the README provides a more specific entry.",
              "parameters": [
                {
                  "name": "inhalt",
                  "type": "str",
                  "description": "The content of the README file."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls _clean_content to sanitize input and _extrahiere_sektion_aus_markdown to parse specific sections. It also uses regular expressions for title and description extraction.",
                "called_by": "This method is called by extrahiere_info after a README file has been identified and its content read."
              }
            },
            "error": null
          },
          {
            "identifier": "_parse_toml",
            "description": {
              "overall": "Parses the content of a pyproject.toml file using the `tomllib` library to extract project metadata. It first cleans the input content. If `tomllib` is available, it attempts to load the TOML data. It then extracts the project name, description, and dependencies from the `[project]` table and updates the corresponding fields in the class's internal info dictionary. It includes error handling for TOML decoding issues and a warning if `tomllib` is not installed.",
              "parameters": [
                {
                  "name": "inhalt",
                  "type": "str",
                  "description": "The content of the pyproject.toml file."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls _clean_content to sanitize input and uses the `tomllib.loads` function to parse TOML data. It also uses dictionary access and `.get()` for data retrieval.",
                "called_by": "This method is called by extrahiere_info after a pyproject.toml file has been identified and its content read."
              }
            },
            "error": null
          },
          {
            "identifier": "_parse_requirements",
            "description": {
              "overall": "Parses the content of a requirements.txt file to extract project dependencies. It cleans the input content first. This method only populates the dependencies field in the internal info dictionary if it hasn't already been set by `pyproject.toml`. It splits the content into lines, filters out empty lines and comments (lines starting with '#'), and stores the remaining lines as a list of dependencies.",
              "parameters": [
                {
                  "name": "inhalt",
                  "type": "str",
                  "description": "The content of the requirements.txt file."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls _clean_content to sanitize input and uses string splitting and list comprehensions to process the file content.",
                "called_by": "This method is called by extrahiere_info after a requirements.txt file has been identified and its content read."
              }
            },
            "error": null
          },
          {
            "identifier": "extrahiere_info",
            "description": {
              "overall": "This is the main orchestrator method that drives the information extraction process. It takes a list of file objects and a repository URL as input. It first uses `_finde_datei` to locate README, pyproject.toml, and requirements.txt files. It then parses these files in a specific order: `pyproject.toml` first for project name, description, and dependencies, followed by `requirements.txt` for dependencies (if not already found), and finally `README.md` for other project details. After parsing, it formats the dependencies into a readable string. If no project title was found, it derives one from the repository URL. The method returns the populated internal info dictionary.",
              "parameters": [
                {
                  "name": "dateien",
                  "type": "List[Any]",
                  "description": "A list of file objects, each expected to have 'path' and 'content' attributes."
                },
                {
                  "name": "repo_url",
                  "type": "str",
                  "description": "The URL of the repository, used to derive the project title if necessary."
                }
              ],
              "returns": [
                {
                  "name": "info",
                  "type": "Dict[str, Any]",
                  "description": "A dictionary containing the extracted project information."
                }
              ],
              "usage_context": {
                "calls": "This method calls _finde_datei to locate relevant files, and then calls _parse_toml, _parse_requirements, and _parse_readme to process their content. It also uses os.path.basename for URL processing and string manipulation for formatting.",
                "called_by": "This method is the primary public interface for the ProjektInfoExtractor class, intended to be called to initiate the information extraction process."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "This class utilizes the 're' module for regular expression operations, 'os' for path manipulation (specifically `os.path.basename`), and 'tomllib' for parsing TOML files. It also uses type hinting from the 'typing' module.",
          "instantiated_by": "This class is instantiated by other parts of the system that need to extract project information from files. The specific locations are not detailed in the provided context."
        }
      },
      "error": null
    },
    "backend.callgraph.CallGraph": {
      "identifier": "backend.callgraph.CallGraph",
      "description": {
        "overall": "The CallGraph class is designed to parse Python source code using the `ast` module and build a directed graph representing function and method calls. It traverses the Abstract Syntax Tree (AST) of a given Python file, identifying imports, class definitions, function definitions, and actual function calls. The class maintains internal state to track the current file, class, and function context during the traversal, resolving callee names by considering local definitions and import mappings to construct a comprehensive call graph. This graph can then be used to analyze the relationships and dependencies between different parts of the codebase.",
        "init_method": {
          "description": "Initializes the CallGraph object with the filename for which the call graph is to be generated. It sets up various internal data structures to store information during the AST traversal, including mappings for imports, sets of functions, and dictionaries for tracking local definitions and call graph edges. It also initializes a NetworkX directed graph to store the call graph itself.",
          "parameters": [
            {
              "name": "filename",
              "type": "str",
              "description": "The name of the Python file to be analyzed for call graph generation."
            }
          ]
        },
        "methods": [
          {
            "identifier": "_recursive_call",
            "description": {
              "overall": "This method recursively traverses an AST node representing a function call to extract the name components of the callee. It handles different AST node types like `ast.Call`, `ast.Name`, and `ast.Attribute` to progressively build a list of name parts. For instance, a call like `pkg.mod.Class.method()` would result in `['pkg', 'mod', 'Class', 'method']`. If the node is not a recognized call structure, it returns an empty list.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.AST",
                  "description": "The AST node to analyze, typically representing a function call or a part of it."
                }
              ],
              "returns": [
                {
                  "name": "parts",
                  "type": "list[str]",
                  "description": "A list of strings representing the hierarchical name components of the callee."
                }
              ],
              "usage_context": {
                "calls": "This method calls itself recursively to process nested call structures and `ast.Name` and `ast.Attribute` nodes.",
                "called_by": "This method is called by `_resolve_all_callee_names` and `visit_Call` to determine the name components of a potential callee."
              }
            },
            "error": null
          },
          {
            "identifier": "_resolve_all_callee_names",
            "description": {
              "overall": "This method takes a list of name components (obtained from `_recursive_call`) and resolves them into fully qualified names within the context of the current analysis. It prioritizes resolving names based on locally defined functions and classes, then checks the `import_mapping` for imported modules. If a name cannot be resolved through local definitions or imports, it constructs a name relative to the current filename and class context. This ensures that callees are represented in a consistent and unambiguous format.",
              "parameters": [
                {
                  "name": "callee_nodes",
                  "type": "list[list[str]]",
                  "description": "A list where each element is a list of strings representing the name parts of a potential callee (e.g., [['pkg', 'mod'], ['Class', 'method']])."
                }
              ],
              "returns": [
                {
                  "name": "resolved",
                  "type": "list[str]",
                  "description": "A list of fully resolved callee names as strings."
                }
              ],
              "usage_context": {
                "calls": "This method calls `_recursive_call` indirectly through the `callee_nodes` input and uses `self.local_defs` and `self.import_mapping` for name resolution.",
                "called_by": "This method is called by `visit_Call` to resolve the names of the functions or methods being called."
              }
            },
            "error": null
          },
          {
            "identifier": "_make_full_name",
            "description": {
              "overall": "Constructs a fully qualified name for a function or method by combining the filename, an optional class name, and the base name of the function/method. This ensures that names are unique within the context of the entire project being analyzed. The format is typically 'filename::ClassName::basename' or 'filename::basename'.",
              "parameters": [
                {
                  "name": "basename",
                  "type": "str",
                  "description": "The base name of the function or method."
                },
                {
                  "name": "class_name",
                  "type": "str | None",
                  "description": "The name of the class the function/method belongs to, if any."
                }
              ],
              "returns": [
                {
                  "name": "full_name",
                  "type": "str",
                  "description": "The complete, qualified name of the function or method."
                }
              ],
              "usage_context": {
                "calls": "This method uses f-strings for string formatting.",
                "called_by": "This method is called by `visit_FunctionDef` and `visit_ClassDef` to generate unique identifiers for functions and classes."
              }
            },
            "error": null
          },
          {
            "identifier": "_current_caller",
            "description": {
              "overall": "Determines the identifier for the current scope from which a call is being made. If `self.current_function` is set, it returns that value. Otherwise, it returns a string representing the global scope of the current file, or '<global-scope>' if the filename is also unavailable.",
              "parameters": [
                {
                  "name": "self",
                  "type": "CallGraph",
                  "description": "The instance of the CallGraph class."
                }
              ],
              "returns": [
                {
                  "name": "caller",
                  "type": "str",
                  "description": "A string representing the current caller's scope."
                }
              ],
              "usage_context": {
                "calls": "This method accesses `self.current_function` and `self.filename`.",
                "called_by": "This method is called by `visit_Call` to identify the source of a function call."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_Import",
            "description": {
              "overall": "This method is part of the AST visitor pattern and is called when an `import` statement is encountered. It iterates through the imported modules and their aliases, populating the `self.import_mapping` dictionary. This mapping stores how imported module names (or their aliases) should be represented in the call graph, linking the alias to the original module name.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.Import",
                  "description": "The AST node representing an import statement."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls `self.generic_visit(node)` to continue traversal of the AST.",
                "called_by": "This method is automatically called by the `ast.NodeVisitor` when it encounters an `import` statement during tree traversal."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_ImportFrom",
            "description": {
              "overall": "This method handles `from ... import ...` statements in the AST. It extracts the module name and the imported names (and their aliases). It then updates the `self.import_mapping` to record these imports, associating the alias or imported name with the module it originates from. This is crucial for correctly resolving names that are imported directly into the current scope.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.ImportFrom",
                  "description": "The AST node representing a 'from ... import ...' statement."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method accesses `node.module` and `node.names` to extract import information.",
                "called_by": "This method is automatically called by the `ast.NodeVisitor` when it encounters a `from ... import ...` statement during tree traversal."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_ClassDef",
            "description": {
              "overall": "This method is invoked when the AST visitor encounters a class definition (`class ...:`). It updates the `self.current_class` attribute to the name of the class being visited, allowing subsequent method visits to be associated with this class. After visiting the nodes within the class definition (e.g., methods), it restores `self.current_class` to its previous value, maintaining the correct context for the AST traversal.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.ClassDef",
                  "description": "The AST node representing a class definition."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls `self.generic_visit(node)` to process the contents of the class definition and uses `self.current_class` to manage context.",
                "called_by": "This method is automatically called by the `ast.NodeVisitor` when it encounters a class definition during tree traversal."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_FunctionDef",
            "description": {
              "overall": "This method handles the definition of regular functions (`def ...:`). It constructs a fully qualified name for the function using `_make_full_name`, stores this name in `self.local_defs` for later resolution, and updates `self.current_function` to reflect the function being visited. It adds the function's full name as a node to the `self.graph` and then recursively visits the nodes within the function body. Finally, it adds the function to `self.function_set` and restores the `self.current_function` context.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.FunctionDef",
                  "description": "The AST node representing a function definition."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls `_make_full_name`, `self.generic_visit(node)`, and `self.graph.add_node`.",
                "called_by": "This method is automatically called by the `ast.NodeVisitor` when it encounters a function definition during tree traversal."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_AsyncFunctionDef",
            "description": {
              "overall": "This method is a convenience wrapper that handles the definition of asynchronous functions (`async def ...:`). It simply delegates the processing to the `visit_FunctionDef` method, as the logic for analyzing function definitions is the same for both synchronous and asynchronous functions in this context.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.AsyncFunctionDef",
                  "description": "The AST node representing an asynchronous function definition."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls `self.visit_FunctionDef(node)`.",
                "called_by": "This method is automatically called by the `ast.NodeVisitor` when it encounters an asynchronous function definition during tree traversal."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_Call",
            "description": {
              "overall": "This method is triggered when the AST visitor encounters a function call (`...()`). It first determines the current caller's context using `_current_caller`. Then, it uses `_recursive_call` to extract the name components of the callee and `_resolve_all_callee_names` to resolve these components into a fully qualified name. Finally, it adds an edge to the `self.edges` dictionary, representing the call from the caller to the callee, and continues the AST traversal.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.Call",
                  "description": "The AST node representing a function call."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls `_current_caller`, `_recursive_call`, `_resolve_all_callee_names`, and `self.generic_visit(node)`.",
                "called_by": "This method is automatically called by the `ast.NodeVisitor` when it encounters a function call during tree traversal."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_If",
            "description": {
              "overall": "This method handles `if` statements in the AST. It includes specific logic to detect the main execution block of a script, typically guarded by `if __name__ == \"__main__\":`. When this condition is met, it temporarily sets `self.current_function` to '<main_block>' to correctly attribute any calls within this block to the main script execution. After visiting the `if` block's contents, it restores the original `self.current_function` context. For other `if` statements, it simply continues the generic AST traversal.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.If",
                  "description": "The AST node representing an if statement."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls `self.generic_visit(node)` and manipulates `self.current_function`.",
                "called_by": "This method is automatically called by the `ast.NodeVisitor` when it encounters an `if` statement during tree traversal."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "The class relies on the `ast` module for parsing Python code and the `networkx` library for graph manipulation. It also utilizes typing hints like `Dict` and `str | None`.",
          "instantiated_by": "The provided context does not specify where this class is instantiated."
        }
      },
      "error": null
    },
    "backend.getRepo.RepoFile": {
      "identifier": "backend.getRepo.RepoFile",
      "description": {
        "overall": "The RepoFile class represents a single file within a Git repository. It is designed to load file content and metadata lazily, meaning that information like the file's blob, content, and size are only fetched when they are explicitly accessed. This class provides methods to access file properties, analyze its content (e.g., word count), and represent the file as a dictionary.",
        "init_method": {
          "description": "Initializes a RepoFile object with the file's path and the commit tree it belongs to. It sets up internal attributes to store the path and the commit tree, and initializes placeholders for the blob, content, and size, which will be loaded lazily upon first access.",
          "parameters": [
            {
              "name": "file_path",
              "type": "str",
              "description": "The path to the file within the repository."
            },
            {
              "name": "commit_tree",
              "type": "git.Tree",
              "description": "The Tree object of the commit from which the file originates."
            }
          ]
        },
        "methods": [
          {
            "identifier": "blob",
            "description": {
              "overall": "This property provides lazy loading for the Git blob object associated with the file. If the blob has not been accessed before, it attempts to retrieve it from the commit tree using the file's path. If the file is not found in the tree, it raises a FileNotFoundError. Once loaded, the blob object is cached for subsequent accesses.",
              "parameters": [],
              "returns": [
                {
                  "name": "self._blob",
                  "type": "git.Blob",
                  "description": "The Git blob object for the file."
                }
              ],
              "usage_context": {
                "calls": "This method calls `self._tree[self.path]` to retrieve the blob object.",
                "called_by": "This method is called by other methods within the RepoFile class that require access to the file's blob object, such as `content` and `size`."
              }
            },
            "error": null
          },
          {
            "identifier": "content",
            "description": {
              "overall": "This property lazily loads and returns the decoded content of the file. It first ensures that the file's blob object is loaded (by calling the `blob` property). Then, it reads the data from the blob's data stream, decodes it as UTF-8, ignoring any errors, and caches the result. This decoded content is returned upon subsequent calls.",
              "parameters": [],
              "returns": [
                {
                  "name": "self._content",
                  "type": "str",
                  "description": "The decoded content of the file as a string."
                }
              ],
              "usage_context": {
                "calls": "This method calls `self.blob` to get the file's blob and then accesses `blob.data_stream.read().decode('utf-8', errors='ignore')` to get the content.",
                "called_by": "This method is called by other methods or external code that needs to read the file's content, such as `analyze_word_count` and `to_dict`."
              }
            },
            "error": null
          },
          {
            "identifier": "size",
            "description": {
              "overall": "This property lazily loads and returns the size of the file in bytes. It first ensures that the file's blob object is loaded (by calling the `blob` property). Then, it retrieves the size attribute from the blob object and caches it for future use. This cached size is returned upon subsequent calls.",
              "parameters": [],
              "returns": [
                {
                  "name": "self._size",
                  "type": "int",
                  "description": "The size of the file in bytes."
                }
              ],
              "usage_context": {
                "calls": "This method calls `self.blob` to get the file's blob and then accesses `blob.size` to get the file size.",
                "called_by": "This method is called by other methods or external code that needs to know the file's size, such as `to_dict`."
              }
            },
            "error": null
          },
          {
            "identifier": "analyze_word_count",
            "description": {
              "overall": "This is an example analysis method that calculates the number of words present in the file's content. It retrieves the file's content by calling the `content` property, splits the content into words based on whitespace, and returns the total count of these words.",
              "parameters": [],
              "returns": [
                {
                  "name": "word_count",
                  "type": "int",
                  "description": "The total number of words found in the file's content."
                }
              ],
              "usage_context": {
                "calls": "This method calls `self.content` to retrieve the file's content and then uses the string method `split()`.",
                "called_by": "This method is called by external code that needs to perform a word count analysis on the file."
              }
            },
            "error": null
          },
          {
            "identifier": "__repr__",
            "description": {
              "overall": "This method provides a developer-friendly string representation of the RepoFile object. It formats a string that includes the class name and the file path, making it easier to identify and debug instances of this class.",
              "parameters": [],
              "returns": [
                {
                  "name": "representation",
                  "type": "str",
                  "description": "A string representation of the RepoFile object, e.g., '<RepoFile(path='your/file.txt')>'."
                }
              ],
              "usage_context": {
                "calls": "This method uses an f-string for formatting and accesses `self.path`.",
                "called_by": "This method is called implicitly when a RepoFile object is printed or inspected in an interactive session."
              }
            },
            "error": null
          },
          {
            "identifier": "to_dict",
            "description": {
              "overall": "This method converts the RepoFile object into a dictionary representation. It includes basic file information such as path, name (derived from the path), size, and type. Optionally, if the `include_content` flag is set to True, it also includes the file's content in the dictionary. This method is useful for serializing file information.",
              "parameters": [
                {
                  "name": "include_content",
                  "type": "bool",
                  "description": "A flag to determine if the file's content should be included in the dictionary. Defaults to False."
                }
              ],
              "returns": [
                {
                  "name": "data",
                  "type": "dict",
                  "description": "A dictionary containing the file's metadata and optionally its content."
                }
              ],
              "usage_context": {
                "calls": "This method calls `os.path.basename(self.path)`, `self.size`, and potentially `self.content`. It also uses dictionary literals and conditional logic.",
                "called_by": "This method is called by external code that requires a dictionary representation of the file, possibly for API responses or data storage."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "This class utilizes the 'os' module for path manipulation and interacts with objects from the 'git' library (specifically `git.Tree` and `git.Blob`) for repository file operations.",
          "instantiated_by": "The context does not specify where this class is instantiated."
        }
      },
      "error": null
    },
    "backend.getRepo.GitRepository": {
      "identifier": "backend.getRepo.GitRepository",
      "description": {
        "overall": "The GitRepository class manages a Git repository, handling its cloning into a temporary directory and providing access to its files. It facilitates operations like retrieving all files and constructing a hierarchical file tree representation. The class is designed to be used as a context manager, ensuring the temporary directory is cleaned up after use.",
        "init_method": {
          "description": "Initializes the GitRepository by cloning a specified repository URL into a temporary directory. It attempts to clone the repository and captures the latest commit and its tree. If cloning fails, it cleans up any partially created temporary directory and raises a RuntimeError. It also initializes an empty list to store file objects.",
          "parameters": [
            {
              "name": "repo_url",
              "type": "string",
              "description": "The URL of the Git repository to clone."
            }
          ]
        },
        "methods": [
          {
            "identifier": "get_all_files",
            "description": {
              "overall": "Retrieves all files within the Git repository. It uses the Git command `ls-files` to get a list of file paths, then iterates through these paths to create `RepoFile` objects. Each `RepoFile` is initialized with its path and the current commit's tree. The method stores these `RepoFile` objects in the `self.files` attribute and returns them.",
              "parameters": [
                {
                  "name": "self",
                  "type": "GitRepository",
                  "description": "The instance of the GitRepository class."
                }
              ],
              "returns": [
                {
                  "name": "files",
                  "type": "list[RepoFile]",
                  "description": "A list containing RepoFile objects, each representing a file in the repository."
                }
              ],
              "usage_context": {
                "calls": "This method calls the RepoFile constructor to create file objects.",
                "called_by": "This method is called by other methods within the GitRepository class, such as get_file_tree, to populate the list of files."
              }
            },
            "error": null
          },
          {
            "identifier": "close",
            "description": {
              "overall": "Cleans up the GitRepository by deleting the temporary directory that was created during initialization. It checks if a temporary directory path exists before attempting to remove it and sets `self.temp_dir` to None to indicate cleanup.",
              "parameters": [
                {
                  "name": "self",
                  "type": "GitRepository",
                  "description": "The instance of the GitRepository class."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method does not call any other methods.",
                "called_by": "This method is called by the __exit__ method to ensure cleanup when the GitRepository is used as a context manager, and also by the __init__ method in case of an error during cloning."
              }
            },
            "error": null
          },
          {
            "identifier": "__enter__",
            "description": {
              "overall": "Implements the context management protocol, specifically the entry point. It returns the instance of the GitRepository itself, allowing it to be used in a `with` statement.",
              "parameters": [
                {
                  "name": "self",
                  "type": "GitRepository",
                  "description": "The instance of the GitRepository class."
                }
              ],
              "returns": [
                {
                  "name": "self",
                  "type": "GitRepository",
                  "description": "The current GitRepository instance."
                }
              ],
              "usage_context": {
                "calls": "This method does not call any other methods.",
                "called_by": "This method is implicitly called when entering a 'with' statement block that uses a GitRepository instance."
              }
            },
            "error": null
          },
          {
            "identifier": "__exit__",
            "description": {
              "overall": "Implements the context management protocol, specifically the exit point. It is called when exiting a `with` statement block. This method ensures that the `close` method is called to clean up the temporary directory, regardless of whether an exception occurred within the `with` block.",
              "parameters": [
                {
                  "name": "self",
                  "type": "GitRepository",
                  "description": "The instance of the GitRepository class."
                },
                {
                  "name": "exc_type",
                  "type": "type",
                  "description": "The type of the exception raised in the `with` block, if any."
                },
                {
                  "name": "exc_val",
                  "type": "Exception",
                  "description": "The exception instance raised in the `with` block, if any."
                },
                {
                  "name": "exc_tb",
                  "type": "traceback",
                  "description": "The traceback object associated with the exception, if any."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls the close method of the GitRepository instance.",
                "called_by": "This method is implicitly called when exiting a 'with' statement block that uses a GitRepository instance."
              }
            },
            "error": null
          },
          {
            "identifier": "get_file_tree",
            "description": {
              "overall": "Constructs and returns a hierarchical tree structure representing the files and directories within the repository. If no files have been loaded yet, it first calls `get_all_files()` to populate the file list. It then iterates through each file, parsing its path to build a nested dictionary structure that mirrors the directory layout. Optionally, file content can be included in the dictionary representation.",
              "parameters": [
                {
                  "name": "self",
                  "type": "GitRepository",
                  "description": "The instance of the GitRepository class."
                },
                {
                  "name": "include_content",
                  "type": "bool",
                  "description": "A boolean flag indicating whether to include the content of each file in the returned tree structure. Defaults to False."
                }
              ],
              "returns": [
                {
                  "name": "tree",
                  "type": "dict",
                  "description": "A dictionary representing the file tree, with 'root' as the top-level key and nested dictionaries for directories and files."
                }
              ],
              "usage_context": {
                "calls": "This method calls the get_all_files method if no files are currently loaded and the to_dict method on RepoFile objects.",
                "called_by": "This method is called to generate a structured representation of the repository's file system."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "This class depends on the `RepoFile` class for representing individual files within the repository.",
          "instantiated_by": "This class is not explicitly shown to be instantiated by any other code within the provided context."
        }
      },
      "error": null
    },
    "backend.relationship_analyzer.ProjectAnalyzer": {
      "identifier": "backend.relationship_analyzer.ProjectAnalyzer",
      "description": {
        "overall": "The ProjectAnalyzer class is designed to analyze a Python project's codebase to build a call graph and identify relationships between different code elements. It traverses the project directory, parses Python files to collect definitions (functions, classes, methods), and then resolves call relationships between them. The class stores these relationships in a call graph and can also provide raw outgoing and incoming relationships.",
        "init_method": {
          "description": "Initializes the ProjectAnalyzer with the root directory of the project. It sets up instance variables to store project root, definitions, call graph, file Abstract Syntax Trees (ASTs), and a set of directories to ignore during the file search.",
          "parameters": [
            {
              "name": "project_root",
              "type": "string",
              "description": "The absolute path to the root directory of the project to be analyzed."
            }
          ]
        },
        "methods": [
          {
            "identifier": "analyze",
            "description": {
              "overall": "Initiates the analysis of the Python project. It first finds all Python files within the project, then iterates through them to collect definitions (functions, classes, methods) and subsequently resolves the call relationships between these definitions. Finally, it clears the stored file ASTs and returns the constructed call graph.",
              "parameters": [
                {
                  "name": "self",
                  "type": "ProjectAnalyzer",
                  "description": "The instance of the ProjectAnalyzer class."
                }
              ],
              "returns": [
                {
                  "name": "call_graph",
                  "type": "defaultdict(list)",
                  "description": "A dictionary representing the call graph, where keys are callee identifiers and values are lists of caller information."
                }
              ],
              "usage_context": {
                "calls": "This method calls _find_py_files to get a list of Python files, then iterates through these files calling _collect_definitions and _resolve_calls.",
                "called_by": "This method is called to start the analysis process of a project."
              }
            },
            "error": null
          },
          {
            "identifier": "get_raw_relationships",
            "description": {
              "overall": "Processes the internal call graph to generate structured dictionaries of outgoing and incoming relationships. It iterates through the call graph, identifying callers and callees, and populates two dictionaries: one for outgoing calls from a caller to callees, and another for incoming calls to a callee from callers. The results are sorted lists for each relationship.",
              "parameters": [
                {
                  "name": "self",
                  "type": "ProjectAnalyzer",
                  "description": "The instance of the ProjectAnalyzer class."
                }
              ],
              "returns": [
                {
                  "name": "relationships",
                  "type": "dict",
                  "description": "A dictionary containing two keys: 'outgoing' and 'incoming', each mapping to a dictionary of relationships."
                }
              ],
              "usage_context": {
                "calls": "This method iterates through the self.call_graph attribute and uses defaultdict(set) to build outgoing and incoming relationship dictionaries.",
                "called_by": "This method is called to retrieve the processed call relationships after the project has been analyzed."
              }
            },
            "error": null
          },
          {
            "identifier": "_find_py_files",
            "description": {
              "overall": "Recursively walks through the project directory starting from `self.project_root` to find all Python files. It utilizes `os.walk` and filters out files in ignored directories. Each found Python file's absolute path is added to a list.",
              "parameters": [
                {
                  "name": "self",
                  "type": "ProjectAnalyzer",
                  "description": "The instance of the ProjectAnalyzer class."
                }
              ],
              "returns": [
                {
                  "name": "py_files",
                  "type": "list[str]",
                  "description": "A list of absolute file paths to all Python files found in the project."
                }
              ],
              "usage_context": {
                "calls": "This method uses os.walk to traverse directories and os.path.join to construct file paths.",
                "called_by": "This method is called by the analyze method to discover all Python source files within the project."
              }
            },
            "error": null
          },
          {
            "identifier": "_collect_definitions",
            "description": {
              "overall": "Reads a given Python file, parses its source code into an Abstract Syntax Tree (AST), and identifies definitions of functions, classes, and methods. It stores the file path, line number, and type of each definition in the `self.definitions` dictionary. It also stores the AST in `self.file_asts` for later use. Errors during parsing are logged, and the AST for the file is set to None.",
              "parameters": [
                {
                  "name": "self",
                  "type": "ProjectAnalyzer",
                  "description": "The instance of the ProjectAnalyzer class."
                },
                {
                  "name": "filepath",
                  "type": "str",
                  "description": "The path to the Python file to be analyzed."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls ast.parse to create an AST from source code, ast.walk to traverse the AST, and path_to_module to convert a file path to a module path. It also uses logging.error for error reporting.",
                "called_by": "This method is called by the analyze method for each Python file found in the project to gather information about defined code elements."
              }
            },
            "error": null
          },
          {
            "identifier": "_get_parent",
            "description": {
              "overall": "Traverses the AST of a given tree to find the parent node of a specified node. It iterates through all nodes in the tree and checks if any of their direct child nodes match the target node. If a match is found, the parent node is returned; otherwise, it returns None.",
              "parameters": [
                {
                  "name": "self",
                  "type": "ProjectAnalyzer",
                  "description": "The instance of the ProjectAnalyzer class."
                },
                {
                  "name": "tree",
                  "type": "ast.AST",
                  "description": "The Abstract Syntax Tree to search within."
                },
                {
                  "name": "node",
                  "type": "ast.AST",
                  "description": "The node whose parent is to be found."
                }
              ],
              "returns": [
                {
                  "name": "parent",
                  "type": "ast.AST | None",
                  "description": "The parent node of the given node, or None if the node is the root or not found."
                }
              ],
              "usage_context": {
                "calls": "This method uses ast.walk to iterate through the AST and ast.iter_child_nodes to examine children of each node.",
                "called_by": "This method is called by _collect_definitions to determine if a function definition is a method within a class."
              }
            },
            "error": null
          },
          {
            "identifier": "_resolve_calls",
            "description": {
              "overall": "Resolves call relationships within a given Python file by utilizing a `CallResolverVisitor`. It retrieves the AST for the file from `self.file_asts`, instantiates the `CallResolverVisitor` with file-specific information and the collected definitions, and then visits the AST. The calls found by the visitor are then merged into the class's main `self.call_graph`. Errors during this process are logged.",
              "parameters": [
                {
                  "name": "self",
                  "type": "ProjectAnalyzer",
                  "description": "The instance of the ProjectAnalyzer class."
                },
                {
                  "name": "filepath",
                  "type": "str",
                  "description": "The path to the Python file for which to resolve calls."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method instantiates and uses CallResolverVisitor to visit the AST and logs errors using logging.error.",
                "called_by": "This method is called by the analyze method for each Python file to identify and record function and method calls."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "This class depends on the 'ast' module for parsing Python code, the 'os' module for file system operations, the 'logging' module for error reporting, and 'collections.defaultdict' for data structure management. It also relies on external functions `backend.relationship_analyzer.path_to_module` and the class `backend.relationship_analyzer.CallResolverVisitor`.",
          "instantiated_by": "This class is not instantiated by any other known code within the provided context."
        }
      },
      "error": null
    },
    "backend.relationship_analyzer.CallResolverVisitor": {
      "identifier": "backend.relationship_analyzer.CallResolverVisitor",
      "description": {
        "overall": "The CallResolverVisitor is an Abstract Syntax Tree (AST) visitor designed to traverse Python code and identify function and method calls. It maintains scope information, tracks class definitions, and resolves qualified names (QNames) of called functions or methods. This allows it to build a map of which definitions are called by which parts of the code, along with their file, line number, and caller type.",
        "init_method": {
          "description": "Initializes the CallResolverVisitor with the file path, project root, and a dictionary of known definitions. It sets up internal state to track scope, instance types, current caller information, and a defaultdict to store call relationships.",
          "parameters": [
            {
              "name": "filepath",
              "type": "str",
              "description": "The absolute path to the Python file being analyzed."
            },
            {
              "name": "project_root",
              "type": "str",
              "description": "The root directory of the project, used for resolving module paths."
            },
            {
              "name": "definitions",
              "type": "dict",
              "description": "A dictionary containing known definitions within the project, likely mapping qualified names to their details."
            }
          ]
        },
        "methods": [
          {
            "identifier": "visit_ClassDef",
            "description": {
              "overall": "Visits a class definition node in the AST. It updates the `current_class_name` to the name of the class being visited, allowing subsequent method calls within that class to be correctly associated. After visiting the class's body, it restores the previous `current_class_name` to maintain correct scope.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.ClassDef",
                  "description": "The AST node representing a class definition."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls `generic_visit` to continue the AST traversal.",
                "called_by": "This method is called automatically by the `ast.NodeVisitor` when it encounters a class definition."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_FunctionDef",
            "description": {
              "overall": "Visits a function definition node in the AST. It constructs the full identifier for the function, considering whether it's a method within a class or a standalone function. It updates `current_caller_name` to this full identifier before recursively visiting the function's body and then restores the previous caller name.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.FunctionDef",
                  "description": "The AST node representing a function definition."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls `generic_visit` to continue the AST traversal.",
                "called_by": "This method is called automatically by the `ast.NodeVisitor` when it encounters a function definition."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_Call",
            "description": {
              "overall": "Visits a call expression node in the AST. It resolves the qualified name of the called function or method using `_resolve_call_qname`. If the called entity is found in the project's definitions, it records the call information (file, line, caller, caller type) in the `self.calls` dictionary. The caller type is determined based on the current context (module, method, local function, or function).",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.Call",
                  "description": "The AST node representing a function or method call."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls `_resolve_call_qname` to determine the called function's name and `generic_visit` to continue the AST traversal.",
                "called_by": "This method is called automatically by the `ast.NodeVisitor` when it encounters a call expression."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_Import",
            "description": {
              "overall": "Visits an import statement node in the AST. It processes each imported name and adds it to the `self.scope` dictionary, mapping the alias (or the original name if no alias is used) to the imported module's name. This helps in resolving names used later in the code.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.Import",
                  "description": "The AST node representing an import statement."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls `generic_visit` to continue the AST traversal.",
                "called_by": "This method is called automatically by the `ast.NodeVisitor` when it encounters an import statement."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_ImportFrom",
            "description": {
              "overall": "Visits an import-from statement node in the AST. It determines the full module path for imported names, handling relative imports based on `node.level`. Each imported name (and its alias, if any) is stored in `self.scope` with its fully qualified module path.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.ImportFrom",
                  "description": "The AST node representing an import-from statement."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls `generic_visit` to continue the AST traversal.",
                "called_by": "This method is called automatically by the `ast.NodeVisitor` when it encounters an import-from statement."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_Assign",
            "description": {
              "overall": "Visits an assignment node in the AST. It specifically checks if the assignment involves calling a class constructor. If it does, and the class is known (present in `self.scope` and `self.definitions`), it records the type of the instance being created in `self.instance_types` for each target variable name. This helps in resolving method calls on instances later.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.Assign",
                  "description": "The AST node representing an assignment statement."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls `generic_visit` to continue the AST traversal.",
                "called_by": "This method is called automatically by the `ast.NodeVisitor` when it encounters an assignment statement."
              }
            },
            "error": null
          },
          {
            "identifier": "_resolve_call_qname",
            "description": {
              "overall": "A private helper method that attempts to resolve the qualified name (QName) of a function or method call from its AST node. It handles direct name lookups in the scope and attribute access (e.g., `module.function` or `instance.method`), using `self.scope` and `self.instance_types` to find the fully qualified path. It returns the resolved QName or `None` if resolution fails.",
              "parameters": [
                {
                  "name": "func_node",
                  "type": "ast.expr",
                  "description": "The AST node representing the function or method being called (e.g., ast.Name or ast.Attribute)."
                }
              ],
              "returns": [
                {
                  "name": "qualified_name",
                  "type": "str | None",
                  "description": "The fully qualified name of the function/method, or None if it cannot be resolved."
                }
              ],
              "usage_context": {
                "calls": "This method does not call any other methods directly within its implementation.",
                "called_by": "This method is called by `visit_Call` to resolve the name of the function being invoked."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "This class depends on the `path_to_module` function for resolving file paths to module paths.",
          "instantiated_by": "The `CallResolverVisitor` class is not instantiated by any other part of the code provided in the context."
        }
      },
      "error": null
    },
    "schemas.types.ParameterDescription": {
      "identifier": "schemas.types.ParameterDescription",
      "description": {
        "overall": "The ParameterDescription class is a Pydantic model used to define the structure for describing a single parameter within a function or method. It enforces that each parameter must have a name, a type, and a textual description.",
        "init_method": {
          "description": "Initializes a ParameterDescription object with the name, type, and description of a function parameter. It leverages Pydantic's BaseModel for data validation.",
          "parameters": [
            {
              "name": "name",
              "type": "str",
              "description": "The name of the parameter."
            },
            {
              "name": "type",
              "type": "str",
              "description": "The data type of the parameter."
            },
            {
              "name": "description",
              "type": "str",
              "description": "A textual explanation of the parameter's purpose."
            }
          ]
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class depends on Pydantic's BaseModel for data validation and structure.",
          "instantiated_by": "This class is typically instantiated within systems that need to represent and validate function or method parameter metadata."
        }
      },
      "error": null
    },
    "schemas.types.ReturnDescription": {
      "identifier": "schemas.types.ReturnDescription",
      "description": {
        "overall": "The ReturnDescription class is a Pydantic model used to define the structure for describing the return value of a function. It captures the name, type, and a textual description of the returned data.",
        "init_method": {
          "description": "Initializes a ReturnDescription object with the name, type, and description of a function's return value. This is a Pydantic model, so initialization is handled by Pydantic's data validation and assignment.",
          "parameters": [
            {
              "name": "name",
              "type": "str",
              "description": "The name of the return value."
            },
            {
              "name": "type",
              "type": "str",
              "description": "The data type of the return value."
            },
            {
              "name": "description",
              "type": "str",
              "description": "A textual description of the return value."
            }
          ]
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class does not have any external dependencies beyond Pydantic.",
          "instantiated_by": "This class is likely instantiated within systems that need to define and document function return values, such as API documentation generators or code analysis tools."
        }
      },
      "error": null
    },
    "schemas.types.UsageContext": {
      "identifier": "schemas.types.UsageContext",
      "description": {
        "overall": "The UsageContext class is a Pydantic model designed to encapsulate information about the calling context of a function. It specifically details what functions or methods the current function calls and which functions or methods call the current function.",
        "init_method": {
          "description": "Initializes the UsageContext model with information about the functions called by and calling the current function. It takes two string arguments, 'calls' and 'called_by', to populate these details.",
          "parameters": [
            {
              "name": "calls",
              "type": "str",
              "description": "A string describing the functions or methods that this function calls."
            },
            {
              "name": "called_by",
              "type": "str",
              "description": "A string describing the functions or methods that call this function."
            }
          ]
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class depends on Pydantic's BaseModel for its structure and validation.",
          "instantiated_by": "This class is typically instantiated within the context of defining function or method metadata, likely as part of a larger documentation or analysis system."
        }
      },
      "error": null
    },
    "schemas.types.FunctionDescription": {
      "identifier": "schemas.types.FunctionDescription",
      "description": {
        "overall": "The FunctionDescription class is a Pydantic model designed to encapsulate a comprehensive analysis of a function. It holds details about the function's overall purpose, its parameters, its return values, and its usage context within a larger system.",
        "init_method": {
          "description": "Initializes a FunctionDescription object. This constructor is implicitly defined by Pydantic's BaseModel and is responsible for validating and assigning the provided fields: overall description, a list of parameter descriptions, a list of return value descriptions, and usage context information.",
          "parameters": [
            {
              "name": "overall",
              "type": "str",
              "description": "A detailed explanation of the function's overall purpose and behavior."
            },
            {
              "name": "parameters",
              "type": "List[ParameterDescription]",
              "description": "A list of ParameterDescription objects, each detailing a function parameter."
            },
            {
              "name": "returns",
              "type": "List[ReturnDescription]",
              "description": "A list of ReturnDescription objects, each detailing a function's return value."
            },
            {
              "name": "usage_context",
              "type": "UsageContext",
              "description": "A UsageContext object that describes how and where the function is called and by whom."
            }
          ]
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class depends on Pydantic's BaseModel for its structure and validation. It also relies on other defined types such as ParameterDescription, ReturnDescription, and UsageContext, which are assumed to be defined elsewhere.",
          "instantiated_by": "This class is likely instantiated by systems that perform code analysis or documentation generation, where a detailed breakdown of functions is required."
        }
      },
      "error": null
    },
    "schemas.types.FunctionAnalysis": {
      "identifier": "schemas.types.FunctionAnalysis",
      "description": {
        "overall": "The FunctionAnalysis class is a Pydantic model designed to represent the structured analysis of a Python function. It serves as a data container for detailed information about a function, including its identifier, a description object, and an optional error field for reporting analysis issues.",
        "init_method": {
          "description": "Initializes a FunctionAnalysis object. It takes the function's identifier, a FunctionDescription object, and an optional error string as arguments. The identifier is a mandatory string representing the function's name. The description is a mandatory FunctionDescription object containing details about the function's purpose, parameters, return values, and usage context. An optional error string can be provided if there were issues during the analysis of the function.",
          "parameters": [
            {
              "name": "identifier",
              "type": "str",
              "description": "The name of the function being analyzed."
            },
            {
              "name": "description",
              "type": "FunctionDescription",
              "description": "A FunctionDescription object containing detailed analysis of the function."
            },
            {
              "name": "error",
              "type": "Optional[str]",
              "description": "An optional string describing any errors encountered during function analysis. Defaults to None."
            }
          ]
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class depends on the FunctionDescription Pydantic model and BaseModel from the pydantic library.",
          "instantiated_by": "This class is likely instantiated by systems or tools that perform code analysis and need to structure the results of function analysis."
        }
      },
      "error": null
    },
    "schemas.types.ConstructorDescription": {
      "identifier": "schemas.types.ConstructorDescription",
      "description": {
        "overall": "The ConstructorDescription class is a Pydantic model used to represent the initialization method of a Python class. It captures a textual description of the constructor's purpose and a list of its parameters, where each parameter is further detailed by the ParameterDescription model.",
        "init_method": {
          "description": "Initializes a ConstructorDescription object. It takes a string description of the constructor and a list of ParameterDescription objects, each detailing a parameter of the constructor.",
          "parameters": [
            {
              "name": "description",
              "type": "str",
              "description": "A textual summary of the constructor's purpose."
            },
            {
              "name": "parameters",
              "type": "List[ParameterDescription]",
              "description": "A list of ParameterDescription objects, each detailing a parameter of the constructor."
            }
          ]
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class depends on Pydantic's BaseModel for its structure and validation, and it uses typing.List for type hinting. It also implicitly relies on a ParameterDescription model for its parameters, though that model is not provided in this context.",
          "instantiated_by": "This class is intended to be instantiated by systems that are analyzing Python class structures and need to represent the details of their constructors in a structured format. It is likely used within documentation generation tools or code analysis frameworks."
        }
      },
      "error": null
    },
    "schemas.types.ClassContext": {
      "identifier": "schemas.types.ClassContext",
      "description": {
        "overall": "The ClassContext class is a Pydantic model designed to describe a class's external dependencies and its instantiation points within a system. It serves as a structured way to document these crucial aspects of a class's integration and usage.",
        "init_method": {
          "description": "Initializes the ClassContext model with details about the class's dependencies and where it is instantiated. It sets up the attributes required for documenting a class's context.",
          "parameters": [
            {
              "name": "dependencies",
              "type": "str",
              "description": "A string describing the external dependencies of the class."
            },
            {
              "name": "instantiated_by",
              "type": "str",
              "description": "A string describing the locations or mechanisms by which the class is instantiated."
            }
          ]
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class does not define any external dependencies within its own code, as it is a Pydantic model for data structure.",
          "instantiated_by": "This class is likely instantiated as part of a larger documentation generation system or a system that analyzes and describes other classes."
        }
      },
      "error": null
    },
    "schemas.types.ClassDescription": {
      "identifier": "schemas.types.ClassDescription",
      "description": {
        "overall": "The ClassDescription class serves as a comprehensive data structure for holding the detailed analysis of a Python class. It encapsulates information about the class's overall purpose, its initialization method, a list of its individual methods, and its usage context within a larger system. This structure is designed to be used within a documentation generation system, providing a machine-readable format for class analysis.",
        "init_method": {
          "description": "The constructor for ClassDescription initializes a new instance with the analyzed components of a Python class. It takes the overall description of the class, a detailed description of its initialization method, a list of analyses for its other methods, and a description of its usage context as arguments.",
          "parameters": [
            {
              "name": "overall",
              "type": "str",
              "description": "A string providing a high-level summary of the class's purpose and responsibilities."
            },
            {
              "name": "init_method",
              "type": "ConstructorDescription",
              "description": "An object detailing the class's constructor (__init__ method), including its description and parameters."
            },
            {
              "name": "methods",
              "type": "List[FunctionAnalysis]",
              "description": "A list of objects, where each object represents the analysis of a method within the class."
            },
            {
              "name": "usage_context",
              "type": "ClassContext",
              "description": "An object describing how the class is used, including its dependencies and where it is instantiated."
            }
          ]
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class relies on other defined types such as BaseModel, ConstructorDescription, FunctionAnalysis, and ClassContext, which are likely part of the same schema definition module.",
          "instantiated_by": "This class is intended to be instantiated by systems that perform code analysis and require a structured way to represent the findings for a given Python class."
        }
      },
      "error": null
    },
    "schemas.types.ClassAnalysis": {
      "identifier": "schemas.types.ClassAnalysis",
      "description": {
        "overall": "The ClassAnalysis model represents the entire JSON schema for analyzing a Python class. It encapsulates the class's identifier, a detailed description of its components (including constructor and methods), and an optional error field for reporting analysis issues.",
        "init_method": {
          "description": "Initializes a ClassAnalysis object. It takes the class identifier and a ClassDescription object as mandatory arguments, and an optional error string.",
          "parameters": [
            {
              "name": "identifier",
              "type": "str",
              "description": "The name of the class being analyzed."
            },
            {
              "name": "description",
              "type": "ClassDescription",
              "description": "An object containing the detailed analysis of the class, including its overall purpose, constructor, methods, and usage context."
            },
            {
              "name": "error",
              "type": "Optional[str]",
              "description": "An optional string that holds an error message if the analysis failed. Defaults to None."
            }
          ]
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class does not appear to have any external dependencies beyond Pydantic's BaseModel.",
          "instantiated_by": "This class is likely instantiated by the main documentation generation system or a component responsible for orchestrating class analysis."
        }
      },
      "error": null
    },
    "schemas.types.CallInfo": {
      "identifier": "schemas.types.CallInfo",
      "description": {
        "overall": "The CallInfo class is a Pydantic BaseModel used to represent detailed information about a specific call event within a system. It captures the source file, the calling function or method name, the mode of the call (e.g., 'method', 'function', 'module'), and the specific line number where the call occurred. This structure is primarily utilized for documenting relationships, such as which functions or methods are calling a particular piece of code ('called_by') or where an object is instantiated from ('instantiated_by').",
        "init_method": {
          "description": "Initializes a CallInfo object with details about a specific call event. It takes the file path, function name, call mode, and line number as arguments and assigns them to corresponding attributes.",
          "parameters": [
            {
              "name": "file",
              "type": "str",
              "description": "The path to the file where the call originated."
            },
            {
              "name": "function",
              "type": "str",
              "description": "The name of the function or method that made the call."
            },
            {
              "name": "mode",
              "type": "str",
              "description": "The type of call, such as 'method', 'function', or 'module'."
            },
            {
              "name": "line",
              "type": "int",
              "description": "The line number in the source file where the call occurred."
            }
          ]
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class depends on Pydantic's BaseModel for data validation and structure.",
          "instantiated_by": "This class is designed to be instantiated by systems that track code relationships, such as a relationship analyzer, to record details of call events. It is specifically mentioned for use in 'called_by' and 'instantiated_by' lists."
        }
      },
      "error": null
    },
    "schemas.types.FunctionContextInput": {
      "identifier": "schemas.types.FunctionContextInput",
      "description": {
        "overall": "The FunctionContextInput class is a Pydantic model designed to structure contextual information for analyzing a function. It specifically captures the functions a given function calls and the functions that call it, providing essential data for documentation generation or code analysis tools.",
        "init_method": {
          "description": "Initializes the FunctionContextInput model with lists of function calls and callers. This constructor is automatically generated by Pydantic based on the defined fields.",
          "parameters": [
            {
              "name": "calls",
              "type": "List[str]",
              "description": "A list of strings, where each string represents a function or method called by the analyzed function."
            },
            {
              "name": "called_by",
              "type": "List[CallInfo]",
              "description": "A list of CallInfo objects, where each object details a function or method that calls the analyzed function."
            }
          ]
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class depends on Pydantic's BaseModel for its structure and validation. It also relies on a type named 'CallInfo', which is not defined in the provided source code but is expected to be available in the environment.",
          "instantiated_by": "This class is intended to be instantiated by systems or processes that require structured input for function analysis, such as documentation generation tools or static analysis engines. Specific instantiation points are not detailed in the provided source."
        }
      },
      "error": null
    },
    "schemas.types.FunctionAnalysisInput": {
      "identifier": "schemas.types.FunctionAnalysisInput",
      "description": {
        "overall": "The FunctionAnalysisInput class serves as a data structure to encapsulate all necessary information required for analyzing a Python function. It inherits from Pydantic's BaseModel, ensuring data validation for its fields. This class is designed to be a standardized input for a function analysis process within a larger system.",
        "init_method": {
          "description": "Initializes a FunctionAnalysisInput object with specific details required for function analysis. It takes the mode, identifier, source code, a list of import statements, and a FunctionContextInput object as arguments, setting up the necessary data for subsequent analysis.",
          "parameters": [
            {
              "name": "mode",
              "type": "Literal[\"function_analysis\"]",
              "description": "Specifies the analysis mode, which must be 'function_analysis'."
            },
            {
              "name": "identifier",
              "type": "str",
              "description": "The name or identifier of the function being analyzed."
            },
            {
              "name": "source_code",
              "type": "str",
              "description": "The raw source code of the function."
            },
            {
              "name": "imports",
              "type": "List[str]",
              "description": "A list of import statements relevant to the source code."
            },
            {
              "name": "context",
              "type": "FunctionContextInput",
              "description": "An object containing contextual information about the function's environment and usage."
            }
          ]
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class has no external functional dependencies listed in the provided context.",
          "instantiated_by": "The provided context does not specify where this class is instantiated."
        }
      },
      "error": null
    },
    "schemas.types.MethodContextInput": {
      "identifier": "schemas.types.MethodContextInput",
      "description": {
        "overall": "The MethodContextInput class is a Pydantic model designed to structure contextual information about a class's methods. It captures details such as the method's identifier, lists of other methods or functions it calls and is called by, its arguments, and an optional docstring. This class serves as a data container for method-specific metadata.",
        "init_method": {
          "description": "Initializes a MethodContextInput object, which is a Pydantic BaseModel. It takes several arguments to define the context of a method, including its identifier, lists of calls and callers, arguments, and an optional docstring. All fields are validated by Pydantic.",
          "parameters": [
            {
              "name": "identifier",
              "type": "str",
              "description": "The unique name or identifier of the method."
            },
            {
              "name": "calls",
              "type": "List[str]",
              "description": "A list of strings, where each string represents an identifier of a function or method that this method calls."
            },
            {
              "name": "called_by",
              "type": "List[CallInfo]",
              "description": "A list of CallInfo objects, where each object details a caller of this method."
            },
            {
              "name": "args",
              "type": "List[str]",
              "description": "A list of strings representing the arguments accepted by the method."
            },
            {
              "name": "docstring",
              "type": "Optional[str]",
              "description": "An optional string containing the documentation string (docstring) of the method."
            }
          ]
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class depends on Pydantic's BaseModel for data validation and typing hints from the `typing` module (List, Optional). It also relies on a `CallInfo` type, which is not defined in the provided source code but is expected to be available in the environment.",
          "instantiated_by": "This class is intended to be instantiated within systems that require structured representation of method metadata, likely as part of a larger documentation generation or code analysis tool. Specific instantiation points are not detailed in the provided source."
        }
      },
      "error": null
    },
    "schemas.types.ClassContextInput": {
      "identifier": "schemas.types.ClassContextInput",
      "description": {
        "overall": "The ClassContextInput class is a Pydantic model designed to structure contextual information required for analyzing a Python class. It encapsulates details about the class's dependencies, where it is instantiated, and the context of its methods.",
        "init_method": {
          "description": "Initializes the ClassContextInput model with lists of dependencies, instantiation information, and method contexts. This constructor is part of the Pydantic BaseModel and handles the validation and storage of the provided data.",
          "parameters": [
            {
              "name": "dependencies",
              "type": "List[str]",
              "description": "A list of strings representing external dependencies of the class being analyzed."
            },
            {
              "name": "instantiated_by",
              "type": "List[CallInfo]",
              "description": "A list of CallInfo objects detailing where instances of the class are created."
            },
            {
              "name": "method_context",
              "type": "List[MethodContextInput]",
              "description": "A list of MethodContextInput objects, each providing context for a specific method within the class."
            }
          ]
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class does not appear to have any external code dependencies beyond Pydantic and typing modules.",
          "instantiated_by": "This class is intended to be instantiated by systems that require structured input for class analysis, such as documentation generation tools or code analysis pipelines."
        }
      },
      "error": null
    },
    "schemas.types.ClassAnalysisInput": {
      "identifier": "schemas.types.ClassAnalysisInput",
      "description": {
        "overall": "The ClassAnalysisInput class is a Pydantic model designed to structure the input required for a class analysis process. It defines the necessary fields for providing source code, metadata, and contextual information about a Python class to be analyzed. This model ensures that the input adheres to a specific schema, facilitating automated processing by other AI components.",
        "init_method": {
          "description": "Initializes a ClassAnalysisInput object, setting up the structure for class analysis input. It takes the analysis mode, class identifier, source code, a list of imports, and contextual input as arguments, validating them against the defined Pydantic schema.",
          "parameters": [
            {
              "name": "mode",
              "type": "Literal[\"class_analysis\"]",
              "description": "Specifies the analysis mode, which must be 'class_analysis' for this input type."
            },
            {
              "name": "identifier",
              "type": "str",
              "description": "The name or identifier of the Python class to be analyzed."
            },
            {
              "name": "source_code",
              "type": "str",
              "description": "The raw source code of the Python class definition."
            },
            {
              "name": "imports",
              "type": "List[str]",
              "description": "A list of import statements relevant to the source code."
            },
            {
              "name": "context",
              "type": "ClassContextInput",
              "description": "An object containing contextual information about the class, such as dependencies and instantiation points."
            }
          ]
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class relies on Pydantic's BaseModel for data validation and typing.Literal for defining specific enumerated values.",
          "instantiated_by": "This class is intended to be instantiated by systems that require structured input for performing class analysis, such as AI documentation generation tools or code analysis pipelines."
        }
      },
      "error": null
    }
  }
}