{
  "functions": {
    "backend.AST_Schema.path_to_module": {
      "identifier": "backend.AST_Schema.path_to_module",
      "description": {
        "overall": "This function converts a given file system path into a Python module path string. It first attempts to get a relative path from a specified project root. If this fails, it defaults to using the base name of the file. It then removes the '.py' extension if present, replaces path separators with dots, and handles '__init__.py' files by removing the '.__init__' suffix to yield the correct package path.",
        "parameters": [
          {
            "name": "filepath",
            "type": "str",
            "description": "The absolute or relative path to a Python file."
          },
          {
            "name": "project_root",
            "type": "str",
            "description": "The root directory of the project, used to calculate the relative path."
          }
        ],
        "returns": [
          {
            "name": "module_path",
            "type": "str",
            "description": "The calculated Python module path string, suitable for import statements."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not explicitly called by any other functions in the provided context."
        }
      },
      "error": null
    },
    "backend.File_Dependency.build_file_dependency_graph": {
      "identifier": "backend.File_Dependency.build_file_dependency_graph",
      "description": {
        "overall": "The `build_file_dependency_graph` function constructs a directed graph representing file-level import dependencies for a given Python file. It initializes a NetworkX directed graph and then utilizes a `FileDependencyGraph` visitor to traverse the provided Abstract Syntax Tree (AST) of the target file. This visitor identifies import statements and collects dependencies. Finally, the function populates the NetworkX graph with nodes for each file involved in an import relationship and adds directed edges from the importing file to the imported files, returning the complete dependency graph.",
        "parameters": [
          {
            "name": "filename",
            "type": "str",
            "description": "The path to the file for which to build the dependency graph."
          },
          {
            "name": "tree",
            "type": "AST",
            "description": "The Abstract Syntax Tree (AST) of the `filename`."
          },
          {
            "name": "repo_root",
            "type": "str",
            "description": "The root directory of the repository, used for resolving relative paths."
          }
        ],
        "returns": [
          {
            "name": "graph",
            "type": "nx.DiGraph",
            "description": "A NetworkX directed graph where nodes represent files and edges represent import dependencies (importer -> imported)."
          }
        ],
        "usage_context": {
          "calls": "The function calls backend.File_Dependency.FileDependencyGraph.",
          "called_by": "This function is not explicitly called by any other functions in the provided context."
        }
      },
      "error": null
    },
    "backend.File_Dependency.build_repository_graph": {
      "identifier": "backend.File_Dependency.build_repository_graph",
      "description": {
        "overall": "The `build_repository_graph` function constructs a directed graph representing file dependencies across an entire Git repository. It first retrieves all files from the provided `GitRepository` object. It then iterates through each Python file, parses its content into an Abstract Syntax Tree (AST), and uses a helper function to build a file-specific dependency graph. Finally, it aggregates all nodes and edges from these individual file graphs into a single global directed graph, which is then returned.",
        "parameters": [
          {
            "name": "repository",
            "type": "GitRepository",
            "description": "The Git repository object from which to extract files and build the dependency graph."
          }
        ],
        "returns": [
          {
            "name": "global_graph",
            "type": "nx.DiGraph",
            "description": "A directed graph representing the dependencies between Python files within the repository."
          }
        ],
        "usage_context": {
          "calls": "This function calls backend.File_Dependency.build_file_dependency_graph.",
          "called_by": "This function is called by no other functions."
        }
      },
      "error": null
    },
    "backend.File_Dependency.get_all_temp_files": {
      "identifier": "backend.File_Dependency.get_all_temp_files",
      "description": {
        "overall": "This function identifies all Python files within a given directory and its subdirectories. It first converts the provided directory string into an absolute `pathlib.Path` object. It then uses the `rglob(\"*.py\")` method to recursively find all files with a `.py` extension within that directory tree. Finally, it returns a list of these file paths, with each path expressed relative to the initial root directory.",
        "parameters": [
          {
            "name": "directory",
            "type": "str",
            "description": "The path to the root directory from which to start searching for Python files."
          }
        ],
        "returns": [
          {
            "name": "all_files",
            "type": "list[Path]",
            "description": "A list of `pathlib.Path` objects, each representing a Python file found within the specified directory, relative to the root directory."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not explicitly called by any other functions in the provided context."
        }
      },
      "error": null
    },
    "backend.HelperLLM.main_orchestrator": {
      "identifier": "backend.HelperLLM.main_orchestrator",
      "description": {
        "overall": "This function serves as a test orchestrator and processing loop for the LLMHelper class. It defines dummy data, including pre-computed analysis inputs and outputs for several example functions and a class, conforming to Pydantic models. The function then instantiates the LLMHelper, simulates the generation of function documentation, and processes the results, logging and printing the final aggregated documentation.",
        "parameters": [],
        "returns": [],
        "usage_context": {
          "calls": "This function calls backend.HelperLLM.LLMHelper, schemas.types.ClassAnalysisInput, and schemas.types.ClassContextInput.",
          "called_by": "This function is called by no other functions."
        }
      },
      "error": null
    },
    "backend.callgraph.make_safe_dot": {
      "identifier": "backend.callgraph.make_safe_dot",
      "description": {
        "overall": "This function takes a NetworkX directed graph and an output file path, then generates a 'safe' DOT file representation of the graph. It achieves this by creating a copy of the input graph and relabeling all nodes with simple, sequential identifiers (e.g., 'n0', 'n1'). The original node names are preserved by storing them as 'label' attributes for the newly named nodes. Finally, the modified graph, with its safe node names and original labels, is written to the specified output path as a DOT file.",
        "parameters": [
          {
            "name": "graph",
            "type": "nx.DiGraph",
            "description": "The NetworkX directed graph to be converted into a safe DOT file format."
          },
          {
            "name": "out_path",
            "type": "str",
            "description": "The file path where the generated DOT file will be saved."
          }
        ],
        "returns": [],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not explicitly called by any other functions in the provided context."
        }
      },
      "error": null
    },
    "backend.callgraph.build_filtered_callgraph": {
      "identifier": "backend.callgraph.build_filtered_callgraph",
      "description": {
        "overall": "This function constructs a filtered call graph for a given Git repository. It begins by retrieving all files from the repository and processing only Python files. For each Python file, it parses the Abstract Syntax Tree (AST) and uses a CallGraph visitor to identify all locally defined functions, collecting them into a set of 'own_functions'. Subsequently, it iterates through the parsed file trees again to identify call relationships between functions. Finally, it builds a networkx.DiGraph, adding edges only when both the caller and the callee are part of the identified 'own_functions', thereby creating a call graph focused on the repository's internal code.",
        "parameters": [
          {
            "name": "repo",
            "type": "GitRepository",
            "description": "The Git repository object from which to extract and analyze source code files."
          }
        ],
        "returns": [
          {
            "name": "global_graph",
            "type": "nx.DiGraph",
            "description": "A directed graph representing the call relationships between functions, filtered to include only 'self-written' functions within the repository."
          }
        ],
        "usage_context": {
          "calls": "This function calls backend.callgraph.CallGraph.",
          "called_by": "This function is not explicitly called by any other functions in the provided context."
        }
      },
      "error": null
    },
    "backend.converter.wrap_cdata": {
      "identifier": "backend.converter.wrap_cdata",
      "description": {
        "overall": "The `wrap_cdata` function is designed to encapsulate a given string `content` within XML CDATA tags. It constructs a new string by prepending \"<![CDATA[\\n\" and appending \"\\n]]>\" to the provided content. This process ensures that the enclosed content is treated as character data by an XML parser, preventing interpretation of special characters within it. The function directly returns this newly formatted string.",
        "parameters": [
          {
            "name": "content",
            "type": "str",
            "description": "The string content to be wrapped within CDATA tags."
          }
        ],
        "returns": [
          {
            "name": "wrapped_content",
            "type": "str",
            "description": "A new string containing the original content enclosed within CDATA tags."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is called by no other functions."
        }
      },
      "error": null
    },
    "backend.converter.extract_output_content": {
      "identifier": "backend.converter.extract_output_content",
      "description": {
        "overall": "This function processes a list of notebook output objects to extract their content, primarily focusing on text and image data. It iterates through each output, identifying its type as display data, execute result, stream, or error. For image data (PNG or JPEG), it decodes Base64 strings, stores the raw image data in a provided `image_list`, and generates an XML placeholder for the image within the extracted content. Textual content from plain text, streams, or formatted error messages is directly appended. The function ultimately returns a list of strings, which can be text or image placeholders.",
        "parameters": [
          {
            "name": "outputs",
            "type": "list",
            "description": "A list of output objects, typically from a notebook execution, each containing data or text."
          },
          {
            "name": "image_list",
            "type": "list",
            "description": "A list that will be populated with dictionaries containing image metadata and Base64 encoded data."
          }
        ],
        "returns": [
          {
            "name": "extracted_xml_snippets",
            "type": "list[str]",
            "description": "A list of strings, where each string is either plain text extracted from the output or an XML placeholder for an image."
          }
        ],
        "usage_context": {
          "calls": "This function calls backend.converter.process_image.",
          "called_by": "This function is called by no other functions."
        }
      },
      "error": null
    },
    "backend.converter.process_image": {
      "identifier": "backend.converter.process_image",
      "description": {
        "overall": "This function processes an image identified by its MIME type. It expects image data to be available in a dictionary-like structure named `data` and maintains a list of processed images in `image_list`. If the specified MIME type is found in `data`, it extracts the base64 encoded string, removes newline characters, and appends the image's MIME type and data to `image_list`. The function then returns a formatted placeholder string containing the image's index and MIME type. If an error occurs during processing, it returns an error message string; otherwise, it returns None if the MIME type is not found in `data`.",
        "parameters": [
          {
            "name": "mime_type",
            "type": "str",
            "description": "The MIME type of the image to be processed, used as a key to retrieve its base64 encoded data from the `data` context variable."
          }
        ],
        "returns": [
          {
            "name": "image_placeholder_tag",
            "type": "str",
            "description": "A formatted string representing an image placeholder tag, including the image's index and MIME type, if processing is successful."
          },
          {
            "name": "error_message",
            "type": "str",
            "description": "An error message string enclosed in <ERROR> tags if an exception occurs during image decoding."
          },
          {
            "name": "None",
            "type": "NoneType",
            "description": "Returns None if the specified MIME type is not found in the available `data` context variable."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not explicitly called by any other functions in the provided context."
        }
      },
      "error": null
    },
    "backend.converter.convert_notebook_to_xml": {
      "identifier": "backend.converter.convert_notebook_to_xml",
      "description": {
        "overall": "This function converts the raw content of a Jupyter notebook file into an XML representation. It parses the input content as a notebook, then iterates through each cell. Markdown cells are wrapped in '<CELL type=\"markdown\">' tags, while code cells are wrapped in '<CELL type=\"code\">' tags, with their source code CDATA-wrapped. If code cells have outputs, these are processed to extract content and potential images, which are then also wrapped in '<CELL type=\"output\">' tags. The function handles parsing errors by returning an error message.",
        "parameters": [
          {
            "name": "file_content",
            "type": "str",
            "description": "The raw content of a Jupyter notebook file, expected to be in JSON format."
          }
        ],
        "returns": [
          {
            "name": "xml_representation",
            "type": "str",
            "description": "A string containing the XML representation of the notebook cells, joined by double newlines. In case of a parsing error, it returns an error string like '<ERROR>Could not parse file as JSON/Notebook</ERROR>'."
          },
          {
            "name": "extracted_images",
            "type": "list",
            "description": "A list of extracted image data or paths from the notebook outputs. This list will be empty if no images are found or if a parsing error occurs."
          }
        ],
        "usage_context": {
          "calls": "This function calls backend.converter.extract_output_content and backend.converter.wrap_cdata.",
          "called_by": "This function is not explicitly called by any other functions in the provided context."
        }
      },
      "error": null
    },
    "backend.converter.process_repo_notebooks": {
      "identifier": "backend.converter.process_repo_notebooks",
      "description": {
        "overall": "This function processes a collection of repository files to identify and convert Jupyter notebooks. It filters the provided `repo_files` to isolate those with a '.ipynb' extension. For each identified notebook, it logs the processing activity and then invokes `convert_notebook_to_xml` to transform the notebook's content into an XML representation and extract associated images. The function compiles these conversion results into a dictionary, mapping each notebook's path to its generated XML and images, and returns this aggregated data.",
        "parameters": [
          {
            "name": "repo_files",
            "type": "List[object]",
            "description": "A list of file-like objects from a repository. Each object is expected to have a 'path' attribute (string) and a 'content' attribute (string)."
          }
        ],
        "returns": [
          {
            "name": "results",
            "type": "Dict[str, Dict[str, Any]]",
            "description": "A dictionary where keys are the paths of the processed notebook files (strings) and values are dictionaries containing the converted XML output ('xml': str) and any extracted images ('images': List[Any]) for each notebook."
          }
        ],
        "usage_context": {
          "calls": "This function calls backend.converter.convert_notebook_to_xml.",
          "called_by": "This function is not explicitly called by any other functions in the provided context."
        }
      },
      "error": null
    },
    "backend.main.create_savings_chart": {
      "identifier": "backend.main.create_savings_chart",
      "description": {
        "overall": "This function generates a bar chart to visually compare the token counts between JSON and TOON formats. It takes the token counts for both formats, a savings percentage, and an output file path as input. The chart displays two bars, one for JSON tokens and one for TOON tokens, with their respective values shown above each bar. The chart is then saved to the specified output path and closed.",
        "parameters": [
          {
            "name": "json_tokens",
            "type": "int",
            "description": "The number of tokens representing the JSON format."
          },
          {
            "name": "toon_tokens",
            "type": "int",
            "description": "The number of tokens representing the TOON format."
          },
          {
            "name": "savings_percent",
            "type": "float",
            "description": "The calculated percentage of token savings between the two formats."
          },
          {
            "name": "output_path",
            "type": "str",
            "description": "The file path where the generated bar chart image will be saved."
          }
        ],
        "returns": [],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not explicitly called by any other functions in the provided context."
        }
      },
      "error": null
    },
    "backend.main.calculate_net_time": {
      "identifier": "backend.main.calculate_net_time",
      "description": {
        "overall": "This function calculates the effective processing time, excluding artificial sleep durations introduced for rate limiting, specifically for \"gemini-\" models. It first determines the total elapsed time between a start and end time. If the model used is not a \"gemini-\" model or if there are no items to process, it returns the total duration or zero, respectively. Otherwise, it calculates the number of batches, estimates the total sleep time based on a fixed duration per batch, and subtracts this from the total duration to yield the net processing time, ensuring the result is not negative.",
        "parameters": [
          {
            "name": "start_time",
            "type": "float",
            "description": "The starting timestamp or time value for the operation."
          },
          {
            "name": "end_time",
            "type": "float",
            "description": "The ending timestamp or time value for the operation."
          },
          {
            "name": "total_items",
            "type": "int",
            "description": "The total number of items processed during the operation."
          },
          {
            "name": "batch_size",
            "type": "int",
            "description": "The number of items processed in each batch."
          },
          {
            "name": "model_name",
            "type": "str",
            "description": "The name of the model used, which determines if rate-limiting sleep times are considered."
          }
        ],
        "returns": [
          {
            "name": "net_time",
            "type": "float",
            "description": "The calculated net processing time, adjusted for rate-limiting sleep durations, or the total duration if no adjustments are needed. The value is always non-negative."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not explicitly called by any other functions in the provided context."
        }
      },
      "error": null
    },
    "backend.main.main_workflow": {
      "identifier": "backend.main.main_workflow",
      "description": {
        "overall": "This function orchestrates a comprehensive workflow for analyzing a software repository. It begins by extracting API keys and model configurations, then clones a specified GitHub repository. The workflow proceeds to extract basic project information, construct a file tree, perform relationship analysis, and build an Abstract Syntax Tree (AST) schema, which is subsequently enriched with relationship data. Finally, it prepares and dispatches analysis tasks to a Helper LLM for functions and classes, and then to a Main LLM to generate a final report, including token usage metrics. The function handles various exceptions throughout the process, logging errors and raising them where critical.",
        "parameters": [
          {
            "name": "input",
            "type": "str",
            "description": "The user input, which is expected to contain a GitHub repository URL for analysis."
          },
          {
            "name": "api_keys",
            "type": "dict",
            "description": "A dictionary containing various API keys (e.g., for Gemini, GPT, SCADSLLM) and base URLs required for external services."
          },
          {
            "name": "model_names",
            "type": "dict",
            "description": "A dictionary specifying the names of the helper and main language models to be utilized in the analysis workflow."
          },
          {
            "name": "status_callback",
            "type": "callable | None",
            "description": "An optional callback function that receives status messages to provide real-time updates on the workflow's progress."
          }
        ],
        "returns": [
          {
            "name": "report",
            "type": "str",
            "description": "The final generated report from the Main LLM, detailing the repository analysis."
          },
          {
            "name": "metrics",
            "type": "dict",
            "description": "A dictionary containing performance metrics, including the time spent by helper and main LLMs, total active time, model names used, and token savings data."
          }
        ],
        "usage_context": {
          "calls": "This function calls backend.AST_Schema.ASTAnalyzer, backend.AST_Schema.ASTAnalyzer.analyze_repository, backend.AST_Schema.ASTAnalyzer.merge_relationship_data, backend.HelperLLM.LLMHelper, backend.HelperLLM.LLMHelper.generate_for_classes, backend.HelperLLM.LLMHelper.generate_for_functions, backend.MainLLM.MainLLM, backend.MainLLM.MainLLM.call_llm, backend.basic_info.ProjektInfoExtractor, backend.basic_info.ProjektInfoExtractor.extrahiere_info, backend.getRepo.GitRepository, backend.main.calculate_net_time, backend.main.create_savings_chart, backend.main.update_status, backend.relationship_analyzer.ProjectAnalyzer, backend.relationship_analyzer.ProjectAnalyzer.analyze, backend.relationship_analyzer.ProjectAnalyzer.get_raw_relationships, schemas.types.ClassAnalysisInput, schemas.types.ClassContextInput, schemas.types.FunctionAnalysisInput, schemas.types.FunctionContextInput, and schemas.types.MethodContextInput.",
          "called_by": "This function is called by no other functions."
        }
      },
      "error": null
    },
    "backend.main.update_status": {
      "identifier": "backend.main.update_status",
      "description": {
        "overall": "This function, `update_status`, is designed to handle status updates by taking a message as input. It first checks if a `status_callback` function is available and, if so, invokes it with the provided message. Regardless of the callback's presence, the function logs the message using the `logging.info` method. Its primary purpose is to provide a standardized way to disseminate status information, either through a UI callback or a log.",
        "parameters": [
          {
            "name": "msg",
            "type": "str",
            "description": "The message string to be used for the status update and logging."
          }
        ],
        "returns": [],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not explicitly called by any other functions in the provided context."
        }
      },
      "error": null
    },
    "backend.main.notebook_workflow": {
      "identifier": "backend.main.notebook_workflow",
      "description": {
        "overall": "The `notebook_workflow` function orchestrates the analysis of Jupyter notebooks from a specified GitHub repository. It begins by extracting the repository URL from the input, cloning the repository, and then processing its notebooks into an XML format. The function also extracts basic project information from the repository files. It then iterates through each processed notebook, generating a detailed report for each using a configured Language Model (LLM) and a dynamically constructed payload that includes context information, notebook XML structure, and embedded images. Finally, all individual reports are concatenated into a single markdown file, saved to a designated output directory, and the function returns the final report along with execution metrics.",
        "parameters": [
          {
            "name": "input",
            "type": "str",
            "description": "The input string, expected to contain a GitHub repository URL from which notebooks will be processed."
          },
          {
            "name": "api_keys",
            "type": "dict",
            "description": "A dictionary containing API keys for various Language Model services (e.g., 'gpt', 'gemini', 'scadsllm', 'ollama') used for authentication."
          },
          {
            "name": "model",
            "type": "str",
            "description": "The name of the Language Model to be used for generating notebook reports (e.g., 'gpt-4', 'gemini-pro')."
          },
          {
            "name": "status_callback",
            "type": "callable or None",
            "description": "An optional callback function that can be provided to receive status updates during the workflow execution."
          }
        ],
        "returns": [
          {
            "name": "report",
            "type": "str",
            "description": "The concatenated markdown string of all generated notebook analysis reports."
          },
          {
            "name": "metrics",
            "type": "dict",
            "description": "A dictionary containing performance metrics for the workflow, including execution times and model information."
          }
        ],
        "usage_context": {
          "calls": "This function calls backend.MainLLM.MainLLM, backend.MainLLM.MainLLM.call_llm, backend.basic_info.ProjektInfoExtractor, backend.basic_info.ProjektInfoExtractor.extrahiere_info, backend.converter.process_repo_notebooks, backend.getRepo.GitRepository, backend.main.gemini_payload, and backend.main.update_status.",
          "called_by": "This function is not explicitly called by any other functions in the provided context."
        }
      },
      "error": null
    },
    "backend.main.gemini_payload": {
      "identifier": "backend.main.gemini_payload",
      "description": {
        "overall": "This function `gemini_payload` constructs a multimodal payload suitable for a Gemini-like model. It integrates basic contextual information and the notebook's path with the notebook's XML content, which may contain image placeholders. The function parses the XML content, extracting text segments and replacing image placeholders with their corresponding base64 encoded image data from a provided list. The output is a structured list of dictionaries, alternating between text and image content blocks, ready for multimodal model consumption.",
        "parameters": [
          {
            "name": "basic_info",
            "type": "dict",
            "description": "Contains basic information about the project or context, which will be serialized into a JSON string."
          },
          {
            "name": "nb_path",
            "type": "str",
            "description": "The current notebook's file path, which will be included in the context JSON."
          },
          {
            "name": "xml_content",
            "type": "str",
            "description": "The XML representation of the notebook content. This string is parsed to extract text and identify image placeholders."
          },
          {
            "name": "images",
            "type": "list[dict]",
            "description": "A list of image data objects. Each object is expected to contain a 'data' key with a base64 encoded image string, corresponding to image placeholders in `xml_content`."
          }
        ],
        "returns": [
          {
            "name": "payload_content",
            "type": "list[dict]",
            "description": "A list of content blocks, formatted as a multimodal payload. Each dictionary represents either a text segment or an image URL with base64 data, ready for a Gemini-like model."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not explicitly called by any other functions in the provided context."
        }
      },
      "error": null
    },
    "backend.relationship_analyzer.path_to_module": {
      "identifier": "backend.relationship_analyzer.path_to_module",
      "description": {
        "overall": "This function converts a given file path into a Python module path. It first attempts to determine the relative path of the file with respect to a specified project root. If the relative path calculation fails, it defaults to using just the base name of the file. The function then removes the '.py' extension if present, replaces path separators with dots, and finally removes '.__init__' if it appears at the end of the module path.",
        "parameters": [
          {
            "name": "filepath",
            "type": "str",
            "description": "The absolute or relative path to a Python file."
          },
          {
            "name": "project_root",
            "type": "str",
            "description": "The root directory of the project, used to calculate the relative path of the file."
          }
        ],
        "returns": [
          {
            "name": "module_path",
            "type": "str",
            "description": "The converted Python module path string."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not explicitly called by any other functions in the provided context."
        }
      },
      "error": null
    },
    "database.db.encrypt_text": {
      "identifier": "database.db.encrypt_text",
      "description": {
        "overall": "This function encrypts a given text string using a `cipher_suite` object. It first checks if the input text or the `cipher_suite` itself is null or empty; if so, it returns the original text without encryption. Otherwise, it prepares the text by stripping leading/trailing whitespace, encodes it to bytes, encrypts it using the `cipher_suite`, and then decodes the resulting bytes back into a string before returning it.",
        "parameters": [
          {
            "name": "text",
            "type": "str",
            "description": "The string of text to be encrypted."
          }
        ],
        "returns": [
          {
            "name": "encrypted_text",
            "type": "str",
            "description": "The encrypted version of the input text, or the original text if encryption conditions are not met."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not explicitly called by any other functions in the provided context."
        }
      },
      "error": null
    },
    "database.db.decrypt_text": {
      "identifier": "database.db.decrypt_text",
      "description": {
        "overall": "This function attempts to decrypt a given string using a global `cipher_suite` object. It first checks if the input `text` or `cipher_suite` is falsey, returning the original text immediately if either condition is met. If decryption is attempted, the text is stripped, encoded to bytes, decrypted, and then decoded back into a string. In case of any exception during the decryption process, the function gracefully falls back to returning the original, unencrypted text.",
        "parameters": [
          {
            "name": "text",
            "type": "str",
            "description": "The string value that needs to be decrypted."
          }
        ],
        "returns": [
          {
            "name": "decrypted_text",
            "type": "str",
            "description": "The decrypted string if successful, or the original string if decryption is not performed or fails due to an exception."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not explicitly called by any other functions in the provided context."
        }
      },
      "error": null
    },
    "database.db.insert_user": {
      "identifier": "database.db.insert_user",
      "description": {
        "overall": "This function is designed to insert a new user record into a database collection. It accepts a username, the user's full name, and a plain-text password. The provided password is securely hashed using `stauth.Hasher.hash` before storage. A user dictionary is constructed, including default empty strings for various API keys, and then persisted using `dbusers.insert_one`. The function concludes by returning the unique identifier of the newly created user document.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The unique identifier for the user, which also serves as the document's `_id`."
          },
          {
            "name": "name",
            "type": "str",
            "description": "The full name of the user."
          },
          {
            "name": "password",
            "type": "str",
            "description": "The plain-text password for the user, which will be hashed before being stored in the database."
          }
        ],
        "returns": [
          {
            "name": "inserted_id",
            "type": "str",
            "description": "The unique identifier (`_id`) of the newly inserted user document, which corresponds to the provided username."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not explicitly called by any other functions in the provided context."
        }
      },
      "error": null
    },
    "database.db.fetch_all_users": {
      "identifier": "database.db.fetch_all_users",
      "description": {
        "overall": "The `fetch_all_users` function is designed to retrieve all user records from a database collection, presumably named `dbusers`. It executes a `find()` operation on this collection, which typically returns a cursor containing all documents. This cursor is then immediately converted into a Python list, effectively returning all user data as a collection of items.",
        "parameters": [],
        "returns": [
          {
            "name": "users",
            "type": "list",
            "description": "A list containing all user documents retrieved from the `dbusers` collection. Each item in the list represents a user record."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not explicitly called by any other functions in the provided context."
        }
      },
      "error": null
    },
    "database.db.fetch_user": {
      "identifier": "database.db.fetch_user",
      "description": {
        "overall": "This function, `fetch_user`, is designed to retrieve a single user record from a database collection. It queries the `dbusers` collection using the `find_one` method. The lookup is performed based on the provided `username`, which is matched against the `_id` field in the database documents. If a matching user is found, their document is returned; otherwise, `None` is returned.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The unique identifier for the user to be fetched, which is used to query the `_id` field in the database."
          }
        ],
        "returns": [
          {
            "name": "user_document",
            "type": "dict | None",
            "description": "A dictionary representing the user document if a match is found in the `dbusers` collection, otherwise `None`."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not explicitly called by any other functions in the provided context."
        }
      },
      "error": null
    },
    "database.db.update_user_name": {
      "identifier": "database.db.update_user_name",
      "description": {
        "overall": "This function is designed to update a user's name in a database. It takes the existing username, which is used as the document's `_id`, and a new name. The function performs an update operation on the `dbusers` collection, specifically setting the 'name' field for the document matching the provided `_id`. It then returns the count of documents that were modified by this operation.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The current username, which serves as the unique identifier (`_id`) for the user to be updated."
          },
          {
            "name": "new_name",
            "type": "str",
            "description": "The new name to be assigned to the user."
          }
        ],
        "returns": [
          {
            "name": "modified_count",
            "type": "int",
            "description": "The number of documents that were modified by the update operation."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.update_gemini_key": {
      "identifier": "database.db.update_gemini_key",
      "description": {
        "overall": "This function is responsible for updating a user's Gemini API key within a database. It takes the username and the new Gemini API key as input. The provided API key is first stripped of any leading or trailing whitespace and then encrypted using an external utility function. Finally, the function updates the database record associated with the given username, setting the 'gemini_api_key' field to the newly encrypted value. It returns the count of documents that were modified by this operation.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The unique identifier for the user whose Gemini API key is to be updated."
          },
          {
            "name": "gemini_api_key",
            "type": "str",
            "description": "The new Gemini API key to be stored for the specified user. It will be stripped of whitespace and encrypted before storage."
          }
        ],
        "returns": [
          {
            "name": "modified_count",
            "type": "int",
            "description": "The number of documents modified by the update operation, typically 0 or 1."
          }
        ],
        "usage_context": {
          "calls": "This function calls database.db.encrypt_text.",
          "called_by": "This function is called by no other functions."
        }
      },
      "error": null
    },
    "database.db.update_gpt_key": {
      "identifier": "database.db.update_gpt_key",
      "description": {
        "overall": "This function updates a user's GPT API key within the database. It takes a username and the new API key as input. The provided API key is first stripped of any leading or trailing whitespace and then encrypted using the `encrypt_text` utility. Finally, it attempts to locate the user by their username (acting as `_id`) in the `dbusers` collection and sets their `gpt_api_key` field to the newly encrypted value. The function returns the count of documents that were successfully modified by this operation.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The unique identifier for the user whose GPT API key is to be updated."
          },
          {
            "name": "gpt_api_key",
            "type": "str",
            "description": "The new GPT API key to be stored for the user. This key will be stripped of whitespace and encrypted before being saved."
          }
        ],
        "returns": [
          {
            "name": "modified_count",
            "type": "int",
            "description": "The number of documents that were modified in the database by the update operation. This is typically 1 if the user was found and updated, or 0 if the user was not found."
          }
        ],
        "usage_context": {
          "calls": "This function calls database.db.encrypt_text.",
          "called_by": "This function is not explicitly called by any other functions in the provided context."
        }
      },
      "error": null
    },
    "database.db.update_ollama_url": {
      "identifier": "database.db.update_ollama_url",
      "description": {
        "overall": "This function updates the Ollama base URL for a specific user in a database. It takes a username and a new Ollama base URL as input. The function uses `dbusers.update_one` to locate the user by their username (acting as the `_id`) and sets the `ollama_base_url` field to the provided URL after stripping any leading or trailing whitespace. It then returns the count of documents that were modified by this operation.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The unique identifier for the user whose Ollama URL needs to be updated. This is used as the `_id` in the database query."
          },
          {
            "name": "ollama_base_url",
            "type": "str",
            "description": "The new base URL for Ollama to be associated with the user. This value will have leading/trailing whitespace removed before being stored."
          }
        ],
        "returns": [
          {
            "name": "modified_count",
            "type": "int",
            "description": "The number of documents that were modified in the database by the update operation. A value of 1 indicates success if the user existed."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.update_opensrc_key": {
      "identifier": "database.db.update_opensrc_key",
      "description": {
        "overall": "This function is responsible for updating a user's Open Source API key within a database. It accepts a username and the new API key as string inputs. The provided API key is first processed by stripping any leading or trailing whitespace, then encrypted using a dedicated encryption function. Finally, the function attempts to locate a user document by its username and updates the 'opensrc_api_key' field with the newly encrypted key. It returns an integer indicating how many documents were modified.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The unique identifier for the user whose Open Source API key needs to be updated."
          },
          {
            "name": "opensrc_api_key",
            "type": "str",
            "description": "The new Open Source API key to be stored for the specified user. This key will be encrypted before being saved."
          }
        ],
        "returns": [
          {
            "name": "modified_count",
            "type": "int",
            "description": "The number of documents that were modified in the database by the update operation. This is typically 0 if no user was found or 1 if the user's key was successfully updated."
          }
        ],
        "usage_context": {
          "calls": "The function calls database.db.encrypt_text.",
          "called_by": "This function is called by no other functions."
        }
      },
      "error": null
    },
    "database.db.update_opensrc_url": {
      "identifier": "database.db.update_opensrc_url",
      "description": {
        "overall": "This function updates a user's open-source base URL in the database. It takes a username and a new URL as input. The function performs an `update_one` operation on the `dbusers` collection, setting the `opensrc_base_url` field for the document identified by the provided username. The `opensrc_base_url` is stripped of leading and trailing whitespace before being stored. It returns the count of documents that were modified by the update operation.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The unique identifier for the user whose open-source base URL needs to be updated."
          },
          {
            "name": "opensrc_base_url",
            "type": "str",
            "description": "The new open-source base URL to be set for the user. This string will be stripped of whitespace before storage."
          }
        ],
        "returns": [
          {
            "name": "modified_count",
            "type": "int",
            "description": "The number of documents that were modified by the update operation."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not explicitly called by any other functions in the provided context."
        }
      },
      "error": null
    },
    "database.db.fetch_gemini_key": {
      "identifier": "database.db.fetch_gemini_key",
      "description": {
        "overall": "This function retrieves the Gemini API key associated with a specific username from a database. It queries the `dbusers` collection for a user document matching the provided username. The query specifically projects only the `gemini_api_key` field. If a user document is found, the function extracts and returns the `gemini_api_key`; otherwise, it returns `None`.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username for which to fetch the Gemini API key."
          }
        ],
        "returns": [
          {
            "name": "gemini_api_key",
            "type": "str | None",
            "description": "The Gemini API key associated with the username, or None if the user or key is not found."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not explicitly called by any other functions in the provided context."
        }
      },
      "error": null
    },
    "database.db.fetch_ollama_url": {
      "identifier": "database.db.fetch_ollama_url",
      "description": {
        "overall": "This function retrieves the Ollama base URL associated with a specific user from a database. It queries the 'dbusers' collection using the provided username as the document ID. If a user document is found, it extracts and returns the 'ollama_base_url' field. If the user is not found, or the 'ollama_base_url' field is missing, the function returns None.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The unique identifier for the user whose Ollama base URL is to be fetched."
          }
        ],
        "returns": [
          {
            "name": "ollama_base_url",
            "type": "str | None",
            "description": "The Ollama base URL associated with the user, or None if the user is not found or the URL is not set."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not explicitly called by any other functions in the provided context."
        }
      },
      "error": null
    },
    "database.db.fetch_gpt_key": {
      "identifier": "database.db.fetch_gpt_key",
      "description": {
        "overall": "This function is designed to retrieve a user's GPT API key from a database. It performs a lookup in the 'dbusers' collection, searching for a document that matches the provided username. The function specifically projects the 'gpt_api_key' field. If a matching user is found, it extracts and returns their GPT API key; otherwise, it returns None.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The unique identifier for the user whose GPT API key is to be fetched."
          }
        ],
        "returns": [
          {
            "name": "gpt_api_key",
            "type": "str | None",
            "description": "The GPT API key associated with the specified username, or None if the user is not found or the key does not exist."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not explicitly called by any other functions in the provided context."
        }
      },
      "error": null
    },
    "database.db.fetch_opensrc_key": {
      "identifier": "database.db.fetch_opensrc_key",
      "description": {
        "overall": "This function is designed to retrieve the 'opensrc_api_key' for a specific user from a database. It queries the 'dbusers' collection using the provided username as the identifier. The query specifically projects only the 'opensrc_api_key' field. If a user document is found, the function returns the associated API key; otherwise, it returns None, indicating that no key was found for the given username.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The unique identifier for the user whose Open Source API key is to be fetched."
          }
        ],
        "returns": [
          {
            "name": "opensrc_api_key",
            "type": "str | None",
            "description": "The Open Source API key associated with the username, or None if the user is not found or the key does not exist."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.fetch_opensrc_url": {
      "identifier": "database.db.fetch_opensrc_url",
      "description": {
        "overall": "This function, `fetch_opensrc_url`, is designed to retrieve a specific URL associated with a user from a database. It takes a username as input and queries a collection named `dbusers` to find a matching user document. The function specifically extracts the `opensrc_base_url` field from the found document. If a user document corresponding to the provided username is located, the function returns the value of this URL; otherwise, it returns `None`.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The unique identifier for the user whose opensrc base URL is to be fetched."
          }
        ],
        "returns": [
          {
            "name": "opensrc_base_url",
            "type": "str | None",
            "description": "The opensrc base URL associated with the user, or None if the user is not found in the database."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not explicitly called by any other functions in the provided context."
        }
      },
      "error": null
    },
    "database.db.delete_user": {
      "identifier": "database.db.delete_user",
      "description": {
        "overall": "This function is responsible for deleting a user record from a database collection. It accepts a username as an argument, which serves as the unique identifier for the user document to be removed. The function performs a delete operation using the provided username and returns an integer indicating the number of documents that were successfully deleted.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The unique identifier (username) of the user to be deleted from the database."
          }
        ],
        "returns": [
          {
            "name": "deleted_count",
            "type": "int",
            "description": "The number of documents deleted by the operation. This is typically 1 if a user matching the username was found and deleted, or 0 if no user matched."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.get_decrypted_api_keys": {
      "identifier": "database.db.get_decrypted_api_keys",
      "description": {
        "overall": "This function retrieves a user's API keys and base URLs from a database, decrypting sensitive keys before returning them. It first attempts to find a user by their username. If the user is not found, it returns None for all values. Otherwise, it decrypts the Gemini, GPT, and Open Source API keys and retrieves the Ollama and Open Source base URLs.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The unique identifier for the user whose API keys and URLs are to be retrieved."
          }
        ],
        "returns": [
          {
            "name": "gemini_plain",
            "type": "str | None",
            "description": "The decrypted Gemini API key, or None if the user is not found."
          },
          {
            "name": "ollama_plain",
            "type": "str | None",
            "description": "The Ollama base URL, or None if the user is not found."
          },
          {
            "name": "gpt_plain",
            "type": "str | None",
            "description": "The decrypted GPT API key, or None if the user is not found."
          },
          {
            "name": "opensrc_plain",
            "type": "str | None",
            "description": "The decrypted Open Source API key, or None if the user is not found."
          },
          {
            "name": "opensrc_url",
            "type": "str | None",
            "description": "The Open Source base URL, or None if the user is not found."
          }
        ],
        "usage_context": {
          "calls": "This function calls database.db.decrypt_text.",
          "called_by": "This function is called by no other functions."
        }
      },
      "error": null
    },
    "database.db.insert_chat": {
      "identifier": "database.db.insert_chat",
      "description": {
        "overall": "This function creates a new chat entry in a database. It constructs a dictionary containing a unique ID generated using UUID, the provided username and chat name, and a timestamp for creation. This chat dictionary is then inserted into the 'dbchats' collection, and the unique identifier of the newly inserted document is returned.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username associated with the chat entry."
          },
          {
            "name": "chat_name",
            "type": "str",
            "description": "The name of the chat entry."
          }
        ],
        "returns": [
          {
            "name": "inserted_id",
            "type": "str",
            "description": "The unique identifier of the newly created chat entry in the database."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not explicitly called by any other functions in the provided context."
        }
      },
      "error": null
    },
    "database.db.fetch_chats_by_user": {
      "identifier": "database.db.fetch_chats_by_user",
      "description": {
        "overall": "This function, `fetch_chats_by_user`, is designed to retrieve all chat records associated with a given username from a database. It queries a collection named `dbchats` for documents where the 'username' field matches the input. The retrieved chat records are then sorted in ascending order based on their 'created_at' timestamp. Finally, the function returns these sorted chat records as a list.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username for which to fetch the associated chat records."
          }
        ],
        "returns": [
          {
            "name": "chats",
            "type": "list",
            "description": "A list of chat records (documents) belonging to the specified user, sorted by their creation timestamp."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not explicitly called by any other functions in the provided context."
        }
      },
      "error": null
    },
    "database.db.check_chat_exists": {
      "identifier": "database.db.check_chat_exists",
      "description": {
        "overall": "The `check_chat_exists` function verifies the presence of a specific chat within the `dbchats` collection. It takes a username and a chat name as input parameters. The function performs a database query to find a document that matches both the provided username and chat name. It returns a boolean value indicating whether such a chat document was found or not.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username associated with the chat to be checked."
          },
          {
            "name": "chat_name",
            "type": "str",
            "description": "The name of the chat to check for existence."
          }
        ],
        "returns": [
          {
            "name": "exists",
            "type": "bool",
            "description": "Returns `True` if a chat matching the given username and chat name exists in the `dbchats` collection, `False` otherwise."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not explicitly called by any other functions in the provided context."
        }
      },
      "error": null
    },
    "database.db.rename_chat_fully": {
      "identifier": "database.db.rename_chat_fully",
      "description": {
        "overall": "This function renames a chat and all its associated exchanges within the database. It first updates a single chat entry in the 'dbchats' collection, changing the 'chat_name' from 'old_name' to 'new_name' for a specified 'username'. Subsequently, it updates all related exchange entries in the 'dbexchanges' collection to reflect the new chat name. The function returns the count of modified chat entries from the initial chat renaming operation.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username associated with the chat to be renamed."
          },
          {
            "name": "old_name",
            "type": "str",
            "description": "The current name of the chat."
          },
          {
            "name": "new_name",
            "type": "str",
            "description": "The desired new name for the chat."
          }
        ],
        "returns": [
          {
            "name": "modified_count",
            "type": "int",
            "description": "The number of chat documents that were modified by the update_one operation."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not explicitly called by any other functions in the provided context."
        }
      },
      "error": null
    },
    "database.db.insert_exchange": {
      "identifier": "database.db.insert_exchange",
      "description": {
        "overall": "This function records a user exchange into a database. It generates a unique identifier using `uuid.uuid4()` for each exchange and compiles various details such as the question, answer, feedback, user information, chat name, and optional performance metrics into a dictionary. It also adds a `created_at` timestamp using `datetime.now()`. The function then attempts to insert this constructed record into the `dbexchanges` collection. If the insertion is successful, it returns the new exchange's ID; otherwise, it catches any exceptions and returns `None`.",
        "parameters": [
          {
            "name": "question",
            "type": "str",
            "description": "The user's question in the exchange."
          },
          {
            "name": "answer",
            "type": "str",
            "description": "The generated answer for the question."
          },
          {
            "name": "feedback",
            "type": "str",
            "description": "The user's feedback on the exchange."
          },
          {
            "name": "username",
            "type": "str",
            "description": "The username associated with the exchange."
          },
          {
            "name": "chat_name",
            "type": "str",
            "description": "The name of the chat session."
          },
          {
            "name": "helper_used",
            "type": "str",
            "description": "Optional. Indicates which helper model was used. Defaults to an empty string."
          },
          {
            "name": "main_used",
            "type": "str",
            "description": "Optional. Indicates which main model was used. Defaults to an empty string."
          },
          {
            "name": "total_time",
            "type": "str",
            "description": "Optional. The total time taken for the exchange. Defaults to an empty string."
          },
          {
            "name": "helper_time",
            "type": "str",
            "description": "Optional. The time taken by the helper model. Defaults to an empty string."
          },
          {
            "name": "main_time",
            "type": "str",
            "description": "Optional. The time taken by the main model. Defaults to an empty string."
          },
          {
            "name": "json_tokens",
            "type": "int",
            "description": "Optional. The number of JSON tokens used. Defaults to 0."
          },
          {
            "name": "toon_tokens",
            "type": "int",
            "description": "Optional. The number of 'toon' tokens used. Defaults to 0."
          },
          {
            "name": "savings_percent",
            "type": "float",
            "description": "Optional. The percentage of savings achieved. Defaults to 0.0."
          }
        ],
        "returns": [
          {
            "name": "new_id",
            "type": "str",
            "description": "The unique identifier of the newly inserted exchange record."
          },
          {
            "name": "None",
            "type": "None",
            "description": "Returned if an error occurs during the database insertion process."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not explicitly called by any other functions in the provided context."
        }
      },
      "error": null
    },
    "database.db.fetch_exchanges_by_user": {
      "identifier": "database.db.fetch_exchanges_by_user",
      "description": {
        "overall": "This function, `fetch_exchanges_by_user`, is designed to retrieve exchange records from a database collection, likely `dbexchanges`. It queries for all records where the 'username' field matches the provided input username. The results are then sorted in ascending order based on their 'created_at' timestamp, which is noted as important for display. Finally, the function returns these sorted exchange records as a list.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username for which to fetch exchange records."
          }
        ],
        "returns": [
          {
            "name": "exchanges",
            "type": "list",
            "description": "A list of exchange records associated with the specified username, sorted by their creation timestamp."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not explicitly called by any other functions in the provided context."
        }
      },
      "error": null
    },
    "database.db.fetch_exchanges_by_chat": {
      "identifier": "database.db.fetch_exchanges_by_chat",
      "description": {
        "overall": "This function retrieves a list of exchange documents from the 'dbexchanges' collection. It filters these exchanges based on a provided username and chat name. The results are then sorted by their 'created_at' timestamp in ascending order before being returned as a list.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username to filter exchanges by."
          },
          {
            "name": "chat_name",
            "type": "str",
            "description": "The name of the chat to filter exchanges by."
          }
        ],
        "returns": [
          {
            "name": "exchanges",
            "type": "list",
            "description": "A list of exchange documents matching the specified username and chat name, sorted by creation time."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not explicitly called by any other functions in the provided context."
        }
      },
      "error": null
    },
    "database.db.update_exchange_feedback": {
      "identifier": "database.db.update_exchange_feedback",
      "description": {
        "overall": "This function updates the feedback value for a specific exchange record in a database. It accepts an exchange identifier and an integer feedback value. The function executes an update operation on the `dbexchanges` collection, targeting the document that matches the provided `exchange_id` and setting its 'feedback' field. It then returns the total count of documents that were successfully modified by this operation.",
        "parameters": [
          {
            "name": "exchange_id",
            "type": "Any",
            "description": "The unique identifier for the exchange record that needs its feedback updated."
          },
          {
            "name": "feedback",
            "type": "int",
            "description": "The integer value representing the feedback to be assigned to the exchange record."
          }
        ],
        "returns": [
          {
            "name": "modified_count",
            "type": "int",
            "description": "The number of documents that were modified by the update operation."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is called by no other functions."
        }
      },
      "error": null
    },
    "database.db.update_exchange_feedback_message": {
      "identifier": "database.db.update_exchange_feedback_message",
      "description": {
        "overall": "This function updates a specific exchange record in the database. It takes an exchange ID and a new feedback message. It sets the 'feedback_message' field for the document matching the provided exchange ID. The function then returns the number of documents that were modified by the update operation.",
        "parameters": [
          {
            "name": "exchange_id",
            "type": "Any",
            "description": "The unique identifier for the exchange record to be updated. This is used to locate the specific document in the database."
          },
          {
            "name": "feedback_message",
            "type": "str",
            "description": "The new feedback message string to be set for the specified exchange record."
          }
        ],
        "returns": [
          {
            "name": "modified_count",
            "type": "int",
            "description": "The count of documents that were successfully modified by the update operation."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not explicitly called by any other functions in the provided context."
        }
      },
      "error": null
    },
    "database.db.delete_exchange_by_id": {
      "identifier": "database.db.delete_exchange_by_id",
      "description": {
        "overall": "This function is responsible for deleting a specific exchange record from the database. It takes an exchange ID as input and uses it to locate and remove the corresponding document. The function leverages a database client's `delete_one` method to perform the deletion operation. It then reports the number of documents that were successfully deleted.",
        "parameters": [
          {
            "name": "exchange_id",
            "type": "str",
            "description": "The unique identifier of the exchange record to be deleted from the database."
          }
        ],
        "returns": [
          {
            "name": "deleted_count",
            "type": "int",
            "description": "The number of documents deleted from the database. This will typically be 0 or 1."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.delete_full_chat": {
      "identifier": "database.db.delete_full_chat",
      "description": {
        "overall": "This function is designed to completely delete a specific chat and all its associated message exchanges for a given user. It first removes all messages (exchanges) linked to the chat by querying with the username and chat name. Subsequently, it deletes the chat entry itself from the chat collection. This two-step process ensures data consistency by removing all related data. The function returns the count of chat documents that were successfully deleted.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username associated with the chat to be deleted."
          },
          {
            "name": "chat_name",
            "type": "str",
            "description": "The name of the chat to be deleted."
          }
        ],
        "returns": [
          {
            "name": "deleted_count",
            "type": "int",
            "description": "The number of chat documents successfully deleted (typically 1 if the chat existed, 0 otherwise)."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not explicitly called by any other functions in the provided context."
        }
      },
      "error": null
    },
    "frontend.frontend.clean_names": {
      "identifier": "frontend.frontend.clean_names",
      "description": {
        "overall": "This function processes a list of model names, which are assumed to be path-like strings. For each string in the input list, it splits the string by the '/' character and returns only the last component. This effectively extracts the base name from a potentially qualified or path-based model identifier, providing a cleaned list of names.",
        "parameters": [
          {
            "name": "model_list",
            "type": "list",
            "description": "A list of strings, where each string represents a model name, potentially including path separators."
          }
        ],
        "returns": [
          {
            "name": "cleaned_model_names",
            "type": "list[str]",
            "description": "A new list containing the base names of the models, extracted by taking the last component after splitting by '/'."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not explicitly called by any other functions in the provided context."
        }
      },
      "error": null
    },
    "frontend.frontend.get_filtered_models": {
      "identifier": "frontend.frontend.get_filtered_models",
      "description": {
        "overall": "This function filters a given list of models based on a specified category name. It retrieves associated keywords for the category from a global `CATEGORY_KEYWORDS` mapping. If the 'STANDARD' keyword is present for the category, it returns only those models that are also found in a `STANDARD_MODELS` list. Otherwise, it iterates through the `source_list` and includes models whose names contain any of the category's keywords. If no models match the keywords, the original `source_list` is returned.",
        "parameters": [
          {
            "name": "source_list",
            "type": "list",
            "description": "The initial list of models to be filtered."
          },
          {
            "name": "category_name",
            "type": "str",
            "description": "The name of the category used to determine filtering criteria."
          }
        ],
        "returns": [
          {
            "name": "filtered_models",
            "type": "list",
            "description": "A new list containing models that match the filtering criteria, or the original source_list if no matches are found or if the 'STANDARD' category logic is applied."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not explicitly called by any other functions in the provided context."
        }
      },
      "error": null
    },
    "frontend.frontend.save_gemini_cb": {
      "identifier": "frontend.frontend.save_gemini_cb",
      "description": {
        "overall": "This function serves as a callback to securely save a user's Gemini API key. It first attempts to retrieve a new Gemini key from the Streamlit session state. If a valid new key is found, it proceeds to update this key in the database, associating it with the currently logged-in user's username. Following a successful update, the function clears the temporary key from the session state and displays a confirmation toast message to the user.",
        "parameters": [],
        "returns": [],
        "usage_context": {
          "calls": "This function calls database.db.update_gemini_key.",
          "called_by": "This function is called by no other functions."
        }
      },
      "error": null
    },
    "frontend.frontend.save_ollama_cb": {
      "identifier": "frontend.frontend.save_ollama_cb",
      "description": {
        "overall": "This function serves as a callback to save a user-provided Ollama URL. It retrieves the potential new URL from the Streamlit session state. If a valid URL is found, it proceeds to update the Ollama URL in the database for the current user, whose username is also obtained from the session state. Upon successful update, a confirmation toast message is displayed to the user.",
        "parameters": [],
        "returns": [],
        "usage_context": {
          "calls": "This function calls database.db.update_ollama_url.",
          "called_by": "This function is not explicitly called by any other functions in the provided context."
        }
      },
      "error": null
    },
    "frontend.frontend.load_data_from_db": {
      "identifier": "frontend.frontend.load_data_from_db",
      "description": {
        "overall": "This function is responsible for loading chat and exchange data for a specified user from the database and populating the Streamlit session state. It first checks if the data for the given user is already loaded to prevent redundant operations. The function fetches defined chats, then retrieves individual exchanges, associating them with their respective chats, and handles cases where chats might not explicitly exist for exchanges (legacy support). It also ensures that missing feedback values are set to `np.nan`. Finally, it creates a default chat if none exist and sets an active chat in the session state.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username for whom to load chats and exchanges."
          }
        ],
        "returns": [],
        "usage_context": {
          "calls": "This function calls database.db.fetch_chats_by_user, database.db.fetch_exchanges_by_user, and database.db.insert_chat.",
          "called_by": "This function is not explicitly called by any other functions in the provided context."
        }
      },
      "error": null
    },
    "frontend.frontend.handle_feedback_change": {
      "identifier": "frontend.frontend.handle_feedback_change",
      "description": {
        "overall": "This function processes a change in feedback for an exchange object. It first updates the local `ex` object's \"feedback\" key with the new `val`. Subsequently, it persists this feedback change to a database by calling `db.update_exchange_feedback`, using the exchange's `_id` and the new feedback value. Finally, it triggers a re-run of the Streamlit application, likely to reflect the updated feedback in the user interface.",
        "parameters": [
          {
            "name": "ex",
            "type": "dict",
            "description": "An exchange object, expected to be a dictionary-like structure containing keys such as 'feedback' and '_id'."
          },
          {
            "name": "val",
            "type": "unknown",
            "description": "The new feedback value to be assigned to the exchange object and persisted in the database."
          }
        ],
        "returns": [],
        "usage_context": {
          "calls": "This function calls `database.db.update_exchange_feedback`.",
          "called_by": "This function is called by no other functions."
        }
      },
      "error": null
    },
    "frontend.frontend.handle_delete_exchange": {
      "identifier": "frontend.frontend.handle_delete_exchange",
      "description": {
        "overall": "This function handles the deletion of a specific exchange. It first removes the exchange from the database using its unique identifier. Subsequently, it checks if the associated chat exists in the Streamlit session state. If the chat and the specific exchange are found within the session state, the exchange is removed from the chat's list of exchanges. Finally, it triggers a Streamlit rerun to update the UI.",
        "parameters": [
          {
            "name": "chat_name",
            "type": "str",
            "description": "The name or identifier of the chat associated with the exchange, used to locate and update the session state."
          },
          {
            "name": "ex",
            "type": "dict",
            "description": "The exchange object to be deleted. It is expected to be a dictionary containing an '_id' key for database deletion and to be an item within a list of exchanges in the session state."
          }
        ],
        "returns": [],
        "usage_context": {
          "calls": "This function calls database.db.delete_exchange_by_id.",
          "called_by": "This function is not explicitly called by any other functions in the provided context."
        }
      },
      "error": null
    },
    "frontend.frontend.handle_delete_chat": {
      "identifier": "frontend.frontend.handle_delete_chat",
      "description": {
        "overall": "This function handles the deletion of a specified chat for a given user. It first removes the chat from the database using `db.delete_full_chat`. Subsequently, it cleans up the Streamlit session state by removing the chat from `st.session_state.chats`. If other chats exist, the first remaining chat becomes the active chat. If no chats are left, a new default chat named 'Chat 1' is created, inserted into the database, and set as the active chat. Finally, it triggers a Streamlit rerun.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username associated with the chat to be deleted."
          },
          {
            "name": "chat_name",
            "type": "str",
            "description": "The name of the chat to be deleted."
          }
        ],
        "returns": [],
        "usage_context": {
          "calls": "This function calls database.db.delete_full_chat and database.db.insert_chat.",
          "called_by": "This function is not explicitly called by any other functions in the provided context."
        }
      },
      "error": null
    },
    "frontend.frontend.extract_repo_name": {
      "identifier": "frontend.frontend.extract_repo_name",
      "description": {
        "overall": "This function extracts a repository name from a given text string. It first attempts to find a URL within the text using a regular expression. If a URL is identified, it parses the URL to extract its path component. The last segment of the path is then considered the repository name, with a \".git\" suffix removed if present. The function returns the extracted repository name or None if no valid repository name can be determined.",
        "parameters": [
          {
            "name": "text",
            "type": "str",
            "description": "The input string from which to attempt to extract a repository name."
          }
        ],
        "returns": [
          {
            "name": "repo_name",
            "type": "str | None",
            "description": "The extracted repository name as a string, or None if no URL is found or no repository name can be parsed."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not explicitly called by any other functions in the provided context."
        }
      },
      "error": null
    },
    "frontend.frontend.stream_text_generator": {
      "identifier": "frontend.frontend.stream_text_generator",
      "description": {
        "overall": "This function acts as a generator that processes an input string, splitting it into individual words. It then yields each word, followed by a space, one at a time. A small delay of 0.01 seconds is introduced after yielding each word, simulating a streaming or typing effect. This is typically used for displaying text incrementally.",
        "parameters": [
          {
            "name": "text",
            "type": "str",
            "description": "The input string that needs to be streamed word by word."
          }
        ],
        "returns": [
          {
            "name": "word",
            "type": "str",
            "description": "A generator that yields individual words from the input text, each followed by a space, with a slight delay."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not explicitly called by any other functions in the provided context."
        }
      },
      "error": null
    },
    "frontend.frontend.render_text_with_mermaid": {
      "identifier": "frontend.frontend.render_text_with_mermaid",
      "description": {
        "overall": "This function processes a given markdown text, identifying and rendering both standard markdown content and embedded Mermaid diagrams. It splits the input text based on ````mermaid ... ```` blocks. Standard markdown sections are rendered using `st.markdown`, with an option to stream the text via `st.write_stream`. Mermaid diagram code blocks are rendered using `st_mermaid`, with a fallback to `st.code` if the Mermaid rendering fails. The function handles cases where the input markdown text is empty.",
        "parameters": [
          {
            "name": "markdown_text",
            "type": "str",
            "description": "The input text string which may contain standard markdown and embedded Mermaid diagrams."
          },
          {
            "name": "should_stream",
            "type": "bool",
            "description": "A boolean flag indicating whether non-Mermaid text parts should be streamed using `st.write_stream`. Defaults to `False`."
          }
        ],
        "returns": [],
        "usage_context": {
          "calls": "This function calls frontend.frontend.stream_text_generator.",
          "called_by": "This function is not explicitly called by any other functions in the provided context."
        }
      },
      "error": null
    },
    "frontend.frontend.render_exchange": {
      "identifier": "frontend.frontend.render_exchange",
      "description": {
        "overall": "This function is responsible for rendering a single chat exchange, consisting of a user's question and an assistant's answer, within a Streamlit application. It first displays the user's question, then presents the assistant's response. The assistant's message includes an interactive toolbar with feedback buttons (like/dislike), a popover for adding comments, a download button for the answer, and a delete option. It also handles error states in the assistant's answer by displaying an error message and a delete button. Finally, the function renders the answer content, potentially including Mermaid diagrams.",
        "parameters": [
          {
            "name": "ex",
            "type": "dict",
            "description": "A dictionary representing a single chat exchange, containing keys such as 'question', 'answer', 'feedback', 'feedback_message', and '_id'."
          },
          {
            "name": "current_chat_name",
            "type": "str",
            "description": "The name of the current chat, used when handling the deletion of an exchange."
          }
        ],
        "returns": [],
        "usage_context": {
          "calls": "This function calls database.db.update_exchange_feedback_message, frontend.frontend.handle_delete_exchange, frontend.frontend.handle_feedback_change, and frontend.frontend.render_text_with_mermaid.",
          "called_by": "This function calls no other functions."
        }
      },
      "error": null
    }
  },
  "classes": {
    "backend.AST_Schema.ASTVisitor": {
      "identifier": "backend.AST_Schema.ASTVisitor",
      "description": {
        "overall": "The ASTVisitor class extends ast.NodeVisitor to traverse an Abstract Syntax Tree (AST) of Python source code. Its primary purpose is to extract structured information about imports, class definitions, and function/method definitions within a given Python file. It builds a schema dictionary that categorizes these elements, distinguishing between standalone functions and methods nested within classes, and capturing details like identifiers, docstrings, and source code segments.",
        "init_method": {
          "description": "The constructor initializes the ASTVisitor with the source code, file path, and project root. It calculates the module path, sets up an empty schema dictionary to store parsed imports, functions, and classes, and initializes a _current_class attribute to track the class being visited.",
          "parameters": [
            {
              "name": "source_code",
              "type": "str",
              "description": "The raw source code of the file being visited."
            },
            {
              "name": "file_path",
              "type": "str",
              "description": "The absolute path to the file being visited."
            },
            {
              "name": "project_root",
              "type": "str",
              "description": "The root directory of the project."
            }
          ]
        },
        "methods": [
          {
            "identifier": "backend.AST_Schema.ASTVisitor.visit_Import",
            "description": {
              "overall": "This method is part of the ast.NodeVisitor pattern and is called when an ast.Import node is encountered. It iterates through the imported names (aliases) and appends each import statement's name to the imports list within the self.schema dictionary. After processing, it calls self.generic_visit(node) to continue traversing the AST.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.Import",
                  "description": "The AST node representing an import statement."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls self.generic_visit(node) to continue the AST traversal.",
                "called_by": "This method is implicitly called by the ast.NodeVisitor framework when an ast.Import node is encountered during AST traversal."
              }
            },
            "error": null
          },
          {
            "identifier": "backend.AST_Schema.ASTVisitor.visit_ImportFrom",
            "description": {
              "overall": "This method is invoked by the ast.NodeVisitor when an ast.ImportFrom node is found. It processes 'from ... import ...' statements by iterating through the imported names (aliases) and appending a formatted string (e.g., 'module.name') to the imports list in self.schema. It then calls self.generic_visit(node) to ensure further traversal of the node's children.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.ImportFrom",
                  "description": "The AST node representing a 'from ... import ...' statement."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls self.generic_visit(node) to continue the AST traversal.",
                "called_by": "This method is implicitly called by the ast.NodeVisitor framework when an ast.ImportFrom node is encountered during AST traversal."
              }
            },
            "error": null
          },
          {
            "identifier": "backend.AST_Schema.ASTVisitor.visit_ClassDef",
            "description": {
              "overall": "This method handles ast.ClassDef nodes, which represent class definitions. It constructs a dictionary containing detailed information about the class, including its identifier, name, docstring, source code segment, and line numbers. This class information is then appended to the classes list within self.schema. It also sets self._current_class to the newly created class info before calling generic_visit to process nested elements, and then resets _current_class to None.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.ClassDef",
                  "description": "The AST node representing a class definition."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls ast.get_docstring to extract the class docstring, ast.get_source_segment to get the class's source code, and self.generic_visit(node) to continue the AST traversal.",
                "called_by": "This method is implicitly called by the ast.NodeVisitor framework when an ast.ClassDef node is encountered during AST traversal."
              }
            },
            "error": null
          },
          {
            "identifier": "backend.AST_Schema.ASTVisitor.visit_FunctionDef",
            "description": {
              "overall": "This method processes ast.FunctionDef nodes, which represent function or method definitions. It checks if a class is currently being visited (self._current_class). If so, it treats the node as a method, creating a method_context_info dictionary and appending it to the method_context list of the current class. Otherwise, it treats it as a standalone function, creating a func_info dictionary and appending it to the functions list in self.schema. Finally, it calls self.generic_visit(node) to traverse nested nodes.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.FunctionDef",
                  "description": "The AST node representing a function or method definition."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls ast.get_docstring to extract the function/method docstring and ast.get_source_segment to get the function's source code (only for standalone functions), and self.generic_visit(node) to continue the AST traversal.",
                "called_by": "This method is implicitly called by the ast.NodeVisitor framework when an ast.FunctionDef node is encountered during AST traversal, and explicitly called by visit_AsyncFunctionDef."
              }
            },
            "error": null
          },
          {
            "identifier": "backend.AST_Schema.ASTVisitor.visit_AsyncFunctionDef",
            "description": {
              "overall": "This method is designed to handle ast.AsyncFunctionDef nodes, which represent asynchronous function definitions. Its implementation simply delegates to the visit_FunctionDef method, treating asynchronous functions in the same manner as regular functions for the purpose of schema extraction. This indicates a unified processing logic for both synchronous and asynchronous function definitions.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.AsyncFunctionDef",
                  "description": "The AST node representing an asynchronous function definition."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls self.visit_FunctionDef(node) to process the async function.",
                "called_by": "This method is implicitly called by the ast.NodeVisitor framework when an ast.AsyncFunctionDef node is encountered during AST traversal."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "The class depends on backend.AST_Schema.path_to_module for resolving module paths.",
          "instantiated_by": "The class is not explicitly shown to be instantiated by any other component in the provided context."
        }
      },
      "error": null
    },
    "backend.AST_Schema.ASTAnalyzer": {
      "identifier": "backend.AST_Schema.ASTAnalyzer",
      "description": {
        "overall": "The ASTAnalyzer class is designed to process source code from a Git repository, build a structured Abstract Syntax Tree (AST) schema, and integrate relationship data (like function calls and class instantiations) into this schema. It provides functionalities to parse Python files, extract their AST nodes using an ASTVisitor, and enrich the resulting schema with inter-component dependencies and call graphs. This class serves as a core component for static code analysis, providing a detailed, interconnected view of a codebase's structure and interactions.",
        "init_method": {
          "description": "The constructor initializes an instance of the ASTAnalyzer class. It does not take any specific parameters beyond 'self' and performs no initial setup or attribute assignments, effectively creating a blank analyzer instance.",
          "parameters": []
        },
        "methods": [
          {
            "identifier": "merge_relationship_data",
            "description": {
              "overall": "This method integrates raw relationship data, specifically incoming and outgoing calls, into a comprehensive schema of AST nodes. It iterates through files, functions, and classes within the full_schema. For each function, it populates its calls and called_by context. For each class, it populates its instantiated_by context and then iterates through its methods to set their calls and called_by information. Additionally, it identifies and lists external dependencies for each class based on method calls, ensuring a complete graph of interactions.",
              "parameters": [
                {
                  "name": "full_schema",
                  "type": "dict",
                  "description": "A dictionary representing the complete AST schema of a repository, including files, functions, and classes."
                },
                {
                  "name": "raw_relationships",
                  "type": "dict",
                  "description": "A dictionary containing raw incoming and outgoing call relationships, typically structured with 'outgoing' and 'incoming' keys."
                }
              ],
              "returns": [
                {
                  "name": "full_schema",
                  "type": "dict",
                  "description": "The updated full_schema dictionary with integrated relationship data for functions, classes, and methods."
                }
              ],
              "usage_context": {
                "calls": "This method does not explicitly call other methods or functions directly, it primarily processes dictionary data.",
                "called_by": "This method is not called by any other functions or methods in the provided context."
              }
            },
            "error": null
          },
          {
            "identifier": "analyze_repository",
            "description": {
              "overall": "This method processes a list of file objects from a Git repository to build a full AST schema. It first determines the project root from the file paths. It then iterates through each Python file, reads its content, parses it using the ast module, and uses an ASTVisitor to extract AST nodes and build a file-specific schema. If parsing is successful and the file contains imports, functions, or classes, its schema is added to the full_schema. Errors during parsing are caught and logged as warnings.",
              "parameters": [
                {
                  "name": "files",
                  "type": "list",
                  "description": "A list of file objects, each expected to have 'path' and 'content' attributes representing source code files."
                },
                {
                  "name": "repo",
                  "type": "GitRepository",
                  "description": "An object representing the Git repository, though it's not directly used in the provided method body beyond being passed as an argument."
                }
              ],
              "returns": [
                {
                  "name": "full_schema",
                  "type": "dict",
                  "description": "A dictionary representing the complete AST schema of the analyzed repository, organized by file paths."
                }
              ],
              "usage_context": {
                "calls": "This method calls os.path.commonpath, os.path.isfile, os.path.dirname, ast.parse, and instantiates ASTVisitor.",
                "called_by": "This method is not called by any other functions or methods in the provided context."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "This class depends on the ast module for parsing, the os module for path manipulation, and backend.AST_Schema.ASTVisitor for detailed AST node extraction.",
          "instantiated_by": "This class is not instantiated by any other components in the provided context."
        }
      },
      "error": null
    },
    "backend.File_Dependency.FileDependencyGraph": {
      "identifier": "backend.File_Dependency.FileDependencyGraph",
      "description": {
        "overall": "The FileDependencyGraph class is an AST NodeVisitor designed to analyze Python source code files and construct a detailed graph of their import dependencies. It systematically traverses the Abstract Syntax Tree of a given file, identifying and processing all import and from ... import ... statements. The class is capable of resolving both absolute and intricate relative import paths, storing the discovered file-to-file import relationships within its import_dependencies attribute for subsequent analysis.",
        "init_method": {
          "description": "This constructor initializes a FileDependencyGraph instance by setting the filename and repo_root attributes. These attributes are crucial for identifying the current file being analyzed and for resolving relative import paths within the repository. The class also maintains a import_dependencies dictionary to store the discovered file-to-file import relationships.",
          "parameters": [
            {
              "name": "filename",
              "type": "str",
              "description": "The path to the file for which dependencies are being analyzed."
            },
            {
              "name": "repo_root",
              "type": "str",
              "description": "The root directory of the repository."
            }
          ]
        },
        "methods": [
          {
            "identifier": "_resolve_module_name",
            "description": {
              "overall": "This private method handles the complex logic of resolving relative import statements, such as from ..module import name. It determines the correct base directory by navigating up the file system hierarchy based on the import level. The method then verifies if the imported names correspond to existing Python files or symbols exported via __init__.py files, returning a list of successfully resolved module names. If no modules or symbols can be resolved, it raises an ImportError.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ImportFrom",
                  "description": "The AST node representing the 'from ... import ...' statement."
                }
              ],
              "returns": [
                {
                  "name": "resolved",
                  "type": "list[str]",
                  "description": "A list of successfully resolved module or symbol names."
                }
              ],
              "usage_context": {
                "calls": "This method calls get_all_temp_files to retrieve all temporary files in the repository and internally defines and calls module_file_exists and init_exports_symbol to check for module and symbol existence.",
                "called_by": "This method is called by visit_ImportFrom to handle the resolution of relative import statements."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_Import",
            "description": {
              "overall": "This method, acting as an AST visitor, processes both Import and ImportFrom nodes to record direct import dependencies. It updates the import_dependencies dictionary, mapping the current file (self.filename) to a set of module names it imports. The method ensures that each imported module or symbol is added to the dependency set for the current file, and then continues the AST traversal using generic_visit.",
              "parameters": [
                {
                  "name": "node",
                  "type": "Import | ImportFrom",
                  "description": "The AST node representing an import statement."
                },
                {
                  "name": "base_name",
                  "type": "str | None",
                  "description": "An optional base name for the import, used when resolving 'from ... import ...' statements."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls self.generic_visit to continue the AST traversal.",
                "called_by": "This method is called by visit_ImportFrom to record dependencies after resolving relative imports or extracting the module base name."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_ImportFrom",
            "description": {
              "overall": "This AST visitor method specifically handles from ... import ... statements. It first attempts to extract the module's base name for absolute imports and passes it to visit_Import for recording. For relative imports, it delegates the complex resolution logic to the _resolve_module_name method. Upon successful resolution, it iterates through the resolved names and records each as a dependency via visit_Import, while also catching and printing ImportError exceptions.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ImportFrom",
                  "description": "The AST node representing a 'from ... import ...' statement."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls _resolve_module_name to resolve relative imports and visit_Import to record the dependencies. It also calls self.generic_visit for AST traversal.",
                "called_by": "This method is implicitly called by the NodeVisitor framework when traversing an AST that contains ImportFrom nodes."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "This class relies on get_all_temp_files to obtain a list of all temporary files in the repository and utilizes internal helper functions like module_file_exists and init_exports_symbol for verifying the existence of modules and symbols during import resolution.",
          "instantiated_by": "Based on the provided context, this class is not explicitly instantiated by any known external components."
        }
      },
      "error": null
    },
    "backend.HelperLLM.LLMHelper": {
      "identifier": "backend.HelperLLM.LLMHelper",
      "description": {
        "overall": "The LLMHelper class provides a centralized interface for interacting with various Large Language Models (LLMs) to generate structured documentation for Python functions and classes. It abstracts away the complexities of API interaction, prompt management, batch processing, and rate limiting. The class is initialized with API keys and paths to system prompts, dynamically configuring the LLM client (Gemini, OpenAI, custom, Ollama) and its batch processing settings based on the chosen model. Its primary functions are generate_for_functions and generate_for_classes, which handle the batch submission of code snippets to the configured LLM and return validated Pydantic models representing the generated documentation.",
        "init_method": {
          "description": "The constructor initializes the LLMHelper by setting up the API key, loading system prompts from specified file paths for function and class analysis, and configuring the underlying LLM based on the model_name. It supports various LLM providers like Google Gemini, OpenAI, custom APIs (SCADSLLM), and Ollama, ensuring structured output for FunctionAnalysis and ClassAnalysis Pydantic models. It also calls _configure_batch_settings to set the batch size.",
          "parameters": [
            {
              "name": "api_key",
              "type": "str",
              "description": "The API key for the chosen LLM service."
            },
            {
              "name": "function_prompt_path",
              "type": "str",
              "description": "The file path to the system prompt for function analysis."
            },
            {
              "name": "class_prompt_path",
              "type": "str",
              "description": "The file path to the system prompt for class analysis."
            },
            {
              "name": "model_name",
              "type": "str",
              "description": "The name of the LLM model to use (default: \"gemini-2.0-flash-lite\")."
            },
            {
              "name": "base_url",
              "type": "str",
              "description": "The base URL for custom LLM endpoints like Ollama or other custom APIs."
            }
          ]
        },
        "methods": [
          {
            "identifier": "_configure_batch_settings",
            "description": {
              "overall": "This private method sets the batch_size attribute based on the provided model_name. It assigns specific batch sizes for various Gemini models, Llama3, and GPT models, and a default conservative batch size for unknown models. This configuration is crucial for managing API call concurrency and respecting rate limits during batch processing.",
              "parameters": [
                {
                  "name": "model_name",
                  "type": "str",
                  "description": "The name of the LLM model for which to configure batch settings."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method does not explicitly call other functions or methods.",
                "called_by": "This method is called by the __init__ constructor of the LLMHelper class."
              }
            },
            "error": null
          },
          {
            "identifier": "generate_for_functions",
            "description": {
              "overall": "This method generates and validates documentation for a list of functions in batches. It takes a list of FunctionAnalysisInput objects, converts them into JSON payloads, and constructs conversations with the function_system_prompt. It then uses the function_llm to process these conversations in batches, handling potential errors and incorporating a waiting period between batches to manage API rate limits. The method returns a list of FunctionAnalysis objects or None for failed items.",
              "parameters": [
                {
                  "name": "function_inputs",
                  "type": "List[FunctionAnalysisInput]",
                  "description": "A list of input objects containing function details for which documentation is to be generated."
                }
              ],
              "returns": [
                {
                  "name": "None",
                  "type": "List[Optional[FunctionAnalysis]]",
                  "description": "A list of FunctionAnalysis objects, where each object represents the generated and validated documentation for a function, or None if an error occurred during processing."
                }
              ],
              "usage_context": {
                "calls": "This method calls json.dumps, model_dump, SystemMessage, HumanMessage, self.function_llm.batch, logging.info, logging.error, and time.sleep.",
                "called_by": "The input context does not specify where this method is called."
              }
            },
            "error": null
          },
          {
            "identifier": "generate_for_classes",
            "description": {
              "overall": "This method is responsible for generating and validating documentation for a batch of classes. It takes a list of ClassAnalysisInput objects, converts them into JSON payloads, and prepares them as conversations with the class_system_prompt. The method then processes these conversations using the class_llm in batches, implementing error handling for API calls and introducing a delay between batches to comply with rate limits. It returns a list of ClassAnalysis objects, with None for any failed processing.",
              "parameters": [
                {
                  "name": "class_inputs",
                  "type": "List[ClassAnalysisInput]",
                  "description": "A list of input objects containing class details for which documentation is to be generated."
                }
              ],
              "returns": [
                {
                  "name": "None",
                  "type": "List[Optional[ClassAnalysis]]",
                  "description": "A list of ClassAnalysis objects, where each object represents the generated and validated documentation for a class, or None if an error occurred during processing."
                }
              ],
              "usage_context": {
                "calls": "This method calls json.dumps, model_dump, SystemMessage, HumanMessage, self.class_llm.batch, logging.info, logging.error, and time.sleep.",
                "called_by": "The input context does not specify where this method is called."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "This class depends on os, json, logging, time, typing module components, dotenv, langchain_google_genai.ChatGoogleGenerativeAI, langchain_ollama.ChatOllama, langchain_openai.ChatOpenAI, langchain.messages.HumanMessage, langchain.messages.SystemMessage, pydantic.ValidationError, and custom schemas like FunctionAnalysis, ClassAnalysis, FunctionAnalysisInput, FunctionContextInput, ClassAnalysisInput, ClassContextInput.",
          "instantiated_by": "The input context does not specify where this class is instantiated."
        }
      },
      "error": null
    },
    "backend.MainLLM.MainLLM": {
      "identifier": "backend.MainLLM.MainLLM",
      "description": {
        "overall": "The MainLLM class provides a unified interface for interacting with various large language models (LLMs). It dynamically configures and initializes an LLM client based on the specified model name, supporting providers like Google Generative AI, OpenAI-compatible services, and Ollama. The class manages the loading of a system prompt and offers both synchronous and streaming methods for sending user input and receiving LLM responses, incorporating error handling for robust operation.",
        "init_method": {
          "description": "This constructor initializes the MainLLM class by setting up the LLM client based on the provided API key and model name. It loads a system prompt from a specified file path and supports various LLM providers. It raises a ValueError if the API key is missing or if a required environment variable for custom APIs is not set, and a FileNotFoundError if the prompt file cannot be found.",
          "parameters": [
            {
              "name": "api_key",
              "type": "str",
              "description": "The API key required to authenticate with the chosen LLM provider."
            },
            {
              "name": "prompt_file_path",
              "type": "str",
              "description": "The file path to the system prompt text file, which is loaded during initialization."
            },
            {
              "name": "model_name",
              "type": "str",
              "description": "The name of the LLM model to use, defaulting to 'gemini-2.5-pro'. This determines which LLM client (e.g., Google, OpenAI, Ollama) is instantiated."
            },
            {
              "name": "base_url",
              "type": "str",
              "description": "An optional base URL for custom LLM API endpoints, used primarily for Ollama or other OpenAI-compatible services."
            }
          ]
        },
        "methods": [
          {
            "identifier": "call_llm",
            "description": {
              "overall": "This method sends a user input along with the pre-loaded system prompt to the initialized LLM. It constructs a list of SystemMessage and HumanMessage objects, then invokes the LLM client to get a synchronous response. The method logs the process and handles potential errors during the LLM call, returning the content of the LLM's response or None if an error occurs.",
              "parameters": [
                {
                  "name": "user_input",
                  "type": "str",
                  "description": "The user's query or message to be sent to the LLM."
                }
              ],
              "returns": [
                {
                  "name": "content",
                  "type": "str",
                  "description": "The textual content of the LLM's response."
                },
                {
                  "name": "None",
                  "type": "NoneType",
                  "description": "Returns None if an error occurs during the LLM invocation."
                }
              ],
              "usage_context": {
                "calls": "This method does not explicitly call other functions or methods based on the provided context.",
                "called_by": "This method is not explicitly called by other functions or methods based on the provided context."
              }
            },
            "error": null
          },
          {
            "identifier": "stream_llm",
            "description": {
              "overall": "This method facilitates streaming responses from the initialized LLM. It prepares the system prompt and user input as messages, then initiates a streaming call to the LLM client. It yields each content chunk received from the stream, allowing for real-time processing of the LLM's output. Error handling is included to yield an error message if the streaming process fails.",
              "parameters": [
                {
                  "name": "user_input",
                  "type": "str",
                  "description": "The user's query or message for which a streaming LLM response is requested."
                }
              ],
              "returns": [
                {
                  "name": "chunk.content",
                  "type": "str",
                  "description": "Yields individual content chunks from the LLM's streaming response."
                },
                {
                  "name": "error_message",
                  "type": "str",
                  "description": "Yields an error message string if an exception occurs during the streaming call."
                }
              ],
              "usage_context": {
                "calls": "This method does not explicitly call other functions or methods based on the provided context.",
                "called_by": "This method is not explicitly called by other functions or methods based on the provided context."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "This class does not have explicit external dependencies listed in the provided context.",
          "instantiated_by": "This class is not explicitly instantiated by other components based on the provided context."
        }
      },
      "error": null
    },
    "backend.basic_info.ProjektInfoExtractor": {
      "identifier": "backend.basic_info.ProjektInfoExtractor",
      "description": {
        "overall": "The ProjektInfoExtractor class is designed to systematically extract and consolidate fundamental project information from common project files such as README.md, pyproject.toml, and requirements.txt. It initializes a structured dictionary to store details like project title, description, features, tech stack, installation instructions, and dependencies. Through a series of private parsing methods, it processes these files, prioritizing information from pyproject.toml and falling back to other sources, and finally formats the collected data into a comprehensive overview.",
        "init_method": {
          "description": "The constructor initializes the ProjektInfoExtractor instance by setting a constant INFO_NICHT_GEFUNDEN to \"Information not found\". It also sets up a nested dictionary self.info with predefined keys for project overview and installation details, populating all initial values with the INFO_NICHT_GEFUNDEN placeholder.",
          "parameters": []
        },
        "methods": [
          {
            "identifier": "_clean_content",
            "description": {
              "overall": "This private utility method is designed to sanitize string content by removing null bytes (\\x00). Null bytes can appear due to encoding errors, such as reading UTF-16 encoded files as UTF-8. The method first checks if the input content is empty; if so, it returns an empty string. Otherwise, it performs a global replacement of null bytes with an empty string, effectively removing them.",
              "parameters": [
                {
                  "name": "content",
                  "type": "str",
                  "description": "The string content to be cleaned."
                }
              ],
              "returns": [
                {
                  "name": "None",
                  "type": "str",
                  "description": "The cleaned string content with null bytes removed."
                }
              ],
              "usage_context": {
                "calls": "This method does not explicitly call other functions or methods.",
                "called_by": "This method is called by _parse_readme, _parse_toml, and _parse_requirements."
              }
            },
            "error": null
          },
          {
            "identifier": "_finde_datei",
            "description": {
              "overall": "This private helper method searches for a specific file within a list of files based on a set of provided patterns. It iterates through each file and then through each pattern, performing a case-insensitive comparison to check if the file's path ends with any of the given patterns. The first file that matches any pattern is returned. If no matching file is found after checking all files and patterns, the method returns None.",
              "parameters": [
                {
                  "name": "patterns",
                  "type": "List[str]",
                  "description": "A list of string patterns to match against file paths (e.g., 'readme.md')."
                },
                {
                  "name": "dateien",
                  "type": "List[Any]",
                  "description": "A list of file objects, each expected to have a path attribute."
                }
              ],
              "returns": [
                {
                  "name": "None",
                  "type": "Optional[Any]",
                  "description": "The first file object that matches one of the patterns, or None if no match is found."
                }
              ],
              "usage_context": {
                "calls": "This method does not explicitly call other functions or methods, but accesses datei.path.",
                "called_by": "This method is called by extrahiere_info."
              }
            },
            "error": null
          },
          {
            "identifier": "_extrahiere_sektion_aus_markdown",
            "description": {
              "overall": "This private method extracts text content located directly under a Markdown level 2 heading (##) that matches one of the provided keywords. It constructs a regular expression pattern to find headings containing any of the keywords (case-insensitively) and then captures all content following that heading until the next level 2 heading or the end of the document. This allows for structured extraction of specific sections like \"Features\" or \"Tech Stack\" from a Markdown string.",
              "parameters": [
                {
                  "name": "inhalt",
                  "type": "str",
                  "description": "The Markdown content string to parse."
                },
                {
                  "name": "keywords",
                  "type": "List[str]",
                  "description": "A list of keywords to match against Markdown headings (e.g., 'Features', 'Status')."
                }
              ],
              "returns": [
                {
                  "name": "None",
                  "type": "Optional[str]",
                  "description": "The stripped string content of the matched section, or None if no matching section is found."
                }
              ],
              "usage_context": {
                "calls": "This method calls re.escape, re.compile, pattern.search, and match.group for regular expression operations.",
                "called_by": "This method is called by _parse_readme."
              }
            },
            "error": null
          },
          {
            "identifier": "_parse_readme",
            "description": {
              "overall": "This private method processes the content of a README file to extract various project details and populate the self.info dictionary. It first cleans the content using _clean_content to remove potential null bytes. It then attempts to extract the project title and a general description using regular expressions for Markdown level 1 headings. Subsequently, it uses _extrahiere_sektion_aus_markdown to find and extract specific sections like \"Key Features\", \"Tech Stack\", \"Status\", \"Installation\", and \"Quick Start Guide\" based on predefined keywords.",
              "parameters": [
                {
                  "name": "inhalt",
                  "type": "str",
                  "description": "The raw string content of the README file."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls _clean_content, re.search, and _extrahiere_sektion_aus_markdown.",
                "called_by": "This method is called by extrahiere_info."
              }
            },
            "error": null
          },
          {
            "identifier": "_parse_toml",
            "description": {
              "overall": "This private method is responsible for parsing the content of a pyproject.toml file to extract project information. It first cleans the input content using _clean_content. It then checks if the tomllib module is available, printing a warning and returning if not. If tomllib is present, it attempts to load the TOML content into a Python dictionary. From this dictionary, it extracts the project name, description, and dependencies from the [project] section, updating the self.info dictionary accordingly. Error handling is included for TOMLDecodeError.",
              "parameters": [
                {
                  "name": "inhalt",
                  "type": "str",
                  "description": "The raw string content of the pyproject.toml file."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls _clean_content, tomllib.loads, and data.get.",
                "called_by": "This method is called by extrahiere_info."
              }
            },
            "error": null
          },
          {
            "identifier": "_parse_requirements",
            "description": {
              "overall": "This private method parses the content of a requirements.txt file to extract project dependencies. It first cleans the input content using _clean_content. It then proceeds to extract dependencies only if the self.info[\"installation\"][\"dependencies\"] field is still set to the INFO_NICHT_GEFUNDEN placeholder, indicating that dependencies haven't been found from a pyproject.toml file yet. It splits the content into lines, filters out empty lines and comments, and stores the cleaned dependency strings in the self.info dictionary.",
              "parameters": [
                {
                  "name": "inhalt",
                  "type": "str",
                  "description": "The raw string content of the requirements.txt file."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls _clean_content.",
                "called_by": "This method is called by extrahiere_info."
              }
            },
            "error": null
          },
          {
            "identifier": "extrahiere_info",
            "description": {
              "overall": "This public method orchestrates the entire information extraction process from various project files and a repository URL. It first uses _finde_datei to locate README, pyproject.toml, and requirements.txt files within the provided list of dateien. It then parses these files in a prioritized order: pyproject.toml first (for definitive project metadata), then requirements.txt (as a fallback for dependencies), and finally README (for descriptive sections). After parsing, it formats the extracted dependencies into a readable string if they were found as a list. Finally, if a repo_url is provided and a project title hasn't been found, it derives a title from the URL, returning the fully populated self.info dictionary.",
              "parameters": [
                {
                  "name": "dateien",
                  "type": "List[Any]",
                  "description": "A list of file objects, each expected to have path and content attributes, representing files in the project."
                },
                {
                  "name": "repo_url",
                  "type": "str",
                  "description": "The URL of the repository, used as a fallback to derive a project title."
                }
              ],
              "returns": [
                {
                  "name": "None",
                  "type": "Dict[str, Any]",
                  "description": "A dictionary containing extracted project overview and installation information."
                }
              ],
              "usage_context": {
                "calls": "This method calls _finde_datei, _parse_toml, _parse_requirements, _parse_readme, os.path.basename, and repo_url.removesuffix.",
                "called_by": "This method is not explicitly called by other methods within the provided context."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "This class does not explicitly list external functional dependencies in the provided context, but it uses re, os, tomllib, typing.List, typing.Dict, typing.Any, and typing.Optional.",
          "instantiated_by": "This class is not explicitly instantiated by any other components within the provided context."
        }
      },
      "error": null
    },
    "backend.callgraph.CallGraph": {
      "identifier": "backend.callgraph.CallGraph",
      "description": {
        "overall": "The CallGraph class is an ast.NodeVisitor designed to construct a directed call graph for a given Python source file. It traverses the Abstract Syntax Tree (AST) of the file, identifying function and class definitions, import statements, and function calls. By maintaining context of the current class and function, it resolves call targets to fully qualified names, including handling local definitions and import aliases, and records these relationships as edges in a NetworkX graph.",
        "init_method": {
          "description": "The constructor initializes the CallGraph instance, setting the `filename` for the current file being analyzed. It establishes context tracking variables like `current_function` and `current_class`, and initializes data structures such as `local_defs` for local symbol resolution, `graph` as a NetworkX directed graph, `import_mapping` for import alias resolution, `function_set` to track defined functions, and `edges` to store the call relationships.",
          "parameters": [
            {
              "name": "filename",
              "type": "str",
              "description": "The path to the source file being analyzed."
            }
          ]
        },
        "methods": [
          {
            "identifier": "_recursive_call",
            "description": {
              "overall": "This private helper method recursively traverses an Abstract Syntax Tree (AST) node, specifically designed to extract the full dotted name components of a function or attribute call. It handles `ast.Call`, `ast.Name`, and `ast.Attribute` nodes to build a list representing the hierarchical name of the called entity.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.AST",
                  "description": "The AST node representing a call, name, or attribute."
                }
              ],
              "returns": [
                {
                  "name": "name_components",
                  "type": "list[str]",
                  "description": "A list of string components forming the dotted name (e.g., ['pkg', 'mod', 'Class', 'method'])."
                }
              ],
              "usage_context": {
                "calls": "This method does not explicitly call other functions or methods based on the provided context.",
                "called_by": "This method is not explicitly called by other functions or methods based on the provided context."
              }
            },
            "error": null
          },
          {
            "identifier": "_resolve_all_callee_names",
            "description": {
              "overall": "This method takes a list of potential callee name components (e.g., [['module', 'function'], ['Class', 'method']]) and attempts to resolve them to their fully qualified names. It prioritizes local definitions (`self.local_defs`), then import mappings (`self.import_mapping`), and finally constructs a full name based on the current file and class context if no other resolution is found.",
              "parameters": [
                {
                  "name": "callee_nodes",
                  "type": "list[list[str]]",
                  "description": "A list where each inner list represents the name components of a potential callee."
                }
              ],
              "returns": [
                {
                  "name": "resolved_names",
                  "type": "list[str]",
                  "description": "A list of fully resolved callee names as strings."
                }
              ],
              "usage_context": {
                "calls": "This method does not explicitly call other functions or methods based on the provided context.",
                "called_by": "This method is not explicitly called by other functions or methods based on the provided context."
              }
            },
            "error": null
          },
          {
            "identifier": "_make_full_name",
            "description": {
              "overall": "This private helper method constructs a fully qualified name for a function or method. It prepends the filename and optionally the class name to the given base name, creating a unique identifier within the context of the file.",
              "parameters": [
                {
                  "name": "basename",
                  "type": "str",
                  "description": "The base name of the function or method."
                },
                {
                  "name": "class_name",
                  "type": "str | None",
                  "description": "The name of the class if the entity is a method, otherwise None."
                }
              ],
              "returns": [
                {
                  "name": "full_name",
                  "type": "str",
                  "description": "The fully qualified name."
                }
              ],
              "usage_context": {
                "calls": "This method does not explicitly call other functions or methods based on the provided context.",
                "called_by": "This method is not explicitly called by other functions or methods based on the provided context."
              }
            },
            "error": null
          },
          {
            "identifier": "_current_caller",
            "description": {
              "overall": "This method determines the identifier for the current calling context. If a function is currently being visited (`self.current_function`), its full name is returned. Otherwise, it returns a placeholder indicating the global scope within the current file.",
              "parameters": [],
              "returns": [
                {
                  "name": "caller_identifier",
                  "type": "str",
                  "description": "The identifier of the current caller (function name or global scope)."
                }
              ],
              "usage_context": {
                "calls": "This method does not explicitly call other functions or methods based on the provided context.",
                "called_by": "This method is not explicitly called by other functions or methods based on the provided context."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_Import",
            "description": {
              "overall": "This method is an AST visitor for `ast.Import` nodes. It processes top-level import statements, extracting the module name and any `as` aliases. It populates `self.import_mapping` to resolve imported module names later.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.Import",
                  "description": "The AST node representing an import statement."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method does not explicitly call other functions or methods based on the provided context.",
                "called_by": "This method is not explicitly called by other functions or methods based on the provided context."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_ImportFrom",
            "description": {
              "overall": "This method is an AST visitor for `ast.ImportFrom` nodes. It processes `from ... import ...` statements, extracting the module name and the imported names (and their aliases). It updates `self.import_mapping` to facilitate resolution of these imported entities.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.ImportFrom",
                  "description": "The AST node representing a `from ... import ...` statement."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method does not explicitly call other functions or methods based on the provided context.",
                "called_by": "This method is not explicitly called by other functions or methods based on the provided context."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_ClassDef",
            "description": {
              "overall": "This method is an AST visitor for `ast.ClassDef` nodes. It manages the `self.current_class` context during AST traversal. When entering a class definition, it sets `self.current_class` to the class's name, allowing nested functions to be correctly identified as methods. It restores the previous class context upon exiting.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.ClassDef",
                  "description": "The AST node representing a class definition."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method does not explicitly call other functions or methods based on the provided context.",
                "called_by": "This method is not explicitly called by other functions or methods based on the provided context."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_FunctionDef",
            "description": {
              "overall": "This method is an AST visitor for `ast.FunctionDef` nodes. It processes function definitions, constructing a fully qualified name for the function using `_make_full_name`. It updates `self.local_defs` to map the function's simple name (and class-qualified name if applicable) to its full name. It also adds the function as a node to the call graph and manages the `self.current_function` context for nested calls.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.FunctionDef",
                  "description": "The AST node representing a function definition."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method does not explicitly call other functions or methods based on the provided context.",
                "called_by": "This method is not explicitly called by other functions or methods based on the provided context."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_AsyncFunctionDef",
            "description": {
              "overall": "This method is an AST visitor for `ast.AsyncFunctionDef` nodes. It handles asynchronous function definitions by simply delegating to the `visit_FunctionDef` method, ensuring that async functions are processed in the same manner as regular functions for call graph construction.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.AsyncFunctionDef",
                  "description": "The AST node representing an asynchronous function definition."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method does not explicitly call other functions or methods based on the provided context.",
                "called_by": "This method is not explicitly called by other functions or methods based on the provided context."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_Call",
            "description": {
              "overall": "This method is an AST visitor for `ast.Call` nodes, which represent function or method calls. It identifies the current caller using `_current_caller`, extracts the callee's name components using `_recursive_call`, and then resolves the callee's full name using `_resolve_all_callee_names`. Finally, it records the call as an edge in the `self.edges` dictionary.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.Call",
                  "description": "The AST node representing a function or method call."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method does not explicitly call other functions or methods based on the provided context.",
                "called_by": "This method is not explicitly called by other functions or methods based on the provided context."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_If",
            "description": {
              "overall": "This method is an AST visitor for `ast.If` nodes. It specifically handles the common `if __name__ == \"__main__\":` block by temporarily setting the `self.current_function` to `<main_block>`. This ensures that any calls within the main execution block are correctly attributed to a distinct \"main block\" caller in the call graph. For other `if` statements, it simply continues the generic AST traversal.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.If",
                  "description": "The AST node representing an if statement."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method does not explicitly call other functions or methods based on the provided context.",
                "called_by": "This method is not explicitly called by other functions or methods based on the provided context."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "The class does not explicitly list dependencies in its `__init__` parameters, but it relies on the `ast` module for parsing and `networkx` for graph representation.",
          "instantiated_by": "This class is not explicitly instantiated by any known entities within the provided context."
        }
      },
      "error": null
    },
    "backend.getRepo.RepoFile": {
      "identifier": "backend.getRepo.RepoFile",
      "description": {
        "overall": "The RepoFile class represents a single file within a Git repository, providing a structured way to access its metadata and content. It implements a lazy loading mechanism for the Git blob object, file content, and size, ensuring these resources are only loaded when explicitly accessed. The class offers properties to retrieve the Git blob, the decoded file content, and its size, along with utility methods for analysis (like word count) and conversion to a dictionary format.",
        "init_method": {
          "description": "Initializes a RepoFile object by storing the file path and the Git Tree object from which the file originates. It also sets up internal attributes for lazy loading of the Git blob, file content, and size, which are initially set to None.",
          "parameters": [
            {
              "name": "file_path",
              "type": "str",
              "description": "The path to the file within the repository."
            },
            {
              "name": "commit_tree",
              "type": "git.Tree",
              "description": "The Tree object of the commit, from which the file originates."
            }
          ]
        },
        "methods": [
          {
            "identifier": "blob",
            "description": {
              "overall": "This property provides lazy loading for the Git blob object associated with the file. It checks if the internal `_blob` attribute is already loaded; if not, it attempts to retrieve the blob from the `_tree` using the file path. If the file is not found in the commit tree, it raises a `FileNotFoundError`.",
              "parameters": [],
              "returns": [
                {
                  "name": "blob",
                  "type": "git.Blob",
                  "description": "The Git blob object representing the file."
                }
              ],
              "usage_context": {
                "calls": "This method does not explicitly call other methods or functions according to the provided context.",
                "called_by": "This method is not explicitly called by other methods or functions according to the provided context."
              }
            },
            "error": null
          },
          {
            "identifier": "content",
            "description": {
              "overall": "This property provides lazy loading for the decoded content of the file. It checks if the internal `_content` attribute is already loaded; if not, it accesses the `blob` property, reads its data stream, and decodes it using UTF-8 with error ignoring. The decoded string content is then stored and returned.",
              "parameters": [],
              "returns": [
                {
                  "name": "content",
                  "type": "str",
                  "description": "The decoded string content of the file."
                }
              ],
              "usage_context": {
                "calls": "This method does not explicitly call other methods or functions according to the provided context.",
                "called_by": "This method is not explicitly called by other methods or functions according to the provided context."
              }
            },
            "error": null
          },
          {
            "identifier": "size",
            "description": {
              "overall": "This property provides lazy loading for the size of the file in bytes. It checks if the internal `_size` attribute is already loaded; if not, it accesses the `blob` property and retrieves its size attribute. The file size is then stored and returned.",
              "parameters": [],
              "returns": [
                {
                  "name": "size",
                  "type": "int",
                  "description": "The size of the file in bytes."
                }
              ],
              "usage_context": {
                "calls": "This method does not explicitly call other methods or functions according to the provided context.",
                "called_by": "This method is not explicitly called by other methods or functions according to the provided context."
              }
            },
            "error": null
          },
          {
            "identifier": "analyze_word_count",
            "description": {
              "overall": "This method serves as an example analysis function, calculating the total number of words in the file's content. It retrieves the file content via the `content` property, splits the string by whitespace, and returns the count of the resulting words.",
              "parameters": [],
              "returns": [
                {
                  "name": "word_count",
                  "type": "int",
                  "description": "The total number of words in the file content."
                }
              ],
              "usage_context": {
                "calls": "This method does not explicitly call other methods or functions according to the provided context.",
                "called_by": "This method is not explicitly called by other methods or functions according to the provided context."
              }
            },
            "error": null
          },
          {
            "identifier": "__repr__",
            "description": {
              "overall": "This special method provides a developer-friendly string representation of the RepoFile object. It returns a string that includes the class name and the path of the file it represents, useful for debugging and logging.",
              "parameters": [],
              "returns": [
                {
                  "name": "representation",
                  "type": "str",
                  "description": "A string representation of the RepoFile object, including its path."
                }
              ],
              "usage_context": {
                "calls": "This method does not explicitly call other methods or functions according to the provided context.",
                "called_by": "This method is not explicitly called by other methods or functions according to the provided context."
              }
            },
            "error": null
          },
          {
            "identifier": "to_dict",
            "description": {
              "overall": "This method converts the RepoFile object into a dictionary representation, providing structured metadata about the file. It includes the file's path, name (basename), size, and type. Optionally, the file's content can be included in the dictionary if the `include_content` flag is set to True.",
              "parameters": [
                {
                  "name": "include_content",
                  "type": "bool",
                  "description": "A flag indicating whether to include the file's content in the dictionary. Defaults to False."
                }
              ],
              "returns": [
                {
                  "name": "file_data",
                  "type": "dict",
                  "description": "A dictionary containing the file's metadata and optionally its content."
                }
              ],
              "usage_context": {
                "calls": "This method does not explicitly call other methods or functions according to the provided context.",
                "called_by": "This method is not explicitly called by other methods or functions according to the provided context."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "The class does not explicitly list any external functional dependencies in the provided context.",
          "instantiated_by": "The class is not explicitly instantiated by other components in the provided context."
        }
      },
      "error": null
    },
    "backend.getRepo.GitRepository": {
      "identifier": "backend.getRepo.GitRepository",
      "description": {
        "overall": "The GitRepository class provides a robust mechanism for interacting with remote Git repositories. It handles the cloning of a specified repository into a temporary local directory upon instantiation, ensuring that the repository data is available for processing. The class offers methods to retrieve all files as RepoFile objects and to generate a hierarchical file tree representation. It also implements the context manager protocol, guaranteeing that the temporary directory is cleaned up automatically upon exiting a with block, thus preventing resource leaks.",
        "init_method": {
          "description": "Initializes a GitRepository instance by cloning a remote Git repository into a temporary local directory. It sets up attributes for the repository URL, the temporary directory path, the GitPython Repo object, and initializes an empty list for files. It also captures the latest commit and its tree, handling potential Git cloning errors by cleaning up the temporary directory.",
          "parameters": [
            {
              "name": "repo_url",
              "type": "str",
              "description": "The URL of the Git repository to clone."
            }
          ]
        },
        "methods": [
          {
            "identifier": "get_all_files",
            "description": {
              "overall": "This method retrieves a list of all file paths present in the cloned Git repository using Git's `ls-files` command. It then iterates through these paths, creating a `RepoFile` object for each one, using the `commit_tree` attribute to access file content. Finally, it stores these `RepoFile` objects in the `self.files` attribute and returns the list.",
              "parameters": [],
              "returns": [
                {
                  "name": "files",
                  "type": "list[RepoFile]",
                  "description": "A list of RepoFile instances representing all files in the repository."
                }
              ],
              "usage_context": {
                "calls": "This method calls self.repo.git.ls_files() to get file paths and RepoFile to create file objects.",
                "called_by": "This method is not explicitly called by other methods in the provided context."
              }
            },
            "error": null
          },
          {
            "identifier": "close",
            "description": {
              "overall": "This method is responsible for cleaning up the temporary directory created during the repository cloning process. It checks if self.temp_dir is set and, if so, prints a message indicating the directory being deleted. It then sets self.temp_dir to None, effectively marking the directory for deletion (though the actual deletion is typically handled by shutil.rmtree or similar, which is missing here, but the intent is clear).",
              "parameters": [],
              "returns": [],
              "usage_context": {
                "calls": "This method does not explicitly call other functions or methods.",
                "called_by": "This method is called by the __exit__ method and within the __init__ method in case of a cloning error."
              }
            },
            "error": null
          },
          {
            "identifier": "__enter__",
            "description": {
              "overall": "This special method allows the GitRepository class to be used as a context manager. When entering a `with` statement, this method is automatically invoked and simply returns the instance of the GitRepository itself, making it available as the `as` target in the `with` statement.",
              "parameters": [],
              "returns": [
                {
                  "name": "self",
                  "type": "GitRepository",
                  "description": "The instance of the GitRepository class."
                }
              ],
              "usage_context": {
                "calls": "This method does not explicitly call other functions or methods.",
                "called_by": "This method is implicitly called when the GitRepository object is used in a with statement."
              }
            },
            "error": null
          },
          {
            "identifier": "__exit__",
            "description": {
              "overall": "This special method is part of the context manager protocol and is automatically called when exiting a `with` statement, regardless of whether an exception occurred. Its primary responsibility is to ensure proper cleanup by invoking the `close` method, which handles the deletion of the temporary repository directory.",
              "parameters": [
                {
                  "name": "exc_type",
                  "type": "type | None",
                  "description": "The type of the exception that caused the exit, or None if no exception occurred."
                },
                {
                  "name": "exc_val",
                  "type": "Exception | None",
                  "description": "The exception instance that caused the exit, or None."
                },
                {
                  "name": "exc_tb",
                  "type": "TracebackType | None",
                  "description": "The traceback object associated with the exception, or None."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls the self.close() method for cleanup.",
                "called_by": "This method is implicitly called when exiting a with statement where GitRepository is the context manager."
              }
            },
            "error": null
          },
          {
            "identifier": "get_file_tree",
            "description": {
              "overall": "This method constructs a hierarchical tree representation of the files within the repository. It first ensures that all files have been loaded by calling `get_all_files()` if `self.files` is empty. It then iterates through each `RepoFile` object, splitting its path to build a nested dictionary structure representing directories and files. Files are added to their respective directory children, and an option `include_content` determines if file content is embedded.",
              "parameters": [
                {
                  "name": "include_content",
                  "type": "bool",
                  "description": "A flag indicating whether the content of each file should be included in its dictionary representation. Defaults to False."
                }
              ],
              "returns": [
                {
                  "name": "tree",
                  "type": "dict",
                  "description": "A dictionary representing the file structure as a nested tree, with directories and files as nodes."
                }
              ],
              "usage_context": {
                "calls": "This method calls self.get_all_files() if self.files is empty and file_obj.to_dict() for each file.",
                "called_by": "This method is not explicitly called by other methods in the provided context."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "The class depends on backend.getRepo.RepoFile for representing individual files.",
          "instantiated_by": "The class is not explicitly instantiated by other components within the provided context."
        }
      },
      "error": null
    },
    "backend.relationship_analyzer.ProjectAnalyzer": {
      "identifier": "backend.relationship_analyzer.ProjectAnalyzer",
      "description": {
        "overall": "The ProjectAnalyzer class is designed to perform static analysis on a Python project to build a comprehensive call graph. It identifies all Python files, collects definitions of functions, methods, and classes, and then resolves the call relationships between these defined entities. The class provides methods to initiate the analysis, retrieve the raw call graph, and present the relationships in a structured outgoing/incoming format. It leverages AST parsing and a custom visitor pattern to achieve its analysis goals.",
        "init_method": {
          "description": "Initializes the ProjectAnalyzer instance by setting the project's root directory, initializing data structures for definitions, call graph, and file ASTs, and defining directories to ignore during file traversal. It prepares the object for subsequent analysis operations.",
          "parameters": [
            {
              "name": "project_root",
              "type": "str",
              "description": "The absolute path to the root directory of the project to be analyzed."
            }
          ]
        },
        "methods": [
          {
            "identifier": "analyze",
            "description": {
              "overall": "This method orchestrates the entire project analysis process. It first identifies all Python files within the project, then iterates through them to collect function, method, and class definitions. Subsequently, it iterates through the files again to resolve and record call relationships between these definitions. Finally, it clears the cached file ASTs and returns the populated call graph.",
              "parameters": [],
              "returns": [
                {
                  "name": "call_graph",
                  "type": "defaultdict(list)",
                  "description": "A dictionary representing the call graph where keys are callee pathnames and values are lists of caller information."
                }
              ],
              "usage_context": {
                "calls": "This method calls _find_py_files, _collect_definitions, and _resolve_calls.",
                "called_by": "This method is not explicitly called by other methods within the provided method_context."
              }
            },
            "error": null
          },
          {
            "identifier": "get_raw_relationships",
            "description": {
              "overall": "This method processes the internal call_graph to generate a structured representation of outgoing and incoming call relationships. It iterates through the call graph, extracting caller and callee identifiers, and populates two defaultdict(set) objects for outgoing and incoming calls. The sets are then converted to sorted lists within a dictionary for a clean, consumable output.",
              "parameters": [],
              "returns": [
                {
                  "name": "relationships",
                  "type": "dict",
                  "description": "A dictionary containing 'outgoing' and 'incoming' keys, each mapping to a dictionary where keys are entity identifiers and values are sorted lists of related entity identifiers."
                }
              ],
              "usage_context": {
                "calls": "This method does not explicitly call other methods or functions within the provided method_context.",
                "called_by": "This method is not explicitly called by other methods within the provided method_context."
              }
            },
            "error": null
          },
          {
            "identifier": "_find_py_files",
            "description": {
              "overall": "This private helper method is responsible for traversing the project directory structure to locate all Python files, while respecting a predefined list of directories to ignore. It uses os.walk to navigate the file system, filters out specified directories, and appends the full path of each .py file found to a list.",
              "parameters": [],
              "returns": [
                {
                  "name": "py_files",
                  "type": "list[str]",
                  "description": "A list of absolute file paths to all Python files found in the project, excluding ignored directories."
                }
              ],
              "usage_context": {
                "calls": "This method does not explicitly call other methods or functions within the provided method_context.",
                "called_by": "This method is called by analyze."
              }
            },
            "error": null
          },
          {
            "identifier": "_collect_definitions",
            "description": {
              "overall": "This private method parses a given Python file to identify and record all function, method, and class definitions. It reads the file, parses its source code into an Abstract Syntax Tree (AST), and then walks the AST to find ast.FunctionDef and ast.ClassDef nodes. For each definition, it constructs a unique path name and stores its file path, line number, and type ('function', 'method', or 'class') in the self.definitions dictionary. It also caches the AST for later use.",
              "parameters": [
                {
                  "name": "filepath",
                  "type": "str",
                  "description": "The absolute path to the Python file being analyzed."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls path_to_module and _get_parent.",
                "called_by": "This method is called by analyze."
              }
            },
            "error": null
          },
          {
            "identifier": "_get_parent",
            "description": {
              "overall": "This private helper method is designed to find the immediate parent node of a given AST node within a larger AST. It iterates through all nodes in the AST and for each parent node, it checks its children to see if any child matches the target node. If a match is found, the parent node is returned. This is primarily used to determine if a function definition is nested within a class, indicating it's a method.",
              "parameters": [
                {
                  "name": "tree",
                  "type": "ast.AST",
                  "description": "The root of the Abstract Syntax Tree to search within."
                },
                {
                  "name": "node",
                  "type": "ast.AST",
                  "description": "The child node for which to find the parent."
                }
              ],
              "returns": [
                {
                  "name": "parent_node",
                  "type": "ast.AST or None",
                  "description": "The parent AST node if found, otherwise None."
                }
              ],
              "usage_context": {
                "calls": "This method does not explicitly call other methods or functions within the provided method_context.",
                "called_by": "This method is called by _collect_definitions."
              }
            },
            "error": null
          },
          {
            "identifier": "_resolve_calls",
            "description": {
              "overall": "This private method processes the AST of a given Python file to identify and resolve function and method calls. It retrieves the cached AST for the specified filepath and then initializes a CallResolverVisitor with the file's context and known definitions. The visitor traverses the AST, identifies calls, and populates its internal calls dictionary. Finally, this method extends the self.call_graph with the resolved call relationships from the visitor.",
              "parameters": [
                {
                  "name": "filepath",
                  "type": "str",
                  "description": "The absolute path to the Python file whose calls are to be resolved."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls CallResolverVisitor.",
                "called_by": "This method is called by analyze."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "This class depends on backend.relationship_analyzer.CallResolverVisitor and backend.relationship_analyzer.path_to_module.",
          "instantiated_by": "This class is not explicitly shown to be instantiated by any other components in the provided context."
        }
      },
      "error": null
    },
    "backend.relationship_analyzer.CallResolverVisitor": {
      "identifier": "backend.relationship_analyzer.CallResolverVisitor",
      "description": {
        "overall": "The CallResolverVisitor class is an `ast.NodeVisitor` subclass designed to traverse a Python Abstract Syntax Tree (AST) and identify call relationships between different parts of a codebase. It maintains an internal state to track the current module, class, and function context, as well as a scope for imported names and types of instantiated objects. Its primary function is to collect and categorize all function and method calls within a given Python file, resolving their fully qualified names to build a comprehensive map of inter-component dependencies.",
        "init_method": {
          "description": "The constructor initializes the visitor with the file path, project root, and a dictionary of known definitions. It sets up internal state variables like `module_path`, `scope` for tracking imports, `instance_types` for tracking object types, and `calls` (a defaultdict) to store detected call relationships.",
          "parameters": [
            {
              "name": "filepath",
              "type": "string",
              "description": "The path to the Python file being analyzed."
            },
            {
              "name": "project_root",
              "type": "string",
              "description": "The root directory of the project, used for module path resolution."
            },
            {
              "name": "definitions",
              "type": "dict",
              "description": "A dictionary containing known definitions (e.g., functions, classes) for resolution."
            }
          ]
        },
        "methods": [
          {
            "identifier": "visit_ClassDef",
            "description": {
              "overall": "This method is an AST visitor for `ClassDef` nodes. It temporarily updates the `current_class_name` attribute to reflect the class being visited, allowing nested methods to correctly identify their parent class. After visiting the class's children, it restores the previous `current_class_name` to maintain correct scope.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.ClassDef",
                  "description": "The AST node representing a class definition."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method implicitly calls `self.generic_visit(node)` to traverse the AST children of the class definition.",
                "called_by": "This method is called by the `ast.NodeVisitor` framework when a `ClassDef` node is encountered during AST traversal."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_FunctionDef",
            "description": {
              "overall": "This method is an AST visitor for `FunctionDef` nodes. It constructs a full identifier for the function, including its module and potentially its class, and updates `current_caller_name`. This ensures that any calls made within this function are correctly attributed to its full identifier. It then traverses the function's body and restores the previous caller name upon exit.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.FunctionDef",
                  "description": "The AST node representing a function definition."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method implicitly calls `self.generic_visit(node)` to traverse the AST children of the function definition.",
                "called_by": "This method is called by the `ast.NodeVisitor` framework when a `FunctionDef` node is encountered during AST traversal."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_Call",
            "description": {
              "overall": "This method is an AST visitor for `Call` nodes, which represent function or method invocations. It attempts to resolve the fully qualified name of the called entity using `_resolve_call_qname`. If the callee is successfully resolved and found in the `definitions`, it records the call, including information about the caller's file, line number, full identifier, and type (module, local function, method, or function).",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.Call",
                  "description": "The AST node representing a function or method call."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls `self._resolve_call_qname` to determine the qualified name of the called function or method.",
                "called_by": "This method is called by the `ast.NodeVisitor` framework when a `Call` node is encountered during AST traversal."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_Import",
            "description": {
              "overall": "This method is an AST visitor for `Import` nodes. It processes `import` statements (e.g., `import os`, `import collections as coll`) and populates the `self.scope` dictionary. The `scope` maps the imported name (or its alias) to its fully qualified module path, which is crucial for resolving subsequent calls.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.Import",
                  "description": "The AST node representing an import statement."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method implicitly calls `self.generic_visit(node)` to traverse the AST children.",
                "called_by": "This method is called by the `ast.NodeVisitor` framework when an `Import` node is encountered during AST traversal."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_ImportFrom",
            "description": {
              "overall": "This method is an AST visitor for `ImportFrom` nodes. It handles `from ... import ...` statements, resolving the full module path for imported names, considering relative imports (`node.level`). It then populates the `self.scope` dictionary with the fully qualified names of the imported objects, enabling accurate resolution of calls to these imported entities.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.ImportFrom",
                  "description": "The AST node representing a `from ... import ...` statement."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method implicitly calls `self.generic_visit(node)` to traverse the AST children.",
                "called_by": "This method is called by the `ast.NodeVisitor` framework when an `ImportFrom` node is encountered during AST traversal."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_Assign",
            "description": {
              "overall": "This method is an AST visitor for `Assign` nodes. It specifically looks for assignments where the assigned value is a call to a class constructor (e.g., `x = MyClass()`). If such an assignment is found and the class name can be resolved, it records the type of the assigned variable in `self.instance_types`. This mapping helps in resolving method calls on instances later (e.g., `x.method()`).",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.Assign",
                  "description": "The AST node representing an assignment statement."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method does not explicitly call other methods within the class, but it implicitly calls `self.generic_visit(node)` which traverses the AST children.",
                "called_by": "This method is called by the `ast.NodeVisitor` framework when an `Assign` node is encountered during AST traversal."
              }
            },
            "error": null
          },
          {
            "identifier": "_resolve_call_qname",
            "description": {
              "overall": "This private helper method attempts to determine the fully qualified name (qname) of a function or method being called. It handles various scenarios: direct name calls (checking `self.scope` and local module paths), and attribute calls (e.g., `obj.method` or `module.function`). For attribute calls, it uses `self.instance_types` to resolve the class of an instance or `self.scope` for module-level attributes.",
              "parameters": [
                {
                  "name": "func_node",
                  "type": "ast.expr",
                  "description": "The AST node representing the function or method being called (e.g., `ast.Name` or `ast.Attribute`)."
                }
              ],
              "returns": [
                {
                  "name": "name",
                  "type": "string | None",
                  "description": "The fully qualified name of the called entity, or `None` if it cannot be resolved."
                }
              ],
              "usage_context": {
                "calls": "This method does not call other methods within the class.",
                "called_by": "This method is called by `self.visit_Call` to resolve the qualified name of the callee."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "This class depends on `backend.relationship_analyzer.path_to_module` for converting file paths to module paths.",
          "instantiated_by": "This class is not explicitly instantiated by any known entities in the provided context."
        }
      },
      "error": null
    },
    "schemas.types.ParameterDescription": {
      "identifier": "schemas.types.ParameterDescription",
      "description": {
        "overall": "This class serves as a structured data model for representing the characteristics of a single parameter within a function or method signature. It leverages Pydantic's BaseModel to enforce type validation and provide a clear, standardized way to describe a parameter's name, its data type, and its purpose. This model is crucial for generating consistent and machine-readable documentation or for internal system representations of function interfaces.",
        "init_method": {
          "description": "As a Pydantic BaseModel, the `__init__` method is automatically generated. It accepts keyword arguments corresponding to its defined fields (`name`, `type`, `description`) to initialize the instance attributes, performing validation based on the provided type hints.",
          "parameters": [
            {
              "name": "name",
              "type": "str",
              "description": "The name of the parameter."
            },
            {
              "name": "type",
              "type": "str",
              "description": "The type hint or inferred type of the parameter."
            },
            {
              "name": "description",
              "type": "str",
              "description": "A brief explanation of the parameter's purpose."
            }
          ]
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class does not explicitly list any external functional dependencies in the provided context.",
          "instantiated_by": "The specific points of instantiation for this class are not provided in the current context."
        }
      },
      "error": null
    },
    "schemas.types.ReturnDescription": {
      "identifier": "schemas.types.ReturnDescription",
      "description": {
        "overall": "The ReturnDescription class is a Pydantic BaseModel designed to encapsulate the details of a function's return value. It provides a structured format to represent the name, type, and a descriptive explanation of what a function returns. This class serves as a data model for consistent documentation or analysis of function outputs.",
        "init_method": {
          "description": "This class, being a Pydantic BaseModel, automatically generates an `__init__` method. This constructor initializes an instance of `ReturnDescription` by validating and assigning the `name`, `type`, and `description` fields based on the provided arguments.",
          "parameters": [
            {
              "name": "name",
              "type": "str",
              "description": "The name or identifier of the return value."
            },
            {
              "name": "type",
              "type": "str",
              "description": "The Python type hint or description of the return value's type."
            },
            {
              "name": "description",
              "type": "str",
              "description": "A detailed explanation of what the return value represents."
            }
          ]
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class does not explicitly list external functional dependencies in the provided context.",
          "instantiated_by": "The specific locations where this class is instantiated are not provided in the current context."
        }
      },
      "error": null
    },
    "schemas.types.UsageContext": {
      "identifier": "schemas.types.UsageContext",
      "description": {
        "overall": "The UsageContext class is a Pydantic BaseModel designed to encapsulate information about the calling context of a function or method. It serves as a structured data container, holding two string attributes: 'calls', which describes what the entity calls, and 'called_by', which describes what calls the entity. This class provides a standardized way to represent interaction patterns within a codebase.",
        "init_method": {
          "description": "This class, being a Pydantic BaseModel, has an implicitly generated constructor. It initializes an instance with two string attributes: 'calls' and 'called_by', which are validated upon instantiation.",
          "parameters": [
            {
              "name": "calls",
              "type": "str",
              "description": "A string describing the functions, methods, or external entities that this context's subject calls."
            },
            {
              "name": "called_by",
              "type": "str",
              "description": "A string describing the functions, methods, or external entities that call this context's subject."
            }
          ]
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class does not explicitly list any external functional dependencies.",
          "instantiated_by": "The points of instantiation for this class are not explicitly provided in the context."
        }
      },
      "error": null
    },
    "schemas.types.FunctionDescription": {
      "identifier": "schemas.types.FunctionDescription",
      "description": {
        "overall": "The FunctionDescription class is a Pydantic BaseModel designed to encapsulate a comprehensive analysis of a Python function. It serves as a structured data container, holding information about the function's high-level purpose, its input parameters, its return values, and its usage context within a larger system. This class facilitates the standardized representation and exchange of function metadata.",
        "init_method": {
          "description": "Initializes a FunctionDescription instance, setting up the structured data for a function's analysis. This Pydantic model's constructor is implicitly generated, accepting values for its defined fields: overall, parameters, returns, and usage_context.",
          "parameters": [
            {
              "name": "overall",
              "type": "str",
              "description": "A high-level summary of the function's purpose and implementation."
            },
            {
              "name": "parameters",
              "type": "List[ParameterDescription]",
              "description": "A list of parameter descriptions for the function."
            },
            {
              "name": "returns",
              "type": "List[ReturnDescription]",
              "description": "A list of return value descriptions for the function."
            },
            {
              "name": "usage_context",
              "type": "UsageContext",
              "description": "Contextual information about where and how the function is used."
            }
          ]
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class does not explicitly depend on other components within the provided context.",
          "instantiated_by": "This class is not explicitly shown to be instantiated by other components within the provided context."
        }
      },
      "error": null
    },
    "schemas.types.FunctionAnalysis": {
      "identifier": "schemas.types.FunctionAnalysis",
      "description": {
        "overall": "The FunctionAnalysis class is a Pydantic BaseModel designed to structure and store a comprehensive analysis of a single Python function. It serves as a data schema, encapsulating the function's unique identifier, a detailed description (which is an instance of FunctionDescription), and an optional error field for reporting analysis issues. This model facilitates the standardized representation of function analysis results for further processing or reporting.",
        "init_method": {
          "description": "The FunctionAnalysis class, inheriting from Pydantic's BaseModel, does not have an explicitly defined __init__ method. Pydantic automatically generates a constructor that initializes instances based on the type-hinted fields: identifier, description, and error.",
          "parameters": [
            {
              "name": "identifier",
              "type": "str",
              "description": "The unique string identifier for the function being analyzed."
            },
            {
              "name": "description",
              "type": "FunctionDescription",
              "description": "A structured object containing the detailed analysis of the function's purpose, parameters, returns, and usage context."
            },
            {
              "name": "error",
              "type": "Optional[str]",
              "description": "An optional string that captures any error messages encountered during the analysis of the function."
            }
          ]
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class does not explicitly list any external functional dependencies.",
          "instantiated_by": "The specific points of instantiation for this class are not provided in the current context."
        }
      },
      "error": null
    },
    "schemas.types.ConstructorDescription": {
      "identifier": "schemas.types.ConstructorDescription",
      "description": {
        "overall": "The `ConstructorDescription` class is a Pydantic BaseModel designed to provide a structured representation of a class's `__init__` method. It encapsulates a textual description of the constructor's purpose and a list of its parameters, each described by a `ParameterDescription` object. This class acts as a data schema for documenting how other classes are initialized.",
        "init_method": {
          "description": "The `__init__` method for `ConstructorDescription` is implicitly generated by Pydantic. It initializes an instance of this model by accepting values for its defined fields: a string for `description` and a list of `ParameterDescription` objects for `parameters`. This sets up the structured data representing a constructor.",
          "parameters": [
            {
              "name": "description",
              "type": "str",
              "description": "A string describing the purpose and behavior of the constructor."
            },
            {
              "name": "parameters",
              "type": "List[ParameterDescription]",
              "description": "A list of `ParameterDescription` objects, each detailing a parameter accepted by the constructor."
            }
          ]
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class does not explicitly list any external functional dependencies in the provided context.",
          "instantiated_by": "The specific instantiation points for this class are not provided in the given context."
        }
      },
      "error": null
    },
    "schemas.types.ClassContext": {
      "identifier": "schemas.types.ClassContext",
      "description": {
        "overall": "The ClassContext class is a Pydantic BaseModel designed to describe the external relationships and usage context of another class. It serves as a structured data container, holding information about the external dependencies that a class relies on and the locations or modules where that class is instantiated. This model is crucial for providing machine-readable context about how a specific class fits into a larger system architecture.",
        "init_method": {
          "description": "The `__init__` method for ClassContext is implicitly generated by Pydantic's BaseModel. It initializes instances of ClassContext by accepting `dependencies` and `instantiated_by` as keyword arguments, validating their types, and assigning them as instance attributes. This ensures that instances are created with valid string values for their contextual information.",
          "parameters": [
            {
              "name": "dependencies",
              "type": "str",
              "description": "A string summarizing the external dependencies of the class being described, indicating what other modules or functions it relies upon."
            },
            {
              "name": "instantiated_by",
              "type": "str",
              "description": "A string summarizing the primary points or locations within the codebase where the class being described is instantiated."
            }
          ]
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class does not explicitly declare external functional dependencies within the provided context.",
          "instantiated_by": "The instantiation points for this class are not specified in the provided context."
        }
      },
      "error": null
    },
    "schemas.types.ClassDescription": {
      "identifier": "schemas.types.ClassDescription",
      "description": {
        "overall": "The ClassDescription class is a Pydantic BaseModel designed to encapsulate a comprehensive analysis of another Python class. It structures information into distinct fields: an overall summary, details about its init_method, a list of analyses for its methods, and its usage_context. This model serves as a standardized data structure for representing class-level documentation and analytical insights.",
        "init_method": {
          "description": "This class, being a Pydantic BaseModel, implicitly generates its constructor. It initializes an instance of ClassDescription by accepting values for its defined fields: overall, init_method, methods, and usage_context. These fields are validated against their respective types upon instantiation.",
          "parameters": [
            {
              "name": "overall",
              "type": "str",
              "description": "A high-level summary of the class's purpose."
            },
            {
              "name": "init_method",
              "type": "ConstructorDescription",
              "description": "Details about the class's constructor."
            },
            {
              "name": "methods",
              "type": "List[FunctionAnalysis]",
              "description": "A list of analyses for each method within the class."
            },
            {
              "name": "usage_context",
              "type": "ClassContext",
              "description": "Information about where the class is used and its dependencies."
            }
          ]
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class does not explicitly declare any external functional dependencies within the provided context.",
          "instantiated_by": "The specific instantiation points for this class are not provided in the current context."
        }
      },
      "error": null
    },
    "schemas.types.ClassAnalysis": {
      "identifier": "schemas.types.ClassAnalysis",
      "description": {
        "overall": "The ClassAnalysis class serves as the root Pydantic model for structuring the comprehensive analysis of a Python class. It encapsulates the class's unique identifier, a detailed ClassDescription object containing its constructor and method analyses, and an optional field to report any errors encountered during the analysis process. This model is designed to provide a standardized, machine-readable output for class analysis.",
        "init_method": {
          "description": "This class does not explicitly define an __init__ method. Pydantic's BaseModel handles the initialization of its fields based on the provided type hints, automatically creating an initializer that accepts keyword arguments corresponding to its defined fields.",
          "parameters": []
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class does not explicitly list any external functional dependencies.",
          "instantiated_by": "The direct instantiation points for this class are not specified in the provided context."
        }
      },
      "error": null
    },
    "schemas.types.CallInfo": {
      "identifier": "schemas.types.CallInfo",
      "description": {
        "overall": "The CallInfo class is a Pydantic BaseModel designed to represent a specific call event within a system, typically used by a relationship analyzer. It encapsulates essential details about a call, such as the file and line number where it occurred, the name of the calling function, and the mode of the caller (e.g., method, function, module). This class serves as a structured data container for call event information.",
        "init_method": {
          "description": "As a Pydantic BaseModel, CallInfo's constructor is automatically generated. It initializes an instance of CallInfo by validating and assigning values to its fields: file, function, mode, and line. This allows for easy creation of CallInfo objects from dictionaries or keyword arguments, ensuring data integrity according to the defined types.",
          "parameters": [
            {
              "name": "file",
              "type": "str",
              "description": "The path to the file where the call event originated."
            },
            {
              "name": "function",
              "type": "str",
              "description": "The name of the function or method that initiated the call."
            },
            {
              "name": "mode",
              "type": "str",
              "description": "The type of the calling entity, such as 'method', 'function', or 'module'."
            },
            {
              "name": "line",
              "type": "int",
              "description": "The line number within the file where the call event is located."
            }
          ]
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class has no explicit external dependencies beyond its base class, pydantic.BaseModel.",
          "instantiated_by": "There are no explicit instantiation points provided for this class in the given context."
        }
      },
      "error": null
    },
    "schemas.types.FunctionContextInput": {
      "identifier": "schemas.types.FunctionContextInput",
      "description": {
        "overall": "The FunctionContextInput class is a Pydantic BaseModel designed to encapsulate structured context relevant for analyzing a specific function. It serves as a data container, defining the expected format for input data related to function call analysis. This class primarily holds information about the functions or methods that the target function calls, and the entities that call the target function itself.",
        "init_method": {
          "description": "This class does not define an explicit `__init__` method. It inherits from `pydantic.BaseModel`, and its initialization is handled implicitly by Pydantic, which constructs instances based on the provided `calls` and `called_by` fields.",
          "parameters": []
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class does not explicitly list any external functional dependencies within its provided context.",
          "instantiated_by": "The specific points where this class is instantiated are not provided in the current context."
        }
      },
      "error": null
    },
    "schemas.types.FunctionAnalysisInput": {
      "identifier": "schemas.types.FunctionAnalysisInput",
      "description": {
        "overall": "The FunctionAnalysisInput class is a Pydantic BaseModel designed to standardize the input data structure for generating a FunctionAnalysis object. It serves as a data transfer object, ensuring that all necessary components\u2014such as the function's identifier, its source code, relevant imports, and contextual information\u2014are present and correctly typed before analysis proceeds. This class facilitates robust data validation and clear communication between different parts of a larger system focused on code analysis.",
        "init_method": {
          "description": "This class does not explicitly define an __init__ method. As a Pydantic BaseModel, its constructor is implicitly generated to accept and validate the fields `mode`, `identifier`, `source_code`, `imports`, and `context`.",
          "parameters": [
            {
              "name": "mode",
              "type": "Literal[\"function_analysis\"]",
              "description": "Specifies the analysis mode, which must be 'function_analysis'."
            },
            {
              "name": "identifier",
              "type": "str",
              "description": "The unique name or identifier of the function to be analyzed."
            },
            {
              "name": "source_code",
              "type": "str",
              "description": "The raw source code of the function."
            },
            {
              "name": "imports",
              "type": "List[str]",
              "description": "A list of import statements relevant to the function's context."
            },
            {
              "name": "context",
              "type": "FunctionContextInput",
              "description": "Additional contextual information required for the function analysis."
            }
          ]
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class does not explicitly list external functional dependencies within the provided context.",
          "instantiated_by": "The instantiation points for this class are not specified in the provided context."
        }
      },
      "error": null
    },
    "schemas.types.MethodContextInput": {
      "identifier": "schemas.types.MethodContextInput",
      "description": {
        "overall": "The `MethodContextInput` class is a Pydantic BaseModel designed to encapsulate structured context information for individual methods within a larger system. It defines fields to store a method's unique identifier, a list of other functions or methods it calls, a list of entities that call it, its arguments, and its docstring. This class acts as a data schema for representing the operational context and relationships of a method.",
        "init_method": {
          "description": "The `__init__` method for `MethodContextInput` is implicitly generated by Pydantic's BaseModel. It handles the validation and assignment of the provided fields (identifier, calls, called_by, args, docstring) to the instance attributes upon object creation, ensuring data integrity according to the defined types.",
          "parameters": [
            {
              "name": "identifier",
              "type": "str",
              "description": "A unique string identifier for the method."
            },
            {
              "name": "calls",
              "type": "List[str]",
              "description": "A list of identifiers for other methods, classes, or functions that this method calls."
            },
            {
              "name": "called_by",
              "type": "List[CallInfo]",
              "description": "A list of `CallInfo` objects indicating where this method is invoked."
            },
            {
              "name": "args",
              "type": "List[str]",
              "description": "A list of argument names that the method accepts."
            },
            {
              "name": "docstring",
              "type": "Optional[str]",
              "description": "The docstring content of the method, if available."
            }
          ]
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class does not explicitly list any external dependencies in the provided context.",
          "instantiated_by": "The instantiation points for this class are not specified in the provided context."
        }
      },
      "error": null
    },
    "schemas.types.ClassContextInput": {
      "identifier": "schemas.types.ClassContextInput",
      "description": {
        "overall": "The ClassContextInput class is a Pydantic BaseModel designed to encapsulate structured contextual information for the analysis of a Python class. It serves as a data container, defining the expected format for input data that describes a class's dependencies, where it is instantiated, and detailed context for its individual methods. This model ensures consistency and validation for the data used in class analysis workflows.",
        "init_method": {
          "description": "This class does not explicitly define an __init__ method. Pydantic's BaseModel automatically generates a constructor that accepts keyword arguments corresponding to its fields: dependencies, instantiated_by, and method_context.",
          "parameters": [
            {
              "name": "dependencies",
              "type": "List[str]",
              "description": "A list of external dependencies relevant to the class being analyzed."
            },
            {
              "name": "instantiated_by",
              "type": "List[CallInfo]",
              "description": "A list of CallInfo objects indicating where the class being analyzed is instantiated."
            },
            {
              "name": "method_context",
              "type": "List[MethodContextInput]",
              "description": "A list of MethodContextInput objects providing specific context for each method within the class being analyzed."
            }
          ]
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class does not explicitly list any external functional dependencies within the provided context.",
          "instantiated_by": "The provided context does not specify any locations where this class is instantiated."
        }
      },
      "error": null
    },
    "schemas.types.ClassAnalysisInput": {
      "identifier": "schemas.types.ClassAnalysisInput",
      "description": {
        "overall": "The ClassAnalysisInput class is a Pydantic model designed to define the structured input required for generating a ClassAnalysis object. It serves as a data validation and serialization schema, ensuring that all necessary components like the analysis mode, class identifier, source code, import statements, and contextual information are present and correctly typed before proceeding with class analysis.",
        "init_method": {
          "description": "The ClassAnalysisInput class does not explicitly define an `__init__` method. As a Pydantic BaseModel, its initialization is handled automatically by Pydantic, which validates and assigns values to its fields based on the provided arguments during instantiation.",
          "parameters": []
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class does not explicitly list any external functional dependencies.",
          "instantiated_by": "The specific points of instantiation for this class are not provided in the context."
        }
      },
      "error": null
    }
  }
}