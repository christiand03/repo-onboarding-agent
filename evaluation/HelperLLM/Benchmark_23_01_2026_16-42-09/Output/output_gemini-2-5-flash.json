{
  "functions": {
    "backend.AST_Schema.path_to_module": {
      "identifier": "backend.AST_Schema.path_to_module",
      "description": {
        "overall": "This function converts a given file path into its corresponding Python module path. It first determines the relative path of the file with respect to a specified project root. If a ValueError occurs during this process, it falls back to using just the base name of the file. The function then removes the '.py' extension if present and replaces all operating system path separators with dots. Finally, it handles '__init__' modules by removing the '.__init__' suffix to yield the package path.",
        "parameters": [
          {
            "name": "filepath",
            "type": "str",
            "description": "The absolute or relative path to the Python file."
          },
          {
            "name": "project_root",
            "type": "str",
            "description": "The root directory of the project, used to calculate the relative path."
          }
        ],
        "returns": [
          {
            "name": "module_path",
            "type": "str",
            "description": "The converted Python module path (e.g., 'my_package.my_module')."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not explicitly called by any other functions in the provided context."
        }
      },
      "error": null
    },
    "backend.File_Dependency.build_file_dependency_graph": {
      "identifier": "backend.File_Dependency.build_file_dependency_graph",
      "description": {
        "overall": "This function constructs a NetworkX directed graph representing the file-level import dependencies within a given Python Abstract Syntax Tree (AST). It initializes a FileDependencyGraph visitor with the target filename and repository root. The visitor then traverses the AST to identify import statements. Finally, the function iterates through the collected import dependencies to populate the NetworkX graph with nodes for files and edges indicating import relationships, returning the completed dependency graph.",
        "parameters": [
          {
            "name": "filename",
            "type": "str",
            "description": "The path to the file whose dependencies are being analyzed."
          },
          {
            "name": "tree",
            "type": "AST",
            "description": "The Abstract Syntax Tree (AST) of the file to be analyzed for import dependencies."
          },
          {
            "name": "repo_root",
            "type": "str",
            "description": "The root directory of the repository, used for resolving file paths and dependencies."
          }
        ],
        "returns": [
          {
            "name": "graph",
            "type": "nx.DiGraph",
            "description": "A directed graph where nodes represent files and edges indicate import dependencies between them."
          }
        ],
        "usage_context": {
          "calls": "This function calls backend.File_Dependency.FileDependencyGraph.",
          "called_by": "This function is not explicitly called by any other functions in the provided context."
        }
      },
      "error": null
    },
    "backend.File_Dependency.build_repository_graph": {
      "identifier": "backend.File_Dependency.build_repository_graph",
      "description": {
        "overall": "This function constructs a comprehensive dependency graph for a given Git repository. It iterates through all Python files found within the repository, parsing each file's content into an Abstract Syntax Tree (AST). For every Python file, it generates a file-specific dependency graph using `build_file_dependency_graph`. These individual file graphs are then merged into a single, global NetworkX directed graph, which is ultimately returned.",
        "parameters": [
          {
            "name": "repository",
            "type": "GitRepository",
            "description": "The Git repository object from which to extract and analyze files for dependencies."
          }
        ],
        "returns": [
          {
            "name": "global_graph",
            "type": "nx.DiGraph",
            "description": "A NetworkX directed graph representing the aggregated file dependencies across the entire repository."
          }
        ],
        "usage_context": {
          "calls": "This function calls backend.File_Dependency.build_file_dependency_graph.",
          "called_by": "This function is not explicitly called by any other functions in the provided context."
        }
      },
      "error": null
    },
    "backend.File_Dependency.get_all_temp_files": {
      "identifier": "backend.File_Dependency.get_all_temp_files",
      "description": {
        "overall": "This function identifies and collects all Python files within a specified directory and its subdirectories. It first resolves the provided directory path to an absolute path. Then, it recursively searches for all files with a '.py' extension. Finally, it returns a list of these file paths, each relative to the initial root directory.",
        "parameters": [
          {
            "name": "directory",
            "type": "str",
            "description": "The path to the root directory from which to start the search for Python files."
          }
        ],
        "returns": [
          {
            "name": "all_files",
            "type": "list[Path]",
            "description": "A list of 'Path' objects, where each path represents a Python file found within the specified directory, relative to the root directory."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not explicitly called by any other functions in the provided context."
        }
      },
      "error": null
    },
    "backend.HelperLLM.main_orchestrator": {
      "identifier": "backend.HelperLLM.main_orchestrator",
      "description": {
        "overall": "This function serves as a dummy data and processing loop for testing the LLMHelper class. It defines pre-computed analysis examples for several functions and a class, then initializes an LLMHelper instance. The function simulates generating documentation for these examples and processes the results, logging the outcome and printing the final aggregated documentation.",
        "parameters": [],
        "returns": [],
        "usage_context": {
          "calls": "This function calls backend.HelperLLM.LLMHelper, schemas.types.ClassAnalysisInput, and schemas.types.ClassContextInput.",
          "called_by": "This function is called by no other functions."
        }
      },
      "error": null
    },
    "backend.callgraph.make_safe_dot": {
      "identifier": "backend.callgraph.make_safe_dot",
      "description": {
        "overall": "This function takes a NetworkX directed graph and an output file path, then generates a DOT file with 'safe' node names. It creates a copy of the input graph and renames all nodes to simple identifiers like 'n0', 'n1', etc., to prevent issues with special characters in the DOT format. The original node names are preserved by assigning them as 'label' attributes to the newly named nodes. Finally, the modified graph is written to the specified output path as a DOT file.",
        "parameters": [
          {
            "name": "graph",
            "type": "nx.DiGraph",
            "description": "The NetworkX directed graph to be processed and written to a DOT file."
          },
          {
            "name": "out_path",
            "type": "str",
            "description": "The file path where the safe DOT representation of the graph will be saved."
          }
        ],
        "returns": [],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not explicitly called by any other functions in the provided context."
        }
      },
      "error": null
    },
    "backend.callgraph.build_filtered_callgraph": {
      "identifier": "backend.callgraph.build_filtered_callgraph",
      "description": {
        "overall": "This function constructs a directed call graph for a given Git repository, focusing exclusively on functions identified as 'self-written'. It first iterates through all Python files in the repository to parse their Abstract Syntax Trees (ASTs) and identify all locally defined functions. Subsequently, it builds a NetworkX directed graph, adding edges only between functions where both the caller and the callee are part of the identified 'self-written' set. The function leverages an internal 'CallGraph' visitor to extract function definitions and call relationships from the ASTs.",
        "parameters": [
          {
            "name": "repo",
            "type": "GitRepository",
            "description": "The Git repository object from which to extract files and build the call graph."
          }
        ],
        "returns": [
          {
            "name": "global_graph",
            "type": "nx.DiGraph",
            "description": "A directed graph representing the call relationships between self-written functions within the repository."
          }
        ],
        "usage_context": {
          "calls": "This function calls backend.callgraph.CallGraph.",
          "called_by": "This function is not explicitly called by any other functions in the provided context."
        }
      },
      "error": null
    },
    "backend.converter.wrap_cdata": {
      "identifier": "backend.converter.wrap_cdata",
      "description": {
        "overall": "This function takes a string `content` as input and encloses it within XML CDATA tags. It prepends \"<![CDATA[\\n\" and appends \"\\n]]>\" to the provided content, effectively escaping special characters within the content for XML parsing. The function directly returns this newly formatted string, ensuring the content is treated as character data by an XML parser.",
        "parameters": [
          {
            "name": "content",
            "type": "str",
            "description": "The string content to be wrapped in CDATA tags."
          }
        ],
        "returns": [
          {
            "name": "wrapped_content",
            "type": "str",
            "description": "A string containing the original content wrapped within CDATA tags, including leading and trailing newlines."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not explicitly called by any other functions in the provided context."
        }
      },
      "error": null
    },
    "backend.converter.extract_output_content": {
      "identifier": "backend.converter.extract_output_content",
      "description": {
        "overall": "The extract_output_content function processes a collection of notebook output objects to extract their content, handling both text and images. It iterates through each output, identifying its type. For display data or execution results, it prioritizes extracting PNG images, falling back to JPEG, and stores them in a provided image_list while generating XML placeholders. If no image is present, it extracts plain text. Stream outputs are appended directly, and error outputs are formatted as strings. The function ultimately returns a list of these extracted text snippets or image placeholders.",
        "parameters": [
          {
            "name": "outputs",
            "type": "iterable",
            "description": "An iterable collection of output objects, typically from a notebook execution, which can contain various data types like text, images, or error information."
          },
          {
            "name": "image_list",
            "type": "list",
            "description": "A mutable list that is populated with dictionaries, each containing Base64 encoded image data and its MIME type. It is used to store images found during processing and generate corresponding XML placeholders."
          }
        ],
        "returns": [
          {
            "name": "extracted_xml_snippets",
            "type": "list[str]",
            "description": "A list containing strings that represent either extracted plain text, formatted error messages, or XML placeholders for images that were stored in the image_list."
          }
        ],
        "usage_context": {
          "calls": "This function calls backend.converter.process_image.",
          "called_by": "This function is not explicitly called by any other functions in the provided context."
        }
      },
      "error": null
    },
    "backend.converter.process_image": {
      "identifier": "backend.converter.process_image",
      "description": {
        "overall": "This function is designed to process image data based on a given MIME type. It attempts to retrieve base64 encoded image data from an external `data` structure, clean it by removing newline characters, and then store it in an external `image_list`. Upon successful processing, it constructs and returns an HTML-like placeholder string for the image. If an error occurs during processing, it returns an error message. If the specified `mime_type` is not found in the `data` structure, the function returns `None`. However, the variables `data` and `image_list` are not defined within the function's scope, making its full execution context and behavior dependent on external, undefined variables.",
        "parameters": [
          {
            "name": "mime_type",
            "type": "str",
            "description": "The MIME type string used to identify and retrieve the image data to be processed."
          }
        ],
        "returns": [
          {
            "name": "image_placeholder_tag",
            "type": "str",
            "description": "An HTML-like string representing a placeholder for the processed image, including its index and MIME type, returned upon successful processing."
          },
          {
            "name": "error_message",
            "type": "str",
            "description": "An error message string, returned if an exception occurs during the image processing or decoding."
          },
          {
            "name": "None",
            "type": "None",
            "description": "Indicates that no image data was found for the given MIME type in the external `data` structure."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": "The function `process_image` references external variables `data` and `image_list` which are not defined within its scope or passed as arguments. Without their definition, the function's behavior cannot be fully analyzed."
    },
    "backend.converter.convert_notebook_to_xml": {
      "identifier": "backend.converter.convert_notebook_to_xml",
      "description": {
        "overall": "This function converts the content of a Jupyter notebook, provided as a string, into an XML representation. It first attempts to parse the input string as a notebook format. If parsing fails, it returns an error message. It then iterates through each cell, converting markdown cells directly to XML and processing code cells by wrapping their source in CDATA. For code cells with outputs, it extracts content and images, then includes the processed output as an XML cell. Finally, it returns the concatenated XML parts and any extracted images.",
        "parameters": [
          {
            "name": "file_content",
            "type": "str",
            "description": "The raw content of a Jupyter notebook as a string, expected to be in JSON format."
          }
        ],
        "returns": [
          {
            "name": "xml_output_and_images",
            "type": "tuple[str, list]",
            "description": "A tuple where the first element is a string containing the XML representation of the notebook cells (or an error message if parsing failed), and the second element is a list of extracted image data (or an empty list)."
          }
        ],
        "usage_context": {
          "calls": "This function calls backend.converter.extract_output_content and backend.converter.wrap_cdata.",
          "called_by": "This function is not explicitly called by any other functions in the provided context."
        }
      },
      "error": null
    },
    "backend.converter.process_repo_notebooks": {
      "identifier": "backend.converter.process_repo_notebooks",
      "description": {
        "overall": "This function iterates through a collection of repository files, identifying those that are Jupyter notebooks by their '.ipynb' extension. For each identified notebook, it logs the processing and then invokes the 'convert_notebook_to_xml' function to transform the notebook's content into an XML representation and extract any associated images. The function aggregates these conversion results into a dictionary, mapping each notebook's path to its corresponding XML output and extracted images. Finally, it returns this dictionary containing all processed notebook data.",
        "parameters": [
          {
            "name": "repo_files",
            "type": "list[object]",
            "description": "An iterable collection of repository file objects. Each object is expected to have a 'path' attribute (str) for file identification and a 'content' attribute (str) representing the file's content."
          }
        ],
        "returns": [
          {
            "name": "results",
            "type": "dict[str, dict[str, str | list]]",
            "description": "A dictionary where keys are the paths of the processed notebooks (str) and values are dictionaries. Each inner dictionary contains 'xml' (str) representing the notebook's XML conversion and 'images' (list) which are any extracted images."
          }
        ],
        "usage_context": {
          "calls": "This function calls backend.converter.convert_notebook_to_xml.",
          "called_by": "This function is not explicitly called by any other functions in the provided context."
        }
      },
      "error": null
    },
    "backend.main.create_savings_chart": {
      "identifier": "backend.main.create_savings_chart",
      "description": {
        "overall": "This function generates a bar chart to visually compare two token counts: JSON tokens and TOON tokens. It calculates and displays a savings percentage in the chart's title. The chart is configured with specific labels, values, and colors, and includes numerical values displayed above each bar for clarity. Finally, the generated chart is saved to a specified output file path and the plot is closed.",
        "parameters": [
          {
            "name": "json_tokens",
            "type": "int",
            "description": "The number of tokens associated with the JSON format."
          },
          {
            "name": "toon_tokens",
            "type": "int",
            "description": "The number of tokens associated with the TOON format."
          },
          {
            "name": "savings_percent",
            "type": "float",
            "description": "The calculated percentage of savings to be displayed in the chart's title."
          },
          {
            "name": "output_path",
            "type": "str",
            "description": "The file path where the generated bar chart image will be saved."
          }
        ],
        "returns": [],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "backend.main.calculate_net_time": {
      "identifier": "backend.main.calculate_net_time",
      "description": {
        "overall": "This function calculates the effective processing time by subtracting estimated sleep times, which are introduced for rate limiting, from the total duration. It specifically applies this logic for models whose names start with \"gemini-\", otherwise returning the total duration directly. It handles cases where no items are processed or where the calculated net time would be negative, ensuring a non-negative result.",
        "parameters": [
          {
            "name": "start_time",
            "type": "datetime.datetime",
            "description": "The starting timestamp of the operation."
          },
          {
            "name": "end_time",
            "type": "datetime.datetime",
            "description": "The ending timestamp of the operation."
          },
          {
            "name": "total_items",
            "type": "int",
            "description": "The total number of items processed."
          },
          {
            "name": "batch_size",
            "type": "int",
            "description": "The number of items processed per batch."
          },
          {
            "name": "model_name",
            "type": "str",
            "description": "The name of the model being used, which determines if sleep time calculation is applied."
          }
        ],
        "returns": [
          {
            "name": "net_time",
            "type": "float",
            "description": "The calculated net processing time in a numeric format (e.g., seconds), excluding estimated rate-limit-induced sleep."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not explicitly called by any other functions in the provided context."
        }
      },
      "error": null
    },
    "backend.main.main_workflow": {
      "identifier": "backend.main.main_workflow",
      "description": {
        "overall": "The main_workflow function orchestrates a comprehensive analysis pipeline for a given GitHub repository URL. It begins by parsing input for API keys and model configurations, then clones the specified repository. The workflow extracts basic project information, constructs a file tree, performs relationship analysis, and builds an Abstract Syntax Tree (AST) schema, which is subsequently enriched with relationship data. It then prepares and dispatches analysis tasks for individual functions and classes to a 'Helper LLM', before consolidating these results and generating a final report using a 'Main LLM'. The function concludes by saving the generated report and performance metrics, including token savings, to designated output directories.",
        "parameters": [
          {
            "name": "input",
            "type": "str",
            "description": "The initial input string, expected to contain a GitHub repository URL for analysis."
          },
          {
            "name": "api_keys",
            "type": "dict",
            "description": "A dictionary containing API keys for various LLM services (e.g., Gemini, GPT, SCADSLLM) and base URLs for services like Ollama."
          },
          {
            "name": "model_names",
            "type": "dict",
            "description": "A dictionary specifying the names of the 'helper' and 'main' LLM models to be used in the workflow."
          },
          {
            "name": "status_callback",
            "type": "callable",
            "description": "An optional function to be called with status messages to provide real-time updates on the workflow's progress."
          }
        ],
        "returns": [
          {
            "name": "report",
            "type": "str",
            "description": "The comprehensive final report generated by the Main LLM based on the repository analysis."
          },
          {
            "name": "metrics",
            "type": "dict",
            "description": "A dictionary containing various performance statistics and model information, including execution times for Helper and Main LLMs, and token savings data."
          }
        ],
        "usage_context": {
          "calls": "This function calls backend.AST_Schema.ASTAnalyzer, backend.AST_Schema.ASTAnalyzer.analyze_repository, backend.AST_Schema.ASTAnalyzer.merge_relationship_data, backend.HelperLLM.LLMHelper, backend.HelperLLM.LLMHelper.generate_for_classes, backend.HelperLLM.LLMHelper.generate_for_functions, backend.MainLLM.MainLLM, backend.MainLLM.MainLLM.call_llm, backend.basic_info.ProjektInfoExtractor, backend.basic_info.ProjektInfoExtractor.extrahiere_info, backend.getRepo.GitRepository, backend.main.calculate_net_time, backend.main.create_savings_chart, backend.main.update_status, backend.relationship_analyzer.ProjectAnalyzer, backend.relationship_analyzer.ProjectAnalyzer.analyze, backend.relationship_analyzer.ProjectAnalyzer.get_raw_relationships, schemas.types.ClassAnalysisInput, schemas.types.ClassContextInput, schemas.types.FunctionAnalysisInput, schemas.types.FunctionContextInput, and schemas.types.MethodContextInput.",
          "called_by": "This function is not explicitly called by any other functions in the provided context."
        }
      },
      "error": null
    },
    "backend.main.update_status": {
      "identifier": "backend.main.update_status",
      "description": {
        "overall": "This function, `update_status`, takes a single message as input. It first checks if a `status_callback` function is defined and, if so, invokes it with the provided message. Subsequently, it logs the message at the INFO level using the `logging` module. The primary purpose is to standardize status updates and ensure they are logged.",
        "parameters": [
          {
            "name": "msg",
            "type": "str",
            "description": "The message string to be processed for status updates and logging."
          }
        ],
        "returns": [],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is called by no other functions."
        }
      },
      "error": null
    },
    "backend.main.notebook_workflow": {
      "identifier": "backend.main.notebook_workflow",
      "description": {
        "overall": "The notebook_workflow function orchestrates the end-to-end process of analyzing Jupyter notebooks from a specified GitHub repository. It begins by cloning the repository and extracting a URL from the input. Subsequently, it processes all found notebooks into an XML-like structure and gathers basic project information. The function then utilizes a configured Large Language Model (LLM) to generate individual reports for each notebook, dynamically selecting the LLM based on the model name. Finally, it consolidates these reports into a single markdown file, saves it, and returns the combined report along with execution metrics.",
        "parameters": [
          {
            "name": "input",
            "type": "str",
            "description": "The primary input string, expected to contain a GitHub repository URL from which notebooks will be analyzed."
          },
          {
            "name": "api_keys",
            "type": "dict",
            "description": "A dictionary holding various API keys necessary for authenticating with different Large Language Models (LLMs)."
          },
          {
            "name": "model",
            "type": "str",
            "description": "Specifies the name of the Large Language Model to be used for notebook analysis, influencing API key selection and base URL."
          },
          {
            "name": "status_callback",
            "type": "callable | None",
            "description": "An optional callback function that can be provided to receive status updates during the workflow execution."
          }
        ],
        "returns": [
          {
            "name": "report",
            "type": "str",
            "description": "The comprehensive, concatenated markdown report generated from the analysis of all notebooks in the repository."
          },
          {
            "name": "metrics",
            "type": "dict",
            "description": "A dictionary containing various time-based and token-related metrics detailing the execution performance of the workflow."
          }
        ],
        "usage_context": {
          "calls": "This function calls backend.MainLLM.MainLLM, backend.MainLLM.MainLLM.call_llm, backend.basic_info.ProjektInfoExtractor, backend.basic_info.ProjektInfoExtractor.extrahiere_info, backend.converter.process_repo_notebooks, backend.getRepo.GitRepository, backend.main.gemini_payload, and backend.main.update_status.",
          "called_by": "This function is not explicitly called by any other functions in the provided context."
        }
      },
      "error": null
    },
    "backend.main.gemini_payload": {
      "identifier": "backend.main.gemini_payload",
      "description": {
        "overall": "This function constructs a multimodal payload suitable for a Gemini-like AI model. It begins by serializing basic contextual information and the notebook path into an initial JSON string. The core logic involves parsing an XML content string to identify and extract image placeholders using regular expressions. Text segments from the XML are added as 'text' entries, while identified images are retrieved from the 'images' list, converted into base64 data URLs, and added as 'image_url' entries. The function ensures all textual and image components are correctly structured into a list of content blocks for the final payload.",
        "parameters": [
          {
            "name": "basic_info",
            "type": "dict",
            "description": "A dictionary containing basic contextual information relevant to the notebook."
          },
          {
            "name": "nb_path",
            "type": "str",
            "description": "The file path of the current notebook being processed."
          },
          {
            "name": "xml_content",
            "type": "str",
            "description": "The XML string representing the notebook's structure, which may include image placeholders."
          },
          {
            "name": "images",
            "type": "list[dict]",
            "description": "A list of dictionaries, where each dictionary contains 'data' (base64 string) and 'mime' type for an image referenced in the XML."
          }
        ],
        "returns": [
          {
            "name": "payload_content",
            "type": "list[dict]",
            "description": "A list of dictionaries, each formatted as a content block (either 'text' or 'image_url') suitable for a Gemini API payload."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "backend.relationship_analyzer.path_to_module": {
      "identifier": "backend.relationship_analyzer.path_to_module",
      "description": {
        "overall": "This function converts a given file system path into its corresponding Python module path string. It first attempts to determine the path relative to a specified project root. If that fails, it uses the base name of the file. It then strips the '.py' extension if present, replaces directory separators with dots, and finally removes the '.__init__' suffix if the module represents a package initialization file, returning the resulting module path.",
        "parameters": [
          {
            "name": "filepath",
            "type": "str",
            "description": "The absolute or relative path to a Python file."
          },
          {
            "name": "project_root",
            "type": "str",
            "description": "The root directory of the project, used to calculate the relative path."
          }
        ],
        "returns": [
          {
            "name": "module_path",
            "type": "str",
            "description": "The Python module path string derived from the input filepath."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not explicitly called by any other functions in the provided context."
        }
      },
      "error": null
    },
    "database.db.encrypt_text": {
      "identifier": "database.db.encrypt_text",
      "description": {
        "overall": "This function encrypts a given string using a `cipher_suite` object. It first checks if the input text is empty or if `cipher_suite` is not initialized; in such cases, it returns the original text without encryption. Otherwise, it strips whitespace from the text, encodes it to bytes, encrypts it using `cipher_suite.encrypt`, and then decodes the result back into a string before returning it.",
        "parameters": [
          {
            "name": "text",
            "type": "str",
            "description": "The string to be encrypted."
          }
        ],
        "returns": [
          {
            "name": "encrypted_text",
            "type": "str",
            "description": "The encrypted string, or the original string if encryption was skipped due to empty input or missing cipher suite."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not explicitly called by any other functions in the provided context."
        }
      },
      "error": null
    },
    "database.db.decrypt_text": {
      "identifier": "database.db.decrypt_text",
      "description": {
        "overall": "This function attempts to decrypt a given text string using a global `cipher_suite` object. It first checks if the input text or the `cipher_suite` is empty, returning the original text if either condition is true. If decryption proceeds, it strips whitespace, encodes the text, decrypts it, and then decodes the result back to a string. A try-except block handles any exceptions during the decryption process, returning the original text in case of an error.",
        "parameters": [
          {
            "name": "text",
            "type": "str",
            "description": "The string value to be decrypted."
          }
        ],
        "returns": [
          {
            "name": "decrypted_or_original_text",
            "type": "str",
            "description": "The decrypted string if successful, or the original string if decryption is skipped or an error occurs."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not explicitly called by any other functions in the provided context."
        }
      },
      "error": null
    },
    "database.db.insert_user": {
      "identifier": "database.db.insert_user",
      "description": {
        "overall": "This function is responsible for creating a new user entry in the database. It takes a username, full name, and a plain-text password as input. The password is then hashed using `stauth.Hasher.hash` before being stored. A user document is constructed with the provided details, including empty strings for various API keys, and then inserted into the `dbusers` collection.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The unique identifier for the user, which will also serve as the document's `_id`."
          },
          {
            "name": "name",
            "type": "str",
            "description": "The full name of the user."
          },
          {
            "name": "password",
            "type": "str",
            "description": "The plain-text password provided by the user, which will be hashed before storage."
          }
        ],
        "returns": [
          {
            "name": "inserted_id",
            "type": "Any",
            "description": "The `_id` of the newly inserted user document, which corresponds to the provided username."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not explicitly called by any other functions in the provided context."
        }
      },
      "error": null
    },
    "database.db.fetch_all_users": {
      "identifier": "database.db.fetch_all_users",
      "description": {
        "overall": "This function, `fetch_all_users`, is designed to retrieve all user records from a database collection. It executes a `find()` operation on the `dbusers` collection, which is presumed to be a database client or collection object. The results, typically a cursor, are then converted into a standard Python list before being returned. This provides a snapshot of all user data stored in that collection.",
        "parameters": [],
        "returns": [
          {
            "name": "users",
            "type": "list",
            "description": "A list containing all user documents or records retrieved from the 'dbusers' collection."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not explicitly called by any other functions in the provided context."
        }
      },
      "error": null
    },
    "database.db.fetch_user": {
      "identifier": "database.db.fetch_user",
      "description": {
        "overall": "The `fetch_user` function is designed to retrieve a single user record from a database collection. It takes a username as input and uses it to query the `dbusers` collection. The function specifically searches for a document where the `_id` field matches the provided username, returning the first matching entry found.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The unique identifier (username) of the user to be fetched from the database."
          }
        ],
        "returns": [
          {
            "name": "user_document",
            "type": "dict | None",
            "description": "The user document as a dictionary if a matching user is found, otherwise None."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not explicitly called by any other functions in the provided context."
        }
      },
      "error": null
    },
    "database.db.update_user_name": {
      "identifier": "database.db.update_user_name",
      "description": {
        "overall": "This function updates the 'name' field for a specific user in the 'dbusers' collection. It identifies the user document by matching the provided 'username' with the '_id' field. The function then sets the 'name' field of the matched document to the 'new_name' value. It returns the count of documents that were successfully modified by this operation.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The unique identifier of the user, which corresponds to the '_id' field in the database."
          },
          {
            "name": "new_name",
            "type": "str",
            "description": "The new name to be assigned to the user."
          }
        ],
        "returns": [
          {
            "name": "modified_count",
            "type": "int",
            "description": "The number of documents that were modified by the update operation."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.update_gemini_key": {
      "identifier": "database.db.update_gemini_key",
      "description": {
        "overall": "This function updates a user's Gemini API key in the database. It takes a username and a new Gemini API key as input. The provided API key is first stripped of any leading or trailing whitespace and then encrypted using an external encryption utility. Finally, the function updates the 'gemini_api_key' field for the specified user in the 'dbusers' collection with the newly encrypted key. It returns the count of documents that were modified by this operation.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The unique identifier for the user whose Gemini API key needs to be updated. This is used as the document's '_id' in the database."
          },
          {
            "name": "gemini_api_key",
            "type": "str",
            "description": "The new Gemini API key to be stored for the user. It will be stripped of whitespace and then encrypted before storage."
          }
        ],
        "returns": [
          {
            "name": "modified_count",
            "type": "int",
            "description": "The number of documents that were modified by the update operation, typically 0 or 1."
          }
        ],
        "usage_context": {
          "calls": "This function calls database.db.encrypt_text.",
          "called_by": "This function is not explicitly called by any other functions in the provided context."
        }
      },
      "error": null
    },
    "database.db.update_gpt_key": {
      "identifier": "database.db.update_gpt_key",
      "description": {
        "overall": "The `update_gpt_key` function is designed to securely update a user's GPT API key within the database. It accepts a username and the new GPT API key as input. The provided API key is first processed by stripping any leading or trailing whitespace, then it is encrypted using a dedicated encryption function. Finally, the function updates the `gpt_api_key` field for the specified user in the `dbusers` collection with the encrypted key. It returns the count of documents that were modified by this operation.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The unique identifier for the user whose GPT API key is to be updated."
          },
          {
            "name": "gpt_api_key",
            "type": "str",
            "description": "The new GPT API key to be stored for the user. This key will be stripped of whitespace and encrypted before storage."
          }
        ],
        "returns": [
          {
            "name": "modified_count",
            "type": "int",
            "description": "The number of documents modified in the database, indicating whether the user's GPT API key was successfully updated."
          }
        ],
        "usage_context": {
          "calls": "This function calls database.db.encrypt_text.",
          "called_by": "This function is not called by any other functions in the provided context."
        }
      },
      "error": null
    },
    "database.db.update_ollama_url": {
      "identifier": "database.db.update_ollama_url",
      "description": {
        "overall": "This function updates the Ollama base URL for a specific user in the database. It takes a username and a new Ollama base URL as input. The provided URL is first stripped of any leading or trailing whitespace before being stored. The function then performs an update operation on the 'dbusers' collection, setting the 'ollama_base_url' field for the user matching the given username. It returns the count of documents that were modified by this operation.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The unique identifier for the user whose Ollama URL is to be updated."
          },
          {
            "name": "ollama_base_url",
            "type": "str",
            "description": "The new base URL for Ollama, which will be stripped of leading/trailing whitespace before storage."
          }
        ],
        "returns": [
          {
            "name": "modified_count",
            "type": "int",
            "description": "The number of documents modified by the update operation. A value of 1 indicates success if the user exists and the URL was different, or 0 if the user exists but the URL was already the same."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not explicitly called by any other functions in the provided context."
        }
      },
      "error": null
    },
    "database.db.update_opensrc_key": {
      "identifier": "database.db.update_opensrc_key",
      "description": {
        "overall": "This function updates a user's Open Source API key in the database. It takes a username and the new API key as input. The provided API key is first stripped of any leading or trailing whitespace, then encrypted using the `encrypt_text` helper function. Finally, it updates the `opensrc_api_key` field for the specified user in the `dbusers` collection with the newly encrypted key. The function returns the count of documents that were modified by this operation.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The unique identifier for the user whose Open Source API key needs to be updated."
          },
          {
            "name": "opensrc_api_key",
            "type": "str",
            "description": "The new Open Source API key to be stored for the user."
          }
        ],
        "returns": [
          {
            "name": "modified_count",
            "type": "int",
            "description": "The number of documents modified by the update operation, typically 0 or 1."
          }
        ],
        "usage_context": {
          "calls": "This function calls database.db.encrypt_text.",
          "called_by": "This function is called by no other functions."
        }
      },
      "error": null
    },
    "database.db.update_opensrc_url": {
      "identifier": "database.db.update_opensrc_url",
      "description": {
        "overall": "This function updates the `opensrc_base_url` for a specific user in the database. It takes a username and a new base URL as input. The function uses `dbusers.update_one` to locate the user by their `_id` (which is the username) and sets the `opensrc_base_url` field to the provided URL after stripping any leading or trailing whitespace. It returns the count of modified documents.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The unique identifier for the user, used as the `_id` in the database."
          },
          {
            "name": "opensrc_base_url",
            "type": "str",
            "description": "The new base URL for opensource projects to be associated with the user. Leading/trailing whitespace will be removed before storage."
          }
        ],
        "returns": [
          {
            "name": "modified_count",
            "type": "int",
            "description": "The number of documents that were modified by the update operation. This will typically be 0 or 1."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not explicitly called by any other functions in the provided context."
        }
      },
      "error": null
    },
    "database.db.fetch_gemini_key": {
      "identifier": "database.db.fetch_gemini_key",
      "description": {
        "overall": "This function is designed to retrieve a user's Gemini API key from a database. It takes a username as input and queries the 'dbusers' collection to find a document matching that username. The function specifically projects the 'gemini_api_key' field. If a user document is found, it extracts and returns the 'gemini_api_key'; otherwise, it returns None.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The unique identifier for the user whose Gemini API key is to be fetched."
          }
        ],
        "returns": [
          {
            "name": "gemini_api_key",
            "type": "str | None",
            "description": "The Gemini API key associated with the provided username, or None if the user is not found or the key does not exist."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not explicitly called by any other functions in the provided context."
        }
      },
      "error": null
    },
    "database.db.fetch_ollama_url": {
      "identifier": "database.db.fetch_ollama_url",
      "description": {
        "overall": "This function retrieves the Ollama base URL for a specific user from a database. It queries the `dbusers` collection using the provided username as the document's `_id`. If a user document is found, it extracts and returns the `ollama_base_url` field. If no user is found, the function returns `None`.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username (which serves as the `_id`) of the user whose Ollama base URL is to be fetched."
          }
        ],
        "returns": [
          {
            "name": "ollama_base_url",
            "type": "str | None",
            "description": "The Ollama base URL associated with the user, or `None` if the user is not found in the database."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not explicitly called by any other functions in the provided context."
        }
      },
      "error": null
    },
    "database.db.fetch_gpt_key": {
      "identifier": "database.db.fetch_gpt_key",
      "description": {
        "overall": "This function retrieves the GPT API key for a specified username from a database collection named `dbusers`. It performs a database query to find a user document matching the provided username and then extracts the `gpt_api_key` field. If a user is found, the associated API key is returned; otherwise, it returns `None`.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username for which to fetch the GPT API key."
          }
        ],
        "returns": [
          {
            "name": "gpt_api_key",
            "type": "str | None",
            "description": "The GPT API key associated with the username, or None if the user is not found in the database."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not explicitly called by any other functions in the provided context."
        }
      },
      "error": null
    },
    "database.db.fetch_opensrc_key": {
      "identifier": "database.db.fetch_opensrc_key",
      "description": {
        "overall": "This function retrieves the 'opensrc_api_key' for a specified user from a database. It queries the 'dbusers' collection using the provided username as the document's '_id'. The function returns the 'opensrc_api_key' if a matching user is found; otherwise, it returns None. This is a read-only operation designed to fetch a specific user credential.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The unique identifier for the user whose 'opensrc_api_key' is to be fetched."
          }
        ],
        "returns": [
          {
            "name": "opensrc_api_key",
            "type": "str | None",
            "description": "The 'opensrc_api_key' associated with the provided username, or None if the user is not found in the database."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not explicitly called by any other functions in the provided context."
        }
      },
      "error": null
    },
    "database.db.fetch_opensrc_url": {
      "identifier": "database.db.fetch_opensrc_url",
      "description": {
        "overall": "This function, `fetch_opensrc_url`, is designed to retrieve a specific URL associated with a user from a database. It takes a username as input and queries the `dbusers` collection. The function searches for a document where the `_id` field matches the provided username. If a matching user document is found, it extracts and returns the value of the `opensrc_base_url` field. If no user is found, or if the `opensrc_base_url` field is not present, the function returns `None`.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The unique identifier for the user whose Open Source base URL is to be fetched."
          }
        ],
        "returns": [
          {
            "name": "opensrc_base_url",
            "type": "str | None",
            "description": "The Open Source base URL associated with the user, or None if the user is not found or the URL is not set."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not explicitly called by any other functions in the provided context."
        }
      },
      "error": null
    },
    "database.db.delete_user": {
      "identifier": "database.db.delete_user",
      "description": {
        "overall": "This function is responsible for deleting a user record from a database collection named `dbusers`. It takes a username as input, which is used to locate the specific user document by its `_id` field. The function then performs a delete operation and returns the count of documents that were successfully removed.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The unique identifier of the user to be deleted from the database."
          }
        ],
        "returns": [
          {
            "name": "deleted_count",
            "type": "int",
            "description": "The number of documents deleted by the operation, typically 0 or 1."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not explicitly called by any other functions in the provided context."
        }
      },
      "error": null
    },
    "database.db.get_decrypted_api_keys": {
      "identifier": "database.db.get_decrypted_api_keys",
      "description": {
        "overall": "This function retrieves and decrypts various API keys and base URLs associated with a given username from a database. It first queries the 'dbusers' collection for the specified username. If the user is not found, it returns two None values. Otherwise, it decrypts the Gemini, GPT, and Open Source API keys using the 'decrypt_text' function and retrieves the Ollama and Open Source base URLs directly from the user's record. Finally, it returns all these retrieved values.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username for whom to retrieve the API keys and base URLs."
          }
        ],
        "returns": [
          {
            "name": "gemini_plain",
            "type": "str",
            "description": "The decrypted Gemini API key, or an empty string if not found."
          },
          {
            "name": "ollama_plain",
            "type": "str",
            "description": "The Ollama base URL, or an empty string if not found."
          },
          {
            "name": "gpt_plain",
            "type": "str",
            "description": "The decrypted GPT API key, or an empty string if not found."
          },
          {
            "name": "opensrc_plain",
            "type": "str",
            "description": "The decrypted Open Source API key, or an empty string if not found."
          },
          {
            "name": "opensrc_url",
            "type": "str",
            "description": "The Open Source base URL, or an empty string if not found."
          }
        ],
        "usage_context": {
          "calls": "This function calls database.db.decrypt_text.",
          "called_by": "This function is not explicitly called by any other functions in the provided context."
        }
      },
      "error": null
    },
    "database.db.insert_chat": {
      "identifier": "database.db.insert_chat",
      "description": {
        "overall": "This function, `insert_chat`, creates a new chat entry in a database. It constructs a dictionary containing a unique identifier generated using `uuid.uuid4()`, the provided username, the chat name, and the current timestamp using `datetime.now()`. This chat dictionary is then inserted into a MongoDB collection referred to as `dbchats` via the `insert_one` method. The function concludes by returning the unique `_id` of the newly inserted chat document.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username associated with the new chat entry."
          },
          {
            "name": "chat_name",
            "type": "str",
            "description": "The name of the chat to be created."
          }
        ],
        "returns": [
          {
            "name": "inserted_id",
            "type": "str",
            "description": "The unique identifier (`_id`) of the newly created chat document in the database."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not explicitly called by any other functions in the provided context."
        }
      },
      "error": null
    },
    "database.db.fetch_chats_by_user": {
      "identifier": "database.db.fetch_chats_by_user",
      "description": {
        "overall": "This function retrieves all chat records associated with a specific user from a database collection named `dbchats`. It filters the chat documents based on the provided username and then sorts the results by the `created_at` timestamp in ascending order. The function returns these sorted chat documents as a list.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username for which to fetch the chat records."
          }
        ],
        "returns": [
          {
            "name": "chats",
            "type": "list",
            "description": "A list of chat documents (dictionaries) associated with the specified username, sorted by their creation date."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not explicitly called by any other functions in the provided context."
        }
      },
      "error": null
    },
    "database.db.check_chat_exists": {
      "identifier": "database.db.check_chat_exists",
      "description": {
        "overall": "The `check_chat_exists` function verifies the presence of a specific chat entry within the `dbchats` collection. It takes a username and a chat name as input. The function performs a query to find a document that matches both the provided username and chat name. It returns a boolean value indicating whether such a chat entry exists in the database.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username associated with the chat to be checked."
          },
          {
            "name": "chat_name",
            "type": "str",
            "description": "The name of the chat to be checked for existence."
          }
        ],
        "returns": [
          {
            "name": "exists",
            "type": "bool",
            "description": "True if a chat matching the username and chat name is found, False otherwise."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not explicitly called by any other functions in the provided context."
        }
      },
      "error": null
    },
    "database.db.rename_chat_fully": {
      "identifier": "database.db.rename_chat_fully",
      "description": {
        "overall": "This function renames a chat entry and all its associated messages (exchanges) within a database. It first updates the chat's name in the `dbchats` collection using the provided username and old chat name. Subsequently, it updates the chat name for all related exchanges in the `dbexchanges` collection. The function returns the count of chat entries that were modified during the initial update operation.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username associated with the chat to be renamed."
          },
          {
            "name": "old_name",
            "type": "str",
            "description": "The current name of the chat."
          },
          {
            "name": "new_name",
            "type": "str",
            "description": "The new desired name for the chat."
          }
        ],
        "returns": [
          {
            "name": "modified_count",
            "type": "int",
            "description": "An integer representing the number of chat entries modified in the 'dbchats' collection."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not explicitly called by any other functions in the provided context."
        }
      },
      "error": null
    },
    "database.db.insert_exchange": {
      "identifier": "database.db.insert_exchange",
      "description": {
        "overall": "This function inserts a new chat exchange record into a database. It generates a unique identifier for the exchange, constructs a dictionary containing various details such as the question, answer, feedback, user information, model usage, time metrics, and token counts, along with a creation timestamp. The function then attempts to insert this structured data into the 'dbexchanges' collection. Upon successful insertion, it returns the generated unique ID; otherwise, it catches any exceptions, prints an error message, and returns None.",
        "parameters": [
          {
            "name": "question",
            "type": "str",
            "description": "The question string from the chat exchange."
          },
          {
            "name": "answer",
            "type": "str",
            "description": "The answer string provided in the chat exchange."
          },
          {
            "name": "feedback",
            "type": "str",
            "description": "The feedback string associated with the exchange."
          },
          {
            "name": "username",
            "type": "str",
            "description": "The username of the participant in the exchange."
          },
          {
            "name": "chat_name",
            "type": "str",
            "description": "The name of the chat session."
          },
          {
            "name": "helper_used",
            "type": "str",
            "description": "The name of the helper model used, defaulting to an empty string."
          },
          {
            "name": "main_used",
            "type": "str",
            "description": "The name of the main model used, defaulting to an empty string."
          },
          {
            "name": "total_time",
            "type": "str",
            "description": "The total time taken for the exchange, defaulting to an empty string."
          },
          {
            "name": "helper_time",
            "type": "str",
            "description": "The time taken by the helper model, defaulting to an empty string."
          },
          {
            "name": "main_time",
            "type": "str",
            "description": "The time taken by the main model, defaulting to an empty string."
          },
          {
            "name": "json_tokens",
            "type": "int",
            "description": "The number of JSON tokens used, defaulting to 0."
          },
          {
            "name": "toon_tokens",
            "type": "int",
            "description": "The number of Toon tokens used, defaulting to 0."
          },
          {
            "name": "savings_percent",
            "type": "float",
            "description": "The percentage of savings, defaulting to 0.0."
          }
        ],
        "returns": [
          {
            "name": "new_id",
            "type": "str",
            "description": "The unique identifier of the newly inserted exchange record upon success."
          },
          {
            "name": "None",
            "type": "NoneType",
            "description": "Returns None if an error occurs during the database insertion."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not explicitly called by any other functions in the provided context."
        }
      },
      "error": null
    },
    "database.db.fetch_exchanges_by_user": {
      "identifier": "database.db.fetch_exchanges_by_user",
      "description": {
        "overall": "This function retrieves exchange records from a database. It filters these records based on a provided username and then sorts the results by their 'created_at' timestamp in ascending order. The function converts the database query result into a list before returning it.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username used to filter the exchange records."
          }
        ],
        "returns": [
          {
            "name": "exchanges",
            "type": "list",
            "description": "A list of exchange records associated with the specified username, sorted by 'created_at' in ascending order."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not explicitly called by any other functions in the provided context."
        }
      },
      "error": null
    },
    "database.db.fetch_exchanges_by_chat": {
      "identifier": "database.db.fetch_exchanges_by_chat",
      "description": {
        "overall": "This function, `fetch_exchanges_by_chat`, is designed to retrieve chat exchanges from a database. It queries a collection named `dbexchanges` using a specified username and chat name as filters. The results are then sorted chronologically by their 'created_at' timestamp in ascending order. Finally, the function returns these filtered and sorted exchanges as a list.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username used to filter the chat exchanges."
          },
          {
            "name": "chat_name",
            "type": "str",
            "description": "The name of the chat to filter the exchanges by."
          }
        ],
        "returns": [
          {
            "name": "exchanges",
            "type": "list",
            "description": "A list of exchange documents (dictionaries) that match the provided username and chat name, sorted by their creation date."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not explicitly called by any other functions in the provided context."
        }
      },
      "error": null
    },
    "database.db.update_exchange_feedback": {
      "identifier": "database.db.update_exchange_feedback",
      "description": {
        "overall": "This function is designed to update the feedback score for a specific exchange record within a database. It takes an exchange identifier and an integer feedback value as input. The function utilizes a database operation, specifically `dbexchanges.update_one`, to locate the exchange by its `_id` and then sets the 'feedback' field with the new value. Finally, it returns the number of documents that were successfully modified by this operation.",
        "parameters": [
          {
            "name": "exchange_id",
            "type": "Any",
            "description": "The unique identifier of the exchange record to be updated in the database."
          },
          {
            "name": "feedback",
            "type": "int",
            "description": "The integer feedback value to set for the specified exchange."
          }
        ],
        "returns": [
          {
            "name": "modified_count",
            "type": "int",
            "description": "The count of documents that were modified by the update operation."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not explicitly called by any other functions in the provided context."
        }
      },
      "error": null
    },
    "database.db.update_exchange_feedback_message": {
      "identifier": "database.db.update_exchange_feedback_message",
      "description": {
        "overall": "This function is designed to update the feedback message for a specific exchange record within a database. It takes an exchange identifier and a new feedback message as input. The function performs an update operation on the 'dbexchanges' collection, setting the 'feedback_message' field for the document matching the provided exchange ID. It then returns the count of documents that were modified by this operation.",
        "parameters": [
          {
            "name": "exchange_id",
            "type": "Any",
            "description": "The unique identifier of the exchange document to be updated in the database."
          },
          {
            "name": "feedback_message",
            "type": "str",
            "description": "The new feedback message string to be associated with the specified exchange."
          }
        ],
        "returns": [
          {
            "name": "modified_count",
            "type": "int",
            "description": "The number of documents that were modified by the update operation."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not explicitly called by any other functions in the provided context."
        }
      },
      "error": null
    },
    "database.db.delete_exchange_by_id": {
      "identifier": "database.db.delete_exchange_by_id",
      "description": {
        "overall": "This function is responsible for deleting a specific exchange record from the 'dbexchanges' collection. It takes a unique identifier for the exchange as input. The function executes a delete operation on the collection, targeting the document whose '_id' matches the provided 'exchange_id'. It then returns the count of documents that were successfully deleted.",
        "parameters": [
          {
            "name": "exchange_id",
            "type": "str",
            "description": "The unique identifier (MongoDB _id) of the exchange document to be deleted."
          }
        ],
        "returns": [
          {
            "name": "deleted_count",
            "type": "int",
            "description": "The number of documents that were deleted (typically 0 or 1)."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not explicitly called by any other functions in the provided context."
        }
      },
      "error": null
    },
    "database.db.delete_full_chat": {
      "identifier": "database.db.delete_full_chat",
      "description": {
        "overall": "This function is responsible for completely deleting a specified chat and all its associated messages (exchanges) for a given user. It first removes all messages linked to the chat and username by calling `dbexchanges.delete_many`. Subsequently, it deletes the chat entry itself from the chat list using `dbchats.delete_one`. This two-step process ensures data consistency between frontend and backend representations by removing all related data.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username associated with the chat to be deleted."
          },
          {
            "name": "chat_name",
            "type": "str",
            "description": "The name of the chat to be deleted."
          }
        ],
        "returns": [
          {
            "name": "deleted_count",
            "type": "int",
            "description": "The number of chat documents deleted, typically 0 or 1, representing the success of deleting the chat entry itself."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not explicitly called by any other functions in the provided context."
        }
      },
      "error": null
    },
    "frontend.frontend.clean_names": {
      "identifier": "frontend.frontend.clean_names",
      "description": {
        "overall": "This function processes a list of strings, typically representing model names or paths. For each string in the input list, it splits the string by the '/' character and extracts the last segment. The function then returns a new list containing these extracted, 'cleaned' names, effectively removing any preceding path information.",
        "parameters": [
          {
            "name": "model_list",
            "type": "list",
            "description": "A list of strings, where each string is expected to be a model identifier or path that may contain '/' separators."
          }
        ],
        "returns": [
          {
            "name": "cleaned_model_names",
            "type": "list[str]",
            "description": "A new list containing strings, where each string is the last segment of the corresponding input string after splitting by '/'."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is called by no other functions."
        }
      },
      "error": null
    },
    "frontend.frontend.get_filtered_models": {
      "identifier": "frontend.frontend.get_filtered_models",
      "description": {
        "overall": "This function filters a given list of models based on a specified category name. It retrieves associated keywords for the category. If 'STANDARD' is among the keywords, it returns only those models from the source list that are also present in a predefined `STANDARD_MODELS` list. Otherwise, it iterates through the source list, checking if any of the category keywords are contained within each model's name (case-insensitive). The function returns the filtered list; if no models match the keywords, the original source list is returned.",
        "parameters": [
          {
            "name": "source_list",
            "type": "list",
            "description": "The initial list of models to be filtered."
          },
          {
            "name": "category_name",
            "type": "str",
            "description": "The name of the category used to determine filtering keywords."
          }
        ],
        "returns": [
          {
            "name": "filtered_models",
            "type": "list",
            "description": "A list of models filtered according to the category keywords, or the original source list if no models match."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not explicitly called by any other functions in the provided context."
        }
      },
      "error": null
    },
    "frontend.frontend.save_gemini_cb": {
      "identifier": "frontend.frontend.save_gemini_cb",
      "description": {
        "overall": "This callback function is designed to save a user-provided Gemini API key. It first attempts to retrieve a new Gemini key from the Streamlit session state. If a non-empty key is found, it proceeds to update this key in the database, associating it with the current user's username. After a successful update, the function clears the temporary key from the session state and displays a success notification to the user.",
        "parameters": [],
        "returns": [],
        "usage_context": {
          "calls": "This function calls database.db.update_gemini_key.",
          "called_by": "This function is called by no other functions."
        }
      },
      "error": null
    },
    "frontend.frontend.save_ollama_cb": {
      "identifier": "frontend.frontend.save_ollama_cb",
      "description": {
        "overall": "This function, `save_ollama_cb`, serves as a callback to handle the saving of a new Ollama URL. It first attempts to retrieve a URL value from the Streamlit session state using the key \"in_ollama_url\". If a non-empty URL is successfully retrieved, the function proceeds to update this new URL in the database. This update is performed by calling `db.update_ollama_url`, passing the current username from the session state along with the new URL. Upon successful update, a confirmation toast message is displayed to the user within the Streamlit application.",
        "parameters": [],
        "returns": [],
        "usage_context": {
          "calls": "This function calls database.db.update_ollama_url.",
          "called_by": "This function is called by no other functions."
        }
      },
      "error": null
    },
    "frontend.frontend.load_data_from_db": {
      "identifier": "frontend.frontend.load_data_from_db",
      "description": {
        "overall": "This function loads chat and exchange data for a specific user from the database into the Streamlit session state. It first checks if the data for the given username is already loaded to avoid redundant operations. If not loaded, it initializes the session state's chats dictionary. The function then fetches predefined chats and their names, populating the session state, followed by retrieving all exchanges and categorizing them into their respective chats, including support for legacy chats. Finally, it ensures a default chat exists if none were loaded and sets the active chat in the session state.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username for whom chats and exchanges should be loaded from the database."
          }
        ],
        "returns": [],
        "usage_context": {
          "calls": "This function calls database.db.fetch_chats_by_user, database.db.fetch_exchanges_by_user, and database.db.insert_chat.",
          "called_by": "This function is called by no other functions."
        }
      },
      "error": null
    },
    "frontend.frontend.handle_feedback_change": {
      "identifier": "frontend.frontend.handle_feedback_change",
      "description": {
        "overall": "This function, `handle_feedback_change`, processes and persists feedback for a specific exchange object. It updates the 'feedback' key within the provided `ex` dictionary with the new `val`. Concurrently, it invokes the `db.update_exchange_feedback` function to store this updated feedback in the database, using the `_id` from the `ex` object. Finally, it triggers a Streamlit application rerun to reflect the changes in the user interface.",
        "parameters": [
          {
            "name": "ex",
            "type": "dict",
            "description": "The exchange object, expected to be a dictionary containing at least 'feedback' and '_id' keys."
          },
          {
            "name": "val",
            "type": "Any",
            "description": "The new feedback value to be assigned to the exchange."
          }
        ],
        "returns": [],
        "usage_context": {
          "calls": "This function calls database.db.update_exchange_feedback.",
          "called_by": "This function is called by no other functions."
        }
      },
      "error": null
    },
    "frontend.frontend.handle_delete_exchange": {
      "identifier": "frontend.frontend.handle_delete_exchange",
      "description": {
        "overall": "This function handles the deletion of a specific exchange. It first removes the exchange from the database using its `_id`. Subsequently, it checks if the associated chat exists in the Streamlit session state and, if the exchange is present within that chat's exchanges list, it removes it from the session state. Finally, it triggers a Streamlit rerun to update the user interface.",
        "parameters": [
          {
            "name": "chat_name",
            "type": "str",
            "description": "The name of the chat from which the exchange should be deleted. This is used as a key to access the chat in the Streamlit session state."
          },
          {
            "name": "ex",
            "type": "dict",
            "description": "The exchange object to be deleted. It is expected to be a dictionary-like object containing an '_id' key for database deletion and to be directly comparable for removal from the session state list."
          }
        ],
        "returns": [],
        "usage_context": {
          "calls": "This function calls database.db.delete_exchange_by_id.",
          "called_by": "This function is not explicitly called by any other functions in the provided context."
        }
      },
      "error": null
    },
    "frontend.frontend.handle_delete_chat": {
      "identifier": "frontend.frontend.handle_delete_chat",
      "description": {
        "overall": "This function handles the deletion of a specified chat for a given user. It first removes the chat from the database using `db.delete_full_chat`. Subsequently, it cleans up the chat from the Streamlit session state. If other chats exist, it sets the first available chat as the new active chat. If no chats remain after deletion, it creates a new default chat named 'Chat 1' in both the database and session state, setting it as the active chat. Finally, it triggers a Streamlit rerun.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username associated with the chat to be deleted."
          },
          {
            "name": "chat_name",
            "type": "str",
            "description": "The name of the chat to be deleted."
          }
        ],
        "returns": [],
        "usage_context": {
          "calls": "This function calls database.db.delete_full_chat and database.db.insert_chat.",
          "called_by": "This function is not explicitly called by any other functions in the provided context."
        }
      },
      "error": null
    },
    "frontend.frontend.extract_repo_name": {
      "identifier": "frontend.frontend.extract_repo_name",
      "description": {
        "overall": "This function is designed to extract a repository name from an input text string. It first searches for a URL within the provided text using a regular expression. If a URL is found, it parses the URL to obtain its path component. The last segment of this path is then considered the repository name, with any '.git' suffix removed for cleanliness. If no URL is found or a repository name cannot be successfully extracted from the URL's path, the function returns None.",
        "parameters": [
          {
            "name": "text",
            "type": "str",
            "description": "The input string, which may contain a URL from which to extract a repository name."
          }
        ],
        "returns": [
          {
            "name": "repo_name",
            "type": "str | None",
            "description": "The extracted repository name as a string, or None if no valid repository name could be found or parsed from the input text."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not explicitly called by any other functions in the provided context."
        }
      },
      "error": null
    },
    "frontend.frontend.stream_text_generator": {
      "identifier": "frontend.frontend.stream_text_generator",
      "description": {
        "overall": "This function acts as a generator that takes a string of text and yields its words one by one. It splits the input text by spaces and iterates through each word. After yielding a word followed by a space, it introduces a small delay of 0.01 seconds. This behavior is typically used to simulate a typing effect or stream text output gradually.",
        "parameters": [
          {
            "name": "text",
            "type": "str",
            "description": "The input string of text to be processed and streamed word by word."
          }
        ],
        "returns": [
          {
            "name": "word_with_space",
            "type": "str",
            "description": "A single word from the input text, followed by a space, yielded sequentially."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not explicitly called by any other functions in the provided context."
        }
      },
      "error": null
    },
    "frontend.frontend.render_text_with_mermaid": {
      "identifier": "frontend.frontend.render_text_with_mermaid",
      "description": {
        "overall": "This function processes a given markdown text, identifying and rendering embedded Mermaid diagrams. It splits the input text into parts based on ````mermaid` delimiters. Non-Mermaid sections are rendered as standard markdown using `st.markdown` or streamed via `st.write_stream` if `should_stream` is true. Mermaid code blocks are attempted to be rendered using `st_mermaid`, with a fallback to displaying the raw Mermaid code using `st.code` in case of an error. The function handles empty input by returning early.",
        "parameters": [
          {
            "name": "markdown_text",
            "type": "str",
            "description": "The input text, which may contain embedded Mermaid diagrams within ````mermaid` blocks."
          },
          {
            "name": "should_stream",
            "type": "bool",
            "description": "A flag indicating whether non-Mermaid text parts should be streamed using `st.write_stream` or rendered directly with `st.markdown`. Defaults to `False`."
          }
        ],
        "returns": [],
        "usage_context": {
          "calls": "This function calls frontend.frontend.stream_text_generator.",
          "called_by": "This function is called by no other functions."
        }
      },
      "error": null
    },
    "frontend.frontend.render_exchange": {
      "identifier": "frontend.frontend.render_exchange",
      "description": {
        "overall": "This function is responsible for rendering a single chat exchange within a Streamlit application. It first displays the user's question, followed by the assistant's answer. The function includes a dynamic toolbar that provides feedback mechanisms (like/dislike buttons, comment popover), a download option for the answer, and a delete button. It handles error states by displaying an error message and a delete option. Finally, it renders the answer content using a specialized text rendering function.",
        "parameters": [
          {
            "name": "ex",
            "type": "dict",
            "description": "A dictionary-like object representing a single chat exchange, containing keys such as 'question', 'answer', 'feedback', 'feedback_message', and '_id'."
          },
          {
            "name": "current_chat_name",
            "type": "str",
            "description": "The name of the current chat, used for context when deleting an exchange."
          }
        ],
        "returns": [],
        "usage_context": {
          "calls": "This function calls database.db.update_exchange_feedback_message, frontend.frontend.handle_delete_exchange, frontend.frontend.handle_feedback_change, and frontend.frontend.render_text_with_mermaid.",
          "called_by": "This function is not explicitly called by any other functions in the provided context."
        }
      },
      "error": null
    }
  },
  "classes": {
    "backend.AST_Schema.ASTVisitor": {
      "identifier": "backend.AST_Schema.ASTVisitor",
      "description": {
        "overall": "The ASTVisitor class is a specialized `ast.NodeVisitor` designed to traverse the Abstract Syntax Tree (AST) of a Python source file. Its primary purpose is to extract and structure metadata about imports, top-level functions, and class definitions, including their nested methods. It builds a comprehensive `schema` dictionary that organizes this information, making it suitable for further analysis or documentation generation.",
        "init_method": {
          "description": "The `__init__` method initializes the `ASTVisitor` instance by storing the provided source code, file path, and project root. It calculates the module path and sets up an empty `schema` dictionary to collect parsed AST information, including imports, functions, and classes. It also initializes `_current_class` to `None` for tracking nested class contexts.",
          "parameters": [
            {
              "name": "source_code",
              "type": "str",
              "description": "The raw source code string to be analyzed."
            },
            {
              "name": "file_path",
              "type": "str",
              "description": "The absolute path to the file being analyzed."
            },
            {
              "name": "project_root",
              "type": "str",
              "description": "The root directory of the project, used for module path calculation."
            }
          ]
        },
        "methods": [
          {
            "identifier": "visit_Import",
            "description": {
              "overall": "This method processes `ast.Import` nodes, which represent `import module` statements. It iterates through the imported module aliases and appends their names to the `self.schema[\"imports\"]` list, effectively collecting all top-level imports. After processing, it calls `generic_visit` to continue AST traversal.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.Import",
                  "description": "The AST node representing an `import` statement."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls `self.generic_visit` to continue the AST traversal.",
                "called_by": "This method is implicitly called by the `ast.NodeVisitor`'s dispatch mechanism when an `ast.Import` node is encountered."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_ImportFrom",
            "description": {
              "overall": "This method handles `ast.ImportFrom` nodes, corresponding to `from module import name` statements. It extracts the module name and each imported alias, then formats them as `module.name` and adds them to the `self.schema[\"imports\"]` list. It ensures all `from ... import ...` statements are recorded.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.ImportFrom",
                  "description": "The AST node representing a `from ... import ...` statement."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls `self.generic_visit` to continue the AST traversal.",
                "called_by": "This method is implicitly called by the `ast.NodeVisitor`'s dispatch mechanism when an `ast.ImportFrom` node is encountered."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_ClassDef",
            "description": {
              "overall": "This method processes `ast.ClassDef` nodes, which define classes. It constructs a dictionary containing comprehensive information about the class, including its full identifier, name, docstring, and source code segment. This class information is then appended to `self.schema[\"classes\"]`. It also temporarily stores the current class in `_current_class` to enable nested method analysis and resets it afterward.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.ClassDef",
                  "description": "The AST node representing a class definition."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls `ast.get_docstring`, `ast.get_source_segment`, and `self.generic_visit` to extract class details and continue AST traversal.",
                "called_by": "This method is implicitly called by the `ast.NodeVisitor`'s dispatch mechanism when an `ast.ClassDef` node is encountered."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_FunctionDef",
            "description": {
              "overall": "This method processes `ast.FunctionDef` nodes, representing both regular functions and methods. It checks if it's currently inside a class (indicated by `_current_class`). If so, it extracts method details and appends them to the `method_context` of the `_current_class`. Otherwise, it treats it as a top-level function, extracting its details and adding them to `self.schema[\"functions\"]`.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.FunctionDef",
                  "description": "The AST node representing a function or method definition."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls `ast.get_docstring`, `ast.get_source_segment`, and `self.generic_visit` to extract function/method details and continue AST traversal.",
                "called_by": "This method is implicitly called by the `ast.NodeVisitor`'s dispatch mechanism when an `ast.FunctionDef` node is encountered, and explicitly by `visit_AsyncFunctionDef`."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_AsyncFunctionDef",
            "description": {
              "overall": "This method specifically handles `ast.AsyncFunctionDef` nodes, which define asynchronous functions or methods. Instead of duplicating logic, it delegates the entire processing to the `visit_FunctionDef` method, ensuring that async functions are analyzed in the same manner as regular functions.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.AsyncFunctionDef",
                  "description": "The AST node representing an asynchronous function definition."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls `self.visit_FunctionDef` to process the asynchronous function definition.",
                "called_by": "This method is implicitly called by the `ast.NodeVisitor`'s dispatch mechanism when an `ast.AsyncFunctionDef` node is encountered."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "This class depends on `backend.AST_Schema.path_to_module` for converting file paths to module paths.",
          "instantiated_by": "This class is not explicitly shown to be instantiated by any other components in the provided context."
        }
      },
      "error": null
    },
    "backend.AST_Schema.ASTAnalyzer": {
      "identifier": "backend.AST_Schema.ASTAnalyzer",
      "description": {
        "overall": "The ASTAnalyzer class is designed to perform static analysis on Python source code within a repository. It provides functionality to parse Python files into an Abstract Syntax Tree (AST) and extract structural information such as functions, classes, and imports. Additionally, it can integrate call relationship data into the generated AST schema, enriching it with details about how different code components interact. Its primary role is to build a comprehensive, structured representation of a codebase for further analysis or documentation.",
        "init_method": {
          "description": "This constructor initializes an instance of the ASTAnalyzer class. It does not take any specific parameters beyond `self` and performs no initialization logic, effectively creating an empty instance.",
          "parameters": []
        },
        "methods": [
          {
            "identifier": "merge_relationship_data",
            "description": {
              "overall": "This method integrates raw call relationship data (incoming and outgoing calls) into a structured AST schema. It iterates through files, functions, and classes within the `full_schema` to enrich their context with call information. For functions, it populates `calls` and `called_by` lists. For classes, it identifies where they are `instantiated_by` and calculates external `dependencies` based on method calls that are not internal to the class. The method modifies the `full_schema` in place and then returns the updated schema.",
              "parameters": [
                {
                  "name": "self",
                  "type": "ASTAnalyzer",
                  "description": "The instance of the class."
                },
                {
                  "name": "full_schema",
                  "type": "dict",
                  "description": "A dictionary representing the complete AST schema of a project, including files, functions, and classes."
                },
                {
                  "name": "raw_relationships",
                  "type": "dict",
                  "description": "A dictionary containing raw incoming and outgoing call relationships, typically parsed from a separate analysis step."
                }
              ],
              "returns": [
                {
                  "name": "full_schema",
                  "type": "dict",
                  "description": "The updated `full_schema` dictionary, now enriched with call and dependency information for functions and classes."
                }
              ],
              "usage_context": {
                "calls": "This method does not explicitly call other methods, classes, or functions directly within its source code.",
                "called_by": "This method is not explicitly called by any other function or method in the provided context."
              }
            },
            "error": null
          },
          {
            "identifier": "analyze_repository",
            "description": {
              "overall": "This method processes a list of file objects from a Git repository to build a comprehensive AST schema. It first determines the common project root. Then, it iterates through each Python file, parses its content into an Abstract Syntax Tree (AST), and uses an `ASTVisitor` to extract structural information like imports, functions, and classes. The extracted schema for each file is then added to a `full_schema` dictionary, which is returned upon completion. Error handling is included for parsing failures.",
              "parameters": [
                {
                  "name": "self",
                  "type": "ASTAnalyzer",
                  "description": "The instance of the class."
                },
                {
                  "name": "files",
                  "type": "list",
                  "description": "A list of file objects, each expected to have `path` and `content` attributes."
                },
                {
                  "name": "repo",
                  "type": "GitRepository",
                  "description": "An object representing the Git repository, though it's not directly used in the provided snippet beyond implying the source of `files`."
                }
              ],
              "returns": [
                {
                  "name": "full_schema",
                  "type": "dict",
                  "description": "A dictionary representing the AST schema of the entire repository, structured by file paths."
                }
              ],
              "usage_context": {
                "calls": "This method calls `backend.AST_Schema.ASTVisitor`.",
                "called_by": "This method is not explicitly called by any other function or method in the provided context."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "The class depends on `backend.AST_Schema.ASTVisitor`.",
          "instantiated_by": "This class is not explicitly instantiated by any other component in the provided context."
        }
      },
      "error": null
    },
    "backend.File_Dependency.FileDependencyGraph": {
      "identifier": "backend.File_Dependency.FileDependencyGraph",
      "description": {
        "overall": "The FileDependencyGraph class extends NodeVisitor to construct a graph of file-level import dependencies within a Python repository. It traverses the Abstract Syntax Tree (AST) of a given file, identifying both absolute and relative import statements. The class resolves relative imports to their actual module paths and records these dependencies, mapping the current file to the modules it imports, storing them in the 'import_dependencies' dictionary.",
        "init_method": {
          "description": "Initializes the File Dependency Graph with the current filename being analyzed and the root directory of the repository. These values are stored as instance attributes for later use in resolving file paths and dependencies.",
          "parameters": [
            {
              "name": "filename",
              "type": "str",
              "description": "The name of the file currently being analyzed for dependencies."
            },
            {
              "name": "repo_root",
              "type": "str",
              "description": "The root directory of the repository, used as a base for resolving file paths."
            }
          ]
        },
        "methods": [
          {
            "identifier": "_resolve_module_name",
            "description": {
              "overall": "This method resolves relative Python imports, such as 'from .. import name1, name2', by determining the actual module or symbol names. It calculates the correct file path based on the import level and the repository root, then checks for existing module files or symbols exported via '__init__.py' files. If successful, it returns a list of resolved names; otherwise, it raises an ImportError.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ImportFrom",
                  "description": "The AST node representing the 'from ... import ...' statement to be resolved."
                }
              ],
              "returns": [
                {
                  "name": "resolved",
                  "type": "list[str]",
                  "description": "A list of actual module or symbol names that the relative import resolves to."
                }
              ],
              "usage_context": {
                "calls": "This method calls 'get_all_temp_files' to retrieve all temporary files in the repository and internally utilizes 'module_file_exists' and 'init_exports_symbol' to verify module and symbol existence. It also uses 'Path' for path manipulation and 'iskeyword' for identifier validation.",
                "called_by": "This method is called by 'visit_ImportFrom' when processing relative import statements."
              }
            },
            "error": null
          },
          {
            "identifier": "module_file_exists",
            "description": {
              "overall": "This helper function, nested within '_resolve_module_name', checks if a given module name corresponds to an existing Python file (e.g., 'name.py') or a package's '__init__.py' file. It constructs potential file paths relative to a specified base directory and the repository root, returning true if either path exists.",
              "parameters": [
                {
                  "name": "rel_base",
                  "type": "Path",
                  "description": "The relative base directory path to search within."
                },
                {
                  "name": "name",
                  "type": "str",
                  "description": "The module name to check for existence."
                }
              ],
              "returns": [
                {
                  "name": "",
                  "type": "bool",
                  "description": "Returns True if the module file or package '__init__.py' exists, False otherwise."
                }
              ],
              "usage_context": {
                "calls": "This function does not explicitly call other methods or functions from the provided 'method_context'. It primarily uses 'pathlib.Path' objects and their 'exists()' method.",
                "called_by": "This function is called by '_resolve_module_name' to verify the physical existence of module files or packages."
              }
            },
            "error": null
          },
          {
            "identifier": "init_exports_symbol",
            "description": {
              "overall": "This helper function, nested within '_resolve_module_name', determines if a specific symbol is exported by an '__init__.py' file within a given relative base directory. It parses the '__init__.py' content to check if the symbol is present in '__all__', or defined as a function, class, or assigned variable. It handles potential parsing errors gracefully.",
              "parameters": [
                {
                  "name": "rel_base",
                  "type": "Path",
                  "description": "The relative base directory where the '__init__.py' file is located."
                },
                {
                  "name": "symbol",
                  "type": "str",
                  "description": "The symbol name to check for export within the '__init__.py' file."
                }
              ],
              "returns": [
                {
                  "name": "",
                  "type": "bool",
                  "description": "Returns True if the '__init__.py' exists and exports the symbol, False otherwise."
                }
              ],
              "usage_context": {
                "calls": "This function uses 'pathlib.Path' for file operations and 'ast.parse', 'ast.walk', and 'ast.literal_eval' for parsing and analyzing the '__init__.py' file's content.",
                "called_by": "This function is called by '_resolve_module_name' to check if a symbol is explicitly exported by a package's '__init__.py' file."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_Import",
            "description": {
              "overall": "This method, part of the NodeVisitor pattern, processes AST nodes representing 'import' or 'from ... import' statements. It records the imported module or symbol as a dependency for the current file ('self.filename') in the 'import_dependencies' dictionary. It prioritizes a provided 'base_name' over the alias name from the import node.",
              "parameters": [
                {
                  "name": "node",
                  "type": "Import | ImportFrom",
                  "description": "The AST node representing the import statement."
                },
                {
                  "name": "base_name",
                  "type": "str | None",
                  "description": "An optional base name for the import, typically used for the module part of a 'from ... import ...' statement."
                }
              ],
              "returns": [
                {
                  "name": "",
                  "type": "None",
                  "description": "This method does not return a value; it modifies the 'import_dependencies' attribute."
                }
              ],
              "usage_context": {
                "calls": "This method calls 'self.generic_visit(node)' to ensure continued traversal of the AST.",
                "called_by": "This method is called by 'visit_ImportFrom' to record dependencies after resolving relative imports or extracting the base module name from an 'ImportFrom' node."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_ImportFrom",
            "description": {
              "overall": "This method processes 'ImportFrom' AST nodes to extract and record file dependencies. For absolute imports, it identifies the last part of the module name and passes it to 'visit_Import'. For relative imports, it attempts to resolve the actual module names using '_resolve_module_name' and then records each resolved base name as a dependency via 'visit_Import'. It includes error handling for failed relative import resolutions.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ImportFrom",
                  "description": "The AST node representing the 'from ... import ...' statement."
                }
              ],
              "returns": [
                {
                  "name": "",
                  "type": "None",
                  "description": "This method does not return a value; it records dependencies by calling 'visit_Import' and continues AST traversal."
                }
              ],
              "usage_context": {
                "calls": "This method calls 'self._resolve_module_name' to handle the resolution of relative imports and 'self.visit_Import' to record the identified dependencies. It also calls 'self.generic_visit(node)' for general AST traversal.",
                "called_by": "This method is part of the 'NodeVisitor' pattern and is implicitly invoked by the AST walker when an 'ImportFrom' node is encountered during AST traversal."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "This class depends on 'backend.File_Dependency.get_all_temp_files' for discovering files within the repository. It also internally leverages 'backend.File_Dependency.init_exports_symbol' and 'backend.File_Dependency.module_file_exists' for resolving module paths and symbols.",
          "instantiated_by": "The input indicates that this class is not explicitly instantiated by other known components in the provided context."
        }
      },
      "error": null
    },
    "backend.HelperLLM.LLMHelper": {
      "identifier": "backend.HelperLLM.LLMHelper",
      "description": {
        "overall": "The LLMHelper class provides a centralized interface for interacting with various Large Language Models (LLMs), such as Google Gemini, OpenAI, and Ollama, to generate structured documentation for Python functions and classes. It handles the configuration of different LLM providers, loads specific system prompts, and manages API calls in batches to optimize performance and adhere to rate limits. The class ensures that LLM outputs are validated against Pydantic schemas (FunctionAnalysis and ClassAnalysis) for reliable data processing.",
        "init_method": {
          "description": "The constructor initializes the LLMHelper instance by setting up the API key and loading system prompts for function and class analysis from specified file paths. It dynamically configures the underlying Language Model (LLM) based on the 'model_name' (supporting Google Gemini, OpenAI, custom APIs, and Ollama) and sets up structured output parsers for FunctionAnalysis and ClassAnalysis Pydantic models. It also calls '_configure_batch_settings' to set an appropriate batch size for API calls.",
          "parameters": [
            {
              "name": "api_key",
              "type": "str",
              "description": "The API key for the chosen LLM service (e.g., Gemini, OpenAI)."
            },
            {
              "name": "function_prompt_path",
              "type": "str",
              "description": "The file path to the system prompt for function analysis."
            },
            {
              "name": "class_prompt_path",
              "type": "str",
              "description": "The file path to the system prompt for class analysis."
            },
            {
              "name": "model_name",
              "type": "str",
              "description": "The name of the LLM model to use (default: \"gemini-2.0-flash-lite\")."
            },
            {
              "name": "base_url",
              "type": "str | None",
              "description": "The base URL for custom or Ollama LLM endpoints, if applicable."
            }
          ]
        },
        "methods": [
          {
            "identifier": "_configure_batch_settings",
            "description": {
              "overall": "This private method sets the 'batch_size' attribute of the LLMHelper instance based on the provided 'model_name'. It assigns specific batch sizes for various Gemini, Llama, and GPT models, as well as for custom API models. If the model name is unrecognized, it defaults to a conservative batch size of 2 and logs a warning. This helps optimize API calls by adjusting concurrency based on known model capabilities or rate limits.",
              "parameters": [
                {
                  "name": "model_name",
                  "type": "str",
                  "description": "The name of the LLM model for which to configure batch settings."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method does not explicitly call other methods, classes, or functions within its source code.",
                "called_by": "This method is called by the '__init__' method."
              }
            },
            "error": null
          },
          {
            "identifier": "generate_for_functions",
            "description": {
              "overall": "This method generates documentation for a list of functions by sending them in batches to the configured LLM. It takes a list of FunctionAnalysisInput objects, converts them into JSON payloads, and constructs conversations with the 'function_system_prompt'. The method then iterates through these conversations in batches, calling the 'function_llm.batch' method, and handles potential errors by extending the results with None for failed items. It also includes a waiting period between batches to respect API rate limits.",
              "parameters": [
                {
                  "name": "function_inputs",
                  "type": "List[FunctionAnalysisInput]",
                  "description": "A list of input objects containing function details for which documentation is to be generated."
                }
              ],
              "returns": [
                {
                  "name": "all_validated_functions",
                  "type": "List[Optional[FunctionAnalysis]]",
                  "description": "A list of FunctionAnalysis objects, or None for any failed generations, representing the generated documentation for each function."
                }
              ],
              "usage_context": {
                "calls": "This method calls 'json.dumps', 'model_dump', 'SystemMessage', 'HumanMessage', 'len', 'range', 'min', 'logging.info', 'self.function_llm.batch', 'all_validated_functions.extend', 'logging.error', and 'time.sleep'.",
                "called_by": "This method is not explicitly called by any other methods within the provided context."
              }
            },
            "error": null
          },
          {
            "identifier": "generate_for_classes",
            "description": {
              "overall": "This method generates documentation for a list of classes by processing them in batches using the configured LLM. It accepts a list of ClassAnalysisInput objects, serializes them into JSON, and prepares them as HumanMessage content alongside the 'class_system_prompt'. The method then iterates through these prepared conversations in batches, invoking 'self.class_llm.batch' to get structured class analysis. It includes error handling for batch calls and implements a waiting period between batches to manage API rate limits.",
              "parameters": [
                {
                  "name": "class_inputs",
                  "type": "List[ClassAnalysisInput]",
                  "description": "A list of input objects containing class details for which documentation is to be generated."
                }
              ],
              "returns": [
                {
                  "name": "all_validated_classes",
                  "type": "List[Optional[ClassAnalysis]]",
                  "description": "A list of ClassAnalysis objects, or None for any failed generations, representing the generated documentation for each class."
                }
              ],
              "usage_context": {
                "calls": "This method calls 'json.dumps', 'model_dump', 'SystemMessage', 'HumanMessage', 'len', 'range', 'min', 'logging.info', 'self.class_llm.batch', 'all_validated_classes.extend', 'logging.error', and 'time.sleep'.",
                "called_by": "This method is not explicitly called by any other methods within the provided context."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "This class depends on 'os', 'json', 'logging', 'time', 'typing.List', 'typing.Optional', 'dotenv.load_dotenv', 'langchain_google_genai.ChatGoogleGenerativeAI', 'langchain_ollama.ChatOllama', 'langchain_openai.ChatOpenAI', 'langchain.messages.HumanMessage', 'langchain.messages.SystemMessage', 'pydantic.ValidationError', 'schemas.types.FunctionAnalysis', 'schemas.types.ClassAnalysis', 'schemas.types.FunctionAnalysisInput', and 'schemas.types.ClassAnalysisInput'.",
          "instantiated_by": "This class is not explicitly instantiated by any other components within the provided context."
        }
      },
      "error": null
    },
    "backend.MainLLM.MainLLM": {
      "identifier": "backend.MainLLM.MainLLM",
      "description": {
        "overall": "The MainLLM class serves as a versatile interface for interacting with various Large Language Models (LLMs). It abstracts away the complexities of different LLM providers by dynamically initializing the appropriate client (e.g., Google Generative AI, OpenAI-compatible, Ollama) based on the specified model name. The class manages a system prompt for consistent LLM behavior and offers both synchronous (`call_llm`) and asynchronous streaming (`stream_llm`) methods for generating responses.",
        "init_method": {
          "description": "The constructor initializes the MainLLM instance by setting up the system prompt from a file and configuring the underlying Large Language Model (LLM) client. It supports various LLM providers like Gemini, OpenAI-compatible APIs (e.g., SCADSLLM), and Ollama, dynamically selecting the client based on the `model_name`. It also performs validation for the API key and prompt file path, and initializes `self.system_prompt`, `self.model_name`, and `self.llm`.",
          "parameters": [
            {
              "name": "api_key",
              "type": "str",
              "description": "The API key required for authenticating with the chosen LLM service."
            },
            {
              "name": "prompt_file_path",
              "type": "str",
              "description": "The file path to the system prompt that will guide the LLM's behavior."
            },
            {
              "name": "model_name",
              "type": "str",
              "description": "The name of the LLM model to use, defaulting to 'gemini-2.5-pro'. This determines which LLM client is initialized."
            },
            {
              "name": "base_url",
              "type": "str",
              "description": "An optional base URL for custom LLM endpoints, used primarily for Ollama or other OpenAI-compatible services."
            }
          ]
        },
        "methods": [
          {
            "identifier": "call_llm",
            "description": {
              "overall": "This method sends a user input along with the pre-configured system prompt to the initialized LLM and retrieves a single, complete response. It constructs a list of messages, including a `SystemMessage` and a `HumanMessage`, and then invokes the `self.llm` object. The method includes logging for the call process and error handling to catch exceptions during the LLM invocation.",
              "parameters": [
                {
                  "name": "user_input",
                  "type": "str",
                  "description": "The user's query or message to be sent to the LLM."
                }
              ],
              "returns": [
                {
                  "name": "content",
                  "type": "str",
                  "description": "The textual content of the LLM's response."
                },
                {
                  "name": "None",
                  "type": "None",
                  "description": "Returns None if an error occurs during the LLM call."
                }
              ],
              "usage_context": {
                "calls": "This method does not explicitly call other methods, classes, or functions listed in its context.",
                "called_by": "This method is not explicitly called by other functions or methods listed in its context."
              }
            },
            "error": null
          },
          {
            "identifier": "stream_llm",
            "description": {
              "overall": "This method interacts with the LLM to stream its response in chunks, rather than waiting for a complete reply. It constructs the same message structure as `call_llm` but uses the `self.llm.stream` method. It then iterates through the chunks yielded by the LLM, yielding each chunk's content. Error handling is included to catch exceptions during the streaming process and yield an error message.",
              "parameters": [
                {
                  "name": "user_input",
                  "type": "str",
                  "description": "The user's query or message for which a streaming response is desired."
                }
              ],
              "returns": [
                {
                  "name": "chunk.content",
                  "type": "str",
                  "description": "Yields individual content chunks from the LLM's streaming response."
                },
                {
                  "name": "error_message",
                  "type": "str",
                  "description": "Yields an error message string if an exception occurs during streaming."
                }
              ],
              "usage_context": {
                "calls": "This method does not explicitly call other methods, classes, or functions listed in its context.",
                "called_by": "This method is not explicitly called by other functions or methods listed in its context."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "This class does not explicitly list external functional dependencies in its provided context.",
          "instantiated_by": "This class is not explicitly listed as being instantiated by other components in its provided context."
        }
      },
      "error": null
    },
    "backend.basic_info.ProjektInfoExtractor": {
      "identifier": "backend.basic_info.ProjektInfoExtractor",
      "description": {
        "overall": "The ProjektInfoExtractor class is designed to extract fundamental project information from various common project files such as README, pyproject.toml, and requirements.txt. It consolidates this information into a structured dictionary, prioritizing certain file types for specific data points. The class handles data cleaning, markdown parsing, and provides fallback mechanisms for missing information, including deriving a project title from a repository URL.",
        "init_method": {
          "description": "The constructor initializes the extractor by setting a default 'Information not found' string and establishing the base structure of the 'info' dictionary. This dictionary serves as a container for extracted project details, including project overview (title, description, status, features, tech stack) and installation information (dependencies, setup guide, quick start guide), all pre-filled with the 'Information not found' placeholder.",
          "parameters": []
        },
        "methods": [
          {
            "identifier": "_clean_content",
            "description": {
              "overall": "This private method is responsible for cleaning string content by removing null bytes. Null bytes can appear due to encoding errors, particularly when a file encoded as UTF-16 is incorrectly read as UTF-8. The method ensures that the content is free of these problematic characters before further processing.",
              "parameters": [
                {
                  "name": "content",
                  "type": "str",
                  "description": "The string content to be cleaned."
                }
              ],
              "returns": [
                {
                  "name": "",
                  "type": "str",
                  "description": "The cleaned string content, with null bytes removed. Returns an empty string if the input content is empty."
                }
              ],
              "usage_context": {
                "calls": "This method does not explicitly call other methods, classes, or functions within its source code beyond basic string operations.",
                "called_by": "This method is called by _parse_readme, _parse_toml, and _parse_requirements."
              }
            },
            "error": null
          },
          {
            "identifier": "_finde_datei",
            "description": {
              "overall": "This private method searches through a list of files to find one that matches any of the provided patterns. The search is case-insensitive, making it robust against variations in file naming conventions. It iterates through each file and each pattern, returning the first file object that matches.",
              "parameters": [
                {
                  "name": "patterns",
                  "type": "List[str]",
                  "description": "A list of string patterns to match against file paths."
                },
                {
                  "name": "dateien",
                  "type": "List[Any]",
                  "description": "A list of file-like objects, each expected to have a 'path' attribute."
                }
              ],
              "returns": [
                {
                  "name": "",
                  "type": "Optional[Any]",
                  "description": "The first file object that matches one of the patterns, or None if no match is found."
                }
              ],
              "usage_context": {
                "calls": "This method does not explicitly call other methods, classes, or functions within its source code beyond basic string operations.",
                "called_by": "This method is called by extrahiere_info."
              }
            },
            "error": null
          },
          {
            "identifier": "_extrahiere_sektion_aus_markdown",
            "description": {
              "overall": "This private method extracts text content located directly beneath a Markdown H2 heading (##) that matches one of the specified keywords. It constructs a regular expression dynamically to find the heading and then captures all content until the next H2 heading or the end of the document. This is useful for parsing structured sections within Markdown files.",
              "parameters": [
                {
                  "name": "inhalt",
                  "type": "str",
                  "description": "The Markdown content string to be parsed."
                },
                {
                  "name": "keywords",
                  "type": "List[str]",
                  "description": "A list of keywords to match against the H2 heading text."
                }
              ],
              "returns": [
                {
                  "name": "",
                  "type": "Optional[str]",
                  "description": "The extracted text content under the matching H2 heading, stripped of leading/trailing whitespace, or None if no matching section is found."
                }
              ],
              "usage_context": {
                "calls": "This method calls re.escape, re.compile, re.IGNORECASE, re.DOTALL, pattern.search, match.group, and strip.",
                "called_by": "This method is called by _parse_readme."
              }
            },
            "error": null
          },
          {
            "identifier": "_parse_readme",
            "description": {
              "overall": "This private method parses the content of a README file to extract various project details. It first cleans the content using `_clean_content`. It then attempts to find the project title and a general description using regular expressions. Subsequently, it utilizes `_extrahiere_sektion_aus_markdown` to extract specific sections like 'Key Features', 'Tech Stack', 'Status', 'Installation', and 'Quick Start Guide', updating the class's `self.info` dictionary.",
              "parameters": [
                {
                  "name": "inhalt",
                  "type": "str",
                  "description": "The content of the README file as a string."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls self._clean_content, re.search, and self._extrahiere_sektion_aus_markdown.",
                "called_by": "This method is called by extrahiere_info."
              }
            },
            "error": null
          },
          {
            "identifier": "_parse_toml",
            "description": {
              "overall": "This private method parses the content of a `pyproject.toml` file to extract project-related metadata. It first cleans the content using `_clean_content`. If the `tomllib` module is available, it attempts to load and parse the TOML content. It then extracts the project 'name', 'description', and 'dependencies' from the 'project' table, updating the `self.info` dictionary. It includes error handling for `tomllib` not being installed or for TOML decoding errors.",
              "parameters": [
                {
                  "name": "inhalt",
                  "type": "str",
                  "description": "The content of the pyproject.toml file as a string."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls self._clean_content, print, tomllib.loads, data.get, and tomllib.TOMLDecodeError.",
                "called_by": "This method is called by extrahiere_info."
              }
            },
            "error": null
          },
          {
            "identifier": "_parse_requirements",
            "description": {
              "overall": "This private method parses the content of a `requirements.txt` file to extract project dependencies. It first cleans the content using `_clean_content`. It then processes each line, filtering out empty lines and comments, to compile a list of dependencies. This method only updates the `self.info` dictionary if dependencies have not already been populated from another source, such as a `pyproject.toml` file, ensuring prioritization.",
              "parameters": [
                {
                  "name": "inhalt",
                  "type": "str",
                  "description": "The content of the requirements.txt file as a string."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls self._clean_content.",
                "called_by": "This method is called by extrahiere_info."
              }
            },
            "error": null
          },
          {
            "identifier": "extrahiere_info",
            "description": {
              "overall": "This public method orchestrates the entire process of extracting project information. It begins by identifying relevant project files (README, pyproject.toml, requirements.txt) using `_finde_datei`. It then parses these files in a specific order of priority: `pyproject.toml` first, then `requirements.txt`, and finally `README.md`. After parsing, it formats the extracted dependencies and, if no project title was found, attempts to derive one from the provided repository URL. The method returns the comprehensive `self.info` dictionary containing all gathered project details.",
              "parameters": [
                {
                  "name": "dateien",
                  "type": "List[Any]",
                  "description": "A list of file-like objects, each expected to have 'path' and 'content' attributes, representing files in the project."
                },
                {
                  "name": "repo_url",
                  "type": "str",
                  "description": "The URL of the repository, used as a fallback to derive the project title."
                }
              ],
              "returns": [
                {
                  "name": "",
                  "type": "Dict[str, Any]",
                  "description": "A dictionary containing all extracted project information, including overview and installation details."
                }
              ],
              "usage_context": {
                "calls": "This method calls self._finde_datei, self._parse_toml, self._parse_requirements, self._parse_readme, isinstance, os.path.basename, and removesuffix.",
                "called_by": "This method is not explicitly called by any other functions or methods in the provided context."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "This class does not explicitly list any external functional dependencies in the provided context.",
          "instantiated_by": "This class is not explicitly instantiated by any other functions or methods in the provided context."
        }
      },
      "error": null
    },
    "backend.callgraph.CallGraph": {
      "identifier": "backend.callgraph.CallGraph",
      "description": {
        "overall": "The CallGraph class is an ast.NodeVisitor implementation designed to construct a call graph for a given Python source file. It traverses the Abstract Syntax Tree (AST) of the file, identifying function and class definitions, import statements, and function calls. It resolves function and method names to their fully qualified forms, considering local definitions and import aliases, and records the calling relationships (edges) between functions in a directed graph. This class is crucial for understanding the structural dependencies and execution flow within a Python codebase.",
        "init_method": {
          "description": "Initializes the CallGraph instance by setting up the filename, tracking current function and class context, and initializing various data structures like local_defs, graph (a NetworkX DiGraph), import_mapping, function_set, and edges to store call graph information.",
          "parameters": [
            {
              "name": "filename",
              "type": "str",
              "description": "The path to the source file being analyzed."
            }
          ]
        },
        "methods": [
          {
            "identifier": "_recursive_call",
            "description": {
              "overall": "This private helper method recursively traverses an Abstract Syntax Tree (AST) node, specifically designed to extract the full dotted name components of a function call or attribute access. It handles ast.Call, ast.Name, and ast.Attribute nodes, returning a list of string parts that represent the full name.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.AST",
                  "description": "The AST node to be recursively processed."
                }
              ],
              "returns": [
                {
                  "name": "name",
                  "type": "list[str]",
                  "description": "A list of string components representing the dotted name (e.g., ['pkg', 'mod', 'Class', 'method'])."
                }
              ],
              "usage_context": {
                "calls": "This method recursively calls itself.",
                "called_by": "This method is called by visit_Call."
              }
            },
            "error": null
          },
          {
            "identifier": "_resolve_all_callee_names",
            "description": {
              "overall": "This private helper method takes a list of potential callee name components (e.g., [['module', 'function'], ['Class', 'method']]) and attempts to resolve them to their fully qualified names. It prioritizes local definitions (self.local_defs), then uses the import_mapping for imported modules, and finally constructs a full name based on the current filename and class context if no other resolution is found.",
              "parameters": [
                {
                  "name": "callee_nodes",
                  "type": "list[list[str]]",
                  "description": "A list where each inner list represents the name components of a potential callee."
                }
              ],
              "returns": [
                {
                  "name": "resolved",
                  "type": "list[str]",
                  "description": "A list of fully qualified names for the callees."
                }
              ],
              "usage_context": {
                "calls": "This method does not explicitly call other functions or methods within its own definition.",
                "called_by": "This method is called by visit_Call."
              }
            },
            "error": null
          },
          {
            "identifier": "_make_full_name",
            "description": {
              "overall": "This private helper method constructs a fully qualified name for a function or method. It takes a base name and an optional class name, prepending the self.filename and class_name (if provided) to form a unique identifier using \"::\" as a separator.",
              "parameters": [
                {
                  "name": "basename",
                  "type": "str",
                  "description": "The base name of the function or method."
                },
                {
                  "name": "class_name",
                  "type": "str | None",
                  "description": "The name of the class if the entity is a method, otherwise None."
                }
              ],
              "returns": [
                {
                  "name": "full_name",
                  "type": "str",
                  "description": "The fully qualified name (e.g., filename::ClassName::methodName or filename::functionName)."
                }
              ],
              "usage_context": {
                "calls": "This method does not explicitly call other functions or methods within its own definition.",
                "called_by": "This method is called by visit_FunctionDef."
              }
            },
            "error": null
          },
          {
            "identifier": "_current_caller",
            "description": {
              "overall": "This private helper method determines the identifier of the currently active caller context. If self.current_function is set, it returns that value. Otherwise, it returns a placeholder indicating the global scope within the current file or a generic global scope if the filename is not available.",
              "parameters": [],
              "returns": [
                {
                  "name": "caller_identifier",
                  "type": "str",
                  "description": "The fully qualified name of the current function or a string indicating the global scope."
                }
              ],
              "usage_context": {
                "calls": "This method does not explicitly call other functions or methods within its own definition.",
                "called_by": "This method is called by visit_Call."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_Import",
            "description": {
              "overall": "This method, overriding an ast.NodeVisitor method, processes ast.Import nodes. It iterates through the imported modules, extracts their names and any aliases, and populates self.import_mapping to store the mapping from alias (or original name) to the module's actual name. It then calls generic_visit to continue AST traversal.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.Import",
                  "description": "The AST node representing an import statement."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls self.generic_visit.",
                "called_by": "This method is implicitly called by the ast.NodeVisitor's traversal mechanism when an ast.Import node is encountered."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_ImportFrom",
            "description": {
              "overall": "This method, overriding an ast.NodeVisitor method, processes ast.ImportFrom nodes. It extracts the module name and then iterates through the imported names (e.g., from module import name as alias). It populates self.import_mapping with mappings from the alias (or original name) to the imported module or specific name. It then calls generic_visit to continue AST traversal.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.ImportFrom",
                  "description": "The AST node representing an from ... import ... statement."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls self.generic_visit.",
                "called_by": "This method is implicitly called by the ast.NodeVisitor's traversal mechanism when an ast.ImportFrom node is encountered."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_ClassDef",
            "description": {
              "overall": "This method, overriding an ast.NodeVisitor method, processes ast.ClassDef nodes. It temporarily sets self.current_class to the name of the class being visited, allowing nested functions/methods to correctly determine their full names. After visiting the class's body using generic_visit, it restores self.current_class to its previous value, ensuring proper context management.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.ClassDef",
                  "description": "The AST node representing a class definition."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls self.generic_visit.",
                "called_by": "This method is implicitly called by the ast.NodeVisitor's traversal mechanism when an ast.ClassDef node is encountered."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_FunctionDef",
            "description": {
              "overall": "This method, overriding an ast.NodeVisitor method, processes ast.FunctionDef nodes. It constructs the full qualified name of the function using _make_full_name, stores it in self.local_defs for resolution, and updates self.current_function to reflect the current context. It adds the function as a node to the self.graph and then traverses its body. Finally, it adds the function to self.function_set and restores self.current_function.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.FunctionDef",
                  "description": "The AST node representing a function definition."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls self._make_full_name, self.graph.add_node, and self.generic_visit.",
                "called_by": "This method is implicitly called by the ast.NodeVisitor's traversal mechanism when an ast.FunctionDef node is encountered. It is also explicitly called by visit_AsyncFunctionDef."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_AsyncFunctionDef",
            "description": {
              "overall": "This method, overriding an ast.NodeVisitor method, processes ast.AsyncFunctionDef nodes. It delegates the entire processing logic to visit_FunctionDef, treating asynchronous function definitions identically to regular function definitions for the purpose of call graph construction.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.AsyncFunctionDef",
                  "description": "The AST node representing an asynchronous function definition."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls self.visit_FunctionDef.",
                "called_by": "This method is implicitly called by the ast.NodeVisitor's traversal mechanism when an ast.AsyncFunctionDef node is encountered."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_Call",
            "description": {
              "overall": "This method, overriding an ast.NodeVisitor method, processes ast.Call nodes to identify function calls. It determines the caller using _current_caller, extracts the callee name components using _recursive_call, and then resolves these names to fully qualified identifiers using _resolve_all_callee_names. The resolved callees are then added as edges from the caller in self.edges. It ensures that the caller exists in self.edges before adding callees.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.Call",
                  "description": "The AST node representing a function call."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls self._current_caller, self._recursive_call, self._resolve_all_callee_names, and self.generic_visit.",
                "called_by": "This method is implicitly called by the ast.NodeVisitor's traversal mechanism when an ast.Call node is encountered."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_If",
            "description": {
              "overall": "This method, overriding an ast.NodeVisitor method, processes ast.If nodes. It specifically handles the common if __name__ == \"__main__\": block by temporarily setting self.current_function to \"<main_block>\" to correctly attribute calls within this block. For other if statements, it simply continues the generic AST traversal.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.If",
                  "description": "The AST node representing an if statement."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls self.generic_visit.",
                "called_by": "This method is implicitly called by the ast.NodeVisitor's traversal mechanism when an ast.If node is encountered."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "The class depends on the 'ast' module for parsing Python code and the 'networkx' library for graph representation.",
          "instantiated_by": "The input context does not specify where this class is instantiated."
        }
      },
      "error": null
    },
    "backend.getRepo.RepoFile": {
      "identifier": "backend.getRepo.RepoFile",
      "description": {
        "overall": "The RepoFile class represents a single file within a Git repository, providing a structured way to access its metadata and content. It employs a lazy-loading strategy for its Git blob object, content, and size, ensuring that these potentially heavy resources are only loaded when explicitly accessed. The class offers properties to retrieve the underlying Git blob, the file's decoded content, and its size, along with utility methods for analysis (like word count) and serialization to a dictionary.",
        "init_method": {
          "description": "The __init__ method initializes a RepoFile object by storing the file path and the Git Tree object from which the file originates. It also sets up internal attributes such as `_blob`, `_content`, and `_size` to `None` for subsequent lazy loading.",
          "parameters": [
            {
              "name": "file_path",
              "type": "str",
              "description": "The path to the file within the repository."
            },
            {
              "name": "commit_tree",
              "type": "git.Tree",
              "description": "The Tree-object of the commit from which the file originates."
            }
          ]
        },
        "methods": [
          {
            "identifier": "blob",
            "description": {
              "overall": "This property provides lazy loading for the Git blob object associated with the file. It checks if the `_blob` attribute is already loaded; if not, it attempts to retrieve the blob from the `_tree` using the stored `path`. If the file is not found in the tree, it raises a `FileNotFoundError` to indicate the missing file.",
              "parameters": [],
              "returns": [
                {
                  "name": "blob",
                  "type": "git.Blob",
                  "description": "The Git blob object representing the file."
                }
              ],
              "usage_context": {
                "calls": "This method does not explicitly call other functions or methods.",
                "called_by": "This method is not explicitly called by other functions or methods in the provided context, but it is accessed as a property by `content` and `size`."
              }
            },
            "error": null
          },
          {
            "identifier": "content",
            "description": {
              "overall": "This property provides lazy loading for the decoded content of the file. It first checks if the `_content` attribute is already loaded. If not, it accesses the `blob` property (which handles its own lazy loading) and reads its `data_stream`, decoding it as UTF-8 while ignoring any decoding errors.",
              "parameters": [],
              "returns": [
                {
                  "name": "content",
                  "type": "str",
                  "description": "The decoded string content of the file."
                }
              ],
              "usage_context": {
                "calls": "This method calls the `blob` property to retrieve the Git blob object.",
                "called_by": "This method is not explicitly called by other functions or methods in the provided context, but it is accessed as a property by `analyze_word_count` and `to_dict`."
              }
            },
            "error": null
          },
          {
            "identifier": "size",
            "description": {
              "overall": "This property provides lazy loading for the size of the file in bytes. It checks if the `_size` attribute is already loaded. If not, it accesses the `blob` property (which handles its own lazy loading) and retrieves its `size` attribute, storing it for future access.",
              "parameters": [],
              "returns": [
                {
                  "name": "size",
                  "type": "int",
                  "description": "The size of the file in bytes."
                }
              ],
              "usage_context": {
                "calls": "This method calls the `blob` property to retrieve the Git blob object.",
                "called_by": "This method is not explicitly called by other functions or methods in the provided context, but it is accessed as a property by `to_dict`."
              }
            },
            "error": null
          },
          {
            "identifier": "analyze_word_count",
            "description": {
              "overall": "This method serves as an example analysis method, demonstrating how to process the file's content. It calculates and returns the total number of words present in the file's content. It achieves this by accessing the `content` property, splitting the string by whitespace, and then returning the length of the resulting list.",
              "parameters": [],
              "returns": [
                {
                  "name": "word_count",
                  "type": "int",
                  "description": "The total number of words in the file content."
                }
              ],
              "usage_context": {
                "calls": "This method calls the `content` property to get the file's content.",
                "called_by": "This method is not explicitly called by other functions or methods in the provided context."
              }
            },
            "error": null
          },
          {
            "identifier": "__repr__",
            "description": {
              "overall": "This special method provides a developer-friendly string representation of the `RepoFile` object. It returns a string formatted to show the class name and the path of the file it represents, which is useful for debugging and logging purposes.",
              "parameters": [],
              "returns": [
                {
                  "name": "representation",
                  "type": "str",
                  "description": "A string representation of the RepoFile object, including its path."
                }
              ],
              "usage_context": {
                "calls": "This method does not explicitly call other functions or methods.",
                "called_by": "This method is not explicitly called by other functions or methods in the provided context."
              }
            },
            "error": null
          },
          {
            "identifier": "to_dict",
            "description": {
              "overall": "This method converts the `RepoFile` object into a dictionary representation, providing structured data about the file. It includes the file's path, its base name, its size, and its type as 'file'. Optionally, it can also include the full content of the file if the `include_content` parameter is set to `True`.",
              "parameters": [
                {
                  "name": "include_content",
                  "type": "bool",
                  "description": "A flag indicating whether the file's content should be included in the dictionary. Defaults to `False`."
                }
              ],
              "returns": [
                {
                  "name": "file_data",
                  "type": "dict",
                  "description": "A dictionary containing file metadata and optionally its content."
                }
              ],
              "usage_context": {
                "calls": "This method calls `os.path.basename` to extract the file name and accesses the `size` and `content` properties of the instance.",
                "called_by": "This method is not explicitly called by other functions or methods in the provided context."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "This class does not have any explicit external dependencies listed in the provided context.",
          "instantiated_by": "This class is not explicitly shown to be instantiated by other functions or methods in the provided context."
        }
      },
      "error": null
    },
    "backend.getRepo.GitRepository": {
      "identifier": "backend.getRepo.GitRepository",
      "description": {
        "overall": "The GitRepository class is designed to manage a Git repository by cloning it into a temporary local directory and providing structured access to its contents. It acts as a context manager, ensuring that the temporary directory is automatically cleaned up upon exiting a 'with' block. The class facilitates retrieving all files as RepoFile objects and constructing a hierarchical representation of the repository's file structure, making it easy to navigate and process repository contents programmatically.",
        "init_method": {
          "description": "The constructor initializes a GitRepository instance by cloning a specified Git repository into a temporary directory. It sets up instance attributes such as the repository URL, the path to the temporary directory, the GitPython Repo object, the latest commit, and its commit tree. If cloning fails, it cleans up the temporary directory and raises a RuntimeError.",
          "parameters": [
            {
              "name": "repo_url",
              "type": "string",
              "description": "The URL of the Git repository to be cloned."
            }
          ]
        },
        "methods": [
          {
            "identifier": "get_all_files",
            "description": {
              "overall": "This method retrieves a list of all files present in the cloned Git repository. It uses the underlying Git command 'ls-files' to get file paths, then iterates through these paths to create RepoFile objects. These RepoFile instances, each representing a file in the repository, are stored internally and returned.",
              "parameters": [],
              "returns": [
                {
                  "name": "None",
                  "type": "list[RepoFile]",
                  "description": "A list of RepoFile instances representing all files in the repository."
                }
              ],
              "usage_context": {
                "calls": "This method calls the RepoFile constructor.",
                "called_by": "This method is not explicitly called by other methods in the provided context."
              }
            },
            "error": null
          },
          {
            "identifier": "close",
            "description": {
              "overall": "This method is responsible for cleaning up resources by deleting the temporary directory where the Git repository was cloned. It first checks if self.temp_dir is set, prints a message indicating the directory is being deleted, and then sets self.temp_dir to None. This ensures that the temporary directory and its contents are removed from the filesystem.",
              "parameters": [],
              "returns": [],
              "usage_context": {
                "calls": "This method does not explicitly call other methods, classes, or functions.",
                "called_by": "This method is called by the __init__ method in case of a cloning error and by the __exit__ context manager method."
              }
            },
            "error": null
          },
          {
            "identifier": "__enter__",
            "description": {
              "overall": "This special method makes the GitRepository class compatible with the context manager protocol (i.e., usable with the 'with' statement). When an instance of GitRepository is used in a 'with' statement, this method is invoked upon entering the runtime context. It simply returns the instance itself, allowing it to be bound to a variable in the 'as' clause of the 'with' statement.",
              "parameters": [],
              "returns": [
                {
                  "name": "None",
                  "type": "GitRepository",
                  "description": "The instance of the GitRepository itself."
                }
              ],
              "usage_context": {
                "calls": "This method does not explicitly call other methods, classes, or functions.",
                "called_by": "This method is implicitly called when the GitRepository object is used in a 'with' statement."
              }
            },
            "error": null
          },
          {
            "identifier": "__exit__",
            "description": {
              "overall": "This special method is part of the context manager protocol and is automatically called when exiting the runtime context established by a 'with' statement. Its primary responsibility is to ensure that the close method is invoked, which handles the cleanup of the temporary repository directory. This guarantees resource deallocation even if exceptions occur within the 'with' block.",
              "parameters": [
                {
                  "name": "exc_type",
                  "type": "type",
                  "description": "The type of the exception that caused the context to be exited, or None if no exception occurred."
                },
                {
                  "name": "exc_val",
                  "type": "Exception",
                  "description": "The exception instance that caused the context to be exited, or None."
                },
                {
                  "name": "exc_tb",
                  "type": "traceback",
                  "description": "A traceback object encapsulating the call stack at the point where the exception originally occurred, or None."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls the close method of the GitRepository instance.",
                "called_by": "This method is implicitly called when exiting a 'with' statement block that uses a GitRepository object."
              }
            },
            "error": null
          },
          {
            "identifier": "get_file_tree",
            "description": {
              "overall": "This method constructs a hierarchical tree representation of the repository's files and directories. If the list of files (self.files) is not yet populated, it first calls get_all_files to retrieve them. It then iterates through each RepoFile object, splitting its path to build a nested dictionary structure that mimics the file system hierarchy. Each file is added to its respective directory node, optionally including its content.",
              "parameters": [
                {
                  "name": "include_content",
                  "type": "bool",
                  "description": "A flag indicating whether the content of the files should be included in the generated tree structure. Defaults to False."
                }
              ],
              "returns": [
                {
                  "name": "None",
                  "type": "dict",
                  "description": "A dictionary representing the hierarchical file tree of the repository, with directories and files nested appropriately."
                }
              ],
              "usage_context": {
                "calls": "This method calls self.get_all_files() and file_obj.to_dict().",
                "called_by": "This method is not explicitly called by other methods in the provided context."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "This class depends on backend.getRepo.RepoFile for representing individual files within the repository.",
          "instantiated_by": "This class is not explicitly instantiated by other methods in the provided context."
        }
      },
      "error": null
    },
    "backend.relationship_analyzer.ProjectAnalyzer": {
      "identifier": "backend.relationship_analyzer.ProjectAnalyzer",
      "description": {
        "overall": "The ProjectAnalyzer class is designed to perform static analysis on a Python project to build a comprehensive call graph. It identifies all Python files, collects definitions of functions, methods, and classes, and then resolves calls between these defined entities. The class provides methods to initiate the analysis, retrieve the raw call graph, and extract structured incoming and outgoing relationships, serving as a core component for understanding code dependencies.",
        "init_method": {
          "description": "The __init__ method initializes a ProjectAnalyzer instance by setting up the project's root directory, initializing data structures like definitions, call_graph, and file_asts, and defining a set of directories to ignore during file traversal. It converts the provided project_root to an absolute path.",
          "parameters": [
            {
              "name": "project_root",
              "type": "str",
              "description": "The root directory of the project to be analyzed."
            }
          ]
        },
        "methods": [
          {
            "identifier": "analyze",
            "description": {
              "overall": "This method orchestrates the entire project analysis process. It first identifies all Python files within the project, then iterates through them to collect function, method, and class definitions. Subsequently, it resolves calls within each file to build a comprehensive call graph. Finally, it clears the stored ASTs and returns the generated call graph.",
              "parameters": [],
              "returns": [
                {
                  "name": "call_graph",
                  "type": "defaultdict",
                  "description": "A defaultdict representing the call graph, where keys are callee pathnames and values are lists of caller information."
                }
              ],
              "usage_context": {
                "calls": "This method does not make any external calls to other functions or methods based on the provided context.",
                "called_by": "This method is not explicitly called by other methods within the provided context."
              }
            },
            "error": null
          },
          {
            "identifier": "get_raw_relationships",
            "description": {
              "overall": "This method processes the internal call_graph to generate structured outgoing and incoming relationship dictionaries. It iterates through the call graph, extracting caller and callee identifiers, and populates two defaultdict instances to represent the relationships. The final output provides sorted lists of relationships for both outgoing and incoming calls.",
              "parameters": [],
              "returns": [
                {
                  "name": "relationships",
                  "type": "dict",
                  "description": "A dictionary containing 'outgoing' and 'incoming' relationships, where each is a dictionary mapping an identifier to a sorted list of related identifiers."
                }
              ],
              "usage_context": {
                "calls": "This method does not make any external calls to other functions or methods based on the provided context.",
                "called_by": "This method is not explicitly called by other methods within the provided context."
              }
            },
            "error": null
          },
          {
            "identifier": "_find_py_files",
            "description": {
              "overall": "This private helper method traverses the project directory starting from self.project_root to locate all Python files. It uses os.walk and filters out directories specified in self.ignore_dirs to avoid analyzing irrelevant paths. It returns a list of absolute file paths for all discovered Python files.",
              "parameters": [],
              "returns": [
                {
                  "name": "py_files",
                  "type": "list[str]",
                  "description": "A list of absolute file paths to all Python files found in the project, excluding ignored directories."
                }
              ],
              "usage_context": {
                "calls": "This method does not make any external calls to other functions or methods based on the provided context.",
                "called_by": "This method is not explicitly called by other methods within the provided context."
              }
            },
            "error": null
          },
          {
            "identifier": "_collect_definitions",
            "description": {
              "overall": "This private method is responsible for parsing a given Python file and collecting all function, method, and class definitions within it. It reads the file, parses its Abstract Syntax Tree (AST), and stores the AST in self.file_asts. It then walks the AST to identify definitions, determining their type (function, method, or class) and their fully qualified path name, which are stored in self.definitions. Error handling is included for file processing issues.",
              "parameters": [
                {
                  "name": "filepath",
                  "type": "str",
                  "description": "The absolute path to the Python file to be analyzed for definitions."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls backend.relationship_analyzer.path_to_module.",
                "called_by": "This method is not explicitly called by other methods within the provided context."
              }
            },
            "error": null
          },
          {
            "identifier": "_get_parent",
            "description": {
              "overall": "This private helper method traverses an Abstract Syntax Tree (AST) to find the immediate parent node of a given child node. It iterates through all nodes in the tree and checks their children to identify if any child matches the provided node. If a match is found, the parent node is returned. If no parent is found (e.g., for the root node), it returns None.",
              "parameters": [
                {
                  "name": "tree",
                  "type": "ast.AST",
                  "description": "The Abstract Syntax Tree to search within."
                },
                {
                  "name": "node",
                  "type": "ast.AST",
                  "description": "The child node for which to find the parent."
                }
              ],
              "returns": [
                {
                  "name": "parent",
                  "type": "ast.AST | None",
                  "description": "The parent AST node of the given node, or None if no parent is found."
                }
              ],
              "usage_context": {
                "calls": "This method does not make any external calls to other functions or methods based on the provided context.",
                "called_by": "This method is not explicitly called by other methods within the provided context."
              }
            },
            "error": null
          },
          {
            "identifier": "_resolve_calls",
            "description": {
              "overall": "This private method takes a file's AST and uses a CallResolverVisitor to identify and resolve function and method calls within that file. It retrieves the AST from self.file_asts, initializes the visitor with necessary context (filepath, project root, definitions), and then visits the AST. The resolved calls are then extended into the self.call_graph structure. Error handling is included for issues during call resolution.",
              "parameters": [
                {
                  "name": "filepath",
                  "type": "str",
                  "description": "The absolute path to the Python file whose calls need to be resolved."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls backend.relationship_analyzer.CallResolverVisitor.",
                "called_by": "This method is not explicitly called by other methods within the provided context."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "This class depends on CallResolverVisitor for resolving function calls and path_to_module for converting file paths to module paths.",
          "instantiated_by": "This class is not explicitly instantiated by other components within the provided context."
        }
      },
      "error": null
    },
    "backend.relationship_analyzer.CallResolverVisitor": {
      "identifier": "backend.relationship_analyzer.CallResolverVisitor",
      "description": {
        "overall": "The CallResolverVisitor class is an AST NodeVisitor designed to traverse Python source code's Abstract Syntax Tree (AST) to identify and resolve function and method calls. It builds a comprehensive map of call relationships within a project by tracking imports, class definitions, function definitions, and object instantiations. The visitor's core functionality involves determining the fully qualified name of both the caller and the callee to accurately record dependencies.",
        "init_method": {
          "description": "This constructor initializes the CallResolverVisitor instance by setting up essential attributes. It stores the file path, calculates the module path, and takes a dictionary of known definitions. It also initializes internal state variables such as `scope` for tracking imports, `instance_types` for mapping variable names to their class types, and `calls` to store the detected call relationships.",
          "parameters": [
            {
              "name": "filepath",
              "type": "string",
              "description": "The absolute path to the Python file currently being analyzed."
            },
            {
              "name": "project_root",
              "type": "string",
              "description": "The root directory of the entire project, used to determine relative module paths."
            },
            {
              "name": "definitions",
              "type": "dict",
              "description": "A dictionary containing all known qualified definitions (functions, classes) in the project, used for validating resolved call targets."
            }
          ]
        },
        "methods": [
          {
            "identifier": "visit_ClassDef",
            "description": {
              "overall": "This method is invoked by the AST visitor framework when a class definition node (`ast.ClassDef`) is encountered. Its primary role is to manage the `current_class_name` attribute, setting it to the name of the class being visited before recursively traversing its children. This ensures that any methods defined within the class are correctly associated with their parent class. After visiting the class's body, it restores the previous `current_class_name` to maintain correct scope.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.ClassDef",
                  "description": "The AST node representing the class definition."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method implicitly calls `self.generic_visit` to continue AST traversal.",
                "called_by": "This method is called by the `ast.NodeVisitor` framework during AST traversal when a class definition is encountered."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_FunctionDef",
            "description": {
              "overall": "This method is called when an `ast.FunctionDef` node is visited, indicating a function or method definition. It constructs the full qualified identifier for the function, taking into account whether it's a method within a class or a standalone function. The `current_caller_name` attribute is updated to this identifier, ensuring that any calls made within this function are correctly attributed to it. The original `current_caller_name` is restored upon exiting the function's scope.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.FunctionDef",
                  "description": "The AST node representing the function definition."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method implicitly calls `self.generic_visit` to continue AST traversal.",
                "called_by": "This method is called by the `ast.NodeVisitor` framework during AST traversal when a function definition is encountered."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_Call",
            "description": {
              "overall": "This method is triggered when an `ast.Call` node is encountered, signifying a function or method invocation. It attempts to resolve the fully qualified name of the callee using the `_resolve_call_qname` helper method. If the callee's qualified name is successfully resolved and exists within the known project definitions, the call information (including the caller's file, line number, qualified name, and type) is recorded in the `self.calls` dictionary, mapping the callee to a list of its callers.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.Call",
                  "description": "The AST node representing a function or method call."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls `self._resolve_call_qname` to determine the callee's qualified name and `os.path.basename` to extract the filename.",
                "called_by": "This method is called by the `ast.NodeVisitor` framework during AST traversal when a function or method call is encountered."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_Import",
            "description": {
              "overall": "This method processes `ast.Import` nodes, which represent `import module` statements. It iterates through each imported alias and stores it in the `self.scope` dictionary. The local name (either the alias or the original module name) is mapped to its corresponding module name, which is essential for resolving fully qualified names of entities imported directly.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.Import",
                  "description": "The AST node representing an import statement (e.g., `import os`)."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method implicitly calls `self.generic_visit` to continue AST traversal.",
                "called_by": "This method is called by the `ast.NodeVisitor` framework during AST traversal when an import statement is encountered."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_ImportFrom",
            "description": {
              "overall": "This method handles `ast.ImportFrom` nodes, which correspond to `from module import name` statements. It determines the full module path, correctly handling relative imports based on `node.level` and the current `module_path`. For each imported name, it populates the `self.scope` dictionary, mapping the local alias (or original name) to its fully qualified path. This mapping is crucial for accurate resolution of imported functions, classes, or variables.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.ImportFrom",
                  "description": "The AST node representing a `from ... import ...` statement."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method implicitly calls `self.generic_visit` to continue AST traversal.",
                "called_by": "This method is called by the `ast.NodeVisitor` framework during AST traversal when a `from ... import ...` statement is encountered."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_Assign",
            "description": {
              "overall": "This method processes `ast.Assign` nodes to identify and track class instantiations. It specifically looks for assignments where the right-hand side is a call to a constructor (e.g., `my_obj = MyClass()`). If the called class is found in the current `self.scope` and `self.definitions`, it records the qualified class name against the assigned variable's name in `self.instance_types`. This mapping is then used to resolve method calls on instances of that class.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.Assign",
                  "description": "The AST node representing an assignment statement."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method implicitly calls `self.generic_visit` to continue AST traversal.",
                "called_by": "This method is called by the `ast.NodeVisitor` framework during AST traversal when an assignment statement is encountered."
              }
            },
            "error": null
          },
          {
            "identifier": "_resolve_call_qname",
            "description": {
              "overall": "This is a helper method responsible for resolving the fully qualified name (QName) of a function or method being called. It handles two main scenarios: direct calls to names (`ast.Name`) by checking `self.scope` for imports or local definitions, and attribute calls (`ast.Attribute`) like `obj.method` by first checking `self.instance_types` to determine the class of the object, or `self.scope` for module-level attributes. It returns the resolved QName as a string or `None` if it cannot be determined.",
              "parameters": [
                {
                  "name": "func_node",
                  "type": "ast.expr",
                  "description": "The AST node representing the callable part of a call expression (e.g., `ast.Name` for a function, `ast.Attribute` for a method)."
                }
              ],
              "returns": [
                {
                  "name": "name",
                  "type": "str",
                  "description": "The fully qualified name of the callable, if successfully resolved."
                },
                {
                  "name": "None",
                  "type": "None",
                  "description": "If the callable's qualified name cannot be resolved from the current context."
                }
              ],
              "usage_context": {
                "calls": "This method does not explicitly call other functions or methods from the provided `method_context`.",
                "called_by": "This method is called by `backend.relationship_analyzer.CallResolverVisitor.visit_Call` to determine the qualified name of a called entity."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "This class depends on `backend.relationship_analyzer.path_to_module` for converting file paths to module paths during initialization.",
          "instantiated_by": "The specific instantiation points for this class are not provided in the context."
        }
      },
      "error": null
    },
    "schemas.types.ParameterDescription": {
      "identifier": "schemas.types.ParameterDescription",
      "description": {
        "overall": "The ParameterDescription class is a Pydantic BaseModel designed to provide a structured and validated representation of a single function parameter. It serves as a data model to encapsulate the essential details of a parameter, including its name, data type, and a descriptive explanation. This class is fundamental for documenting function signatures in a machine-readable format.",
        "init_method": {
          "description": "This class, being a Pydantic BaseModel, has an automatically generated constructor. It initializes an instance of ParameterDescription by validating and assigning the provided 'name', 'type', and 'description' to its corresponding attributes.",
          "parameters": [
            {
              "name": "name",
              "type": "str",
              "description": "The name of the parameter."
            },
            {
              "name": "type",
              "type": "str",
              "description": "The type hint or inferred type of the parameter."
            },
            {
              "name": "description",
              "type": "str",
              "description": "A textual description of the parameter's purpose."
            }
          ]
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class does not explicitly list any external functional dependencies within the provided context.",
          "instantiated_by": "The specific points of instantiation for this class are not provided in the current context."
        }
      },
      "error": null
    },
    "schemas.types.ReturnDescription": {
      "identifier": "schemas.types.ReturnDescription",
      "description": {
        "overall": "The ReturnDescription class is a Pydantic BaseModel designed to standardize the representation of a function's return value. It encapsulates three essential pieces of information: the return value's name, its data type, and a descriptive explanation of its purpose. This model ensures consistent data structuring for documenting function outputs within a larger system.",
        "init_method": {
          "description": "This class, being a Pydantic BaseModel, automatically generates an `__init__` method. This constructor is used to initialize instances of `ReturnDescription` by accepting values for `name`, `type`, and `description`, ensuring they conform to the specified string types.",
          "parameters": [
            {
              "name": "name",
              "type": "str",
              "description": "The name or identifier of the return value."
            },
            {
              "name": "type",
              "type": "str",
              "description": "The Python type hint or description of the return value's data type."
            },
            {
              "name": "description",
              "type": "str",
              "description": "A textual explanation of what the return value represents or its purpose."
            }
          ]
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class does not explicitly list any external functional dependencies in the provided context.",
          "instantiated_by": "The instantiation points for this class are not specified in the provided context."
        }
      },
      "error": null
    },
    "schemas.types.UsageContext": {
      "identifier": "schemas.types.UsageContext",
      "description": {
        "overall": "The UsageContext class is a Pydantic BaseModel designed to encapsulate information about how a function or method interacts with other parts of a system. It serves as a structured data container for describing what a function calls and by whom it is called. This model ensures that usage context information is consistently represented with `calls` and `called_by` string attributes.",
        "init_method": {
          "description": "The `UsageContext` class is a Pydantic BaseModel, meaning its constructor is implicitly generated by Pydantic. It initializes instances with `calls` and `called_by` string values, enforcing type validation automatically based on the class annotations.",
          "parameters": [
            {
              "name": "calls",
              "type": "str",
              "description": "A string summarizing the functions, methods, or classes that this context's subject calls."
            },
            {
              "name": "called_by",
              "type": "str",
              "description": "A string summarizing the functions or methods that call this context's subject."
            }
          ]
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class does not explicitly list any external functional dependencies beyond its base class, Pydantic's BaseModel.",
          "instantiated_by": "There are no explicit instantiations of this class mentioned in the provided context."
        }
      },
      "error": null
    },
    "schemas.types.FunctionDescription": {
      "identifier": "schemas.types.FunctionDescription",
      "description": {
        "overall": "The FunctionDescription class is a Pydantic model designed to provide a structured and comprehensive analysis of a Python function. It serves as a data schema to encapsulate various aspects of a function, including its high-level purpose, detailed parameter descriptions, return value specifications, and its contextual usage within a larger system. This model facilitates the standardized representation and exchange of function analysis data.",
        "init_method": {
          "description": "This class, being a Pydantic BaseModel, has its `__init__` method automatically generated by Pydantic. It initializes an instance by validating and assigning values to its fields: `overall`, `parameters`, `returns`, and `usage_context`, ensuring data integrity according to their defined types.",
          "parameters": [
            {
              "name": "overall",
              "type": "str",
              "description": "A high-level summary of the function's purpose and implementation."
            },
            {
              "name": "parameters",
              "type": "List[ParameterDescription]",
              "description": "A list of objects, each describing a parameter of the function."
            },
            {
              "name": "returns",
              "type": "List[ReturnDescription]",
              "description": "A list of objects, each describing a return value of the function."
            },
            {
              "name": "usage_context",
              "type": "UsageContext",
              "description": "An object detailing the external calls made by the function and where it is called."
            }
          ]
        },
        "methods": [],
        "usage_context": {
          "dependencies": "The class depends on `pydantic.BaseModel` for its core functionality as a data validation and serialization model, and `typing.List` for type hinting its list fields.",
          "instantiated_by": "The provided context does not explicitly list where this class is instantiated. It is likely instantiated programmatically when structuring function analysis data."
        }
      },
      "error": null
    },
    "schemas.types.FunctionAnalysis": {
      "identifier": "schemas.types.FunctionAnalysis",
      "description": {
        "overall": "The FunctionAnalysis class is a Pydantic BaseModel designed to encapsulate a comprehensive analysis of a single Python function. It serves as a structured data container, holding the function's unique identifier, a detailed description object, and an optional error message. This model is crucial for standardizing the output of function analysis, making it machine-readable and easily processable by other systems.",
        "init_method": {
          "description": "The FunctionAnalysis class, inheriting from Pydantic's BaseModel, utilizes an automatically generated constructor. This constructor initializes the instance attributes `identifier`, `description`, and `error` based on the keyword arguments provided during object creation, ensuring type validation and default value assignment for `error`.",
          "parameters": [
            {
              "name": "identifier",
              "type": "str",
              "description": "The unique name or label for the function being analyzed."
            },
            {
              "name": "description",
              "type": "FunctionDescription",
              "description": "An object containing a detailed analysis of the function's purpose, parameters, returns, and usage context."
            },
            {
              "name": "error",
              "type": "Optional[str]",
              "description": "An optional string to capture any errors encountered during the function's analysis. Defaults to None."
            }
          ]
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class has no explicitly listed external functional dependencies.",
          "instantiated_by": "This class has no explicitly listed instantiation points."
        }
      },
      "error": null
    },
    "schemas.types.ConstructorDescription": {
      "identifier": "schemas.types.ConstructorDescription",
      "description": {
        "overall": "The `ConstructorDescription` class is a Pydantic BaseModel specifically designed to structure and store metadata about the `__init__` method of another class. It encapsulates a textual summary of the constructor's purpose and a detailed list of its parameters, providing a standardized data model for constructor analysis within a larger system.",
        "init_method": {
          "description": "As a Pydantic BaseModel, `ConstructorDescription` implicitly generates its `__init__` method. This constructor initializes instances by accepting keyword arguments that directly correspond to its defined fields: `description` (a string) and `parameters` (a list of `ParameterDescription` objects). This allows for straightforward creation of objects representing constructor metadata.",
          "parameters": [
            {
              "name": "description",
              "type": "str",
              "description": "A string providing a concise summary or explanation of the constructor's overall function and behavior."
            },
            {
              "name": "parameters",
              "type": "List[ParameterDescription]",
              "description": "A list containing `ParameterDescription` objects, each detailing a specific parameter of the constructor, including its name, type, and individual description."
            }
          ]
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class does not explicitly list any external functional dependencies in the provided context.",
          "instantiated_by": "The provided context does not specify where this class is instantiated."
        }
      },
      "error": null
    },
    "schemas.types.ClassContext": {
      "identifier": "schemas.types.ClassContext",
      "description": {
        "overall": "The ClassContext class is a Pydantic BaseModel designed to encapsulate information about a class's external interactions. It specifically describes the external dependencies that a class relies upon and the locations or entities responsible for its instantiation. This model provides a structured way to represent the contextual usage of a class within a larger system.",
        "init_method": {
          "description": "This class, being a Pydantic BaseModel, is initialized by providing values for its fields: `dependencies` and `instantiated_by`. Pydantic handles the validation and assignment of these values upon instantiation, ensuring type correctness.",
          "parameters": [
            {
              "name": "dependencies",
              "type": "str",
              "description": "A string representing the external dependencies of the class."
            },
            {
              "name": "instantiated_by",
              "type": "str",
              "description": "A string representing where the class is instantiated."
            }
          ]
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class does not explicitly list any external dependencies in the provided context.",
          "instantiated_by": "The provided context does not specify where this class is instantiated."
        }
      },
      "error": null
    },
    "schemas.types.ClassDescription": {
      "identifier": "schemas.types.ClassDescription",
      "description": {
        "overall": "The `ClassDescription` class is a Pydantic BaseModel designed to structure a comprehensive analysis of a Python class. It serves as a data container, holding an overall summary of the class, detailed information about its constructor, a list of analyses for its individual methods, and context regarding its dependencies and instantiation points. This model is crucial for generating structured documentation or for further automated processing of class analyses.",
        "init_method": {
          "description": "As a Pydantic BaseModel, `ClassDescription` automatically generates its `__init__` method. This constructor is responsible for accepting and validating the fields defined in the class: `overall`, `init_method`, `methods`, and `usage_context`, ensuring that instances are created with correctly typed and structured data representing a class's analysis.",
          "parameters": [
            {
              "name": "overall",
              "type": "str",
              "description": "A high-level summary of the class's purpose and functionality."
            },
            {
              "name": "init_method",
              "type": "ConstructorDescription",
              "description": "An object containing the description and parameters of the class's constructor."
            },
            {
              "name": "methods",
              "type": "List[FunctionAnalysis]",
              "description": "A list of detailed analyses for each method defined within the class, excluding the constructor."
            },
            {
              "name": "usage_context",
              "type": "ClassContext",
              "description": "An object describing the class's external dependencies and where it is instantiated."
            }
          ]
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class does not explicitly declare external functional dependencies within its definition, relying on Pydantic's BaseModel for its core functionality.",
          "instantiated_by": "There are no explicit instantiation points provided for this class in the given context."
        }
      },
      "error": null
    },
    "schemas.types.ClassAnalysis": {
      "identifier": "schemas.types.ClassAnalysis",
      "description": {
        "overall": "The ClassAnalysis class serves as the root Pydantic model for structuring a comprehensive analysis of a Python class. It encapsulates the class's unique identifier, a detailed ClassDescription object containing insights into its constructor and methods, and an optional field for recording any analysis errors. This model is designed to provide a standardized, machine-readable format for class analysis reports.",
        "init_method": {
          "description": "This class, being a Pydantic BaseModel, implicitly defines its constructor based on its field annotations. It initializes an instance with an identifier string, a ClassDescription object, and an optional error string, setting default values where specified.",
          "parameters": [
            {
              "name": "identifier",
              "type": "str",
              "description": "A unique string identifier for the class."
            },
            {
              "name": "description",
              "type": "ClassDescription",
              "description": "A detailed analysis object containing the class's overall purpose, constructor, and methods."
            },
            {
              "name": "error",
              "type": "Optional[str]",
              "description": "An optional string to store any error messages encountered during analysis, defaulting to None."
            }
          ]
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class does not explicitly list any external functional dependencies within the provided context.",
          "instantiated_by": "The instantiation points for this class are not specified within the provided context."
        }
      },
      "error": null
    },
    "schemas.types.CallInfo": {
      "identifier": "schemas.types.CallInfo",
      "description": {
        "overall": "The CallInfo class is a Pydantic BaseModel designed to represent a specific call event within a system, typically used by a relationship analyzer. It encapsulates key information about a call, including the file path, the name of the calling function, the mode of the caller (e.g., method, function, module), and the line number where the call occurs. This class provides a structured format for tracking and analyzing inter-component relationships.",
        "init_method": {
          "description": "The `__init__` method for CallInfo is implicitly generated by Pydantic's BaseModel. It initializes an instance of CallInfo by validating and assigning values to its fields: file, function, mode, and line. These fields are directly mapped from the constructor arguments, ensuring type correctness and data integrity.",
          "parameters": [
            {
              "name": "file",
              "type": "str",
              "description": "The path to the file where the call event occurred."
            },
            {
              "name": "function",
              "type": "str",
              "description": "The name of the function or method that made the call."
            },
            {
              "name": "mode",
              "type": "str",
              "description": "The type of the caller, e.g., 'method', 'function', or 'module'."
            },
            {
              "name": "line",
              "type": "int",
              "description": "The line number in the file where the call event occurred."
            }
          ]
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class does not explicitly list any external functional dependencies within the provided context.",
          "instantiated_by": "The instantiation points for this class are not specified in the provided context."
        }
      },
      "error": null
    },
    "schemas.types.FunctionContextInput": {
      "identifier": "schemas.types.FunctionContextInput",
      "description": {
        "overall": "The FunctionContextInput class is a Pydantic BaseModel designed to encapsulate structured contextual information relevant to the analysis of a function. It serves as a data transfer object, defining the expected format for input data when performing function analysis. The class primarily holds information about the functions or methods that a given function calls, and the functions or methods that call it.",
        "init_method": {
          "description": "This class does not define an explicit `__init__` method. It inherits from `pydantic.BaseModel`, and its initialization is handled automatically by Pydantic based on the declared fields `calls` and `called_by`.",
          "parameters": []
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class does not explicitly list any external functional dependencies within the provided context.",
          "instantiated_by": "The instantiation points for this class are not specified within the provided context."
        }
      },
      "error": null
    },
    "schemas.types.FunctionAnalysisInput": {
      "identifier": "schemas.types.FunctionAnalysisInput",
      "description": {
        "overall": "The FunctionAnalysisInput class is a Pydantic BaseModel that defines the structured input required to perform an analysis of a Python function. It serves as a data schema, ensuring that all necessary components like the function's identifier, source code, relevant imports, and contextual information are provided in a consistent format. This class is crucial for validating and organizing the data before a detailed function analysis can be executed by a larger system.",
        "init_method": {
          "description": "This class utilizes an implicit Pydantic-generated constructor. It initializes instances by validating and assigning values to its defined fields: 'mode', 'identifier', 'source_code', 'imports', and 'context'. This ensures that all input data conforms to the specified types and structure.",
          "parameters": [
            {
              "name": "mode",
              "type": "Literal[\"function_analysis\"]",
              "description": "Specifies the analysis mode, which is fixed to 'function_analysis' for this input type."
            },
            {
              "name": "identifier",
              "type": "str",
              "description": "The unique name or identifier of the function targeted for analysis."
            },
            {
              "name": "source_code",
              "type": "str",
              "description": "The complete raw source code string of the function to be analyzed."
            },
            {
              "name": "imports",
              "type": "List[str]",
              "description": "A list of strings representing the import statements relevant to the function's execution context."
            },
            {
              "name": "context",
              "type": "FunctionContextInput",
              "description": "An object containing additional contextual information for the function, such as its callers and calls."
            }
          ]
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class does not explicitly list external functional dependencies beyond its Pydantic BaseModel inheritance, which handles data validation and serialization.",
          "instantiated_by": "The instantiation points for this class are not specified in the provided context, but it is typically instantiated by components that prepare data for function analysis."
        }
      },
      "error": null
    },
    "schemas.types.MethodContextInput": {
      "identifier": "schemas.types.MethodContextInput",
      "description": {
        "overall": "The `MethodContextInput` class is a Pydantic `BaseModel` designed to provide a structured representation of context information for individual methods within a class. It encapsulates details such as the method's unique identifier, a list of other functions or methods it invokes, a list of entities that call it, its arguments, and its docstring. This model is fundamental for standardizing and organizing method-level metadata, facilitating automated analysis and documentation generation.",
        "init_method": {
          "description": "This class is a Pydantic `BaseModel`, meaning its initialization is implicitly handled by Pydantic. Upon instantiation, Pydantic validates and assigns values to its defined fields: `identifier`, `calls`, `called_by`, `args`, and `docstring`. There is no explicit `__init__` method defined in the source code.",
          "parameters": []
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class does not explicitly list any external functional dependencies in the provided context, beyond its base class Pydantic BaseModel and standard Python types.",
          "instantiated_by": "The provided context does not specify where this class is instantiated."
        }
      },
      "error": null
    },
    "schemas.types.ClassContextInput": {
      "identifier": "schemas.types.ClassContextInput",
      "description": {
        "overall": "The ClassContextInput class is a Pydantic BaseModel designed to encapsulate structured context information relevant for analyzing a Python class. It defines the expected data structure for dependencies, instantiation points, and method-specific contexts, serving as a robust input schema for analytical processes.",
        "init_method": {
          "description": "This class, being a Pydantic BaseModel, does not explicitly define an __init__ method. Instead, Pydantic automatically generates a constructor that validates and assigns values to its fields: dependencies, instantiated_by, and method_context, based on their type hints.",
          "parameters": [
            {
              "name": "dependencies",
              "type": "List[str]",
              "description": "A list of strings representing external dependencies of the class."
            },
            {
              "name": "instantiated_by",
              "type": "List[CallInfo]",
              "description": "A list of CallInfo objects indicating where this class is instantiated."
            },
            {
              "name": "method_context",
              "type": "List[MethodContextInput]",
              "description": "A list of MethodContextInput objects providing context for each method within the class."
            }
          ]
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class does not explicitly list any external functional dependencies within the provided context.",
          "instantiated_by": "The provided context does not specify any locations where this class is instantiated."
        }
      },
      "error": null
    },
    "schemas.types.ClassAnalysisInput": {
      "identifier": "schemas.types.ClassAnalysisInput",
      "description": {
        "overall": "The ClassAnalysisInput class is a Pydantic BaseModel designed to define the structured input required for generating a ClassAnalysis object. It serves as a data transfer object, ensuring that all necessary components for a comprehensive class analysis, such as the class identifier, its source code, relevant imports, and contextual information, are provided in a consistent format. This class acts as a contract for the data expected by the class analysis system.",
        "init_method": {
          "description": "This class does not explicitly define an `__init__` method. As a Pydantic `BaseModel`, its constructor is implicitly generated to accept keyword arguments corresponding to its defined fields: `mode`, `identifier`, `source_code`, `imports`, and `context`.",
          "parameters": [
            {
              "name": "mode",
              "type": "Literal[\"class_analysis\"]",
              "description": "A literal string indicating the analysis mode, which must be 'class_analysis'."
            },
            {
              "name": "identifier",
              "type": "str",
              "description": "The unique name or identifier of the class to be analyzed."
            },
            {
              "name": "source_code",
              "type": "str",
              "description": "The raw Python source code of the entire class definition."
            },
            {
              "name": "imports",
              "type": "List[str]",
              "description": "A list of import statements relevant to the source code."
            },
            {
              "name": "context",
              "type": "ClassContextInput",
              "description": "Additional contextual information for the class analysis, such as dependencies and instantiation points."
            }
          ]
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class does not explicitly list any direct functional dependencies within the provided context.",
          "instantiated_by": "The instantiation points for this class are not specified in the provided context."
        }
      },
      "error": null
    }
  }
}