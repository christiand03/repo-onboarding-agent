{
  "functions": {
    "backend.AST_Schema.path_to_module": {
      "identifier": "backend.AST_Schema.path_to_module",
      "description": {
        "overall": "This function converts a given file path into a Python module path relative to a specified project root. It handles cases where the file might not be directly within the project root by using the base filename. It also correctly formats the path by replacing directory separators with dots and removes the '.py' extension. Special handling is included for '__init__.py' files to represent package directories.",
        "parameters": [
          {
            "name": "filepath",
            "type": "str",
            "description": "The absolute or relative path to the file."
          },
          {
            "name": "project_root",
            "type": "str",
            "description": "The root directory of the Python project."
          }
        ],
        "returns": [
          {
            "name": "module_path",
            "type": "str",
            "description": "The Python module path derived from the filepath."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is called by no other functions."
        }
      },
      "error": null
    },
    "backend.File_Dependency.build_file_dependency_graph": {
      "identifier": "backend.File_Dependency.build_file_dependency_graph",
      "description": {
        "overall": "This function constructs a directed graph representing file dependencies within a Python project. It takes a filename, an Abstract Syntax Tree (AST) of the file, and the repository root as input. The function initializes a graph and uses a visitor pattern to traverse the AST, identifying import dependencies. It then populates the graph with nodes representing the files and adds edges to show the import relationships. The resulting graph is returned.",
        "parameters": [
          {
            "name": "filename",
            "type": "str",
            "description": "The name of the file being analyzed."
          },
          {
            "name": "tree",
            "type": "AST",
            "description": "The Abstract Syntax Tree (AST) of the file."
          },
          {
            "name": "repo_root",
            "type": "str",
            "description": "The root directory of the repository."
          }
        ],
        "returns": [
          {
            "name": "graph",
            "type": "nx.DiGraph",
            "description": "A directed graph representing the file dependencies."
          }
        ],
        "usage_context": {
          "calls": "This function calls backend.File_Dependency.FileDependencyGraph.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "backend.File_Dependency.build_repository_graph": {
      "identifier": "backend.File_Dependency.build_repository_graph",
      "description": {
        "overall": "This function constructs a directed graph representing the dependencies between Python files within a Git repository. It iterates through all Python files in the repository, parses their Abstract Syntax Trees (ASTs), and builds a dependency graph for each file. These individual file graphs are then merged into a single, global repository graph. The function specifically focuses on Python files, ignoring others, and uses the `build_file_dependency_graph` helper function to process each file's content.",
        "parameters": [
          {
            "name": "repository",
            "type": "GitRepository",
            "description": "An object representing the Git repository, providing methods to access files and the repository's temporary directory."
          }
        ],
        "returns": [
          {
            "name": "global_graph",
            "type": "nx.DiGraph",
            "description": "A NetworkX directed graph where nodes represent file dependencies and edges represent the relationships between them."
          }
        ],
        "usage_context": {
          "calls": "This function calls backend.File_Dependency.build_file_dependency_graph.",
          "called_by": "This function is not called by any other functions within the provided context."
        }
      },
      "error": null
    },
    "backend.File_Dependency.get_all_temp_files": {
      "identifier": "backend.File_Dependency.get_all_temp_files",
      "description": {
        "overall": "This function takes a directory path as input and recursively searches for all Python files (*.py) within that directory and its subdirectories. It resolves the root path to an absolute path and then returns a list of Path objects, where each Path object represents the relative path of a found Python file from the root directory. The function is designed to identify temporary Python files within a specified file system location.",
        "parameters": [
          {
            "name": "directory",
            "type": "str",
            "description": "The path to the directory to search for temporary Python files."
          }
        ],
        "returns": [
          {
            "name": "all_files",
            "type": "list[Path]",
            "description": "A list of Path objects, each representing the relative path of a found Python file from the root directory."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "backend.HelperLLM.main_orchestrator": {
      "identifier": "backend.HelperLLM.main_orchestrator",
      "description": {
        "overall": "This function serves as a dummy orchestrator for testing the LLMHelper class and its documentation generation capabilities. It simulates the process of analyzing individual functions and classes by defining sample inputs and pre-computed analyses for methods like 'add_item', 'check_stock', and 'generate_report'. It then instantiates an LLMHelper object and uses it to generate documentation for these methods, ultimately aggregating and printing the results in a JSON format. The function is designed to be syntactically correct and logically aligned with Pydantic models for validation.",
        "parameters": [],
        "returns": [],
        "usage_context": {
          "calls": "backend.HelperLLM.LLMHelper, schemas.types.ClassAnalysisInput, schemas.types.ClassContextInput",
          "called_by": "This function calls no other functions."
        }
      },
      "error": null
    },
    "backend.callgraph.make_safe_dot": {
      "identifier": "backend.callgraph.make_safe_dot",
      "description": {
        "overall": "This function takes a NetworkX directed graph and an output path as input. It creates a copy of the graph and relabels its nodes to ensure they are safe for DOT format, which is used for graph visualization. It then assigns the original node names as labels to the relabeled nodes and writes the modified graph to a DOT file at the specified output path. This process is essential for generating visual representations of call graphs where node names might contain characters not suitable for the DOT language.",
        "parameters": [
          {
            "name": "graph",
            "type": "nx.DiGraph",
            "description": "The input directed graph, likely representing a call graph, to be processed."
          },
          {
            "name": "out_path",
            "type": "str",
            "description": "The file path where the DOT representation of the graph will be saved."
          }
        ],
        "returns": [],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is called by no other functions."
        }
      },
      "error": null
    },
    "backend.callgraph.build_filtered_callgraph": {
      "identifier": "backend.callgraph.build_filtered_callgraph",
      "description": {
        "overall": "This function constructs a global call graph for a given Git repository and then filters it to include only functions defined within the repository itself. It iterates through all Python files, parses their Abstract Syntax Trees (ASTs), and uses a `CallGraph` visitor to identify functions and their calls. The function first collects all functions defined in the repository and then builds a directed graph (`nx.DiGraph`) by adding edges only between functions that are both defined within the repository. This results in a call graph representing the internal call structure of the project.",
        "parameters": [
          {
            "name": "repo",
            "type": "GitRepository",
            "description": "An object representing the Git repository to analyze, providing methods to access files."
          }
        ],
        "returns": [
          {
            "name": "global_graph",
            "type": "nx.DiGraph",
            "description": "A NetworkX directed graph representing the filtered call graph, where nodes are function names and edges represent calls between them."
          }
        ],
        "usage_context": {
          "calls": "This function calls backend.callgraph.CallGraph.",
          "called_by": "This function is not called by any other function."
        }
      },
      "error": null
    },
    "backend.converter.wrap_cdata": {
      "identifier": "backend.converter.wrap_cdata",
      "description": {
        "overall": "This function takes a string `content` as input and returns a new string where the input content is wrapped within XML CDATA (Character Data) tags. The CDATA tags are formatted as '<![CDATA[\\n{content}\\n]]>', ensuring that the content inside is treated as raw character data and not parsed as markup. This is useful for embedding blocks of text that might contain characters that would otherwise be interpreted as XML markup.",
        "parameters": [
          {
            "name": "content",
            "type": "str",
            "description": "The string content to be wrapped in CDATA tags."
          }
        ],
        "returns": [
          {
            "name": "wrapped_content",
            "type": "str",
            "description": "The input content enclosed within CDATA tags."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "backend.converter.extract_output_content": {
      "identifier": "backend.converter.extract_output_content",
      "description": {
        "overall": "This function iterates through a list of outputs, extracting relevant content based on the output type. It specifically handles 'display_data' and 'execute_result' types by processing text and images. For images, it decodes Base64 encoded strings, stores them in a provided image list, and returns a placeholder. It also processes 'stream' outputs by appending their text content and 'error' outputs by formatting them as strings. The function aims to convert various output formats into a unified list of strings and image placeholders.",
        "parameters": [
          {
            "name": "outputs",
            "type": "list",
            "description": "A list of output objects, each containing data and an output type."
          },
          {
            "name": "image_list",
            "type": "list",
            "description": "A list to which image data (as dictionaries) will be appended."
          }
        ],
        "returns": [
          {
            "name": "extracted_xml_snippets",
            "type": "list",
            "description": "A list containing extracted text snippets and image placeholders or error messages."
          }
        ],
        "usage_context": {
          "calls": "This function calls backend.converter.process_image.",
          "called_by": "This function is not called by any other function."
        }
      },
      "error": null
    },
    "backend.converter.process_image": {
      "identifier": "backend.converter.process_image",
      "description": {
        "overall": "This function processes an image based on its MIME type. It checks if the MIME type exists in a predefined data structure. If found, it attempts to decode a base64 encoded string associated with that MIME type, removes newline characters, and appends the image data to a global `image_list`. It then returns an HTML-like placeholder string with the image's index and MIME type. If any error occurs during decoding or processing, it returns an error message. If the MIME type is not found in the data, it returns None.",
        "parameters": [
          {
            "name": "mime_type",
            "type": "string",
            "description": "The MIME type of the image to be processed."
          }
        ],
        "returns": [
          {
            "name": "placeholder_or_error",
            "type": "string",
            "description": "A string representing an image placeholder with its index and MIME type, or an error message if processing fails."
          },
          {
            "name": "none",
            "type": "None",
            "description": "Returned if the provided mime_type is not found in the data."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "backend.converter.convert_notebook_to_xml": {
      "identifier": "backend.converter.convert_notebook_to_xml",
      "description": {
        "overall": "This function takes the content of a Jupyter notebook as a string and converts it into an XML format. It iterates through each cell of the notebook, identifying whether it's a markdown or code cell. For markdown cells, it wraps the source content in a '<CELL type=\"markdown\">' tag. For code cells, it wraps the source code in CDATA and includes it within a '<CELL type=\"code\">' tag. If a code cell has outputs, it extracts and formats the content of these outputs, wrapping them in CDATA and enclosing them in a '<CELL type=\"output\">' tag. The function also handles potential errors during the initial parsing of the file content, returning an error message if the file cannot be read as JSON or a notebook. It returns the generated XML string and a list of extracted image data.",
        "parameters": [
          {
            "name": "file_content",
            "type": "str",
            "description": "A string containing the raw content of the Jupyter notebook file."
          }
        ],
        "returns": [
          {
            "name": "xml_output",
            "type": "str",
            "description": "A string representing the converted notebook content in XML format, or an error message if parsing fails."
          },
          {
            "name": "extracted_images",
            "type": "list",
            "description": "A list containing extracted image data from the notebook outputs."
          }
        ],
        "usage_context": {
          "calls": "This function calls backend.converter.extract_output_content and backend.converter.wrap_cdata.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "backend.converter.process_repo_notebooks": {
      "identifier": "backend.converter.process_repo_notebooks",
      "description": {
        "overall": "This function iterates through a list of repository files, identifies Jupyter Notebooks (.ipynb), and converts each notebook into an XML representation along with any associated images. It logs the number of notebooks found and the processing of each individual notebook. The function aggregates the XML output and image data for each notebook into a dictionary, keyed by the notebook's file path.",
        "parameters": [
          {
            "name": "repo_files",
            "type": "List[FileObject]",
            "description": "A list of file objects, where each object is expected to have 'path' and 'content' attributes."
          }
        ],
        "returns": [
          {
            "name": "results",
            "type": "Dict[str, Dict[str, Any]]",
            "description": "A dictionary where keys are notebook file paths and values are dictionaries containing 'xml' (the XML representation) and 'images' (a list of image data)."
          }
        ],
        "usage_context": {
          "calls": "This function calls backend.converter.convert_notebook_to_xml.",
          "called_by": "This function is not called by any other function."
        }
      },
      "error": null
    },
    "backend.main.create_savings_chart": {
      "identifier": "backend.main.create_savings_chart",
      "description": {
        "overall": "This function generates a bar chart to visualize the comparison of JSON and TOON tokens, highlighting the savings percentage. It takes the token counts for both formats, the calculated savings percentage, and the desired output path as input. The function configures the chart with specific labels, colors, and titles, then adds the exact token values above each bar for clarity. Finally, it saves the generated chart to the specified file path and closes the plot to free up resources.",
        "parameters": [
          {
            "name": "json_tokens",
            "type": "int",
            "description": "The number of tokens in the JSON format."
          },
          {
            "name": "toon_tokens",
            "type": "int",
            "description": "The number of tokens in the TOON format."
          },
          {
            "name": "savings_percent",
            "type": "float",
            "description": "The percentage of savings achieved by using the TOON format compared to JSON."
          },
          {
            "name": "output_path",
            "type": "str",
            "description": "The file path where the generated chart image will be saved."
          }
        ],
        "returns": [],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is called by no other functions."
        }
      },
      "error": null
    },
    "backend.main.calculate_net_time": {
      "identifier": "backend.main.calculate_net_time",
      "description": {
        "overall": "This function calculates the net processing time by subtracting estimated sleep times from the total duration. It specifically handles cases where the model name starts with 'gemini-'. If the model is not a gemini model, it returns the total duration. If there are no items, it returns 0. For gemini models, it calculates the number of batches, estimates total sleep time based on the number of batches, and then subtracts this sleep time from the total duration, ensuring the net time is not negative.",
        "parameters": [
          {
            "name": "start_time",
            "type": "Any",
            "description": "The start time of the process."
          },
          {
            "name": "end_time",
            "type": "Any",
            "description": "The end time of the process."
          },
          {
            "name": "total_items",
            "type": "int",
            "description": "The total number of items processed."
          },
          {
            "name": "batch_size",
            "type": "int",
            "description": "The size of each batch."
          },
          {
            "name": "model_name",
            "type": "str",
            "description": "The name of the model being used."
          }
        ],
        "returns": [
          {
            "name": "net_time",
            "type": "int",
            "description": "The calculated net processing time after subtracting sleep times, or 0 if total_items is 0, or the total_duration if the model is not a gemini model."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "backend.main.main_workflow": {
      "identifier": "backend.main.main_workflow",
      "description": {
        "overall": "The main_workflow function orchestrates a complex process of analyzing a GitHub repository to generate documentation. It begins by extracting API keys and model names, then clones the specified repository. It proceeds to extract basic project information, construct a file tree, and perform relationship analysis (calls and instantiations). The function then generates an Abstract Syntax Tree (AST) schema and enriches it with the relationship data. Subsequently, it prepares inputs for a Helper LLM to analyze functions and classes within the repository. The results from the Helper LLM are then used to prepare input for a Main LLM, which generates a final report. Finally, it calculates and returns metrics related to the process, including execution times and token usage.",
        "parameters": [
          {
            "name": "input",
            "type": "Any",
            "description": "The primary input to the workflow, likely containing information or a URL for the repository."
          },
          {
            "name": "api_keys",
            "type": "dict",
            "description": "A dictionary containing API keys for various LLM services (e.g., gemini, gpt, scadsllm) and base URLs."
          },
          {
            "name": "model_names",
            "type": "dict",
            "description": "A dictionary specifying the model names to be used for helper and main LLM tasks."
          },
          {
            "name": "status_callback",
            "type": "Optional[Callable]",
            "description": "An optional callback function to report status updates during the workflow."
          }
        ],
        "returns": [
          {
            "name": "report",
            "type": "str",
            "description": "The final generated report, likely in Markdown format."
          },
          {
            "name": "metrics",
            "type": "dict",
            "description": "A dictionary containing performance metrics of the workflow, such as execution times and token counts."
          }
        ],
        "usage_context": {
          "calls": "This function calls backend.AST_Schema.ASTAnalyzer, backend.AST_Schema.ASTAnalyzer.analyze_repository, backend.AST_Schema.ASTAnalyzer.merge_relationship_data, backend.HelperLLM.LLMHelper, backend.HelperLLM.LLMHelper.generate_for_classes, backend.HelperLLM.LLMHelper.generate_for_functions, backend.MainLLM.MainLLM, backend.MainLLM.MainLLM.call_llm, backend.basic_info.ProjektInfoExtractor, backend.basic_info.ProjektInfoExtractor.extrahiere_info, backend.getRepo.GitRepository, backend.main.calculate_net_time, backend.main.create_savings_chart, backend.main.update_status, backend.relationship_analyzer.ProjectAnalyzer, backend.relationship_analyzer.ProjectAnalyzer.analyze, backend.relationship_analyzer.ProjectAnalyzer.get_raw_relationships, schemas.types.ClassAnalysisInput, schemas.types.ClassContextInput, schemas.types.FunctionAnalysisInput, schemas.types.FunctionContextInput, and schemas.types.MethodContextInput.",
          "called_by": "This function is not called by any other functions within the provided context."
        }
      },
      "error": null
    },
    "backend.main.update_status": {
      "identifier": "backend.main.update_status",
      "description": {
        "overall": "This function, `update_status`, is designed to report a status message. It first checks if a global `status_callback` function is defined and, if so, calls it with the provided message. Subsequently, it logs the message using the standard Python `logging` module at the INFO level. This function serves as a centralized way to communicate progress or status updates during a process, both to a potential callback handler and for persistent logging.",
        "parameters": [
          {
            "name": "msg",
            "type": "string",
            "description": "The status message to be reported and logged."
          }
        ],
        "returns": [],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "backend.main.notebook_workflow": {
      "identifier": "backend.main.notebook_workflow",
      "description": {
        "overall": "This function orchestrates a workflow for analyzing GitHub repositories containing Jupyter notebooks. It clones a repository, extracts project information, processes each notebook by converting it to an XML structure with embedded images, and then uses a specified LLM to generate a report for each notebook. Finally, it concatenates all individual notebook reports into a single final report, saves it to a file, and returns the report along with processing metrics.",
        "parameters": [
          {
            "name": "input",
            "type": "str",
            "description": "The input string, expected to contain a GitHub repository URL."
          },
          {
            "name": "api_keys",
            "type": "dict",
            "description": "A dictionary containing API keys for different LLM providers (e.g., 'gpt', 'gemini', 'scadsllm', 'ollama')."
          },
          {
            "name": "model",
            "type": "str",
            "description": "The name of the language model to use for report generation. The function determines the appropriate API key and base URL based on this model name."
          },
          {
            "name": "status_callback",
            "type": "Optional[Callable]",
            "description": "An optional callback function to report status updates during the workflow."
          }
        ],
        "returns": [
          {
            "name": "report",
            "type": "str",
            "description": "The concatenated final report generated from all processed notebooks."
          },
          {
            "name": "metrics",
            "type": "dict",
            "description": "A dictionary containing performance metrics for the workflow, including execution times and model information."
          }
        ],
        "usage_context": {
          "calls": "This function calls backend.MainLLM.MainLLM, backend.MainLLM.MainLLM.call_llm, backend.basic_info.ProjektInfoExtractor, backend.basic_info.ProjektInfoExtractor.extrahiere_info, backend.converter.process_repo_notebooks, backend.getRepo.GitRepository, backend.main.gemini_payload, and backend.main.update_status.",
          "called_by": "This function is not called by any other functions within the provided context."
        }
      },
      "error": null
    },
    "backend.main.gemini_payload": {
      "identifier": "backend.main.gemini_payload",
      "description": {
        "overall": "This function constructs a payload for the Gemini API, designed to process and present information including basic project details, notebook paths, XML content, and images. It serializes basic information and the notebook path into a JSON string. The function then iterates through the provided XML content, identifying image placeholders. For each placeholder, it appends the preceding text segment as a text payload and then appends the corresponding image data as an image_url payload, formatted as a base64 encoded data URI. Any remaining text after the last image placeholder is also appended.",
        "parameters": [
          {
            "name": "basic_info",
            "type": "any",
            "description": "A dictionary or object containing basic information about the project or context."
          },
          {
            "name": "nb_path",
            "type": "str",
            "description": "The file path to the current notebook."
          },
          {
            "name": "xml_content",
            "type": "str",
            "description": "A string containing the XML representation of the notebook structure, potentially with image placeholders."
          },
          {
            "name": "images",
            "type": "list[dict]",
            "description": "A list of dictionaries, where each dictionary contains image data, expected to have a 'data' key with a base64 encoded string."
          }
        ],
        "returns": [
          {
            "name": "payload_content",
            "type": "list[dict]",
            "description": "A list of dictionaries, where each dictionary represents a part of the Gemini API payload, with 'type' being either 'text' or 'image_url'."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is called by no other functions."
        }
      },
      "error": null
    },
    "backend.relationship_analyzer.path_to_module": {
      "identifier": "backend.relationship_analyzer.path_to_module",
      "description": {
        "overall": "This function converts a given file path into a Python module path relative to a specified project root. It first calculates the relative path from the project root to the file. If the file is a Python file (ends with '.py'), the '.py' extension is removed. The path separators are then replaced with dots to form a module path. Special handling is included for '__init__.py' files, where the '__init__' part is removed from the module path.",
        "parameters": [
          {
            "name": "filepath",
            "type": "str",
            "description": "The absolute or relative path to the file."
          },
          {
            "name": "project_root",
            "type": "str",
            "description": "The root directory of the project."
          }
        ],
        "returns": [
          {
            "name": "module_path",
            "type": "str",
            "description": "The calculated Python module path."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is called by no other functions."
        }
      },
      "error": null
    },
    "database.db.encrypt_text": {
      "identifier": "database.db.encrypt_text",
      "description": {
        "overall": "This function encrypts a given string using a predefined cipher suite. It first checks if the input text is empty or if the cipher suite is not initialized. If either condition is true, it returns the original text without encryption. Otherwise, it strips leading/trailing whitespace from the text, encodes it into bytes, encrypts the bytes using the cipher suite, and then decodes the resulting encrypted bytes back into a string before returning it.",
        "parameters": [
          {
            "name": "text",
            "type": "str",
            "description": "The string to be encrypted."
          }
        ],
        "returns": [
          {
            "name": "encrypted_text",
            "type": "str",
            "description": "The encrypted string, or the original string if encryption could not be performed."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.decrypt_text": {
      "identifier": "database.db.decrypt_text",
      "description": {
        "overall": "This function decrypts a given string using a cipher suite. It first checks if the input text or the cipher suite is missing, returning the original text if either is absent. If a cipher suite is available, it attempts to decrypt the text. The text is stripped of whitespace and encoded before decryption, and the result is decoded back into a string. If any exception occurs during the decryption process, the original text is returned.",
        "parameters": [
          {
            "name": "text",
            "type": "str",
            "description": "The encrypted string to be decrypted."
          }
        ],
        "returns": [
          {
            "name": "decrypted_text",
            "type": "str",
            "description": "The decrypted string, or the original string if decryption fails or is not possible."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.insert_user": {
      "identifier": "database.db.insert_user",
      "description": {
        "overall": "This function inserts a new user record into the database. It constructs a user dictionary containing the username, name, a hashed password, and default empty values for API keys and base URLs. The function then uses `dbusers.insert_one()` to add this user to the database and returns the unique identifier of the newly inserted document.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The unique username for the new user."
          },
          {
            "name": "name",
            "type": "str",
            "description": "The full name of the user."
          },
          {
            "name": "password",
            "type": "str",
            "description": "The plain text password for the new user, which will be hashed."
          }
        ],
        "returns": [
          {
            "name": "result.inserted_id",
            "type": "Any",
            "description": "The unique identifier of the newly inserted user document."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.fetch_all_users": {
      "identifier": "database.db.fetch_all_users",
      "description": {
        "overall": "This function is designed to retrieve all user records from a database. It interacts with a database collection named 'dbusers' and returns the entire set of documents found. The function is a simple wrapper around a database query operation.",
        "parameters": [],
        "returns": [
          {
            "name": "user_list",
            "type": "list",
            "description": "A list containing all user documents fetched from the database."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.fetch_user": {
      "identifier": "database.db.fetch_user",
      "description": {
        "overall": "This function retrieves a user's data from the database based on their username. It queries the `dbusers` collection for a document where the `_id` field matches the provided username. The function is designed to fetch a single user record.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username of the user to fetch from the database."
          }
        ],
        "returns": [
          {
            "name": "user_document",
            "type": "Any",
            "description": "A dictionary representing the user document found in the database, or None if no user is found."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.update_user_name": {
      "identifier": "database.db.update_user_name",
      "description": {
        "overall": "This function updates the 'name' field for a user in the 'dbusers' collection. It takes the current username and the new name as input. The function targets the document where the '_id' matches the provided username and sets the 'name' field to the new name. It returns the count of modified documents, which indicates whether the update was successful.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The current username of the user whose name needs to be updated."
          },
          {
            "name": "new_name",
            "type": "str",
            "description": "The new name to be set for the user."
          }
        ],
        "returns": [
          {
            "name": "modified_count",
            "type": "int",
            "description": "The number of documents that were modified. This is typically 1 if the update was successful and 0 otherwise."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.update_gemini_key": {
      "identifier": "database.db.update_gemini_key",
      "description": {
        "overall": "This function updates the Gemini API key for a given user in the database. It first encrypts the provided API key using a separate encryption function. Then, it updates a user's record in the 'dbusers' collection using MongoDB's `update_one` method, setting the 'gemini_api_key' field to the encrypted value. The function returns the count of modified documents, indicating whether the update was successful.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username of the user whose Gemini API key needs to be updated."
          },
          {
            "name": "gemini_api_key",
            "type": "str",
            "description": "The new Gemini API key to be stored for the user."
          }
        ],
        "returns": [
          {
            "name": "modified_count",
            "type": "int",
            "description": "The number of documents that were modified in the database. Typically 1 if the update was successful, 0 otherwise."
          }
        ],
        "usage_context": {
          "calls": "This function calls database.db.encrypt_text.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.update_gpt_key": {
      "identifier": "database.db.update_gpt_key",
      "description": {
        "overall": "This function updates the GPT API key for a given user in the database. It first encrypts the provided API key using the `encrypt_text` function. Then, it uses `dbusers.update_one` to find the user by their username and set the `gpt_api_key` field to the encrypted value. The function returns the count of documents that were modified.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username of the user whose GPT API key needs to be updated."
          },
          {
            "name": "gpt_api_key",
            "type": "str",
            "description": "The new GPT API key to be set for the user. Leading/trailing whitespace will be removed."
          }
        ],
        "returns": [
          {
            "name": "modified_count",
            "type": "int",
            "description": "The number of documents that were modified in the database. Expected to be 1 if the update was successful."
          }
        ],
        "usage_context": {
          "calls": "This function calls database.db.encrypt_text.",
          "called_by": "This function is not called by any other functions within the provided context."
        }
      },
      "error": null
    },
    "database.db.update_ollama_url": {
      "identifier": "database.db.update_ollama_url",
      "description": {
        "overall": "This function updates the 'ollama_base_url' field for a specific user in the database. It takes the username and the new base URL as input. The function then uses `dbusers.update_one` to find the user document by their username (using `_id`) and sets the `ollama_base_url` to the provided URL after stripping any leading or trailing whitespace. Finally, it returns the count of modified documents, which indicates whether the update was successful.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username of the user whose 'ollama_base_url' needs to be updated."
          },
          {
            "name": "ollama_base_url",
            "type": "str",
            "description": "The new base URL for the Ollama service to be set for the user."
          }
        ],
        "returns": [
          {
            "name": "modified_count",
            "type": "int",
            "description": "The number of documents that were modified in the database. Typically 1 if the update was successful, 0 otherwise."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.update_opensrc_key": {
      "identifier": "database.db.update_opensrc_key",
      "description": {
        "overall": "This function updates the encrypted 'opensrc_api_key' for a given username in the database. It first encrypts the provided API key after removing leading/trailing whitespace. Then, it uses the 'dbusers.update_one' method to set the encrypted key for the specified user. The function returns the count of documents that were modified.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username of the user whose API key needs to be updated."
          },
          {
            "name": "opensrc_api_key",
            "type": "str",
            "description": "The raw, unencrypted Open Source API key to be stored."
          }
        ],
        "returns": [
          {
            "name": "modified_count",
            "type": "int",
            "description": "The number of documents that were modified in the database (expected to be 1 if the update was successful)."
          }
        ],
        "usage_context": {
          "calls": "This function calls database.db.encrypt_text.",
          "called_by": "This function is not called by any other function."
        }
      },
      "error": null
    },
    "database.db.update_opensrc_url": {
      "identifier": "database.db.update_opensrc_url",
      "description": {
        "overall": "This function updates the 'opensrc_base_url' field for a specific user in the database. It takes a username and a new URL as input. The function then uses a database operation to set the 'opensrc_base_url' to the stripped version of the provided URL for the user identified by the username. Finally, it returns the count of documents that were modified.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The unique identifier for the user whose opensrc_base_url needs to be updated."
          },
          {
            "name": "opensrc_base_url",
            "type": "str",
            "description": "The new base URL for the open source repository to be set for the user."
          }
        ],
        "returns": [
          {
            "name": "modified_count",
            "type": "int",
            "description": "An integer representing the number of documents that were modified in the database. Typically 1 if the update was successful, 0 otherwise."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.fetch_gemini_key": {
      "identifier": "database.db.fetch_gemini_key",
      "description": {
        "overall": "This function retrieves the Gemini API key associated with a given username from the database. It queries the database for a user document matching the provided username and specifically selects the 'gemini_api_key' field, excluding the '_id' field. If a user document is found, it returns the value of the 'gemini_api_key'. If no user is found, it returns None.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username of the user whose Gemini API key needs to be fetched."
          }
        ],
        "returns": [
          {
            "name": "gemini_api_key",
            "type": "str | None",
            "description": "The Gemini API key for the specified user, or None if the user is not found or has no key."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.fetch_ollama_url": {
      "identifier": "database.db.fetch_ollama_url",
      "description": {
        "overall": "This function retrieves the Ollama base URL associated with a given username from a database. It queries a 'dbusers' collection for a user document matching the provided username. If the user is found, it attempts to extract and return the 'ollama_base_url' field. If the user is not found or the field is missing, it returns None.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username to look up in the database."
          }
        ],
        "returns": [
          {
            "name": "ollama_base_url",
            "type": "str | None",
            "description": "The Ollama base URL for the user, or None if the user is not found or the URL is not set."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.fetch_gpt_key": {
      "identifier": "database.db.fetch_gpt_key",
      "description": {
        "overall": "This function retrieves the GPT API key associated with a given username from the database. It queries a collection named 'dbusers' for a document matching the provided username. If a user document is found, it attempts to extract the 'gpt_api_key' field. The function is designed to handle cases where the user might not exist or might not have a GPT API key stored.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username of the user whose GPT API key needs to be fetched."
          }
        ],
        "returns": [
          {
            "name": "gpt_api_key",
            "type": "str | None",
            "description": "The GPT API key for the specified user if found, otherwise None."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.fetch_opensrc_key": {
      "identifier": "database.db.fetch_opensrc_key",
      "description": {
        "overall": "This function retrieves the 'opensrc_api_key' for a given username from a database. It queries the database for a user document based on the provided username and specifically selects the 'opensrc_api_key' field while excluding the '_id' field. If the user is found, it returns the associated API key; otherwise, it returns None.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username of the user whose opensrc_api_key needs to be fetched."
          }
        ],
        "returns": [
          {
            "name": "opensrc_api_key",
            "type": "str | None",
            "description": "The opensrc_api_key associated with the username, or None if the user is not found or has no such key."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.fetch_opensrc_url": {
      "identifier": "database.db.fetch_opensrc_url",
      "description": {
        "overall": "This function retrieves the 'opensrc_base_url' for a given username from a database. It queries the 'dbusers' collection for a user document matching the provided username. If a user document is found, it attempts to extract and return the value associated with the 'opensrc_base_url' key. If the user is not found or the key is missing, it returns None.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username to search for in the database."
          }
        ],
        "returns": [
          {
            "name": "opensrc_base_url",
            "type": "str | None",
            "description": "The 'opensrc_base_url' associated with the username, or None if the user is not found or the URL is not present."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.delete_user": {
      "identifier": "database.db.delete_user",
      "description": {
        "overall": "This function deletes a user from the database. It takes a username as input and returns the count of deleted documents. The function interacts with a database collection named 'dbusers' to perform the deletion operation.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username of the user to be deleted."
          }
        ],
        "returns": [
          {
            "name": "deleted_count",
            "type": "int",
            "description": "The number of documents that were deleted from the database."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.get_decrypted_api_keys": {
      "identifier": "database.db.get_decrypted_api_keys",
      "description": {
        "overall": "This function retrieves and decrypts API keys and related configuration for a given user from a database. It queries for a user by their username, and if found, it proceeds to decrypt sensitive API keys using a helper function. It also retrieves non-sensitive configuration like base URLs. The function is designed to return multiple decrypted values and URLs.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username of the user whose API keys and configuration are to be retrieved."
          }
        ],
        "returns": [
          {
            "name": "gemini_plain",
            "type": "str",
            "description": "The decrypted Gemini API key."
          },
          {
            "name": "ollama_plain",
            "type": "str",
            "description": "The Ollama base URL."
          },
          {
            "name": "gpt_plain",
            "type": "str",
            "description": "The decrypted GPT API key."
          },
          {
            "name": "opensrc_plain",
            "type": "str",
            "description": "The decrypted open-source API key."
          },
          {
            "name": "opensrc_url",
            "type": "str",
            "description": "The open-source base URL."
          }
        ],
        "usage_context": {
          "calls": "This function calls database.db.decrypt_text.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.insert_chat": {
      "identifier": "database.db.insert_chat",
      "description": {
        "overall": "This function creates a new chat entry in the database. It generates a unique ID, records the username and chat name, and timestamps the creation. The function then inserts this data into a collection named 'dbchats' and returns the ID of the newly inserted document.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username associated with the chat."
          },
          {
            "name": "chat_name",
            "type": "str",
            "description": "The name of the chat to be created."
          }
        ],
        "returns": [
          {
            "name": "inserted_id",
            "type": "Any",
            "description": "The unique identifier of the newly created chat document."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.fetch_chats_by_user": {
      "identifier": "database.db.fetch_chats_by_user",
      "description": {
        "overall": "This function retrieves all chats associated with a specific user from a database. It queries a collection named 'dbchats' for documents matching the provided username. The results are then sorted by their 'created_at' field in ascending order before being returned as a list. The function's purpose is to fetch a user's chat history, ordered chronologically.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username of the user whose chats are to be fetched."
          }
        ],
        "returns": [
          {
            "name": "chats",
            "type": "list",
            "description": "A list of chat documents associated with the specified user, sorted by creation time."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.check_chat_exists": {
      "identifier": "database.db.check_chat_exists",
      "description": {
        "overall": "This function checks if a specific chat exists for a given username in the database. It queries a collection named 'dbchats' using the provided username and chat name. The function returns a boolean value indicating whether a matching record was found.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username associated with the chat."
          },
          {
            "name": "chat_name",
            "type": "str",
            "description": "The name of the chat to check for."
          }
        ],
        "returns": [
          {
            "name": "chat_exists",
            "type": "bool",
            "description": "True if the chat exists for the user, False otherwise."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.rename_chat_fully": {
      "identifier": "database.db.rename_chat_fully",
      "description": {
        "overall": "This function renames a chat and all associated exchanges in the database. It first updates the chat's name in the `dbchats` collection and then updates the `chat_name` field for all related messages in the `dbexchanges` collection. The function returns the count of modified documents from the chat update operation.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username associated with the chat."
          },
          {
            "name": "old_name",
            "type": "str",
            "description": "The current name of the chat to be renamed."
          },
          {
            "name": "new_name",
            "type": "str",
            "description": "The new name to assign to the chat."
          }
        ],
        "returns": [
          {
            "name": "modified_count",
            "type": "int",
            "description": "The number of documents that were modified in the chat update operation."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is called by no other functions."
        }
      },
      "error": null
    },
    "database.db.insert_exchange": {
      "identifier": "database.db.insert_exchange",
      "description": {
        "overall": "This function inserts a new exchange record into a MongoDB collection named 'dbexchanges'. It constructs a dictionary representing the exchange with various details including question, answer, feedback, user information, usage statistics, and timestamps. A unique ID is generated for each record. The function attempts to insert this record into the database and returns the new record's ID upon success. If an error occurs during the insertion process, it prints an error message and returns None.",
        "parameters": [
          {
            "name": "question",
            "type": "str",
            "description": "The user's question."
          },
          {
            "name": "answer",
            "type": "str",
            "description": "The answer provided to the question."
          },
          {
            "name": "feedback",
            "type": "str",
            "description": "User feedback on the answer."
          },
          {
            "name": "username",
            "type": "str",
            "description": "The username of the user performing the exchange."
          },
          {
            "name": "chat_name",
            "type": "str",
            "description": "The name of the chat session."
          },
          {
            "name": "helper_used",
            "type": "str",
            "description": "Indicates if a helper was used (default: \"\")."
          },
          {
            "name": "main_used",
            "type": "str",
            "description": "Indicates if the main model was used (default: \"\")."
          },
          {
            "name": "total_time",
            "type": "str",
            "description": "Total time taken for the exchange (default: \"\")."
          },
          {
            "name": "helper_time",
            "type": "str",
            "description": "Time spent using the helper (default: \"\")."
          },
          {
            "name": "main_time",
            "type": "str",
            "description": "Time spent using the main model (default: \"\")."
          },
          {
            "name": "json_tokens",
            "type": "int",
            "description": "Number of JSON tokens used (default: 0)."
          },
          {
            "name": "toon_tokens",
            "type": "int",
            "description": "Number of 'toon' tokens used (default: 0)."
          },
          {
            "name": "savings_percent",
            "type": "float",
            "description": "Percentage of savings achieved (default: 0.0)."
          }
        ],
        "returns": [
          {
            "name": "new_id",
            "type": "str",
            "description": "The unique ID of the newly inserted exchange record, or None if an error occurred."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is called by no other functions."
        }
      },
      "error": null
    },
    "database.db.fetch_exchanges_by_user": {
      "identifier": "database.db.fetch_exchanges_by_user",
      "description": {
        "overall": "This function retrieves a list of exchanges associated with a specific username from a database. It queries a collection named 'dbexchanges' for documents matching the provided username. The results are then sorted by the 'created_at' field in ascending order before being returned as a list. This sorting is noted as important for display purposes.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username to filter exchanges by."
          }
        ],
        "returns": [
          {
            "name": "exchanges",
            "type": "list",
            "description": "A list of exchange documents associated with the given username, sorted by 'created_at'."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.fetch_exchanges_by_chat": {
      "identifier": "database.db.fetch_exchanges_by_chat",
      "description": {
        "overall": "This function retrieves a list of exchanges from a database collection based on a provided username and chat name. It queries the 'dbexchanges' collection, filtering documents that match the specified username and chat name. The results are then sorted by the 'created_at' field in ascending order before being returned as a list.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username to filter the exchanges by."
          },
          {
            "name": "chat_name",
            "type": "str",
            "description": "The name of the chat to filter the exchanges by."
          }
        ],
        "returns": [
          {
            "name": "exchanges",
            "type": "list",
            "description": "A list of exchange documents matching the specified username and chat name, sorted by creation time."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.update_exchange_feedback": {
      "identifier": "database.db.update_exchange_feedback",
      "description": {
        "overall": "This function updates the feedback associated with a specific exchange in the database. It takes an exchange ID and a feedback integer as input. The function then uses `dbexchanges.update_one` to find the exchange by its ID and set the new feedback value. Finally, it returns the count of documents that were modified.",
        "parameters": [
          {
            "name": "exchange_id",
            "type": "Any",
            "description": "The unique identifier of the exchange to be updated."
          },
          {
            "name": "feedback",
            "type": "int",
            "description": "The new feedback value to be set for the exchange."
          }
        ],
        "returns": [
          {
            "name": "modified_count",
            "type": "int",
            "description": "The number of documents that were modified in the database. This should typically be 1 if the update was successful."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.update_exchange_feedback_message": {
      "identifier": "database.db.update_exchange_feedback_message",
      "description": {
        "overall": "This function updates the feedback message associated with a specific exchange in the database. It takes an exchange ID and a feedback message string as input. The function then uses `dbexchanges.update_one` to find the exchange by its ID and set the `feedback_message` field to the provided value. Finally, it returns the count of documents that were modified.",
        "parameters": [
          {
            "name": "exchange_id",
            "type": "Any",
            "description": "The unique identifier of the exchange to be updated."
          },
          {
            "name": "feedback_message",
            "type": "str",
            "description": "The new feedback message to be associated with the exchange."
          }
        ],
        "returns": [
          {
            "name": "modified_count",
            "type": "int",
            "description": "The number of documents that were modified in the database (expected to be 1 if successful)."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.delete_exchange_by_id": {
      "identifier": "database.db.delete_exchange_by_id",
      "description": {
        "overall": "This function deletes a single exchange record from the database based on its unique identifier. It interacts with a database collection named 'dbexchanges' to perform the deletion operation. The function returns the count of documents that were successfully deleted.",
        "parameters": [
          {
            "name": "exchange_id",
            "type": "str",
            "description": "The unique identifier of the exchange record to be deleted."
          }
        ],
        "returns": [
          {
            "name": "deleted_count",
            "type": "int",
            "description": "The number of documents that were deleted from the database. This is typically 1 if the exchange was found and deleted, and 0 otherwise."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "database.db.delete_full_chat": {
      "identifier": "database.db.delete_full_chat",
      "description": {
        "overall": "This function deletes a specific chat and all associated exchanges for a given username. It first removes all messages within the specified chat by calling `dbexchanges.delete_many`. Then, it removes the chat itself from the chat list by calling `dbchats.delete_one`. This ensures consistency between the frontend and backend data.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username associated with the chat to be deleted."
          },
          {
            "name": "chat_name",
            "type": "str",
            "description": "The name of the chat to be deleted."
          }
        ],
        "returns": [
          {
            "name": "deleted_count",
            "type": "int",
            "description": "The number of chat documents deleted."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "frontend.frontend.clean_names": {
      "identifier": "frontend.frontend.clean_names",
      "description": {
        "overall": "This function takes a list of strings, where each string is expected to be a path or identifier that includes a '/'. It processes each string by splitting it at the '/' character and extracting the last part. This is useful for cleaning up model names or paths to get just the final component.",
        "parameters": [
          {
            "name": "model_list",
            "type": "list[str]",
            "description": "A list of strings, where each string is a model name or path."
          }
        ],
        "returns": [
          {
            "name": "cleaned_names",
            "type": "list[str]",
            "description": "A new list containing the last component of each string from the input list."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "frontend.frontend.get_filtered_models": {
      "identifier": "frontend.frontend.get_filtered_models",
      "description": {
        "overall": "This function filters a list of models based on a specified category name. It retrieves keywords associated with the category from a dictionary `CATEGORY_KEYWORDS`. If the category is 'STANDARD', it returns models that are also present in `STANDARD_MODELS`. Otherwise, it iterates through the source list and appends models whose names contain any of the category's keywords (case-insensitive). If no models match the keywords, the original source list is returned.",
        "parameters": [
          {
            "name": "source_list",
            "type": "list",
            "description": "The list of models to filter."
          },
          {
            "name": "category_name",
            "type": "str",
            "description": "The name of the category to filter by."
          }
        ],
        "returns": [
          {
            "name": "filtered_models",
            "type": "list",
            "description": "A list of models filtered by the specified category, or the original list if no matches are found or if the category is 'STANDARD' and matches are found."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "frontend.frontend.save_gemini_cb": {
      "identifier": "frontend.frontend.save_gemini_cb",
      "description": {
        "overall": "This function is responsible for saving a Gemini API key provided by the user. It retrieves the key from the Streamlit session state, and if a key exists, it updates the user's Gemini key in the database. After a successful update, it clears the temporary key from the session state and displays a success message to the user.",
        "parameters": [],
        "returns": [],
        "usage_context": {
          "calls": "This function calls database.db.update_gemini_key.",
          "called_by": "This function is not called by any other function."
        }
      },
      "error": null
    },
    "frontend.frontend.save_ollama_cb": {
      "identifier": "frontend.frontend.save_ollama_cb",
      "description": {
        "overall": "This function is a callback designed to save the Ollama URL. It retrieves a new URL from the session state. If a URL is present, it updates the user's Ollama URL in the database and displays a success toast message to the user. The function does not return any value.",
        "parameters": [],
        "returns": [],
        "usage_context": {
          "calls": "This function calls database.db.update_ollama_url.",
          "called_by": "This function is not called by any other function."
        }
      },
      "error": null
    },
    "frontend.frontend.load_data_from_db": {
      "identifier": "frontend.frontend.load_data_from_db",
      "description": {
        "overall": "This function loads chat and exchange data from a database for a given username. It ensures data consistency by only loading if the user is new or data hasn't been loaded yet. The function first fetches predefined chats, then loads and sorts exchanges into their respective chats. If no data exists, it creates a default chat and inserts it into the database. Finally, it sets the active chat to the first available one if not already defined or if the current active chat is invalid.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username for whom to load the data."
          }
        ],
        "returns": [],
        "usage_context": {
          "calls": "This function calls database.db.fetch_chats_by_user, database.db.fetch_exchanges_by_user, and database.db.insert_chat.",
          "called_by": "This function is not called by any other function within the provided context."
        }
      },
      "error": null
    },
    "frontend.frontend.handle_feedback_change": {
      "identifier": "frontend.frontend.handle_feedback_change",
      "description": {
        "overall": "This function updates the feedback associated with an exchange and then triggers a rerun of the Streamlit application. It modifies a dictionary representing an exchange by setting the 'feedback' key to a new value. Subsequently, it calls a database function to persist this feedback change for the specific exchange ID. Finally, it instructs Streamlit to rerun the application, likely to reflect the updated feedback.",
        "parameters": [
          {
            "name": "ex",
            "type": "dict",
            "description": "A dictionary representing the exchange object, expected to contain at least an '_id' key and a 'feedback' key."
          },
          {
            "name": "val",
            "type": "any",
            "description": "The new feedback value to be assigned to the exchange."
          }
        ],
        "returns": [],
        "usage_context": {
          "calls": "This function calls database.db.update_exchange_feedback.",
          "called_by": "This function is not called by any other function within the provided context."
        }
      },
      "error": null
    },
    "frontend.frontend.handle_delete_exchange": {
      "identifier": "frontend.frontend.handle_delete_exchange",
      "description": {
        "overall": "This function handles the deletion of an exchange from the system. It first deletes the exchange from the database using its ID. Then, it checks if the chat associated with the exchange exists in the session state. If it does, and the exchange is present in the list of exchanges for that chat, it removes the exchange from the list. Finally, it triggers a rerun of the Streamlit application to reflect the changes.",
        "parameters": [
          {
            "name": "chat_name",
            "type": "str",
            "description": "The name of the chat associated with the exchange to be deleted."
          },
          {
            "name": "ex",
            "type": "dict",
            "description": "A dictionary representing the exchange to be deleted, expected to contain an '_id' key."
          }
        ],
        "returns": [],
        "usage_context": {
          "calls": "This function calls database.db.delete_exchange_by_id.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "frontend.frontend.handle_delete_chat": {
      "identifier": "frontend.frontend.handle_delete_chat",
      "description": {
        "overall": "This function handles the deletion of a chat for a given user. It first deletes the chat data from the database using `db.delete_full_chat`. Then, it cleans up the session state by removing the chat from `st.session_state.chats`. If there are remaining chats, it sets the first available chat as the active chat. If no chats remain, it creates a new default chat, inserts it into the database, and sets it as the active chat. Finally, it triggers a rerun of the Streamlit application to reflect the changes.",
        "parameters": [
          {
            "name": "username",
            "type": "str",
            "description": "The username of the user whose chat is to be deleted."
          },
          {
            "name": "chat_name",
            "type": "str",
            "description": "The name of the chat to be deleted."
          }
        ],
        "returns": [],
        "usage_context": {
          "calls": "This function calls database.db.delete_full_chat and database.db.insert_chat.",
          "called_by": "This function is not called by any other function."
        }
      },
      "error": null
    },
    "frontend.frontend.extract_repo_name": {
      "identifier": "frontend.frontend.extract_repo_name",
      "description": {
        "overall": "This function takes a string as input and attempts to extract a repository name from it. It first searches for a URL within the text using a regular expression. If a URL is found, it parses the URL, extracts the path, and then isolates the last part of the path, which is assumed to be the repository name. It also handles cases where the repository name might end with '.git', removing that suffix. If no URL is found or if the repository name cannot be determined from the URL path, the function returns None.",
        "parameters": [
          {
            "name": "text",
            "type": "str",
            "description": "The input string potentially containing a URL."
          }
        ],
        "returns": [
          {
            "name": "repo_name",
            "type": "str | None",
            "description": "The extracted repository name if found, otherwise None."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "frontend.frontend.stream_text_generator": {
      "identifier": "frontend.frontend.stream_text_generator",
      "description": {
        "overall": "This function takes a string of text as input and yields words from it one by one with a small delay. It splits the input text into words based on spaces and then yields each word followed by a space. A short delay of 0.01 seconds is introduced after yielding each word. This is likely used for creating a streaming text effect in a user interface.",
        "parameters": [
          {
            "name": "text",
            "type": "str",
            "description": "The input string of text to be streamed."
          }
        ],
        "returns": [
          {
            "name": "word",
            "type": "str",
            "description": "A single word from the input text, followed by a space."
          }
        ],
        "usage_context": {
          "calls": "This function calls no other functions.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "frontend.frontend.render_text_with_mermaid": {
      "identifier": "frontend.frontend.render_text_with_mermaid",
      "description": {
        "overall": "This function takes a markdown text string and optionally a boolean to control streaming output. It splits the markdown text based on mermaid code blocks (```mermaid ... ```). For non-mermaid parts, it either writes them directly using `st.markdown` or streams them using `st.write_stream` if `should_stream` is True. For mermaid code blocks, it attempts to render them using `st_mermaid`. If rendering fails, it falls back to displaying the code block as plain text with a mermaid language hint.",
        "parameters": [
          {
            "name": "markdown_text",
            "type": "str",
            "description": "The markdown text content to be rendered, potentially containing mermaid diagrams."
          },
          {
            "name": "should_stream",
            "type": "bool",
            "description": "A flag indicating whether the non-mermaid text content should be streamed. Defaults to False."
          }
        ],
        "returns": [],
        "usage_context": {
          "calls": "This function calls frontend.frontend.stream_text_generator.",
          "called_by": "This function is not called by any other functions."
        }
      },
      "error": null
    },
    "frontend.frontend.render_exchange": {
      "identifier": "frontend.frontend.render_exchange",
      "description": {
        "overall": "This function renders a chat exchange, displaying both the user's question and the assistant's answer. It handles various interactive elements for the assistant's response, including feedback buttons (like/dislike), a comment popover, a download button for the answer, and a delete button. The function also differentiates between successful answers and error messages, displaying appropriate UI elements for each. It utilizes Streamlit components for rendering the chat interface and containers for organizing the layout. The function also calls other helper functions to manage feedback, deletion, and rendering of the answer content, including mermaid diagrams.",
        "parameters": [
          {
            "name": "ex",
            "type": "dict",
            "description": "A dictionary containing the exchange data, expected to have keys like 'question', 'answer', 'feedback', 'feedback_message', and '_id'."
          },
          {
            "name": "current_chat_name",
            "type": "str",
            "description": "The name of the current chat, used for deletion operations."
          }
        ],
        "returns": [],
        "usage_context": {
          "calls": "This function calls database.db.update_exchange_feedback_message, frontend.frontend.handle_delete_exchange, frontend.frontend.handle_feedback_change, and frontend.frontend.render_text_with_mermaid.",
          "called_by": "This function is not called by any other function within the provided context."
        }
      },
      "error": null
    }
  },
  "classes": {
    "backend.AST_Schema.ASTVisitor": {
      "identifier": "backend.AST_Schema.ASTVisitor",
      "description": {
        "overall": "The ASTVisitor class is designed to traverse an Abstract Syntax Tree (AST) generated from Python source code. It specifically focuses on extracting information about imports, classes, and functions defined within the code. The visitor pattern is employed to systematically visit different node types in the AST, populating a schema object with the discovered structural elements of the codebase. This class is instrumental in analyzing and cataloging the components of a Python project.",
        "init_method": {
          "description": "Initializes the ASTVisitor with the source code, file path, and project root. It sets up instance variables to store this information and initializes an empty schema dictionary to hold the extracted AST information, including imports, functions, and classes. It also prepares a variable to track the current class being visited.",
          "parameters": [
            {
              "name": "source_code",
              "type": "str",
              "description": "The raw source code of the file being analyzed."
            },
            {
              "name": "file_path",
              "type": "str",
              "description": "The absolute path to the file being analyzed."
            },
            {
              "name": "project_root",
              "type": "str",
              "description": "The root directory of the project."
            }
          ]
        },
        "methods": [
          {
            "identifier": "visit_Import",
            "description": {
              "overall": "This method is called when an `import` statement is encountered in the AST. It iterates through the imported names and appends them to the 'imports' list within the schema. It then calls `generic_visit` to continue the traversal down the AST.",
              "parameters": [
                {
                  "name": "self",
                  "type": "ASTVisitor",
                  "description": "The instance of the ASTVisitor class."
                },
                {
                  "name": "node",
                  "type": "ast.Import",
                  "description": "The AST node representing an import statement."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls the `generic_visit` method to continue AST traversal.",
                "called_by": "This method is called automatically by the `ast.NodeVisitor` when it encounters an `ast.Import` node during AST traversal."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_ImportFrom",
            "description": {
              "overall": "This method handles `from ... import ...` statements in the AST. It iterates through the imported names, constructing a fully qualified import path (module.name) and appending it to the 'imports' list in the schema. It ensures that the traversal continues by calling `generic_visit`.",
              "parameters": [
                {
                  "name": "self",
                  "type": "ASTVisitor",
                  "description": "The instance of the ASTVisitor class."
                },
                {
                  "name": "node",
                  "type": "ast.ImportFrom",
                  "description": "The AST node representing a 'from ... import ...' statement."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls the `generic_visit` method to continue AST traversal.",
                "called_by": "This method is called automatically by the `ast.NodeVisitor` when it encounters an `ast.ImportFrom` node during AST traversal."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_ClassDef",
            "description": {
              "overall": "This method is invoked when a class definition is found in the AST. It constructs a unique identifier for the class, extracts its name, docstring, and source code segment, and records its line numbers. It then creates a dictionary to hold class-specific information, including its context (dependencies, instantiation points, and method details), and appends this to the schema's 'classes' list. It sets `_current_class` to track this class and continues the AST traversal, finally resetting `_current_class` after visiting the class's body.",
              "parameters": [
                {
                  "name": "self",
                  "type": "ASTVisitor",
                  "description": "The instance of the ASTVisitor class."
                },
                {
                  "name": "node",
                  "type": "ast.ClassDef",
                  "description": "The AST node representing a class definition."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls `ast.get_docstring`, `ast.get_source_segment`, and `generic_visit` to process the class definition and its contents.",
                "called_by": "This method is called automatically by the `ast.NodeVisitor` when it encounters an `ast.ClassDef` node during AST traversal."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_FunctionDef",
            "description": {
              "overall": "This method processes function definitions within the AST. If the visitor is currently inside a class (indicated by `_current_class`), it treats the function as a method, constructs a method identifier, and stores method-specific details (name, calls, called_by, arguments, docstring, line numbers) within the `_current_class`'s context. If not inside a class, it treats the function as a standalone function, creating a 'function_analysis' entry in the schema with its identifier, name, arguments, docstring, source code, line numbers, and context for calls and called_by. It then proceeds with the generic AST traversal.",
              "parameters": [
                {
                  "name": "self",
                  "type": "ASTVisitor",
                  "description": "The instance of the ASTVisitor class."
                },
                {
                  "name": "node",
                  "type": "ast.FunctionDef",
                  "description": "The AST node representing a function definition."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls `ast.get_docstring`, `ast.get_source_segment`, and `generic_visit` to process function definitions.",
                "called_by": "This method is called automatically by the `ast.NodeVisitor` when it encounters an `ast.FunctionDef` node during AST traversal."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_AsyncFunctionDef",
            "description": {
              "overall": "This method serves as an alias for `visit_FunctionDef` to handle asynchronous function definitions. By calling `self.visit_FunctionDef(node)`, it ensures that asynchronous functions are processed and recorded in the schema in the same manner as regular functions or methods.",
              "parameters": [
                {
                  "name": "self",
                  "type": "ASTVisitor",
                  "description": "The instance of the ASTVisitor class."
                },
                {
                  "name": "node",
                  "type": "ast.AsyncFunctionDef",
                  "description": "The AST node representing an asynchronous function definition."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls `self.visit_FunctionDef` to process the asynchronous function definition.",
                "called_by": "This method is called automatically by the `ast.NodeVisitor` when it encounters an `ast.AsyncFunctionDef` node during AST traversal."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "This class depends on the `backend.AST_Schema.path_to_module` function to determine the module path for classes and functions.",
          "instantiated_by": "This class is not instantiated by any other part of the code provided in the context."
        }
      },
      "error": null
    },
    "backend.AST_Schema.ASTAnalyzer": {
      "identifier": "backend.AST_Schema.ASTAnalyzer",
      "description": {
        "overall": "The ASTAnalyzer class is designed to process and enrich Abstract Syntax Tree (AST) data obtained from a codebase. It takes raw schema information and relationship data (like function calls and class instantiations) and merges them to provide a more comprehensive view of the code structure. It also facilitates the analysis of an entire repository by parsing individual files and extracting their AST information.",
        "init_method": {
          "description": "Initializes the ASTAnalyzer. Currently, this method does not perform any setup or attribute initialization.",
          "parameters": []
        },
        "methods": [
          {
            "identifier": "merge_relationship_data",
            "description": {
              "overall": "This method merges relationship data, such as outgoing calls and incoming calls, into a full schema representation. It iterates through files, functions, classes, and methods within the schema, enriching them with call and instantiation information derived from the `raw_relationships` dictionary. It also identifies and aggregates dependencies between classes based on method calls.",
              "parameters": [
                {
                  "name": "full_schema",
                  "type": "dict",
                  "description": "A dictionary representing the complete schema of the codebase, including file structures, AST nodes, functions, and classes."
                },
                {
                  "name": "raw_relationships",
                  "type": "dict",
                  "description": "A dictionary containing raw relationship data, expected to have keys like 'outgoing' and 'incoming' which map identifiers to lists of related entities."
                }
              ],
              "returns": [
                {
                  "name": "full_schema",
                  "type": "dict",
                  "description": "The modified full schema dictionary with relationship data merged into functions, classes, and methods."
                }
              ],
              "usage_context": {
                "calls": "This method retrieves data using .get() on dictionaries and iterates through nested structures. It does not explicitly call other methods or functions from external modules within its scope.",
                "called_by": "This method is called by the analyze_repository method to integrate relationship data into the generated schema."
              }
            },
            "error": null
          },
          {
            "identifier": "analyze_repository",
            "description": {
              "overall": "This method orchestrates the analysis of an entire code repository. It iterates through a list of file objects, parses Python files using the `ast` module and an `ASTVisitor`, and constructs a comprehensive schema. It determines the project root and handles potential parsing errors, ultimately returning a dictionary containing the processed schema for each file.",
              "parameters": [
                {
                  "name": "files",
                  "type": "list",
                  "description": "A list of file objects, where each object is expected to have 'path' and 'content' attributes."
                },
                {
                  "name": "repo",
                  "type": "GitRepository",
                  "description": "An instance of GitRepository, though its methods are not directly used within this method's logic."
                }
              ],
              "returns": [
                {
                  "name": "full_schema",
                  "type": "dict",
                  "description": "A dictionary containing the aggregated schema information for all processed Python files in the repository."
                }
              ],
              "usage_context": {
                "calls": "This method calls the ast.parse function to generate an AST from file content and instantiates and calls the visit method of an ASTVisitor object. It also utilizes os.path functions for path manipulation.",
                "called_by": "This method is intended to be called to initiate the analysis of a code repository."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "This class depends on the ASTVisitor class for parsing and visiting Abstract Syntax Trees, and utilizes the 'ast' and 'os' modules for core Python parsing and operating system interactions.",
          "instantiated_by": "This class is not instantiated by any other part of the code based on the provided context."
        }
      },
      "error": null
    },
    "backend.File_Dependency.FileDependencyGraph": {
      "identifier": "backend.File_Dependency.FileDependencyGraph",
      "description": {
        "overall": "The FileDependencyGraph class is designed to analyze Python source code and build a graph of file dependencies. It inherits from ast.NodeVisitor, allowing it to traverse the Abstract Syntax Tree (AST) of Python files. The primary goal is to record import relationships, specifically handling both direct and relative imports. It identifies which files import which other files or modules, storing this information internally. This graph can then be used to understand the structure and interdependencies within a codebase.",
        "init_method": {
          "description": "Initializes the FileDependencyGraph with the specific file to analyze and the root directory of the repository. This sets up the context for resolving imports within that file and its relationship to the overall project structure.",
          "parameters": [
            {
              "name": "filename",
              "type": "str",
              "description": "The name of the Python file for which the dependency graph is being constructed."
            },
            {
              "name": "repo_root",
              "type": "str",
              "description": "The root directory path of the repository containing the file."
            }
          ]
        },
        "methods": [
          {
            "identifier": "_resolve_module_name",
            "description": {
              "overall": "This method is responsible for resolving relative import statements (e.g., `from .. import module`) within a Python file. It takes an `ImportFrom` AST node as input and determines the actual module path based on the current file's location and the import's level. It searches for potential module files within the repository and checks for `__init__.py` files and `__all__` definitions to correctly identify the imported module or symbol. If a resolution cannot be made, it raises an `ImportError`.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ImportFrom",
                  "description": "The AST node representing a 'from ... import ...' statement."
                }
              ],
              "returns": [
                {
                  "name": "resolved",
                  "type": "list[str]",
                  "description": "A sorted list of strings representing the resolved module or symbol names."
                }
              ],
              "usage_context": {
                "calls": "This method calls external functions like `get_all_temp_files` to find files, and helper functions `module_file_exists` and `init_exports_symbol` to check for module existence and export symbols.",
                "called_by": "This method is called by `visit_ImportFrom` when handling relative imports."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_Import",
            "description": {
              "overall": "This method handles direct import statements (e.g., `import module` or `import module as alias`). It records the imported module name in the `import_dependencies` dictionary, mapping the current filename to a set of imported module names. If a `base_name` is provided (indicating a resolved part of a relative import), it uses that; otherwise, it uses the direct alias name. It then calls `generic_visit` to continue traversing the AST.",
              "parameters": [
                {
                  "name": "node",
                  "type": "Import | ImportFrom",
                  "description": "The AST node representing an import statement."
                },
                {
                  "name": "base_name",
                  "type": "str | None",
                  "description": "An optional base name, typically used when processing resolved relative imports."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls `self.generic_visit` to continue AST traversal.",
                "called_by": "This method is called by `visit_ImportFrom`."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_ImportFrom",
            "description": {
              "overall": "This method specifically handles `from ... import ...` statements. It first extracts the module name from the import statement. If the module name is direct (e.g., `from module import ...`), it calls `visit_Import` with the last part of the module name as `base_name`. If the import is relative (e.g., `from .. import ...`), it calls `_resolve_module_name` to determine the actual module path and then calls `visit_Import` for each resolved name. It includes error handling for failed relative import resolutions.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ImportFrom",
                  "description": "The AST node representing a 'from ... import ...' statement."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls `self._resolve_module_name`, `self.visit_Import`, and `self.generic_visit`.",
                "called_by": "This method is called when the AST visitor encounters an `ImportFrom` node."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "This class depends on several external functions and modules for its operation, including `get_all_temp_files`, `init_exports_symbol`, `module_file_exists` for resolving imports, and standard Python libraries like `ast`, `keyword`, and `pathlib` for code analysis.",
          "instantiated_by": "The provided context does not specify where instances of this class are created."
        }
      },
      "error": null
    },
    "backend.HelperLLM.LLMHelper": {
      "identifier": "backend.HelperLLM.LLMHelper",
      "description": {
        "overall": "The LLMHelper class is designed to facilitate the generation and validation of documentation for code elements like functions and classes using large language models (LLMs). It centralizes interactions with various LLM providers (Google Gemini, OpenAI, Ollama) by abstracting away the specifics of API calls and model configurations. The class handles prompt management, batch processing with rate limiting, and structured output generation, ensuring that the generated documentation conforms to predefined schemas.",
        "init_method": {
          "description": "Initializes the LLMHelper with necessary API keys, prompt file paths, and model configurations. It reads system prompts from specified files, sets up LLM clients based on the model name (supporting Gemini, OpenAI, and Ollama), and configures batch processing settings. It also initializes specialized LLM instances for function and class documentation generation with structured output capabilities.",
          "parameters": [
            {
              "name": "api_key",
              "type": "str",
              "description": "The API key required for authenticating with the LLM service."
            },
            {
              "name": "function_prompt_path",
              "type": "str",
              "description": "The file path to the system prompt used for generating function documentation."
            },
            {
              "name": "class_prompt_path",
              "type": "str",
              "description": "The file path to the system prompt used for generating class documentation."
            },
            {
              "name": "model_name",
              "type": "str",
              "description": "The name of the LLM model to use. Defaults to 'gemini-2.0-flash-lite'."
            },
            {
              "name": "base_url",
              "type": "str",
              "description": "An optional base URL for custom LLM endpoints, particularly for Ollama or other self-hosted models. Defaults to None."
            }
          ]
        },
        "methods": [
          {
            "identifier": "_configure_batch_settings",
            "description": {
              "overall": "This private method configures the batch size for processing LLM requests based on the specified model name. It assigns different batch sizes to various models, including Gemini and GPT variants, and sets a conservative default for unknown models. This helps in optimizing API calls and respecting potential rate limits.",
              "parameters": [
                {
                  "name": "self",
                  "type": "LLMHelper",
                  "description": "The instance of the LLMHelper class."
                },
                {
                  "name": "model_name",
                  "type": "str",
                  "description": "The name of the LLM model being used, which determines the batch size."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method is called internally by the __init__ method to set up the batch size based on the selected LLM model.",
                "called_by": "This method is called by the __init__ method."
              }
            },
            "error": null
          },
          {
            "identifier": "generate_for_functions",
            "description": {
              "overall": "Generates and validates documentation for a list of function inputs using the configured LLM. It processes inputs in batches according to the `batch_size` attribute, constructs conversations with the system prompt and function input payloads, and sends them to the LLM for processing. It includes error handling for batch API calls and implements a waiting period between batches to manage rate limits.",
              "parameters": [
                {
                  "name": "self",
                  "type": "LLMHelper",
                  "description": "The instance of the LLMHelper class."
                },
                {
                  "name": "function_inputs",
                  "type": "List[FunctionAnalysisInput]",
                  "description": "A list of FunctionAnalysisInput objects, each containing the necessary information to generate documentation for a function."
                }
              ],
              "returns": [
                {
                  "name": "all_validated_functions",
                  "type": "List[Optional[FunctionAnalysis]]",
                  "description": "A list containing the generated and validated FunctionAnalysis objects, or None for any inputs that failed during processing."
                }
              ],
              "usage_context": {
                "calls": "This method calls `json.dumps` to serialize input data, constructs `SystemMessage` and `HumanMessage` objects, and uses the `self.function_llm.batch` method to send requests to the LLM API. It also uses `time.sleep` for rate limiting.",
                "called_by": "This method is called to generate documentation for multiple functions."
              }
            },
            "error": null
          },
          {
            "identifier": "generate_for_classes",
            "description": {
              "overall": "Generates and validates documentation for a list of class inputs using the configured LLM. Similar to `generate_for_functions`, it processes inputs in batches, prepares conversations with system prompts and class input payloads, and sends them to the LLM. It handles API call errors and implements rate limiting waits between batches.",
              "parameters": [
                {
                  "name": "self",
                  "type": "LLMHelper",
                  "description": "The instance of the LLMHelper class."
                },
                {
                  "name": "class_inputs",
                  "type": "List[ClassAnalysisInput]",
                  "description": "A list of ClassAnalysisInput objects, each containing the necessary information to generate documentation for a class."
                }
              ],
              "returns": [
                {
                  "name": "all_validated_classes",
                  "type": "List[Optional[ClassAnalysis]]",
                  "description": "A list containing the generated and validated ClassAnalysis objects, or None for any inputs that failed during processing."
                }
              ],
              "usage_context": {
                "calls": "This method calls `json.dumps` to serialize input data, constructs `SystemMessage` and `HumanMessage` objects, and uses the `self.class_llm.batch` method to send requests to the LLM API. It also utilizes `time.sleep` for rate limiting.",
                "called_by": "This method is called to generate documentation for multiple classes."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "This class depends on various LLM provider libraries (ChatGoogleGenerativeAI, ChatOllama, ChatOpenAI), message types (HumanMessage, SystemMessage), Pydantic models for structured output (FunctionAnalysis, ClassAnalysis, FunctionAnalysisInput, ClassAnalysisInput), and standard Python libraries like `os`, `json`, `logging`, and `time`.",
          "instantiated_by": "This class is intended to be instantiated by other parts of the application that require LLM-based documentation generation services, likely within a backend service or a documentation generation pipeline."
        }
      },
      "error": null
    },
    "backend.MainLLM.MainLLM": {
      "identifier": "backend.MainLLM.MainLLM",
      "description": {
        "overall": "The MainLLM class serves as a central orchestrator for interacting with various Large Language Models (LLMs). It handles the initialization of different LLM clients based on the provided model name and configuration, loads system prompts from a file, and provides methods to invoke LLM calls synchronously or stream responses asynchronously. The class abstracts away the complexities of managing different LLM APIs, such as Google Generative AI, Ollama, and custom SCADSLLM endpoints.",
        "init_method": {
          "description": "Initializes the MainLLM class by setting up the LLM client. It validates the API key, loads the system prompt from a specified file, and configures the appropriate LLM client (ChatGoogleGenerativeAI, ChatOpenAI, or ChatOllama) based on the model name. It also sets up logging for initialization and potential errors.",
          "parameters": [
            {
              "name": "api_key",
              "type": "str",
              "description": "The API key required for authenticating with the LLM service."
            },
            {
              "name": "prompt_file_path",
              "type": "str",
              "description": "The path to the file containing the system prompt for the LLM."
            },
            {
              "name": "model_name",
              "type": "str",
              "description": "The name of the LLM model to use. Defaults to 'gemini-2.5-pro'."
            },
            {
              "name": "base_url",
              "type": "str",
              "description": "An optional base URL for custom LLM endpoints. If not provided, OLLAMA_BASE_URL is used."
            }
          ]
        },
        "methods": [
          {
            "identifier": "call_llm",
            "description": {
              "overall": "This method sends a user's input to the configured LLM and returns the model's response content. It constructs a list of messages including the system prompt and the user's input, then invokes the LLM client. If the call is successful, it returns the content of the response; otherwise, it logs the error and returns None.",
              "parameters": [
                {
                  "name": "user_input",
                  "type": "str",
                  "description": "The input string provided by the user to be sent to the LLM."
                }
              ],
              "returns": [
                {
                  "name": "response.content",
                  "type": "str",
                  "description": "The text content generated by the LLM in response to the user input."
                }
              ],
              "usage_context": {
                "calls": "This method calls the 'invoke' method of the internal LLM client to get a synchronous response.",
                "called_by": "This method is called to get a direct response from the LLM."
              }
            },
            "error": null
          },
          {
            "identifier": "stream_llm",
            "description": {
              "overall": "This method enables streaming of LLM responses. It constructs messages similar to `call_llm` but uses the `stream` method of the LLM client to yield response chunks as they are generated. This is useful for real-time applications where immediate feedback is desired. Errors during streaming are logged and included in the yielded output.",
              "parameters": [
                {
                  "name": "user_input",
                  "type": "str",
                  "description": "The input string provided by the user to be sent to the LLM for streaming."
                }
              ],
              "returns": [
                {
                  "name": "chunk.content",
                  "type": "str",
                  "description": "Yields chunks of text content as they are generated by the LLM stream."
                }
              ],
              "usage_context": {
                "calls": "This method calls the 'stream' method of the internal LLM client to get a streaming response.",
                "called_by": "This method is called to receive a response from the LLM in a streaming fashion."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "The class depends on various LLM client libraries including 'langchain_google_genai', 'langchain_ollama', and 'langchain_openai', as well as message types from 'langchain.messages'. It also utilizes 'logging' for output and error reporting, and potentially environment variables like 'SCADSLLM_URL' and 'OLLAMA_BASE_URL' for configuration.",
          "instantiated_by": "The class is instantiated within the backend system, likely to provide LLM interaction capabilities to other parts of the application."
        }
      },
      "error": null
    },
    "backend.basic_info.ProjektInfoExtractor": {
      "identifier": "backend.basic_info.ProjektInfoExtractor",
      "description": {
        "overall": "The ProjektInfoExtractor class is designed to extract fundamental project information from common project files such as README, pyproject.toml, and requirements.txt. It initializes a structured dictionary to hold project overview and installation details, populating it by parsing these files. The class prioritizes information from pyproject.toml for dependencies and title, then falls back to requirements.txt for dependencies, and finally uses README for a broader set of project details. It also attempts to derive the project title from a repository URL if no title is found in the files.",
        "init_method": {
          "description": "The constructor initializes the ProjektInfoExtractor by setting a default string for when information is not found and creating a nested dictionary structure to hold project information. This structure includes placeholders for project overview details like title, description, status, key features, and tech stack, as well as installation details such as dependencies, setup instructions, and a quick start guide.",
          "parameters": []
        },
        "methods": [
          {
            "identifier": "_clean_content",
            "description": {
              "overall": "This private helper method takes a string as input and returns a cleaned version of it. Its primary function is to remove null bytes ('\\x00') which can occur due to encoding errors, specifically when UTF-16 encoded files are read as UTF-8. If the input content is empty or None, it returns an empty string.",
              "parameters": [
                {
                  "name": "content",
                  "type": "str",
                  "description": "The string content to be cleaned."
                }
              ],
              "returns": [
                {
                  "name": "cleaned_content",
                  "type": "str",
                  "description": "The content string with null bytes removed."
                }
              ],
              "usage_context": {
                "calls": "This method is called by other internal methods to clean file content before parsing.",
                "called_by": "This method is called by _parse_readme, _parse_toml, and _parse_requirements."
              }
            },
            "error": null
          },
          {
            "identifier": "_finde_datei",
            "description": {
              "overall": "This private helper method searches through a list of file objects to find a file that matches one of the provided patterns. The search is case-insensitive and checks if the file's path ends with any of the specified patterns. It returns the first matching file object found or None if no match is found.",
              "parameters": [
                {
                  "name": "patterns",
                  "type": "List[str]",
                  "description": "A list of file name patterns (e.g., 'readme.md') to search for."
                },
                {
                  "name": "dateien",
                  "type": "List[Any]",
                  "description": "A list of file objects, where each object is expected to have a 'path' attribute."
                }
              ],
              "returns": [
                {
                  "name": "matching_file",
                  "type": "Optional[Any]",
                  "description": "The file object that matches one of the patterns, or None if no match is found."
                }
              ],
              "usage_context": {
                "calls": "This method iterates through provided file objects and patterns to find a match.",
                "called_by": "This method is called by extrahiere_info to locate specific project files like README, pyproject.toml, and requirements.txt."
              }
            },
            "error": null
          },
          {
            "identifier": "_extrahiere_sektion_aus_markdown",
            "description": {
              "overall": "This private helper method extracts a specific section of text from a Markdown content string. It uses regular expressions to find a section that starts with a Markdown heading (##) followed by one of the provided keywords. It captures all text between this heading and the next heading or the end of the file. The extraction is case-insensitive.",
              "parameters": [
                {
                  "name": "inhalt",
                  "type": "str",
                  "description": "The Markdown content from which to extract a section."
                },
                {
                  "name": "keywords",
                  "type": "List[str]",
                  "description": "A list of keywords that identify the desired section's heading."
                }
              ],
              "returns": [
                {
                  "name": "section_content",
                  "type": "Optional[str]",
                  "description": "The extracted text content of the section, stripped of leading/trailing whitespace, or None if the section is not found."
                }
              ],
              "usage_context": {
                "calls": "This method utilizes the 're' module for regular expression matching to find and extract specific sections from Markdown text based on keywords.",
                "called_by": "This method is called by _parse_readme to extract specific information like 'Key Features', 'Tech Stack', 'Status', 'Installation', and 'Quick Start' sections."
              }
            },
            "error": null
          },
          {
            "identifier": "_parse_readme",
            "description": {
              "overall": "This private method parses the content of a README file to extract various project details. It first cleans the content by removing null bytes. It then attempts to extract the project title from the main heading, the description from the text following the title, and specific sections like 'Key Features', 'Tech Stack', 'Status', 'Installation', and 'Quick Start' using the `_extrahiere_sektion_aus_markdown` helper. Information is updated in the instance's `self.info` dictionary, prioritizing existing information if a field is already populated.",
              "parameters": [
                {
                  "name": "inhalt",
                  "type": "str",
                  "description": "The content of the README file as a string."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls _clean_content to preprocess the input string and _extrahiere_sektion_aus_markdown to extract specific sections based on keywords. It also uses the 're' module for pattern matching to find the title and description.",
                "called_by": "This method is called by extrahiere_info after a README file has been found."
              }
            },
            "error": null
          },
          {
            "identifier": "_parse_toml",
            "description": {
              "overall": "This private method parses the content of a pyproject.toml file using the `tomllib` library. It cleans the content first and then attempts to load it as TOML data. If successful, it extracts project name, description, and dependencies from the 'project' section and updates the instance's `self.info` dictionary. It includes a warning if the `tomllib` library is not available and handles potential TOML decoding errors.",
              "parameters": [
                {
                  "name": "inhalt",
                  "type": "str",
                  "description": "The content of the pyproject.toml file as a string."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls _clean_content to preprocess the input string and uses the 'tomllib.loads' function to parse the TOML content. It also prints warnings and error messages.",
                "called_by": "This method is called by extrahiere_info if a pyproject.toml file is found."
              }
            },
            "error": null
          },
          {
            "identifier": "_parse_requirements",
            "description": {
              "overall": "This private method parses the content of a requirements.txt file to extract project dependencies. It cleans the content and then splits it into lines, filtering out empty lines and comments (lines starting with '#'). The extracted dependencies are stored in the instance's `self.info` dictionary under 'installation.dependencies', but only if dependencies have not already been populated from a pyproject.toml file.",
              "parameters": [
                {
                  "name": "inhalt",
                  "type": "str",
                  "description": "The content of the requirements.txt file as a string."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls _clean_content to preprocess the input string and uses string manipulation methods like splitlines() and strip() to process the content.",
                "called_by": "This method is called by extrahiere_info if a requirements.txt file is found and if dependencies haven't been parsed from pyproject.toml."
              }
            },
            "error": null
          },
          {
            "identifier": "extrahiere_info",
            "description": {
              "overall": "This is the main public method of the class, responsible for orchestrating the extraction of project information. It takes a list of file objects and a repository URL as input. It first uses `_finde_datei` to locate README, pyproject.toml, and requirements.txt files. It then parses these files in a specific order (pyproject.toml, then requirements.txt, then README) to populate the internal `self.info` structure, prioritizing information from TOML. Finally, it formats the dependencies and attempts to derive the project title from the repository URL if no title was found, returning the complete `self.info` dictionary.",
              "parameters": [
                {
                  "name": "dateien",
                  "type": "List[Any]",
                  "description": "A list of file objects, each expected to have 'path' and 'content' attributes."
                },
                {
                  "name": "repo_url",
                  "type": "str",
                  "description": "The URL of the repository, used to derive the project title if necessary."
                }
              ],
              "returns": [
                {
                  "name": "info",
                  "type": "Dict[str, Any]",
                  "description": "A dictionary containing the extracted project information, including overview and installation details."
                }
              ],
              "usage_context": {
                "calls": "This method calls _finde_datei multiple times to locate specific project files. It then calls _parse_toml, _parse_requirements, and _parse_readme to process the content of these files. It also uses os.path.basename for URL processing and string manipulation for formatting.",
                "called_by": "This is the primary method used to initiate the information extraction process for a project."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "This class utilizes the 're' module for regular expression operations, 'os' for path manipulation (specifically for extracting the repository name from a URL), and 'tomllib' for parsing TOML files. It also relies on type hinting from the 'typing' module.",
          "instantiated_by": "This class is intended to be instantiated directly by other parts of the application that need to extract project information from a collection of files."
        }
      },
      "error": null
    },
    "backend.callgraph.CallGraph": {
      "identifier": "backend.callgraph.CallGraph",
      "description": {
        "overall": "The CallGraph class is designed to parse Python source code using the `ast` module and build a directed graph representing function and method calls. It traverses the Abstract Syntax Tree (AST) of a given file, identifying imports, class definitions, function definitions, and actual function calls. The class maintains internal state to track the current file, class, and function context, as well as mappings for imports and local definitions, to accurately resolve callee names and construct the call graph. The resulting graph, stored in `self.graph`, and call edges, stored in `self.edges`, can be used for static analysis of code dependencies and execution flow.",
        "init_method": {
          "description": "Initializes the CallGraph object with the filename of the source code to be analyzed. It sets up internal state variables including the filename, current function and class context, dictionaries for local definitions and import mappings, a set for all identified functions, and a directed graph to store the call relationships. It also initializes an empty dictionary to store the edges of the call graph.",
          "parameters": [
            {
              "name": "filename",
              "type": "str",
              "description": "The path to the Python file that will be analyzed to build the call graph."
            }
          ]
        },
        "methods": [
          {
            "identifier": "_recursive_call",
            "description": {
              "overall": "This private helper method recursively traverses an AST node, typically representing a function call, to extract the name components of the callee. It handles different AST node types like `ast.Call`, `ast.Name`, and `ast.Attribute` to reconstruct the fully qualified name as a list of strings. For instance, a call like `pkg.mod.Class.method()` would be resolved into `['pkg', 'mod', 'Class', 'method']`. If the node type is not recognized or does not represent a callable name, it returns an empty list.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.AST",
                  "description": "The AST node to analyze, typically representing the function or method being called."
                }
              ],
              "returns": [
                {
                  "name": "parts",
                  "type": "list[str]",
                  "description": "A list of strings representing the hierarchical name components of the callee."
                }
              ],
              "usage_context": {
                "calls": "This method calls itself recursively to handle nested attributes and calls.",
                "called_by": "This method is called by `_resolve_all_callee_names` to break down the callee's name structure."
              }
            },
            "error": null
          },
          {
            "identifier": "_resolve_all_callee_names",
            "description": {
              "overall": "This private method takes a list of callee name components (obtained from `_recursive_call`) and resolves them into fully qualified names within the context of the current analysis. It prioritizes checking against `self.local_defs` for direct mappings and then consults `self.import_mapping` to resolve imported modules. If neither is found, it constructs a name based on the current class and filename context. This ensures that calls are accurately represented, whether they are local, imported, or within the current scope.",
              "parameters": [
                {
                  "name": "callee_nodes",
                  "type": "list[list[str]]",
                  "description": "A list where each element is a list of string parts representing a potential callee's name."
                }
              ],
              "returns": [
                {
                  "name": "resolved",
                  "type": "list[str]",
                  "description": "A list of fully resolved callee names as strings."
                }
              ],
              "usage_context": {
                "calls": "This method calls `_recursive_call` indirectly through the `callee_nodes` input and uses `self.local_defs` and `self.import_mapping` for lookups.",
                "called_by": "This method is called by `visit_Call` to determine the actual name of the function or method being called."
              }
            },
            "error": null
          },
          {
            "identifier": "_make_full_name",
            "description": {
              "overall": "A utility method to construct a fully qualified name for a function or method within the context of the analyzed file. It prepends the filename and optionally includes a class name if provided, ensuring a unique identifier for each callable entity across different files. This is crucial for building an accurate and unambiguous call graph.",
              "parameters": [
                {
                  "name": "basename",
                  "type": "str",
                  "description": "The base name of the function or method."
                },
                {
                  "name": "class_name",
                  "type": "str | None",
                  "description": "The name of the class if the callable is a method; otherwise, None."
                }
              ],
              "returns": [
                {
                  "name": "full_name",
                  "type": "str",
                  "description": "The fully qualified name of the callable, formatted as 'filename::[class_name::]basename'."
                }
              ],
              "usage_context": {
                "calls": "This method constructs strings using f-strings.",
                "called_by": "This method is called by `visit_FunctionDef` to generate the full name for a function or method."
              }
            },
            "error": null
          },
          {
            "identifier": "_current_caller",
            "description": {
              "overall": "Determines and returns the identifier of the current code block that is making a call. If `self.current_function` is set, it returns that value. Otherwise, it returns a representation of the global scope within the current file, or '<global-scope>' if the filename is not available. This helps in correctly attributing calls to their originating context.",
              "parameters": [
                {
                  "name": "self",
                  "type": "CallGraph",
                  "description": "The instance of the CallGraph class."
                }
              ],
              "returns": [
                {
                  "name": "caller",
                  "type": "str",
                  "description": "The identifier of the current caller, which can be a function name, a class scope, or a global scope indicator."
                }
              ],
              "usage_context": {
                "calls": "This method accesses instance attributes `self.current_function` and `self.filename`.",
                "called_by": "This method is called by `visit_Call` to identify the source of a function call."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_Import",
            "description": {
              "overall": "This method is part of the AST visitor pattern and is invoked when an `import` statement is encountered. It iterates through the imported modules and their aliases, populating the `self.import_mapping` dictionary. This mapping stores the alias (or the module name if no alias is used) as the key and the original module name as the value, which is used later to resolve imported names.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.Import",
                  "description": "The AST node representing an import statement."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls `self.generic_visit(node)` to continue traversal down the AST.",
                "called_by": "This method is automatically called by the `ast.NodeVisitor` when it encounters an `import` statement."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_ImportFrom",
            "description": {
              "overall": "This method handles `from ... import ...` statements in the AST. It extracts the module name and the imported names (and their aliases). It then populates the `self.import_mapping` dictionary, mapping the alias or imported name to the base module name. This allows the call graph to correctly track calls to functions or classes imported from specific modules.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.ImportFrom",
                  "description": "The AST node representing a 'from ... import ...' statement."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method accesses `node.module`, `node.names`, and uses string manipulation.",
                "called_by": "This method is automatically called by the `ast.NodeVisitor` when it encounters a `from ... import ...` statement."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_ClassDef",
            "description": {
              "overall": "This method is called when the AST visitor encounters a class definition. It updates `self.current_class` to the name of the class being visited, allowing subsequent method definitions within this class to be correctly associated. After visiting the class body (including nested functions and methods), it restores `self.current_class` to its previous value, ensuring correct context management.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.ClassDef",
                  "description": "The AST node representing a class definition."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls `self.generic_visit(node)` to process the contents of the class definition and updates instance attributes `self.current_class`.",
                "called_by": "This method is automatically called by the `ast.NodeVisitor` when it encounters a class definition."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_FunctionDef",
            "description": {
              "overall": "This method processes standard function definitions (`def`). It constructs the full name of the function using `_make_full_name`, stores this mapping in `self.local_defs` for both the function name and potentially a class-qualified name, and sets `self.current_function` to this full name. It then adds the function as a node to the call graph, visits the function's body to analyze its contents, adds the function to `self.function_set`, and finally restores the `self.current_function` context.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.FunctionDef",
                  "description": "The AST node representing a function definition."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls `self._make_full_name`, `self._current_caller`, `self.generic_visit`, and `self.graph.add_node`.",
                "called_by": "This method is automatically called by the `ast.NodeVisitor` when it encounters a function definition."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_AsyncFunctionDef",
            "description": {
              "overall": "This method handles asynchronous function definitions (`async def`). It simply delegates the processing to `visit_FunctionDef`, as the logic for analyzing function definitions, including name resolution and graph node creation, is identical for both synchronous and asynchronous functions in this context.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.AsyncFunctionDef",
                  "description": "The AST node representing an asynchronous function definition."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls `self.visit_FunctionDef`.",
                "called_by": "This method is automatically called by the `ast.NodeVisitor` when it encounters an `async def` statement."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_Call",
            "description": {
              "overall": "This method is invoked when an AST visitor encounters a function call. It first determines the current caller context using `_current_caller`. Then, it uses `_recursive_call` to extract the callee's name parts and `_resolve_all_callee_names` to get the fully resolved callee name(s). Finally, it records the call as an edge in the `self.edges` dictionary, mapping the caller to the callee, and continues the AST traversal.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.Call",
                  "description": "The AST node representing a function or method call."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls `self._current_caller`, `self._recursive_call`, and `self._resolve_all_callee_names`, and `self.generic_visit`.",
                "called_by": "This method is automatically called by the `ast.NodeVisitor` when it encounters a function call."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_If",
            "description": {
              "overall": "This method handles `if` statements in the AST. It includes specific logic to detect the common `if __name__ == '__main__':` block. When this block is identified, it temporarily sets the `self.current_function` to '<main_block>' to correctly attribute any calls within this block to the main execution context. After visiting the nodes within the `if` statement, it restores the original `self.current_function` context. For other `if` statements, it simply continues the generic traversal.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.If",
                  "description": "The AST node representing an if statement."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls `self.generic_visit(node)` and modifies `self.current_function`.",
                "called_by": "This method is automatically called by the `ast.NodeVisitor` when it encounters an `if` statement."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "This class relies on the `ast` module for parsing Python code into an Abstract Syntax Tree and the `networkx` library for representing the call graph as a directed graph. It also uses typing hints like `Dict` and `str | None`.",
          "instantiated_by": "The context does not provide specific information about where this class is instantiated. However, it is designed to be instantiated with a filename to begin the call graph analysis process."
        }
      },
      "error": null
    },
    "backend.getRepo.RepoFile": {
      "identifier": "backend.getRepo.RepoFile",
      "description": {
        "overall": "The RepoFile class represents a single file within a Git repository. It is designed to load file content and metadata lazily, meaning that information like the file's content or size is only fetched when explicitly requested. This class provides properties to access the file's blob object, its decoded content, and its size, along with methods for basic analysis like word counting and converting the file's information into a dictionary.",
        "init_method": {
          "description": "Initializes a RepoFile object with the file's path and the commit tree it belongs to. It sets up internal attributes for the path and the commit tree, and initializes placeholders for the blob, content, and size to None, enabling lazy loading.",
          "parameters": [
            {
              "name": "file_path",
              "type": "str",
              "description": "The path to the file within the repository."
            },
            {
              "name": "commit_tree",
              "type": "git.Tree",
              "description": "The Tree object of the commit from which the file originates."
            }
          ]
        },
        "methods": [
          {
            "identifier": "blob",
            "description": {
              "overall": "This property provides lazy access to the Git blob object associated with the file. If the blob has not been loaded yet, it attempts to retrieve it from the commit tree using the file's path. If the file is not found in the tree, it raises a FileNotFoundError. Once loaded, the blob object is cached for subsequent access.",
              "parameters": [],
              "returns": [
                {
                  "name": "self._blob",
                  "type": "git.Blob",
                  "description": "The Git blob object representing the file."
                }
              ],
              "usage_context": {
                "calls": "This method calls `self._tree[self.path]` to retrieve the blob and potentially raises `FileNotFoundError`.",
                "called_by": "This method is called by other methods within the RepoFile class that require access to the file's blob object, such as `content` and `size`."
              }
            },
            "error": null
          },
          {
            "identifier": "content",
            "description": {
              "overall": "This property provides lazy access to the decoded content of the file. It first attempts to retrieve the file's blob object using the `blob` property. If the content has not been loaded, it reads the data from the blob's data stream, decodes it as UTF-8 (ignoring errors), and caches the result. This ensures the file content is only read and decoded when it's actually needed.",
              "parameters": [],
              "returns": [
                {
                  "name": "self._content",
                  "type": "str",
                  "description": "The decoded content of the file as a string."
                }
              ],
              "usage_context": {
                "calls": "This method calls `self.blob` to get the file's blob object and then accesses its `data_stream.read()` and decodes the result.",
                "called_by": "This method is called by other methods or external code that needs to access the file's content, such as `analyze_word_count` and `to_dict`."
              }
            },
            "error": null
          },
          {
            "identifier": "size",
            "description": {
              "overall": "This property provides lazy access to the size of the file in bytes. It first retrieves the file's blob object using the `blob` property. If the size has not been determined, it fetches the size directly from the blob object and caches it. This ensures the file size is only queried when necessary.",
              "parameters": [],
              "returns": [
                {
                  "name": "self._size",
                  "type": "int",
                  "description": "The size of the file in bytes."
                }
              ],
              "usage_context": {
                "calls": "This method calls `self.blob` to get the file's blob object and then accesses its `size` attribute.",
                "called_by": "This method is called by other methods or external code that needs to know the file's size, such as `to_dict`."
              }
            },
            "error": null
          },
          {
            "identifier": "analyze_word_count",
            "description": {
              "overall": "This method performs a simple analysis on the file's content by counting the number of words. It retrieves the file's content using the `content` property and then splits the content into words based on whitespace, returning the total count. This serves as an example of a method that processes the file's content.",
              "parameters": [],
              "returns": [
                {
                  "name": "word_count",
                  "type": "int",
                  "description": "The number of words found in the file's content."
                }
              ],
              "usage_context": {
                "calls": "This method calls `self.content` to get the file's content and then uses the string `split()` method.",
                "called_by": "This method is called by external code that needs to perform a word count analysis on the file."
              }
            },
            "error": null
          },
          {
            "identifier": "__repr__",
            "description": {
              "overall": "This method provides a developer-friendly string representation of the RepoFile object. It returns a formatted string that includes the file's path, making it easy to identify the specific file when inspecting the object, for example, during debugging.",
              "parameters": [],
              "returns": [
                {
                  "name": "representation",
                  "type": "str",
                  "description": "A string representation of the RepoFile object, including its path."
                }
              ],
              "usage_context": {
                "calls": "This method uses an f-string to format the output, including `self.path`.",
                "called_by": "This method is called implicitly when a RepoFile object is printed or inspected in an interactive session."
              }
            },
            "error": null
          },
          {
            "identifier": "to_dict",
            "description": {
              "overall": "This method converts the file's metadata into a dictionary format. It includes the file's path, its base name, its size, and its type ('file'). Optionally, if the `include_content` flag is set to True, it also includes the file's content in the dictionary. This is useful for serializing file information.",
              "parameters": [
                {
                  "name": "include_content",
                  "type": "bool",
                  "description": "A flag to indicate whether to include the file's content in the returned dictionary. Defaults to False."
                }
              ],
              "returns": [
                {
                  "name": "data",
                  "type": "dict",
                  "description": "A dictionary containing the file's metadata, and optionally its content."
                }
              ],
              "usage_context": {
                "calls": "This method calls `os.path.basename(self.path)`, `self.size`, and conditionally `self.content`.",
                "called_by": "This method is called by external code that requires file information in a dictionary format, potentially for serialization or display."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "The class utilizes the 'os' module for path manipulation.",
          "instantiated_by": "This class is instantiated by code that needs to represent individual files within a Git repository, likely within a larger Git repository management system."
        }
      },
      "error": null
    },
    "backend.getRepo.GitRepository": {
      "identifier": "backend.getRepo.GitRepository",
      "description": {
        "overall": "The GitRepository class manages a Git repository, handling its cloning into a temporary directory and providing access to its files. It abstracts the complexities of Git operations, allowing users to interact with repository files and structure through a more Pythonic interface. The class supports context management for automatic cleanup of temporary resources.",
        "init_method": {
          "description": "Initializes the GitRepository by cloning the specified repository URL into a temporary directory. It attempts to clone the repository and captures the latest commit and its tree. If cloning fails, it cleans up any partially created temporary directory and raises a RuntimeError.",
          "parameters": [
            {
              "name": "repo_url",
              "type": "string",
              "description": "The URL of the Git repository to clone."
            }
          ]
        },
        "methods": [
          {
            "identifier": "get_all_files",
            "description": {
              "overall": "Retrieves all files within the Git repository. It uses the Git command `ls-files` to get a list of file paths, then instantiates `RepoFile` objects for each file. These `RepoFile` objects are stored as an instance attribute and returned.",
              "parameters": [
                {
                  "name": "self",
                  "type": "GitRepository",
                  "description": "The instance of the GitRepository class."
                }
              ],
              "returns": [
                {
                  "name": "files",
                  "type": "list[RepoFile]",
                  "description": "A list of RepoFile objects representing all files in the repository."
                }
              ],
              "usage_context": {
                "calls": "This method calls the `RepoFile` constructor to create file objects.",
                "called_by": "This method is called by other methods within the GitRepository class, such as `get_file_tree`, to populate the list of files."
              }
            },
            "error": null
          },
          {
            "identifier": "close",
            "description": {
              "overall": "Cleans up the GitRepository by deleting the temporary directory that was created during initialization. It ensures that the temporary directory is removed to free up disk space.",
              "parameters": [
                {
                  "name": "self",
                  "type": "GitRepository",
                  "description": "The instance of the GitRepository class."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method does not call any other methods or functions.",
                "called_by": "This method is called internally by the `__init__` method in case of an error during cloning, and by the `__exit__` method to ensure cleanup when the context manager exits."
              }
            },
            "error": null
          },
          {
            "identifier": "__enter__",
            "description": {
              "overall": "Implements the entry point for the context manager protocol. It returns the GitRepository instance itself, allowing it to be used within a `with` statement.",
              "parameters": [
                {
                  "name": "self",
                  "type": "GitRepository",
                  "description": "The instance of the GitRepository class."
                }
              ],
              "returns": [
                {
                  "name": "self",
                  "type": "GitRepository",
                  "description": "The current GitRepository instance."
                }
              ],
              "usage_context": {
                "calls": "This method does not call any other methods or functions.",
                "called_by": "This method is called automatically when entering a `with` block that uses a GitRepository instance."
              }
            },
            "error": null
          },
          {
            "identifier": "__exit__",
            "description": {
              "overall": "Implements the exit point for the context manager protocol. It ensures that the `close` method is called to clean up the temporary directory and its contents when exiting the `with` block, regardless of whether an exception occurred.",
              "parameters": [
                {
                  "name": "self",
                  "type": "GitRepository",
                  "description": "The instance of the GitRepository class."
                },
                {
                  "name": "exc_type",
                  "type": "type",
                  "description": "The type of the exception raised, if any."
                },
                {
                  "name": "exc_val",
                  "type": "Exception",
                  "description": "The exception instance raised, if any."
                },
                {
                  "name": "exc_tb",
                  "type": "traceback",
                  "description": "The traceback object associated with the exception, if any."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls the `close` method of the GitRepository instance.",
                "called_by": "This method is called automatically when exiting a `with` block that uses a GitRepository instance."
              }
            },
            "error": null
          },
          {
            "identifier": "get_file_tree",
            "description": {
              "overall": "Constructs and returns a hierarchical tree structure representing the files and directories within the repository. If no files have been loaded yet, it first calls `get_all_files`. It then iterates through the file paths, building the directory structure and adding file information to the appropriate nodes. The `include_content` parameter can optionally include file content in the output.",
              "parameters": [
                {
                  "name": "self",
                  "type": "GitRepository",
                  "description": "The instance of the GitRepository class."
                },
                {
                  "name": "include_content",
                  "type": "bool",
                  "description": "A boolean flag to indicate whether to include the content of each file in the output tree."
                }
              ],
              "returns": [
                {
                  "name": "tree",
                  "type": "dict",
                  "description": "A dictionary representing the file tree structure of the repository."
                }
              ],
              "usage_context": {
                "calls": "This method calls `get_all_files` if no files are loaded and `file_obj.to_dict` for each file.",
                "called_by": "This method is called to retrieve a structured representation of the repository's file system."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "This class depends on `tempfile` for temporary directory creation, `git.Repo` and `git.GitCommandError` for Git operations, `logging` for outputting information, and `backend.getRepo.RepoFile` for representing individual files within the repository.",
          "instantiated_by": "This class is intended to be instantiated directly by the user, likely within a `with` statement to leverage its context management capabilities for automatic cleanup."
        }
      },
      "error": null
    },
    "backend.relationship_analyzer.ProjectAnalyzer": {
      "identifier": "backend.relationship_analyzer.ProjectAnalyzer",
      "description": {
        "overall": "The ProjectAnalyzer class is designed to analyze a Python project's codebase to build a call graph and identify relationships between different code elements. It traverses the project directory, parses Python files to collect definitions of functions, classes, and methods, and then resolves function calls to construct a call graph. Finally, it can provide raw relationship data in terms of outgoing and incoming calls.",
        "init_method": {
          "description": "Initializes the ProjectAnalyzer with the root directory of the project. It sets up instance variables to store project root, definitions, call graph, file Abstract Syntax Trees (ASTs), and a set of directories to ignore during file traversal.",
          "parameters": [
            {
              "name": "project_root",
              "type": "string",
              "description": "The absolute path to the root directory of the Python project to be analyzed."
            }
          ]
        },
        "methods": [
          {
            "identifier": "analyze",
            "description": {
              "overall": "This method orchestrates the entire analysis process. It first finds all Python files within the project, then iterates through them to collect definitions (functions, classes, methods) and subsequently resolves the calls between these definitions. After building the call graph, it clears the stored file ASTs to free up memory and returns the constructed call graph.",
              "parameters": [
                {
                  "name": "self",
                  "type": "ProjectAnalyzer",
                  "description": "The instance of the ProjectAnalyzer."
                }
              ],
              "returns": [
                {
                  "name": "call_graph",
                  "type": "defaultdict(list)",
                  "description": "A dictionary representing the call graph, where keys are callee identifiers and values are lists of caller information."
                }
              ],
              "usage_context": {
                "calls": "This method calls _find_py_files to get a list of Python files, then iterates through these files calling _collect_definitions and _resolve_calls.",
                "called_by": "This method is called to start the analysis process of a project."
              }
            },
            "error": null
          },
          {
            "identifier": "get_raw_relationships",
            "description": {
              "overall": "This method processes the internal call graph to generate structured data representing outgoing and incoming relationships between code elements. It iterates through the call graph, categorizing calls to build sets of callers for each callee (incoming) and callees for each caller (outgoing). The results are returned as dictionaries, with the sets converted to sorted lists for consistent output.",
              "parameters": [
                {
                  "name": "self",
                  "type": "ProjectAnalyzer",
                  "description": "The instance of the ProjectAnalyzer."
                }
              ],
              "returns": [
                {
                  "name": "relationships",
                  "type": "dict",
                  "description": "A dictionary containing two keys: 'outgoing' and 'incoming'. Each key maps to a dictionary where keys are code element identifiers and values are sorted lists of related code element identifiers."
                }
              ],
              "usage_context": {
                "calls": "This method iterates through self.call_graph and uses defaultdict(set) to build outgoing and incoming relationship dictionaries.",
                "called_by": "This method is called to retrieve processed relationship data from the analyzed call graph."
              }
            },
            "error": null
          },
          {
            "identifier": "_find_py_files",
            "description": {
              "overall": "This private method recursively walks the project directory starting from `self.project_root` to find all Python files. It utilizes `os.walk` and filters out files in ignored directories (like '.git', 'venv', '__pycache__') and files that do not end with '.py'. It returns a list of absolute file paths for all discovered Python files.",
              "parameters": [
                {
                  "name": "self",
                  "type": "ProjectAnalyzer",
                  "description": "The instance of the ProjectAnalyzer."
                }
              ],
              "returns": [
                {
                  "name": "py_files",
                  "type": "list[str]",
                  "description": "A list of strings, where each string is the absolute path to a Python file found in the project."
                }
              ],
              "usage_context": {
                "calls": "This method uses os.walk to traverse directories and os.path.join to construct file paths.",
                "called_by": "This method is called by the analyze method to locate all Python source files within the project."
              }
            },
            "error": null
          },
          {
            "identifier": "_collect_definitions",
            "description": {
              "overall": "This private method parses a given Python file to collect definitions of functions, classes, and methods. It reads the source code, parses it into an Abstract Syntax Tree (AST) using the `ast` module, and stores the AST for later use. It then walks the AST to identify `ast.FunctionDef` and `ast.ClassDef` nodes, determining their type (function, method, or class) and constructing a unique path name. This information, along with the file path and line number, is stored in the `self.definitions` dictionary. It includes error handling for file reading and parsing, logging any issues and marking the file's AST as None.",
              "parameters": [
                {
                  "name": "self",
                  "type": "ProjectAnalyzer",
                  "description": "The instance of the ProjectAnalyzer."
                },
                {
                  "name": "filepath",
                  "type": "str",
                  "description": "The absolute path to the Python file to be parsed."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls ast.parse to parse source code into an AST, ast.walk to traverse the AST, and path_to_module to convert a file path to a module path.",
                "called_by": "This method is called by the analyze method for each Python file found in the project to gather information about defined code elements."
              }
            },
            "error": null
          },
          {
            "identifier": "_get_parent",
            "description": {
              "overall": "This private helper method traverses the AST of a given tree to find the parent node of a specified child node. It iterates through all nodes in the tree and checks their direct children. If a child matches the target node, the current parent node is returned. If the node is not found within the tree or is the root node itself, it returns None.",
              "parameters": [
                {
                  "name": "self",
                  "type": "ProjectAnalyzer",
                  "description": "The instance of the ProjectAnalyzer."
                },
                {
                  "name": "tree",
                  "type": "ast.AST",
                  "description": "The Abstract Syntax Tree (AST) to search within."
                },
                {
                  "name": "node",
                  "type": "ast.AST",
                  "description": "The specific AST node whose parent is to be found."
                }
              ],
              "returns": [
                {
                  "name": "parent",
                  "type": "ast.AST | None",
                  "description": "The parent AST node of the given node, or None if the node is not found or is the root."
                }
              ],
              "usage_context": {
                "calls": "This method uses ast.walk to traverse the AST and ast.iter_child_nodes to iterate through children of a node.",
                "called_by": "This method is called by _collect_definitions to determine if a function definition is inside a class (i.e., a method)."
              }
            },
            "error": null
          },
          {
            "identifier": "_resolve_calls",
            "description": {
              "overall": "This private method resolves function and method calls within a given Python file's AST. It retrieves the AST for the specified file from `self.file_asts`. If the AST exists, it instantiates a `CallResolverVisitor` (a dependency) with the file path, project root, and collected definitions. It then visits the AST using this visitor, which populates its `calls` attribute with information about callees and their callers. The collected call information is then merged into the `self.call_graph`. Error handling is included to log any exceptions during the resolution process.",
              "parameters": [
                {
                  "name": "self",
                  "type": "ProjectAnalyzer",
                  "description": "The instance of the ProjectAnalyzer."
                },
                {
                  "name": "filepath",
                  "type": "str",
                  "description": "The absolute path to the Python file whose calls need to be resolved."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method instantiates and uses CallResolverVisitor to visit the AST and collect call information.",
                "called_by": "This method is called by the analyze method for each Python file after definitions have been collected, to map out the call relationships."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "This class depends on the `ast` module for parsing Python code, the `os` module for file system operations, the `logging` module for error reporting, the `collections.defaultdict` for data structures, and external components `backend.relationship_analyzer.CallResolverVisitor` and `backend.relationship_analyzer.path_to_module` for specialized analysis tasks.",
          "instantiated_by": "The `ProjectAnalyzer` class is not instantiated by any other known components within the provided context."
        }
      },
      "error": null
    },
    "backend.relationship_analyzer.CallResolverVisitor": {
      "identifier": "backend.relationship_analyzer.CallResolverVisitor",
      "description": {
        "overall": "The CallResolverVisitor is an Abstract Syntax Tree (AST) visitor designed to traverse Python code and identify function and method calls. It maintains scope information, tracks class definitions, and resolves the fully qualified names of called functions and methods. This visitor is crucial for building a call graph or analyzing code dependencies within a project.",
        "init_method": {
          "description": "Initializes the CallResolverVisitor with essential context for analyzing a Python file. It sets up attributes to store file path, module path, project definitions, scope, instance types, and the current call context.",
          "parameters": [
            {
              "name": "filepath",
              "type": "string",
              "description": "The absolute path to the Python file being analyzed."
            },
            {
              "name": "project_root",
              "type": "string",
              "description": "The root directory of the project, used to determine the module path."
            },
            {
              "name": "definitions",
              "type": "dict",
              "description": "A dictionary containing known definitions within the project, used to resolve call targets."
            }
          ]
        },
        "methods": [
          {
            "identifier": "visit_ClassDef",
            "description": {
              "overall": "Visits a class definition node in the AST. It updates the current class name context before recursively visiting the nodes within the class definition and then restores the previous class name context upon exiting.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.ClassDef",
                  "description": "The AST node representing a class definition."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls the generic_visit method to continue traversal down the AST.",
                "called_by": "This method is called automatically by the ast.NodeVisitor when it encounters a ClassDef node during traversal."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_FunctionDef",
            "description": {
              "overall": "Visits a function definition node in the AST. It constructs the fully qualified name for the function based on whether it's defined within a class or at the module level, updates the current caller name context, and then recursively visits the nodes within the function definition before restoring the previous caller name context.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.FunctionDef",
                  "description": "The AST node representing a function definition."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls the generic_visit method to continue traversal down the AST.",
                "called_by": "This method is called automatically by the ast.NodeVisitor when it encounters a FunctionDef node during traversal."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_Call",
            "description": {
              "overall": "Visits a call expression node in the AST. It resolves the fully qualified name of the called function or method. If the resolved name exists in the project's definitions, it records the call information, including the caller's details and line number, in the `calls` dictionary. It then continues the traversal.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.Call",
                  "description": "The AST node representing a function or method call."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls the _resolve_call_qname method to determine the target of the call and the generic_visit method to continue traversal down the AST.",
                "called_by": "This method is called automatically by the ast.NodeVisitor when it encounters a Call node during traversal."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_Import",
            "description": {
              "overall": "Visits an import statement node in the AST. It processes each imported name, adding it to the current scope with its corresponding module name. This helps in resolving unqualified names later.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.Import",
                  "description": "The AST node representing an import statement."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls the generic_visit method to continue traversal down the AST.",
                "called_by": "This method is called automatically by the ast.NodeVisitor when it encounters an Import node during traversal."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_ImportFrom",
            "description": {
              "overall": "Visits an import-from statement node in the AST. It resolves the full module path for imported names, considering relative imports, and updates the scope dictionary. This allows for the resolution of names imported from specific modules.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.ImportFrom",
                  "description": "The AST node representing an import-from statement."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls the generic_visit method to continue traversal down the AST.",
                "called_by": "This method is called automatically by the ast.NodeVisitor when it encounters an ImportFrom node during traversal."
              }
            },
            "error": null
          },
          {
            "identifier": "visit_Assign",
            "description": {
              "overall": "Visits an assignment statement node in the AST. If the assignment involves a call to a class constructor, it attempts to determine the qualified name of the instantiated class and records this information in the `instance_types` dictionary, mapping the variable name to its class type.",
              "parameters": [
                {
                  "name": "node",
                  "type": "ast.Assign",
                  "description": "The AST node representing an assignment statement."
                }
              ],
              "returns": [],
              "usage_context": {
                "calls": "This method calls the generic_visit method to continue traversal down the AST.",
                "called_by": "This method is called automatically by the ast.NodeVisitor when it encounters an Assign node during traversal."
              }
            },
            "error": null
          },
          {
            "identifier": "_resolve_call_qname",
            "description": {
              "overall": "A helper method to resolve the fully qualified name (QName) of a function or method call from its AST node. It handles direct name lookups in the scope and attribute access (e.g., `obj.method` or `module.function`), utilizing the `scope` and `instance_types` dictionaries to determine the correct path.",
              "parameters": [
                {
                  "name": "func_node",
                  "type": "ast.expr",
                  "description": "The AST node representing the function or method being called (e.g., ast.Name or ast.Attribute)."
                }
              ],
              "returns": [
                {
                  "name": "callee_pathname",
                  "type": "string | None",
                  "description": "The fully qualified name of the called function or method, or None if it cannot be resolved."
                }
              ],
              "usage_context": {
                "calls": "This method checks for the presence of names in `self.scope` and `self.instance_types` and constructs qualified names.",
                "called_by": "This method is called by `visit_Call` to determine the target of a function or method call."
              }
            },
            "error": null
          }
        ],
        "usage_context": {
          "dependencies": "This class depends on the `path_to_module` function from the `backend.relationship_analyzer` module and uses standard Python libraries like `ast` and `os`.",
          "instantiated_by": "This class is intended to be instantiated and used within a larger code analysis or documentation generation system, likely as part of a process that traverses ASTs to build call graphs or dependency information. However, no specific instantiation points are provided in the context."
        }
      },
      "error": null
    },
    "schemas.types.ParameterDescription": {
      "identifier": "schemas.types.ParameterDescription",
      "description": {
        "overall": "This class is a Pydantic model used to describe a single parameter of a function. It defines the structure for holding the parameter's name, its type, and a textual description.",
        "init_method": {
          "description": "Initializes the ParameterDescription object with the name, type, and description of a function parameter. These are defined as class attributes.",
          "parameters": [
            {
              "name": "name",
              "type": "str",
              "description": "The name of the parameter."
            },
            {
              "name": "type",
              "type": "str",
              "description": "The type of the parameter."
            },
            {
              "name": "description",
              "type": "str",
              "description": "A textual description of the parameter."
            }
          ]
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class has no external dependencies beyond Pydantic's BaseModel.",
          "instantiated_by": "This class is intended to be instantiated within data structures that describe functions or methods, likely as part of a larger documentation generation system."
        }
      },
      "error": null
    },
    "schemas.types.ReturnDescription": {
      "identifier": "schemas.types.ReturnDescription",
      "description": {
        "overall": "The ReturnDescription class is a Pydantic model used to define the structure for describing the return value of a function. It captures the name, type, and a textual description of the return value.",
        "init_method": {
          "description": "Initializes the ReturnDescription model with the name, type, and description of a function's return value. All fields are required.",
          "parameters": [
            {
              "name": "name",
              "type": "str",
              "description": "The name of the return value."
            },
            {
              "name": "type",
              "type": "str",
              "description": "The data type of the return value."
            },
            {
              "name": "description",
              "type": "str",
              "description": "A textual explanation of the return value."
            }
          ]
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class does not have any external dependencies beyond Pydantic's BaseModel.",
          "instantiated_by": "This class is likely instantiated within systems that need to define and document function return values, such as API documentation generators or code analysis tools."
        }
      },
      "error": null
    },
    "schemas.types.UsageContext": {
      "identifier": "schemas.types.UsageContext",
      "description": {
        "overall": "The UsageContext class is a Pydantic model designed to describe the calling context of a function. It specifically captures information about what functions or methods a given function calls and which functions or methods call it. This is useful for understanding code dependencies and execution flow.",
        "init_method": {
          "description": "Initializes the UsageContext model with information about the functions called by and calling the current function. It inherits from Pydantic's BaseModel for data validation.",
          "parameters": []
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class depends on Pydantic's BaseModel for its structure and validation.",
          "instantiated_by": "This class is intended to be instantiated within schemas or data structures that require detailed information about function call relationships."
        }
      },
      "error": null
    },
    "schemas.types.FunctionDescription": {
      "identifier": "schemas.types.FunctionDescription",
      "description": {
        "overall": "The FunctionDescription class is a Pydantic model designed to encapsulate a comprehensive analysis of a function. It holds details about the function's overall purpose, its parameters, its return values, and its usage context within a larger system. This class serves as a structured data container for function-related metadata.",
        "init_method": {
          "description": "Initializes a FunctionDescription object. As this is a Pydantic model, initialization is handled by Pydantic's data validation and assignment mechanism based on the defined fields.",
          "parameters": []
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class depends on Pydantic's BaseModel for its structure and validation. It also utilizes List from the typing module to define its fields.",
          "instantiated_by": "This class is likely instantiated by systems that perform code analysis or documentation generation, where a structured representation of function details is required."
        }
      },
      "error": null
    },
    "schemas.types.FunctionAnalysis": {
      "identifier": "schemas.types.FunctionAnalysis",
      "description": {
        "overall": "The FunctionAnalysis class is a Pydantic model designed to represent the structured analysis of a single function or method. It encapsulates the function's identifier, a detailed description object, and an optional error field for reporting analysis issues. This model is crucial for maintaining a consistent and machine-readable format for function-level insights within a larger documentation generation system.",
        "init_method": {
          "description": "Initializes a FunctionAnalysis object. It takes the function's identifier, a FunctionDescription object, and an optional error string as arguments. The identifier is a string representing the function's name, and the FunctionDescription contains the detailed analysis of the function's purpose, parameters, return values, and usage context. The error field is used to report any issues encountered during the analysis of the function.",
          "parameters": [
            {
              "name": "identifier",
              "type": "str",
              "description": "The unique name or identifier of the function being analyzed."
            },
            {
              "name": "description",
              "type": "FunctionDescription",
              "description": "A FunctionDescription object containing the detailed analysis of the function's purpose, parameters, return values, and usage context."
            },
            {
              "name": "error",
              "type": "Optional[str]",
              "description": "An optional string that holds an error message if the analysis of the function failed. Defaults to None if the analysis was successful."
            }
          ]
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class has no external dependencies beyond Pydantic's BaseModel.",
          "instantiated_by": "This class is likely instantiated by a system that analyzes Python code and needs to represent the analysis of individual functions or methods in a structured format."
        }
      },
      "error": null
    },
    "schemas.types.ConstructorDescription": {
      "identifier": "schemas.types.ConstructorDescription",
      "description": {
        "overall": "The ConstructorDescription class is a Pydantic model used to represent the initialization method of a Python class. It captures a textual description of the constructor and a list of its parameters, where each parameter is further detailed by a ParameterDescription object. This structure is useful for documenting or analyzing class constructors.",
        "init_method": {
          "description": "Initializes a ConstructorDescription object. It takes a string description of the constructor and a list of ParameterDescription objects, representing the parameters of the constructor.",
          "parameters": [
            {
              "name": "description",
              "type": "str",
              "description": "A textual summary of the constructor's purpose and behavior."
            },
            {
              "name": "parameters",
              "type": "List[ParameterDescription]",
              "description": "A list containing detailed descriptions of each parameter accepted by the constructor."
            }
          ]
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class depends on Pydantic's BaseModel for data validation and structure. It also utilizes typing.List for type hinting.",
          "instantiated_by": "This class is likely instantiated by systems or tools that analyze Python class definitions and need to represent the details of their constructors in a structured format."
        }
      },
      "error": null
    },
    "schemas.types.ClassContext": {
      "identifier": "schemas.types.ClassContext",
      "description": {
        "overall": "The ClassContext class is a Pydantic model designed to describe a class's external dependencies and its primary points of instantiation. It serves as a structured way to document how a class interacts with other parts of a system and where it is typically created.",
        "init_method": {
          "description": "Initializes the ClassContext model with details about the class's dependencies and instantiation points. It directly assigns the provided values to the corresponding attributes.",
          "parameters": [
            {
              "name": "dependencies",
              "type": "str",
              "description": "A string describing the external dependencies of the class."
            },
            {
              "name": "instantiated_by",
              "type": "str",
              "description": "A string describing where the class is typically instantiated."
            }
          ]
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class does not have any external dependencies beyond Pydantic's BaseModel.",
          "instantiated_by": "This class is intended to be instantiated as part of a larger documentation generation system, likely to describe other classes."
        }
      },
      "error": null
    },
    "schemas.types.ClassDescription": {
      "identifier": "schemas.types.ClassDescription",
      "description": {
        "overall": "The ClassDescription class serves as a comprehensive data structure for holding the detailed analysis of a Python class. It encapsulates information about the class's overall purpose, its constructor, a list of its methods, and its usage context within a larger system. This class is designed to be a part of a documentation generation system, providing structured data for further processing.",
        "init_method": {
          "description": "The __init__ method for ClassDescription is implicitly defined by Pydantic's BaseModel. It initializes the instance with attributes corresponding to the class's analysis: overall description, constructor details, a list of method analyses, and usage context.",
          "parameters": [
            {
              "name": "overall",
              "type": "str",
              "description": "A string representing the overall purpose and responsibilities of the class."
            },
            {
              "name": "init_method",
              "type": "ConstructorDescription",
              "description": "An object detailing the class's constructor (__init__ method), including its description and parameters."
            },
            {
              "name": "methods",
              "type": "List[FunctionAnalysis]",
              "description": "A list of objects, where each object represents the analysis of a method within the class."
            },
            {
              "name": "usage_context",
              "type": "ClassContext",
              "description": "An object detailing how the class is used, including its dependencies and where it is instantiated."
            }
          ]
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class has no explicit external dependencies listed in its context.",
          "instantiated_by": "There are no specific instances of this class mentioned as being created in the provided context."
        }
      },
      "error": null
    },
    "schemas.types.ClassAnalysis": {
      "identifier": "schemas.types.ClassAnalysis",
      "description": {
        "overall": "The ClassAnalysis model represents the comprehensive analysis of a Python class, structured for machine readability. It encapsulates the class's identifier, a detailed description of its components (constructor, methods, overall purpose), and its usage context, including dependencies and instantiation points. It also includes an optional field for reporting any errors encountered during analysis.",
        "init_method": {
          "description": "Initializes the ClassAnalysis model with the class identifier, its detailed description, and an optional error field. The identifier is a string representing the class name, and the description is a ClassDescription object containing the analysis results. The error field is used to report any issues during the analysis process.",
          "parameters": [
            {
              "name": "identifier",
              "type": "str",
              "description": "The name of the class being analyzed."
            },
            {
              "name": "description",
              "type": "ClassDescription",
              "description": "An object containing the detailed analysis of the class, including its methods and overall structure."
            },
            {
              "name": "error",
              "type": "Optional[str]",
              "description": "An optional string that holds an error message if the analysis failed. Defaults to None."
            }
          ]
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class relies on Pydantic's BaseModel for its structure and typing. It also utilizes Optional from the typing module.",
          "instantiated_by": "This class is intended to be instantiated by a documentation generation system or an AI that performs code analysis to produce structured output."
        }
      },
      "error": null
    },
    "schemas.types.CallInfo": {
      "identifier": "schemas.types.CallInfo",
      "description": {
        "overall": "The CallInfo class is a Pydantic BaseModel used to represent detailed information about a specific call event within a system. It captures the source file, the calling function or method name, the mode of the call (e.g., 'method', 'function', 'module'), and the line number where the call occurred. This structure is primarily utilized for documenting relationships like 'called_by' and 'instantiated_by'.",
        "init_method": {
          "description": "Initializes a CallInfo object with details about a specific call event. It takes the file path, function name, call mode, and line number as arguments to define the call's context.",
          "parameters": [
            {
              "name": "file",
              "type": "str",
              "description": "The path to the file where the call originated."
            },
            {
              "name": "function",
              "type": "str",
              "description": "The name of the function or method that made the call."
            },
            {
              "name": "mode",
              "type": "str",
              "description": "The type of call, such as 'method', 'function', or 'module'."
            },
            {
              "name": "line",
              "type": "int",
              "description": "The line number in the source file where the call occurred."
            }
          ]
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class does not have any external dependencies beyond Pydantic's BaseModel.",
          "instantiated_by": "This class is intended to be instantiated by systems that analyze code relationships, specifically for populating 'called_by' and 'instantiated_by' lists."
        }
      },
      "error": null
    },
    "schemas.types.FunctionContextInput": {
      "identifier": "schemas.types.FunctionContextInput",
      "description": {
        "overall": "The FunctionContextInput class is a Pydantic model designed to structure contextual information for analyzing a function. It specifically captures the functions a given function calls and the functions that call it, providing essential data for documentation generation or code analysis tools.",
        "init_method": {
          "description": "Initializes the FunctionContextInput model with lists of function calls and callers. This constructor is automatically generated by Pydantic based on the class attributes.",
          "parameters": [
            {
              "name": "calls",
              "type": "List[str]",
              "description": "A list of strings, where each string represents a function or method called by the analyzed function."
            },
            {
              "name": "called_by",
              "type": "List[CallInfo]",
              "description": "A list of CallInfo objects, where each object details a function or method that calls the analyzed function."
            }
          ]
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class depends on Pydantic's BaseModel for data validation and structure, and typing.List for type hinting. It also implicitly depends on a 'CallInfo' type which is not defined in the provided source code.",
          "instantiated_by": "This class is intended to be instantiated by systems or processes that require structured input for function analysis, such as documentation generators or static code analysis tools. Specific instantiation points are not detailed in the provided source."
        }
      },
      "error": null
    },
    "schemas.types.FunctionAnalysisInput": {
      "identifier": "schemas.types.FunctionAnalysisInput",
      "description": {
        "overall": "The FunctionAnalysisInput class is a Pydantic model designed to encapsulate all necessary information for analyzing a Python function. It specifies the mode of operation, the function's identifier and source code, a list of relevant import statements, and a nested context object containing further details about the function's environment and relationships.",
        "init_method": {
          "description": "Initializes a FunctionAnalysisInput object, setting up the structure for function analysis. It takes the mode, identifier, source code, import statements, and a FunctionContextInput object as arguments, validating them according to Pydantic's BaseModel.",
          "parameters": [
            {
              "name": "mode",
              "type": "Literal[\"function_analysis\"]",
              "description": "Specifies the analysis mode, which must be 'function_analysis' for this input type."
            },
            {
              "name": "identifier",
              "type": "str",
              "description": "The unique name or identifier of the function being analyzed."
            },
            {
              "name": "source_code",
              "type": "str",
              "description": "The raw source code of the function."
            },
            {
              "name": "imports",
              "type": "List[str]",
              "description": "A list of import statements relevant to the source code."
            },
            {
              "name": "context",
              "type": "FunctionContextInput",
              "description": "A nested object containing contextual information about the function, such as its dependencies and call relationships."
            }
          ]
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class does not specify any external dependencies beyond Pydantic's BaseModel and typing modules.",
          "instantiated_by": "This class is intended to be instantiated by systems or processes that require structured input for function analysis, such as documentation generation pipelines or code analysis tools."
        }
      },
      "error": null
    },
    "schemas.types.MethodContextInput": {
      "identifier": "schemas.types.MethodContextInput",
      "description": {
        "overall": "The MethodContextInput class is a Pydantic model designed to structure contextual information about a class's methods. It captures details such as the method's identifier, lists of other methods or functions it calls and is called by, its arguments, and an optional docstring. This class is primarily used for organizing and validating method-related metadata within a larger system, likely for documentation generation or code analysis.",
        "init_method": {
          "description": "Initializes a MethodContextInput object, which is a Pydantic model. It sets up the structure for method context, including the method's identifier, lists of calls and callers, arguments, and an optional docstring. All fields are defined with type hints, and Pydantic handles validation.",
          "parameters": [
            {
              "name": "identifier",
              "type": "str",
              "description": "The unique name or identifier of the method."
            },
            {
              "name": "calls",
              "type": "List[str]",
              "description": "A list of strings representing the identifiers of methods, functions, or classes that this method calls."
            },
            {
              "name": "called_by",
              "type": "List[CallInfo]",
              "description": "A list of CallInfo objects indicating where this method is called from."
            },
            {
              "name": "args",
              "type": "List[str]",
              "description": "A list of strings representing the arguments accepted by the method."
            },
            {
              "name": "docstring",
              "type": "Optional[str]",
              "description": "An optional string containing the docstring of the method."
            }
          ]
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class depends on Pydantic's BaseModel for its structure and validation, and uses typing hints like List and Optional. It also references a 'CallInfo' type, which is assumed to be defined elsewhere.",
          "instantiated_by": "This class is intended to be instantiated by systems that require structured method context, such as code analysis tools, documentation generators, or validation frameworks that process method metadata."
        }
      },
      "error": null
    },
    "schemas.types.ClassContextInput": {
      "identifier": "schemas.types.ClassContextInput",
      "description": {
        "overall": "The ClassContextInput class is a Pydantic model designed to structure the contextual information required for analyzing a Python class. It encapsulates details about the class's dependencies, where it is instantiated, and the context of its individual methods.",
        "init_method": {
          "description": "Initializes a ClassContextInput object, which is a Pydantic model. It expects lists of strings for dependencies, CallInfo objects for instantiation points, and MethodContextInput objects for method-specific context.",
          "parameters": [
            {
              "name": "dependencies",
              "type": "List[str]",
              "description": "A list of strings representing external dependencies of the class."
            },
            {
              "name": "instantiated_by",
              "type": "List[CallInfo]",
              "description": "A list of CallInfo objects indicating where this class is instantiated."
            },
            {
              "name": "method_context",
              "type": "List[MethodContextInput]",
              "description": "A list of MethodContextInput objects providing context for each method within the class."
            }
          ]
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class has no external dependencies explicitly listed.",
          "instantiated_by": "This class is not instantiated by any other components according to the provided context."
        }
      },
      "error": null
    },
    "schemas.types.ClassAnalysisInput": {
      "identifier": "schemas.types.ClassAnalysisInput",
      "description": {
        "overall": "The ClassAnalysisInput class is a Pydantic model designed to structure the input required for a class analysis process. It defines the necessary fields for providing source code, metadata, and contextual information about a Python class to be analyzed.",
        "init_method": {
          "description": "Initializes the ClassAnalysisInput model with all the required fields for class analysis.",
          "parameters": [
            {
              "name": "mode",
              "type": "Literal[\"class_analysis\"]",
              "description": "Specifies the analysis mode, which must be 'class_analysis' for this input type."
            },
            {
              "name": "identifier",
              "type": "str",
              "description": "The name of the class to be analyzed."
            },
            {
              "name": "source_code",
              "type": "str",
              "description": "The raw source code of the Python class."
            },
            {
              "name": "imports",
              "type": "List[str]",
              "description": "A list of import statements relevant to the source code."
            },
            {
              "name": "context",
              "type": "ClassContextInput",
              "description": "An object containing contextual information about the class, such as dependencies and instantiation points."
            }
          ]
        },
        "methods": [],
        "usage_context": {
          "dependencies": "This class has no external dependencies beyond Pydantic and typing modules.",
          "instantiated_by": "This class is intended to be instantiated by systems that require structured input for class analysis."
        }
      },
      "error": null
    }
  }
}