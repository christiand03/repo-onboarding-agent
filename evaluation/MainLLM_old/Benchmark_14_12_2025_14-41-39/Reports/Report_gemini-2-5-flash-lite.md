# Project Documentation: repo-onboarding-agent documentation

## 1. Project Overview (can be accessed under 'basic_info')
    - **Description:** Information not found
    - **Key Features:** 
      - Information not found
    - **Tech Stack:** Information not found

*   **Repository Structure:**
    ```mermaid
    root --> .env.example<br/>.gitignore<br/>SystemPrompts<br/>analysis_output.json<br/>backend<br/>database<br/>frontend<br/>notizen<br/>output.json<br/>output.toon<br/>readme.md<br/>requirements.txt<br/>result<br/>schemas<br/>statistics
    ```

    ## 2. Installation (can be accessed under 'basic_info')
    ### Dependencies
    - a l t a i r = = 4 . 2 . 2 
    - 
    -  a n n o t a t e d - t y p e s = = 0 . 7 . 0 
    - 
    -  a n y i o = = 4 . 1 1 . 0 
    - 
    -  a t t r s = = 2 5 . 4 . 0 
    - 
    -  b c r y p t = = 5 . 0 . 0 
    - 
    -  b l i n k e r = = 1 . 9 . 0 
    - 
    -  c a c h e t o o l s = = 6 . 2 . 2 
    - 
    -  c a p t c h a = = 0 . 7 . 1 
    - 
    -  c e r t i f i = = 2 0 2 5 . 1 1 . 1 2 
    - 
    -  c f f i = = 2 . 0 . 0 
    - 
    -  c h a r s e t - n o r m a l i z e r = = 3 . 4 . 4 
    - 
    -  c l i c k = = 8 . 3 . 1 
    - 
    -  c o l o r a m a = = 0 . 4 . 6 
    - 
    -  c o n t o u r p y = = 1 . 3 . 3 
    - 
    -  c r y p t o g r a p h y = = 4 6 . 0 . 3 
    - 
    -  c y c l e r = = 0 . 1 2 . 1 
    - 
    -  d i s t r o = = 1 . 9 . 0 
    - 
    -  d n s p y t h o n = = 2 . 8 . 0 
    - 
    -  d o t e n v = = 0 . 9 . 9 
    - 
    -  e n t r y p o i n t s = = 0 . 4 
    - 
    -  e x t r a - s t r e a m l i t - c o m p o n e n t s = = 0 . 1 . 8 1 
    - 
    -  f i l e t y p e = = 1 . 2 . 0 
    - 
    -  f o n t t o o l s = = 4 . 6 1 . 0 
    - 
    -  g i t d b = = 4 . 0 . 1 2 
    - 
    -  G i t P y t h o n = = 3 . 1 . 4 5 
    - 
    -  g o o g l e - a i - g e n e r a t i v e l a n g u a g e = = 0 . 9 . 0 
    - 
    -  g o o g l e - a p i - c o r e = = 2 . 2 8 . 1 
    - 
    -  g o o g l e - a u t h = = 2 . 4 3 . 0 
    - 
    -  g o o g l e a p i s - c o m m o n - p r o t o s = = 1 . 7 2 . 0 
    - 
    -  g r p c i o = = 1 . 7 6 . 0 
    - 
    -  g r p c i o - s t a t u s = = 1 . 7 6 . 0 
    - 
    -  h 1 1 = = 0 . 1 6 . 0 
    - 
    -  h t t p c o r e = = 1 . 0 . 9 
    - 
    -  h t t p x = = 0 . 2 8 . 1 
    - 
    -  i d n a = = 3 . 1 1 
    - 
    -  J i n j a 2 = = 3 . 1 . 6 
    - 
    -  j i t e r = = 0 . 1 2 . 0 
    - 
    -  j s o n p a t c h = = 1 . 3 3 
    - 
    -  j s o n p o i n t e r = = 3 . 0 . 0 
    - 
    -  j s o n s c h e m a = = 4 . 2 5 . 1 
    - 
    -  j s o n s c h e m a - s p e c i f i c a t i o n s = = 2 0 2 5 . 9 . 1 
    - 
    -  k i w i s o l v e r = = 1 . 4 . 9 
    - 
    -  l a n g c h a i n = = 1 . 0 . 8 
    - 
    -  l a n g c h a i n - c o r e = = 1 . 1 . 0 
    - 
    -  l a n g c h a i n - g o o g l e - g e n a i = = 3 . 1 . 0 
    - 
    -  l a n g c h a i n - o l l a m a = = 1 . 0 . 0 
    - 
    -  l a n g c h a i n - o p e n a i = = 1 . 1 . 0 
    - 
    -  l a n g g r a p h = = 1 . 0 . 3 
    - 
    -  l a n g g r a p h - c h e c k p o i n t = = 3 . 0 . 1 
    - 
    -  l a n g g r a p h - p r e b u i l t = = 1 . 0 . 5 
    - 
    -  l a n g g r a p h - s d k = = 0 . 2 . 9 
    - 
    -  l a n g s m i t h = = 0 . 4 . 4 6 
    - 
    -  M a r k u p S a f e = = 3 . 0 . 3 
    - 
    -  m a t p l o t l i b = = 3 . 1 0 . 7 
    - 
    -  n a r w h a l s = = 2 . 1 2 . 0 
    - 
    -  n e t w o r k x = = 3 . 6 
    - 
    -  n u m p y = = 2 . 3 . 5 
    - 
    -  o l l a m a = = 0 . 6 . 1 
    - 
    -  o p e n a i = = 2 . 8 . 1 
    - 
    -  o r j s o n = = 3 . 1 1 . 4 
    - 
    -  o r m s g p a c k = = 1 . 1 2 . 0 
    - 
    -  p a c k a g i n g = = 2 5 . 0 
    - 
    -  p a n d a s = = 2 . 3 . 3 
    - 
    -  p i l l o w = = 1 2 . 0 . 0 
    - 
    -  p r o t o - p l u s = = 1 . 2 6 . 1 
    - 
    -  p r o t o b u f = = 6 . 3 3 . 1 
    - 
    -  p y a r r o w = = 2 1 . 0 . 0 
    - 
    -  p y a s n 1 = = 0 . 6 . 1 
    - 
    -  p y a s n 1 _ m o d u l e s = = 0 . 4 . 2 
    - 
    -  p y c p a r s e r = = 2 . 2 3 
    - 
    -  p y d a n t i c = = 2 . 1 2 . 4 
    - 
    -  p y d a n t i c _ c o r e = = 2 . 4 1 . 5 
    - 
    -  p y d e c k = = 0 . 9 . 1 
    - 
    -  P y J W T = = 2 . 1 0 . 1 
    - 
    -  p y m o n g o = = 4 . 1 5 . 4 
    - 
    -  p y p a r s i n g = = 3 . 2 . 5 
    - 
    -  p y t h o n - d a t e u t i l = = 2 . 9 . 0 . p o s t 0 
    - 
    -  p y t h o n - d o t e n v = = 1 . 2 . 1 
    - 
    -  p y t z = = 2 0 2 5 . 2 
    - 
    -  P y Y A M L = = 6 . 0 . 3 
    - 
    -  r e f e r e n c i n g = = 0 . 3 7 . 0 
    - 
    -  r e g e x = = 2 0 2 5 . 1 1 . 3 
    - 
    -  r e q u e s t s = = 2 . 3 2 . 5 
    - 
    -  r e q u e s t s - t o o l b e l t = = 1 . 0 . 0 
    - 
    -  r p d s - p y = = 0 . 2 9 . 0 
    - 
    -  r s a = = 4 . 9 . 1 
    - 
    -  s e t u p t o o l s = = 7 5 . 9 . 1 
    - 
    -  s i x = = 1 . 1 7 . 0 
    - 
    -  s m m a p = = 5 . 0 . 2 
    - 
    -  s n i f f i o = = 1 . 3 . 1 
    - 
    -  s t r e a m l i t = = 1 . 5 1 . 0 
    - 
    -  s t r e a m l i t - a u t h e n t i c a t o r = = 0 . 4 . 2 
    - 
    -  s t r e a m l i t - m e r m a i d = = 0 . 3 . 0 
    - 
    -  t e n a c i t y = = 9 . 1 . 2 
    - 
    -  t i k t o k e n = = 0 . 1 2 . 0 
    - 
    -  t o m l = = 0 . 1 0 . 2 
    - 
    -  t o o l z = = 1 . 1 . 0 
    - 
    -  t o o n _ f o r m a t   @   g i t + h t t p s : / / g i t h u b . c o m / t o o n - f o r m a t / t o o n - p y t h o n . g i t @ 9 c 4 f 0 c 0 c 2 4 f 2 a 0 b 0 b 3 7 6 3 1 5 f 4 b 8 7 0 7 f 8 c 9 0 0 6 d e 6 
    - 
    -  t o r n a d o = = 6 . 5 . 2 
    - 
    -  t q d m = = 4 . 6 7 . 1 
    - 
    -  t y p i n g - i n s p e c t i o n = = 0 . 4 . 2 
    - 
    -  t y p i n g _ e x t e n s i o n s = = 4 . 1 5 . 0 
    - 
    -  t z d a t a = = 2 0 2 5 . 2 
    - 
    -  u r l l i b 3 = = 2 . 5 . 0 
    - 
    -  w a t c h d o g = = 6 . 0 . 0 
    - 
    -  x x h a s h = = 3 . 6 . 0 
    - 
    -  z s t a n d a r d = = 0 . 2 5 . 0 
    - 
    -  "
    ### Setup Guide
    Information not found
    ### Quick Startup
    Information not found

    ## 3. Use Cases & Commands
    This project appears to be an automated documentation pipeline that analyzes code, generates documentation, and potentially optimizes it for different formats. The core functionality involves:
    
    *   **Code Analysis:** Parsing Python code to understand its structure, identify functions and classes, and map their relationships.
    *   **LLM Integration:** Utilizing Language Models (LLMs) for generating descriptive documentation for code elements.
    *   **Repository Onboarding:** Processing entire Git repositories to produce comprehensive documentation.
    
    The project likely involves commands to initiate the documentation generation process for a given repository URL.

    ## 4. Architecture
    The Mermaid Syntax to visualize Graphs is not set up yet and will be added
    but if there is mermaid syntax in your input json display it here



    ## 5. Code Analysis
    
    ### File: `backend/AST_Schema.py`
    
    #### Class: `ASTVisitor`
    *   **Summary:** The ASTVisitor class is a specialized AST (Abstract Syntax Tree) visitor that traverses Python source code to extract structural information such as imports, classes, and functions. It leverages the `ast.NodeVisitor` base class to walk through nodes in the AST and builds a schema representation of the code structure. The visitor maintains context about the current class being processed and organizes collected information into a structured schema containing imports, functions, and classes.
    *   **Instantiation:** `analyze_repository` at line 182 in `AST_Schema.py`
    *   **Dependencies:** `ast`, `networkx`, `os`, `callgraph.build_filtered_callgraph`, `getRepo.GitRepository`
    *   **Constructor:**
        *   *Description:* Initializes the ASTVisitor with source code, file path, and project root. It sets up internal tracking variables including module path derived from the file path and project root, and initializes an empty schema dictionary to store extracted information.
        *   *Parameters:*
            *   **source_code** (`str`): The full source code string of the file being analyzed.
            *   **file_path** (`str`): The file path of the source code being analyzed.
            *   **project_root** (`str`): The root directory of the project to determine module paths.
    *   **Methods:**
        *   **`visit_Import`**
            *   *Signature:* `def visit_Import(self, node)`
            *   *Description:* Handles import nodes in the AST by extracting the names of imported modules and appending them to the schema's imports list. It iterates over all aliases in the import statement and adds their names to the schema.
            *   *Parameters:*
                *   **node** (`ast.Import`): An AST node representing an import statement.
            *   *Returns:*
            *   **Usage:**
        *   **`visit_ImportFrom`**
            *   *Signature:* `def visit_ImportFrom(self, node)`
            *   *Description:* Handles 'from ... import ...' statements in the AST by extracting the fully qualified names of imported items and appending them to the schema's imports list. Each imported item is prefixed with its module name.
            *   *Parameters:*
                *   **node** (`ast.ImportFrom`): An AST node representing a 'from ... import ...' statement.
            *   *Returns:*
            *   **Usage:**
        *   **`visit_ClassDef`**
            *   *Signature:* `def visit_ClassDef(self, node)`
            *   *Description:* Processes class definitions in the AST by creating a structured representation of the class and adding it to the schema. It tracks the current class during traversal and stores metadata such as docstrings, source segments, and line numbers.
            *   *Parameters:*
                *   **node** (`ast.ClassDef`): An AST node representing a class definition.
            *   *Returns:*
            *   **Usage:**
        *   **`visit_FunctionDef`**
            *   *Signature:* `def visit_FunctionDef(self, node)`
            *   *Description:* Handles function definitions in the AST by either associating them with the currently active class or storing them as top-level functions in the schema. It extracts function metadata including arguments, docstrings, and source segments.
            *   *Parameters:*
                *   **node** (`ast.FunctionDef`): An AST node representing a function definition.
            *   *Returns:*
            *   **Usage:**
        *   **`visit_AsyncFunctionDef`**
            *   *Signature:* `def visit_AsyncFunctionDef(self, node)`
            *   *Description:* Handles asynchronous function definitions in the AST by delegating to the standard function visitor method. This ensures that async functions are treated similarly to regular functions in terms of schema extraction.
            *   *Parameters:*
                *   **node** (`ast.AsyncFunctionDef`): An AST node representing an async function definition.
            *   *Returns:*
            *   **Usage:**
    
    #### Class: `ASTAnalyzer`
    *   **Summary:** The ASTAnalyzer class is responsible for analyzing Python repository files by parsing their Abstract Syntax Trees (ASTs) and enriching the resulting schema with call graph information. It merges relationship data into the schema and supports repository-wide analysis by processing multiple files and building a comprehensive view of functions, classes, and their interdependencies.
    *   **Instantiation:** `main_workflow` at line 178 in `main.py`, `prepare_shared_input` at line 125 in `MainLLM_evaluation.py`, `evaluation` at line 120 in `HelperLLM_evaluation.py`
    *   **Dependencies:** `ast`, `networkx`, `os`, `callgraph.build_filtered_callgraph`, `getRepo.GitRepository`
    *   **Constructor:**
        *   *Description:* The constructor for ASTAnalyzer does not initialize any instance variables and simply passes.
        *   *Parameters:*
    *   **Methods:**
        *   **`_enrich_schema_with_callgraph`**
            *   *Signature:* `def _enrich_schema_with_callgraph(schema, call_graph, filename)`
            *   *Description:* This static method enriches a given schema with call graph data by updating function and method contexts with information about what they call and who calls them. It iterates through functions and class methods in the schema and updates their context based on the provided call graph.
            *   *Parameters:*
                *   **schema** (`dict`): A dictionary representing the schema of a parsed Python file, containing functions and classes.
                *   **call_graph** (`nx.DiGraph`): A NetworkX directed graph representing the call relationships between functions and methods.
                *   **filename** (`str`): The path of the file being processed, used to construct unique keys for lookup in the call graph.
            *   *Returns:*
            *   **Usage:**
        *   **`merge_relationship_data`**
            *   *Signature:* `def merge_relationship_data(self, full_schema, relationship_data)`
            *   *Description:* "This method merges relationship data (such as which functions or classes are called by others) into the full schema. It uses a lookup dictionary built from relationship data to update context fields like 'called_by' for functions, classes, and methods in the schema."
            *   *Parameters:*
                *   **full_schema** (`dict`): A dictionary containing the full schema of the repository, including file structures and AST nodes.
                *   **relationship_data** (`list`): A list of dictionaries containing relationship information, such as identifiers and their respective 'called_by' lists.
            *   *Returns:*
                *   **full_schema** (`dict`): The updated schema with merged relationship data.
            *   *Usage:* `main_workflow` at line 197 in `main.py`, `prepare_shared_input` at line 129 in `MainLLM_evaluation.py`, `evaluation` at line 137 in `HelperLLM_evaluation.py`
        *   **`analyze_repository`**
            *   *Signature:* `def analyze_repository(self, files, repo)`
            *   *Description:* "This method performs a complete analysis of a repository by iterating over a list of files, parsing each Python file's content into an AST, visiting the AST with an ASTVisitor to extract schema information, and enriching that schema with call graph data. It constructs a full schema of the repository's structure including files, functions, and classes."
            *   *Parameters:*
                *   **files** (`list`): A list of file objects containing file paths and content to be analyzed.
                *   **repo** (`GitRepository`): An object representing the Git repository being analyzed.
            *   *Returns:*
                *   **full_schema** (`dict`): A dictionary containing the full schema of the repository, organized by file paths and their AST node structures.
            *   *Usage:* `main_workflow` at line 188 in `main.py`, `prepare_shared_input` at line 128 in `MainLLM_evaluation.py`, `evaluation` at line 129 in `HelperLLM_evaluation.py`
    
    #### Function: `path_to_module`
    *   **Signature:** `def path_to_module(filepath, project_root)`
    *   **Description:** "The function converts a file path into a Python module path by computing the relative path from the project root, removing the '.py' extension if present, and replacing directory separators with dots. It handles cases where the filepath is not within the project root by falling back to the basename of the file. If the resulting path ends with '__init__', it removes the trailing part to correctly represent the package structure."
    *   **Parameters:**
        *   **filepath** (`str`): The absolute or relative path to a Python file.
        *   **project_root** (`str`): The root directory of the project used to compute the relative path.
    *   **Returns:**
        *   **module_path** (`str`): A dot-separated module path derived from the given file path.
    *   **Usage:** Called by `__init__` at line 31 in `ASTVisitor`
    
    
    ### File: `backend/File_Dependency.py`
    
    #### Class: `FileDependencyGraph`
    *   **Summary:** The FileDependencyGraph class is designed to analyze and resolve Python file dependencies, particularly focusing on handling relative imports. It extends NodeVisitor to traverse AST nodes of Python files and builds a dependency graph by tracking import relationships between files. The class resolves relative imports by mapping them to actual module or symbol names based on the repository structure and handles both direct and relative import scenarios.
    *   **Instantiation:** `build_file_dependency_graph` at line 156 in `File_Dependency.py`
    *   **Dependencies:** `networkx`, `os`, `ast`, `pathlib`, `get_all_temp_files`
    *   **Constructor:**
        *   *Description:* Initializes the FileDependencyGraph with a filename and repository root path. It sets up the necessary instance variables to track the file being analyzed and the root directory of the repository.
        *   *Parameters:*
            *   **filename** (`str`): The name of the file being analyzed for dependencies.
            *   **repo_root** (`Any`): The root directory path of the repository being analyzed.
    *   **Methods:**
        *   **`_resolve_module_name`**
            *   *Signature:* `def _resolve_module_name(self, node)`
            *   *Description:* "Resolves relative imports of the form 'from .. import name1, name2' by identifying the actual module or symbol names that exist in the file system. It checks for matching files or symbols in the repository structure and raises an ImportError if no match is found."
            *   *Parameters:*
                *   **node** (`ImportFrom`): An AST node representing a relative import statement.
            *   *Returns:*
                *   **`list[str]`**: A list of resolved module or symbol names.
            *   *Usage:* Called by `visit_ImportFrom`
        *   **`visit_Import`**
            *   *Signature:* `def visit_Import(self, node, base_name=None)`
            *   *Description:* Handles import statements by adding the imported module names to the import dependencies dictionary. It tracks which modules are imported by the current file.
            *   *Parameters:*
                *   **node** (`Import | ImportFrom`): An AST node representing an import statement.
                *   **base_name** (`str | None`): The base name of the imported module, if available.
            *   *Returns:*
            *   **Usage:** Called by `visit_ImportFrom`
        *   **`visit_ImportFrom`**
            *   *Signature:* `def visit_ImportFrom(self, node)`
            *   *Description:* "Processes 'from ... import ...' statements by extracting the module name and delegating to 'visit_Import'. For relative imports, it attempts to resolve them using '_resolve_module_name'. If resolution fails, it prints an error message."
            *   *Parameters:*
                *   **node** (`ImportFrom`): An AST node representing a 'from ... import ...' statement.
            *   *Returns:*
            *   **Usage:** Called during AST traversal when encountering 'from ... import ...' statements.
    
    #### Function: `build_file_dependency_graph`
    *   **Signature:** `def build_file_dependency_graph(filename, tree, repo_root)`
    *   **Description:** This function constructs a directed graph representing file dependencies within a repository. It takes an AST representation of a file and uses a custom visitor to extract import dependencies. These dependencies are then added as nodes and edges in a NetworkX DiGraph. The resulting graph captures the relationships between files based on their import statements.
    *   **Parameters:**
        *   **filename** (`str`): The name of the file being analyzed for dependencies.
        *   **tree** (`AST`): The abstract syntax tree representation of the file's source code.
        *   **repo_root** (`str`): The root directory path of the repository being analyzed.
    *   **Returns:**
        *   **graph** (`nx.DiGraph`): A NetworkX directed graph representing the file dependency relationships.
    *   **Usage:** Called by `build_repository_graph` at line 177 in `File_Dependency.py`
    
    #### Function: `build_repository_graph`
    *   **Signature:** `def build_repository_graph(repository)`
    *   **Description:** "This function constructs a directed graph representing the dependencies between Python files within a given Git repository. It iterates through all files in the repository, filters for Python files, parses their content into ASTs, and builds individual file dependency graphs. These are then merged into a global graph that captures the overall dependency structure. The function uses NetworkX to manage the graph structure and relies on helper functions to process individual files."
    *   **Parameters:**
        *   **repository** (`GitRepository`): The GitRepository object containing the files to analyze for dependencies.
    *   **Returns:**
        *   **global_graph** (`nx.DiGraph`): A NetworkX directed graph representing the dependency relationships between Python files in the repository.
    *   **Usage:** Called by the `backend.File_Dependency` module, specifically at line 200 of `File_Dependency.py`.
    
    #### Function: `get_all_temp_files`
    *   **Signature:** `def get_all_temp_files(directory)`
    *   **Description:** "This function retrieves all Python files (.py) from a specified directory and its subdirectories, returning them as relative paths from the given directory. It uses pathlib for path manipulation and recursive globbing to find all matching files. The function resolves the input directory to an absolute path before performing the search."
    *   **Parameters:**
        *   **directory** (`str`): The root directory path from which to search for Python files.
    *   **Returns:**
        *   **`list[pathlib.Path]`**: A list of Path objects representing all Python files found in the directory and its subdirectories, relative to the specified root directory.
    *   **Usage:** Called by `_resolve_module_name` at line 43 in `FileDependencyGraph`
    
    
    ### File: `backend/HelperLLM.py`
    
    #### Class: `LLMHelper`
    *   **Summary:** The LLMHelper class serves as a centralized interface for interacting with various language models, including Google Gemini, OpenAI, custom APIs, and Ollama. It handles API configuration, prompt loading, batching logic, and structured output generation for both function and class documentation. The class supports different models with varying batch sizes and rate-limiting strategies, making it adaptable to diverse LLM environments.
    *   **Instantiation:** `main_workflow` at line 387 in `main.py`, `prepare_shared_input` at line 210 in `MainLLM_evaluation.py`, `evaluation` at line 222 in `HelperLLM_evaluation.py`, `main_orchestrator` at line 387 in `HelperLLM.py`
    *   **Dependencies:** None explicitly listed.
    *   **Constructor:**
        *   *Description:* Initializes the LLMHelper with API credentials, prompt file paths, and model configuration. It loads system prompts from specified files, configures batch settings based on the model name, and sets up appropriate LLM clients depending on the model type. It also prepares structured output parsers for function and class analysis.
        *   *Parameters:*
            *   **api_key** (`str`): API key for authenticating with the language model provider.
            *   **function_prompt_path** (`str`): File path to the system prompt used for function documentation generation.
            *   **class_prompt_path** (`str`): File path to the system prompt used for class documentation generation.
            *   **model_name** (`str`): Name of the language model to use, which determines client instantiation and batch size. Defaults to 'gemini-2.0-flash-lite'.
            *   **base_url** (`Optional[str]`): Base URL for custom API endpoints when using non-standard LLM providers.
    *   **Methods:**
        *   **`_configure_batch_settings`**
            *   *Signature:* `def _configure_batch_settings(self, model_name)`
            *   *Description:* Configures the batch size for processing requests based on the specified model name. Different models have different recommended or supported batch sizes, and this method assigns those values accordingly. For unknown models, it defaults to a conservative batch size.
            *   *Parameters:*
                *   **model_name** (`str`): Name of the language model for which to configure batch settings.
            *   *Returns:*
            *   **Usage:** Called by the `__init__` method during initialization.
        *   **`generate_for_functions`**
            *   *Signature:* `def generate_for_functions(self, function_inputs)`
            *   *Description:* "Processes a batch of function inputs to generate and validate documentation using the configured LLM. It splits inputs into batches according to the configured batch size, sends each batch to the LLM for processing, and handles errors gracefully by filling failed batches with None values while preserving order. Rate limiting is respected by pausing between batches."
            *   *Parameters:*
                *   **function_inputs** (`List[FunctionAnalysisInput]`): A list of function input models to process for documentation generation.
            *   *Returns:*
                *   **`List[Optional[FunctionAnalysis]]`**: A list of validated function analysis results, with None for failed items.
            *   *Usage:* `main_workflow` at line 309 in `main.py`, `prepare_shared_input` at line 221 in `MainLLM_evaluation.py`, `evaluation` at line 245 in `HelperLLM_evaluation.py`
        *   **`generate_for_classes`**
            *   *Signature:* `def generate_for_classes(self, class_inputs)`
            *   *Description:* "Processes a batch of class inputs to generate and validate documentation using the configured LLM. Similar to generate_for_functions, it batches inputs, sends them to the LLM, and manages errors by inserting None placeholders. It respects rate limits by sleeping between batches."
            *   *Parameters:*
                *   **class_inputs** (`List[ClassAnalysisInput]`): A list of class input models to process for documentation generation.
            *   *Returns:*
                *   **`List[Optional[ClassAnalysis]]`**: A list of validated class analysis results, with None for failed items.
            *   *Usage:* `main_workflow` at line 340 in `main.py`, `prepare_shared_input` at line 228 in `MainLLM_evaluation.py`, `evaluation` at line 271 in `HelperLLM_evaluation.py`
    
    #### Function: `main_orchestrator`
    *   **Signature:** `def main_orchestrator()`
    *   **Description:** "This function serves as a dummy data and processing loop for testing the LLMHelper class. It defines pre-computed analysis for three example functions ('add_item', 'check_stock', and 'generate_report') and simulates the documentation generation process for these functions and a class ('InventoryManager'). It sets up mock inputs, validates them using Pydantic models, and uses an LLMHelper instance to generate documentation based on those inputs."
    *   **Parameters:**
    *   **Returns:**
    *   **Usage:** Called by the `backend.HelperLLM` module, specifically at line 419 of `HelperLLM.py`.
    
    
    ### File: `backend/MainLLM.py`
    
    #### Class: `MainLLM`
    *   **Summary:** The MainLLM class serves as the central interface for interacting with various language learning models (LLMs), including Google's Gemini, OpenAI's GPT models, custom API endpoints, and local Ollama instances. It initializes with an API key, a prompt file path, and optional model specifications, setting up the appropriate LLM client based on the model name. The class provides two core functionalities: calling the LLM synchronously with a user input and streaming responses from the LLM, both leveraging a system prompt loaded from a file.
    *   **Instantiation:** `main_workflow` at line 398 in `main.py`, `benchmark_loop` at line 274 in `MainLLM_evaluation.py`
    *   **Dependencies:** `os`, `logging`, `sys`, `dotenv.load_dotenv`, `ChatGoogleGenerativeAI`, `ChatOllama`, `ChatOpenAI`, `HumanMessage`, `SystemMessage`
    *   **Constructor:**
        *   *Description:* Initializes the MainLLM instance by validating the API key, loading a system prompt from a specified file, and configuring the appropriate LLM client based on the model name. It supports multiple LLM backends including Google Generative AI, OpenAI-compatible APIs, and Ollama, with specific handling for different model types such as gemini-, gpt-, and custom models.
        *   *Parameters:*
            *   **api_key** (`str`): The API key used for authenticating with the LLM service.
            *   **prompt_file_path** (`str`): The file path to the system prompt used for initializing the LLM.
            *   **model_name** (`str`): The name of the model to use, which determines the backend client to instantiate. Defaults to 'gemini-2.5-pro'.
            *   **base_url** (`str`): Optional base URL for connecting to a custom LLM endpoint. Used when the model is not a standard Google or OpenAI model.
    *   **Methods:**
        *   **`call_llm`**
            *   *Signature:* `def call_llm(self, user_input)`
            *   *Description:* "Synchronously invokes the configured LLM with a user input message, using the system prompt and the user's input to construct a conversation history. It handles potential exceptions during the LLM call and logs the outcome, returning the content of the LLM's response or None if an error occurs."
            *   *Parameters:*
                *   **user_input** (`str`): The input text provided by the user to be processed by the LLM.
            *   *Returns:*
                *   **response_content** (`str`): The content of the LLM's response if the call is successful, otherwise None.
            *   *Usage:* `main_workflow` at line 417 in `main.py`, `benchmark_loop` at line 283 in `MainLLM_evaluation.py`
        *   **`stream_llm`**
            *   *Signature:* `def stream_llm(self, user_input)`
            *   *Description:* "Initiates a streaming interaction with the configured LLM using a user input message. It constructs a conversation history with the system prompt and user input, then yields chunks of the LLM's response as they become available. In case of an exception, it logs the error and yields an error message."
            *   *Parameters:*
                *   **user_input** (`str`): The input text provided by the user to be streamed through the LLM.
            *   *Returns:*
                *   **chunk_content** (`str`): Yields content chunks from the LLM's streaming response or an error message if an exception occurs.
            *   *Usage:* Not called by any other function in the provided context.
    
    
    ### File: `backend/basic_info.py`
    
    #### Class: `ProjektInfoExtractor`
    *   **Summary:** The ProjektInfoExtractor class is designed to extract basic project information from common project files such as README.md, pyproject.toml, and requirements.txt. It maintains an internal data structure to store extracted information including project overview details like title, description, status, key features, and technology stack, as well as installation-related information such as dependencies, setup instructions, and quick start guides. The extraction process prioritizes pyproject.toml for metadata, falls back to requirements.txt for dependencies, and uses README files for descriptive content. The class orchestrates the parsing of these files and formats the final output based on the available data.
    *   **Instantiation:** `main_workflow` at line 160 in `main.py`, `prepare_shared_input` at line 117 in `MainLLM_evaluation.py`, `evaluation` at line 104 in `HelperLLM_evaluation.py`
    *   **Dependencies:** No external dependencies mentioned.
    *   **Constructor:**
        *   *Description:* Initializes the ProjektInfoExtractor with a predefined data structure to hold project information. It sets up placeholders for various project details under 'projekt_uebersicht' and 'installation' sections, initializing all fields to 'Information not found'.
        *   *Parameters:*
    *   **Methods:**
        *   **`_finde_datei`**
            *   *Signature:* `def _finde_datei(self, patterns, dateien)`
            *   *Description:* "This private method searches for a file among a list of files that matches any of the given patterns, ignoring case. It iterates through the list of files and checks if the file path ends with one of the specified patterns. If a match is found, it returns the matching file object; otherwise, it returns None."
            *   *Parameters:*
                *   **patterns** (`List[str]`): A list of file extension or name patterns to search for.
                *   **dateien** (`List[Any]`): A list of file objects to search through.
            *   *Returns:*
                *   **`Optional[Any]`**: The first matching file object or None if no match is found.
            *   *Usage:* Called by `extrahiere_info` to locate relevant project files.
        *   **`_extrahiere_sektion_aus_markdown`**
            *   *Signature:* `def _extrahiere_sektion_aus_markdown(self, inhalt, keywords)`
            *   *Description:* "This private method extracts text from a markdown document that appears under a specific heading (indicated by ##). It uses regular expressions to find the section associated with one of the provided keywords and returns the content between that heading and the next heading or end of the document. If no matching section is found, it returns None."
            *   *Parameters:*
                *   **inhalt** (`str`): The full markdown text to parse.
                *   **keywords** (`List[str]`): A list of alternative keywords to look for as section headings.
            *   *Returns:*
                *   **`Optional[str]`**: The extracted text from the markdown section or None if no match is found.
            *   *Usage:* Called by `_parse_readme` to extract specific sections from README files.
        *   **`_parse_readme`**
            *   *Signature:* `def _parse_readme(self, inhalt)`
            *   *Description:* "This private method parses the content of a README file to extract various project details such as the title, description, key features, technology stack, current status, setup instructions, and quick start guide. It uses regex patterns to identify these elements and stores them in the internal info structure, only updating fields that are still marked as 'Information not found'."
            *   *Parameters:*
                *   **inhalt** (`str`): The content of the README file to parse.
            *   *Returns:*
            *   **Usage:** Called by `extrahiere_info` when a README file is identified.
        *   **`_parse_toml`**
            *   *Signature:* `def _parse_toml(self, inhalt)`
            *   *Description:* "This private method parses the content of a pyproject.toml file to extract project metadata such as the title and description. It also retrieves dependencies from the project section. If the tomli library is not installed, it prints a warning and exits early. In case of parsing errors, it catches the exception and prints a warning message."
            *   *Parameters:*
                *   **inhalt** (`str`): The content of the pyproject.toml file to parse.
            *   *Returns:*
            *   **Usage:** Called by `extrahiere_info` when a pyproject.toml file is identified.
        *   **`_parse_requirements`**
            *   *Signature:* `def _parse_requirements(self, inhalt)`
            *   *Description:* This private method parses the content of a requirements.txt file to extract dependency information. It only populates the dependencies field if it hasn't already been set by a previous parser (like _parse_toml). It filters out comments and empty lines to create a clean list of dependencies.
            *   *Parameters:*
                *   **inhalt** (`str`): The content of the requirements.txt file to parse.
            *   *Returns:*
            *   **Usage:** Called by `extrahiere_info` when a requirements.txt file is identified.
        *   **`extrahiere_info`**
            *   *Signature:* `def extrahiere_info(self, dateien, repo_url)`
            *   *Description:* "This public method orchestrates the entire information extraction process. It identifies relevant project files (README, pyproject.toml, requirements.txt) using the _finde_datei helper, then parses them in order of priority (_parse_toml, _parse_requirements, _parse_readme). After parsing, it formats the dependencies list and sets the project title based on the repository URL. Finally, it returns the complete info dictionary containing all extracted data."
            *   *Parameters:*
                *   **dateien** (`List[Any]`): A list of file objects representing project files to extract information from.
                *   **repo_url** (`str`): The URL of the repository, used to derive the project title.
            *   *Returns:*
                *   **info** (`Dict[str, Any]`): A dictionary containing the extracted project information organized under 'projekt_uebersicht' and 'installation' keys.
            *   *Usage:* `main_workflow` at line 161 in `main.py`, `prepare_shared_input` at line 118 in `MainLLM_evaluation.py`, `evaluation` at line 105 in `HelperLLM_evaluation.py`
    
    
    ### File: `backend/callgraph.py`
    
    #### Class: `CallGraph`
    *   **Summary:** The CallGraph class is designed to construct a call graph from Python AST nodes, tracking function and method calls within a given file. It extends ast.NodeVisitor to traverse the abstract syntax tree of a Python file, collecting information about imports, local definitions, class and function scopes, and inter-function call relationships. The class maintains internal state such as current function and class names, mappings for local definitions and imports, and a directed graph representing these relationships.
    *   **Instantiation:** `build_filtered_callgraph` at line 199 in `callgraph.py`, `build_filtered_callgraph` at line 206 in `callgraph.py`
    *   **Dependencies:** `ast`, `networkx`, `os`, `pathlib`, `getRepo.GitRepository`, `basic_info.ProjektInfoExtractor`
    *   **Constructor:**
        *   *Description:* Initializes the CallGraph with a filename and sets up internal data structures including dictionaries and sets for tracking local definitions, import mappings, and function calls.
        *   *Parameters:*
            *   **filename** (`str`): The name of the file being processed for call graph construction.
    *   **Methods:**
        *   **`_recursive_call`**
            *   *Signature:* `def _recursive_call(self, node)`
            *   *Description:* "Recursively extracts the dotted name components from an AST node representing a function or attribute access. It handles different types of AST nodes like ast.Call, ast.Name, and ast.Attribute to build a list of name components."
            *   *Parameters:*
                *   **node** (`ast.AST`): The AST node to extract name components from.
            *   *Returns:*
                *   **`list[str]`**: A list of strings representing the dotted name components.
            *   *Usage:* Called by `_resolve_all_callee_names`.
        *   **`_resolve_all_callee_names`**
            *   *Signature:* `def _resolve_all_callee_names(self, callee_nodes)`
            *   *Description:* "Resolves a list of dotted name components into fully qualified names based on local definitions, import mappings, and current class/function context. It checks for local definitions first, then import mappings, and finally constructs full names using the file path and scope information."
            *   *Parameters:*
                *   **callee_nodes** (`list[list[str]]`): A list of lists containing name components for potential callees.
            *   *Returns:*
                *   **`list[str]`**: A list of resolved fully qualified names for the callees.
            *   *Usage:* Called by `visit_Call`.
        *   **`_make_full_name`**
            *   *Signature:* `def _make_full_name(self, basename, class_name=None)`
            *   *Description:* "Constructs a fully qualified name for a function or method using the filename, optional class name, and base name. It formats the name in a consistent way suitable for use in the call graph."
            *   *Parameters:*
                *   **basename** (`str`): The base name of the function or method.
                *   **class_name** (`Optional[str]`): The name of the class if the function is a method.
            *   *Returns:*
                *   **`str`**: A fully qualified name string.
            *   *Usage:* Called by `visit_FunctionDef`.
        *   **`_current_caller`**
            *   *Signature:* `def _current_caller(self)`
            *   *Description:* "Determines the current caller's name based on whether there is an active function or class context. If no function is active, it defaults to the filename or global scope."
            *   *Parameters:*
            *   *Returns:*
                *   **`str`**: The name of the current caller.
            *   *Usage:* Called by `visit_Call`.
        *   **`visit_Import`**
            *   *Signature:* `def visit_Import(self, node)`
            *   *Description:* Handles import statements in the AST by mapping aliases to their actual module names. It updates the import_mapping dictionary with these mappings for later resolution of function calls.
            *   *Parameters:*
                *   **node** (`ast.Import`): The AST node representing an import statement.
            *   *Returns:*
            *   **Usage:** Called by the AST traversal mechanism.
        *   **`visit_ImportFrom`**
            *   *Signature:* `def visit_ImportFrom(self, node)`
            *   *Description:* Handles 'from ... import ...' statements by extracting the module name and mapping imported names to their respective modules. It updates the import_mapping dictionary accordingly.
            *   *Parameters:*
                *   **node** (`ast.ImportFrom`): The AST node representing a 'from ... import ...' statement.
            *   *Returns:*
            *   **Usage:** Called by the AST traversal mechanism.
        *   **`visit_ClassDef`**
            *   *Signature:* `def visit_ClassDef(self, node)`
            *   *Description:* Processes class definitions by temporarily setting the current class context during traversal. It ensures that nested functions and methods are correctly associated with their class scope.
            *   *Parameters:*
                *   **node** (`ast.ClassDef`): The AST node representing a class definition.
            *   *Returns:*
            *   **Usage:** Called by the AST traversal mechanism.
        *   **`visit_FunctionDef`**
            *   *Signature:* `def visit_FunctionDef(self, node)`
            *   *Description:* "Handles function definitions by creating a fully qualified name for the function, updating local definitions, and adding the function to the call graph. It also manages the current function context during traversal."
            *   *Parameters:*
                *   **node** (`ast.FunctionDef`): The AST node representing a function definition.
            *   *Returns:*
            *   **Usage:** Called by the AST traversal mechanism.
        *   **`visit_AsyncFunctionDef`**
            *   *Signature:* `def visit_AsyncFunctionDef(self, node)`
            *   *Description:* "Handles asynchronous function definitions by delegating to the visit_FunctionDef method, ensuring that async functions are treated similarly to regular functions in terms of call graph construction."
            *   *Parameters:*
                *   **node** (`ast.AsyncFunctionDef`): The AST node representing an asynchronous function definition.
            *   *Returns:*
            *   **Usage:** Called by the AST traversal mechanism.
        *   **`visit_Call`**
            *   *Signature:* `def visit_Call(self, node)`
            *   *Description:* Processes function calls by identifying the caller and resolving the callee names. It adds edges between the caller and callees in the call graph based on the resolved names.
            *   *Parameters:*
                *   **node** (`ast.Call`): The AST node representing a function call.
            *   *Returns:*
            *   **Usage:** Called by the AST traversal mechanism.
        *   **`visit_If`**
            *   *Signature:* `def visit_If(self, node)`
            *   *Description:* "Handles conditional statements that check for '__name__ == \"__main__\"'. In such cases, it temporarily changes the current function context to '<main_block>' during traversal to correctly associate main block code with the appropriate scope."
            *   *Parameters:*
                *   **node** (`ast.If`): The AST node representing an if statement.
            *   *Returns:*
            *   **Usage:** Called by the AST traversal mechanism.
    
    #### Function: `make_safe_dot`
    *   **Signature:** `def make_safe_dot(graph, out_path)`
    *   **Description:** "The function 'make_safe_dot' takes a NetworkX directed graph and a file path as inputs. It creates a safe version of the graph by relabeling all nodes with unique identifiers prefixed by 'n', ensuring node names are compatible with graph visualization tools like Graphviz. The original node labels are preserved in the 'label' attribute of the new nodes. Finally, it writes the transformed graph to a DOT file at the specified output path."
    *   **Parameters:**
        *   **graph** (`nx.DiGraph`): A NetworkX directed graph object to be processed and saved.
        *   **out_path** (`str`): The file path where the DOT representation of the graph will be written.
    *   **Returns:**
    *   **Usage:** Called by the `backend.callgraph` module, specifically at line 244 in `callgraph.py`.
    
    #### Function: `build_filtered_callgraph`
    *   **Signature:** `def build_filtered_callgraph(repo)`
    *   **Description:** "Die Funktion erstellt einen globalen Call-Graphen basierend auf allen Python-Dateien eines Git-Repositories und filtert diesen anschließend auf Funktionen, die vom Benutzer selbst geschrieben wurden. Sie durchläuft alle Dateien, parst deren Inhalt mit dem Abstract Syntax Tree (AST), extrahiert Funktionsaufrufe und baut einen gerichteten Graphen auf, wobei nur Kanten zwischen eigenen Funktionen erhalten bleiben."
    *   **Parameters:**
        *   **repo** (`GitRepository`): An object containing information about a Git repository, particularly access to all contained files.
    *   **Returns:**
        *   **global_graph** (`nx.DiGraph`): A directed graph representing the call relationships between functions, filtered for self-written functions.
    *   **Usage:** Called by `analyze_repository` at line 167 in `AST_Schema.py`
    
    
    ### File: `backend/getRepo.py`
    
    #### Class: `RepoFile`
    *   **Summary:** The RepoFile class represents a single file within a Git repository. It implements lazy loading for file metadata such as the blob, content, and size to optimize performance by only loading data when needed. The class provides properties to access these lazily-loaded attributes and includes utility methods like word count analysis and conversion to dictionary format.
    *   **Instantiation:** `get_all_files` at line 111 in `getRepo.py`
    *   **Dependencies:** `os`, `git.Repo`, `git.GitCommandError`
    *   **Constructor:**
        *   *Description:* Initializes a RepoFile object with a file path and a commit tree. Sets up internal attributes for lazy loading including blob, content, and size.
        *   *Parameters:*
            *   **file_path** (`str`): The path to the file within the repository.
            *   **commit_tree** (`git.Tree`): The tree object of the commit from which the file originates.
    *   **Methods:**
        *   **`blob`**
            *   *Signature:* `def blob(self)`
            *   *Description:* "A property that lazily loads the Git blob object associated with the file. If the blob has not been loaded yet, it attempts to retrieve it from the commit tree using the stored file path. Raises a FileNotFoundError if the file cannot be found in the commit tree."
            *   *Parameters:*
            *   *Returns:*
                *   **blob** (`git.Blob`): The Git blob object representing the file.
            *   *Usage:* Not called by any other function in the provided context.
        *   **`content`**
            *   *Signature:* `def content(self)`
            *   *Description:* "A property that lazily loads and returns the decoded content of the file. It reads the data stream from the blob and decodes it into a UTF-8 string, ignoring encoding errors. If the content has already been loaded, it simply returns the cached value."
            *   *Parameters:*
            *   *Returns:*
                *   **content** (`str`): The decoded content of the file.
            *   *Usage:* Not called by any other function in the provided context.
        *   **`size`**
            *   *Signature:* `def size(self)`
            *   *Description:* "A property that lazily loads and returns the size of the file in bytes. It retrieves the size directly from the blob object. If the size has already been determined, it returns the cached value."
            *   *Parameters:*
            *   *Returns:*
                *   **size** (`int`): The size of the file in bytes.
            *   *Usage:* Not called by any other function in the provided context.
        *   **`analyze_word_count`**
            *   *Signature:* `def analyze_word_count(self)`
            *   *Description:* An example analysis method that counts the number of words in the file's content. It splits the content on whitespace and returns the resulting word count.
            *   *Parameters:*
            *   *Returns:*
                *   **word_count** (`int`): The total number of words in the file.
            *   *Usage:* Not called by any other function in the provided context.
        *   **`__repr__`**
            *   *Signature:* `def __repr__(self)`
            *   *Description:* "Provides a useful string representation of the RepoFile object, displaying the file path for debugging and logging purposes."
            *   *Parameters:*
            *   *Returns:*
                *   **repr** (`str`): A string representation of the RepoFile object.
            *   *Usage:* Not called by any other function in the provided context.
        *   **`to_dict`**
            *   *Signature:* `def to_dict(self, include_content=False)`
            *   *Description:* "Converts the RepoFile object into a dictionary format, including basic file information such as path, name, size, and type. Optionally includes the file's content if specified."
            *   *Parameters:*
                *   **include_content** (`bool`): Whether to include the file's content in the returned dictionary.
            *   *Returns:*
                *   **data** (`dict`): A dictionary containing file metadata and optionally the content.
            *   *Usage:* Not called by any other function in the provided context.
    
    #### Class: `GitRepository`
    *   **Summary:** The GitRepository class manages a Git repository by cloning it into a temporary directory and providing functionality to retrieve file information and construct a hierarchical file tree. It ensures proper cleanup of temporary resources upon closing. The class supports initialization with a repository URL, fetching all files as RepoFile objects, and generating a structured tree representation of the repository's contents.
    *   **Instantiation:** `main_workflow` at line 141 in `main.py`, `prepare_shared_input` at line 112 in `MainLLM_evaluation.py`, `evaluation` at line 86 in `HelperLLM_evaluation.py`
    *   **Dependencies:** None explicitly listed.
    *   **Constructor:**
        *   *Description:* Initializes a GitRepository instance by cloning the specified repository URL into a temporary directory. It sets up necessary attributes such as the repository URL, temporary directory path, and references to the cloned repository and its latest commit. If cloning fails, it raises a RuntimeError after cleaning up resources.
        *   *Parameters:*
            *   **repo_url** (`str`): The URL of the Git repository to clone.
    *   **Methods:**
        *   **`get_all_files`**
            *   *Signature:* `def get_all_files(self)`
            *   *Description:* Retrieves a list of all files in the repository and converts them into RepoFile objects. It uses the git command-line interface to list files and filters out any empty entries before creating RepoFile instances.
            *   *Parameters:*
            *   *Returns:*
                *   **files** (`list[RepoFile]`): A list of RepoFile instances representing the files in the repository.
            *   *Usage:* Called by `prepare_shared_input` at line 113 in `MainLLM_evaluation.py`
        *   **`close`**
            *   *Signature:* `def close(self)`
            *   *Description:* Deletes the temporary directory and its contents associated with the repository. It prints a message indicating the deletion and resets the temporary directory reference.
            *   *Parameters:*
            *   *Returns:*
            *   **Usage:** Called by `prepare_shared_input` at line 132 in `MainLLM_evaluation.py`
        *   **`__enter__`**
            *   *Signature:* `def __enter__(self)`
            *   *Description:* Enables the use of the GitRepository instance in a context manager (with statement). It simply returns the instance itself.
            *   *Parameters:*
            *   *Returns:*
                *   **`GitRepository`**: The GitRepository instance.
            *   *Usage:* Not called by any other function in the provided context.
        *   **`__exit__`**
            *   *Signature:* `def __exit__(self, exc_type, exc_val, exc_tb)`
            *   *Description:* Handles cleanup when exiting a context manager. It calls the close method to delete the temporary directory.
            *   *Parameters:*
                *   **exc_type** (`Any`): Exception type, if an exception occurred during execution.
                *   **exc_val** (`Any`): Exception value, if an exception occurred during execution.
                *   **exc_tb** (`Any`): Exception traceback, if an exception occurred during execution.
            *   *Returns:*
            *   **Usage:** Not called by any other function in the provided context.
        *   **`get_file_tree`**
            *   *Signature:* `def get_file_tree(self, include_content=False)`
            *   *Description:* "Constructs a hierarchical tree structure of the repository's files. If no files have been retrieved yet, it fetches them first. Then, it iterates through each file, building nested dictionaries to represent directories and files based on their paths."
            *   *Parameters:*
                *   **include_content** (`bool`): Flag indicating whether to include file content in the returned dictionary.
            *   *Returns:*
                *   **tree** (`dict`): A dictionary representing the hierarchical structure of the repository's files.
            *   *Usage:* Called by `prepare_shared_input` at line 121 in `MainLLM_evaluation.py`
    
    
    ### File: `backend/main.py`
    
    #### Function: `create_savings_chart`
    *   **Signature:** `def create_savings_chart(json_tokens, toon_tokens, savings_percent, output_path)`
    *   **Description:** "Die Funktion erstellt ein Balkendiagramm zur Darstellung des Token-Vergleichs zwischen JSON und TOON Format. Sie verwendet matplotlib, um die Daten zu visualisieren und speichert das Diagramm unter einem angegebenen Pfad. Das Diagramm zeigt die Anzahl der Token für beide Formate sowie den prozentualen Einsparungswert."
    *   **Parameters:**
        *   **json_tokens** (`int`): Die Anzahl der Tokens im JSON-Format.
        *   **toon_tokens** (`int`): Die Anzahl der Tokens im TOON-Format.
        *   **savings_percent** (`float`): Der prozentuale Unterschied in der Token-Nutzung zwischen JSON und TOON.
        *   **output_path** (`str`): Der Dateipfad, unter dem das generierte Diagramm gespeichert wird.
    *   **Returns:**
    *   **Usage:** Called by `main_workflow` at line 503 in `main.py`
    
    #### Function: `calculate_net_time`
    *   **Signature:** `def calculate_net_time(start_time, end_time, total_items, batch_size, model_name)`
    *   **Description:** "The function calculates the net time duration between a start and end time, excluding sleep times caused by rate limits. It specifically adjusts the calculation when the model name starts with 'gemini-', applying additional logic to account for batch processing and associated sleep periods. If the total items count is zero, it returns zero immediately. Otherwise, it computes the number of batches, determines the number of sleep periods, and subtracts the total sleep time from the overall duration."
    *   **Parameters:**
        *   **start_time** (`float or datetime`): The starting timestamp of the operation.
        *   **end_time** (`float or datetime`): The ending timestamp of the operation.
        *   **total_items** (`int`): The total number of items processed during the operation.
        *   **batch_size** (`int`): The size of each batch used for processing items.
        *   **model_name** (`str`): The name of the model being used, which affects whether rate limit adjustments are applied.
    *   **Returns:**
        *   **net_time** (`float or int`): The calculated net time after subtracting sleep durations due to rate limits, ensuring a non-negative result.
    *   **Usage:** Called by `main_workflow` at lines 311 and 342 in `main.py`, `evaluation` at lines 249 and 275 in `HelperLLM_evaluation.py`
    
    #### Function: `main_workflow`
    *   **Signature:** `def main_workflow(input, api_keys: dict, model_names: dict, status_callback=None)`
    *   **Description:** "The `main_workflow` function orchestrates a comprehensive code analysis pipeline for a given repository URL. It begins by extracting API keys and model names, then clones the repository and retrieves all files. It performs various analyses including extracting basic project information, constructing a file tree, analyzing relationships between code elements, and generating an abstract syntax tree (AST). The function prepares inputs for a helper LLM to analyze functions and classes, then calls the helper LLM to generate documentation for these elements. Finally, it prepares inputs for a main LLM to generate a final report based on all collected data."
    *   **Parameters:**
        *   **input** (`Any`): The input data, typically a repository URL, to initiate the workflow.
        *   **api_keys** (`dict`): A dictionary containing API keys for different services such as Gemini, OpenAI, and SCADsLLM.
        *   **model_names** (`dict`): A dictionary specifying the names of models to be used for helper and main LLMs.
        *   **status_callback** (`Callable[[str], None]`): An optional callback function to report progress updates during execution.
    *   **Returns:**
        *   **report** (`str`): The final markdown report generated by the main LLM.
        *   **metrics** (`dict`): A dictionary containing timing metrics for helper and main LLM operations.
    *   **Usage:** Called by the frontend module in `Frontend.py` at line 489 and by the backend main module in `main.py` at line 533.
    
    #### Function: `update_status`
    *   **Signature:** `def update_status(msg)`
    *   **Description:** "The function 'update_status' is designed to handle status updates by invoking an optional callback function if one is defined, and then logging the message using the standard logging module. It serves as a centralized mechanism for reporting status messages throughout the application."
    *   **Parameters:**
        *   **msg** (`Any`): The status message to be processed and logged.
    *   **Returns:**
    *   **Usage:** Called multiple times (14 instances) from the `main_workflow` function in `main.py`.
    
    
    ### File: `backend/relationship_analyzer.py`
    
    #### Function: `path_to_module`
    *   **Signature:** `def path_to_module(filepath, project_root)`
    *   **Description:** "The function converts a file path into a Python module path by computing the relative path from the project root, removing the '.py' extension if present, and replacing directory separators with dots. It handles cases where the filepath is not within the project root by falling back to the basename of the file. If the resulting path ends with '__init__', it removes the trailing part to correctly represent the package structure."
    *   **Parameters:**
        *   **filepath** (`str`): The absolute or relative path to a Python file.
        *   **project_root** (`str`): The root directory of the project used to compute the relative path.
    *   **Returns:**
        *   **module_path** (`str`): A dot-separated module path derived from the given file path.
    *   **Usage:** Called by `_collect_definitions` and `__init__` in `ProjectAnalyzer`
    
    #### Class: `ProjectAnalyzer`
    *   **Summary:** The ProjectAnalyzer class is designed to analyze Python projects by examining their source code structure. It identifies definitions such as functions, classes, and methods, and tracks inter-function call relationships. The analyzer walks through the project directory, parses Python files using AST, collects definitions with their locations, resolves function calls between these definitions, and finally formats the results into a structured output showing which functions or methods are called by others.
    *   **Instantiation:** `main_workflow` at line 177 in `main.py`, `prepare_shared_input` at line 124 in `MainLLM_evaluation.py`, `evaluation` at line 119 in `HelperLLM_evaluation.py`
    *   **Dependencies:** `ast`, `os`, `logging`, `collections.defaultdict`
    *   **Constructor:**
        *   *Description:* Initializes the ProjectAnalyzer with a project root directory. Sets up internal data structures including a dictionary for storing definitions, a call graph, and a mapping of file paths to their parsed ASTs. It also defines a set of directories to ignore during traversal.
        *   *Parameters:*
            *   **project_root** (`str`): The root directory path of the project to be analyzed.
    *   **Methods:**
        *   **`analyze`**
            *   *Signature:* `def analyze(self)`
            *   *Description:* "The main analysis method that orchestrates the process of finding Python files, collecting definitions from those files, resolving function calls, and formatting the final results. It clears the AST cache after processing and returns a formatted list of definitions along with their callers."
            *   *Parameters:*
            *   *Returns:*
                *   **return_value** (`list`): A list of dictionaries representing definitions and their callers.
            *   *Usage:* Called by `main_workflow` at line 178 in `main.py`, `prepare_shared_input` at line 125 in `MainLLM_evaluation.py`, `evaluation` at line 120 in `HelperLLM_evaluation.py`
        *   **`_find_py_files`**
            *   *Signature:* `def _find_py_files(self)`
            *   *Description:* "Recursively finds all Python (.py) files in the project root directory, excluding specified directories like .git, venv, etc. It uses os.walk to traverse the directory tree and filters out ignored directories before adding matching files to a list."
            *   *Parameters:*
            *   *Returns:*
                *   **py_files** (`list`): A list of absolute paths to Python files in the project.
            *   *Usage:* Called by the `analyze` method.
        *   **`_collect_definitions`**
            *   *Signature:* `def _collect_definitions(self, filepath)`
            *   *Description:* "Parses a given Python file and collects all function and class definitions, storing them in a dictionary with metadata such as file location and definition type. It handles both top-level functions and methods within classes, assigning appropriate paths for identification. Errors during parsing are logged but do not halt execution."
            *   *Parameters:*
                *   **filepath** (`str`): The absolute path to the Python file to analyze.
            *   *Returns:*
            *   *Usage:* Called by the `analyze` method.
        *   **`_get_parent`**
            *   *Signature:* `def _get_parent(self, tree, node)`
            *   *Description:* "Given an AST tree and a node within that tree, this method attempts to find the parent node of the given node. It walks through the AST to locate the parent of the specified node, returning None if not found. This utility helps determine whether a function definition is part of a class."
            *   *Parameters:*
                *   **tree** (`ast.AST`): The AST tree to search within.
                *   **node** (`ast.AST`): The node whose parent needs to be identified.
            *   *Returns:*
                *   **parent** (`ast.AST or None`): The parent node of the given node, or None if not found.
            *   *Usage:* Called by the `_collect_definitions` method.
        *   **`_resolve_calls`**
            *   *Signature:* `def _resolve_calls(self, filepath)`
            *   *Description:* Resolves function calls within a given Python file by utilizing a CallResolverVisitor. It updates the call graph with information about which functions call others. Any errors encountered during resolution are logged but do not interrupt the process.
            *   *Parameters:*
                *   **filepath** (`str`): The absolute path to the Python file to resolve calls in.
            *   *Returns:*
            *   *Usage:* Called by the `analyze` method.
        *   **`get_formatted_results`**
            *   *Signature:* `def get_formatted_results(self)`
            *   *Description:* "Formats the collected definitions and call relationships into a structured list of dictionaries. Each dictionary contains details about a definition, including its identifier, mode (function/class/method), origin file, line number, and a list of callers. Duplicate calls are removed, and the final list is sorted by file and line number."
            *   *Parameters:*
            *   *Returns:*
                *   **output_list** (`list`): A list of dictionaries describing definitions and their callers.
            *   *Usage:* Called by the `analyze` method.
    
    #### Class: `CallResolverVisitor`
    *   **Summary:** The CallResolverVisitor class is an AST (Abstract Syntax Tree) visitor designed to analyze Python code and resolve call relationships between functions, methods, and modules. It tracks the current execution context (such as class and function names) to correctly associate calls with their callers. It also maintains mappings of imported names and instance types to resolve qualified names and track which functions are called from where. This class is primarily used during static analysis to understand inter-module and intra-module dependencies.
    *   **Instantiation:** `_resolve_calls` at line 92 in `relationship_analyzer.py`
    *   **Dependencies:** None explicitly listed.
    *   **Constructor:**
        *   *Description:* Initializes the CallResolverVisitor with the file path, project root, and a set of definitions. It sets up internal tracking structures such as scope, instance types, and call records, and initializes the current caller name to the module path.
        *   *Parameters:*
            *   **filepath** (`str`): The absolute path to the Python file being analyzed.
            *   **project_root** (`str`): The root directory of the project, used to compute module paths.
            *   **definitions** (`dict`): A dictionary mapping qualified names to their definitions or metadata.
    *   **Methods:**
        *   **`visit_ClassDef`**
            *   *Signature:* `def visit_ClassDef(self, node)`
            *   *Description:* "Handles the visitation of class definitions in the AST. It updates the current class name context to reflect the class being visited, processes the class body recursively, and restores the previous class name after processing."
            *   *Parameters:*
                *   **node** (`ast.ClassDef`): The AST node representing the class definition.
            *   *Returns:*
            *   **Usage:** Invoked by the generic AST visitor when a class definition node is encountered.
        *   **`visit_FunctionDef`**
            *   *Signature:* `def visit_FunctionDef(self, node)`
            *   *Description:* "Handles the visitation of function definitions in the AST. It updates the current caller name to the function name, processes the function body recursively, and restores the previous caller name after processing."
            *   *Parameters:*
                *   **node** (`ast.FunctionDef`): The AST node representing the function definition.
            *   *Returns:*
            *   **Usage:** Invoked by the generic AST visitor when a function definition node is encountered.
        *   **`visit_Call`**
            *   *Signature:* `def visit_Call(self, node)`
            *   *Description:* "Processes function calls in the AST. It resolves the qualified name of the called function, checks if it exists in the definitions, and records the call with metadata about the caller's context (module, function, or method)."
            *   *Parameters:*
                *   **node** (`ast.Call`): The AST node representing the function call.
            *   *Returns:*
            *   **Usage:** Invoked by the generic AST visitor when a function call node is encountered.
        *   **`visit_Import`**
            *   *Signature:* `def visit_Import(self, node)`
            *   *Description:* "Handles import statements in the AST. It maps imported names to their actual module paths in the scope dictionary, allowing later resolution of qualified names."
            *   *Parameters:*
                *   **node** (`ast.Import`): The AST node representing the import statement.
            *   *Returns:*
            *   **Usage:** Invoked by the generic AST visitor when an import node is encountered.
        *   **`visit_ImportFrom`**
            *   *Signature:* `def visit_ImportFrom(self, node)`
            *   *Description:* Handles 'from ... import ...' statements in the AST. It resolves relative imports and maps imported names to their fully qualified paths in the scope dictionary.
            *   *Parameters:*
                *   **node** (`ast.ImportFrom`): The AST node representing the 'from ... import ...' statement.
            *   *Returns:*
            *   **Usage:** Invoked by the generic AST visitor when an 'import from' node is encountered.
        *   **`visit_Assign`**
            *   *Signature:* `def visit_Assign(self, node)`
            *   *Description:* "Handles assignment statements in the AST. Specifically, it identifies assignments to instances of classes and records the type of the assigned instance for later use in resolving method calls."
            *   *Parameters:*
                *   **node** (`ast.Assign`): The AST node representing the assignment statement.
            *   *Returns:*
            *   **Usage:** Invoked by the generic AST visitor when an assignment node is encountered.
        *   **`_resolve_call_qname`**
            *   *Signature:* `def _resolve_call_qname(self, func_node)`
            *   *Description:* A private helper method that resolves the qualified name of a function call based on the AST node representing the function. It handles both direct function calls and attribute-based calls (like obj.method).
            *   *Parameters:*
                *   **func_node** (`ast.expr`): The AST node representing the function being called.
            *   *Returns:*
                *   **qualified_name** (`str or None`): The fully qualified name of the function if resolved, otherwise None.
            *   *Usage:* Called by the `visit_Call` method to resolve the qualified name of a function call.
    
    
    ### File: `database/db.py`
    
    #### Function: `encrypt_text`
    *   **Signature:** `def encrypt_text(text)`
    *   **Description:** "The function encrypts a given text string using a Fernet cipher suite. It first checks if the input text is empty or if the cipher suite is not initialized, returning the original text in such cases. If both conditions are met, it encodes the stripped text, encrypts it, and returns the decrypted result as a string."
    *   **Parameters:**
        *   **text** (`str`): The text string to be encrypted.
    *   **Returns:**
        *   **encrypted_text** (`str`): The encrypted version of the input text, returned as a string.
    *   **Usage:** Called by `update_gemini_key` at line 71 in `db.py`
    
    #### Function: `decrypt_text`
    *   **Signature:** `def decrypt_text(text)`
    *   **Description:** "The function decrypts a given text using a cipher suite, returning the decrypted string if successful. If the input text is empty or the cipher suite is not available, it returns the original text unchanged. In case of decryption failure, it also returns the original text. The function handles potential exceptions during decryption gracefully by falling back to the original input."
    *   **Parameters:**
        *   **text** (`str`): The encrypted text to be decrypted.
    *   **Returns:**
        *   **result** (`str`): The decrypted text if successful; otherwise, the original input text.
    *   **Usage:** Called by `get_decrypted_api_keys` at line 93 in `db.py`
    
    #### Function: `insert_user`
    *   **Signature:** `def insert_user(username, name, password)`
    *   **Description:** "The function inserts a new user into the database by creating a user document with the provided username, name, and password. The password is hashed using a hasher utility before being stored. The function also initializes additional fields such as API keys and returns the ID of the inserted document."
    *   **Parameters:**
        *   **username** (`str`): The unique identifier for the user, used as the '_id' field in the database.
        *   **name** (`str`): The full name of the user.
        *   **password** (`str`): The plain text password of the user, which gets hashed before storage.
    *   **Returns:**
        *   **inserted_id** (`ObjectId`): The unique identifier assigned by the database to the newly inserted user document.
    *   **Usage:** Called by the `Frontend` class at line 294 in `Frontend.py`
    
    #### Function: `fetch_all_users`
    *   **Signature:** `def fetch_all_users()`
    *   **Description:** This function retrieves all user documents from a MongoDB collection named 'dbusers'. It performs a database query to find all records and returns them as a list. The function does not take any parameters and directly accesses the global 'dbusers' collection object.
    *   **Parameters:**
    *   **Returns:**
        *   **result** (`list`): A list containing all user documents retrieved from the 'dbusers' MongoDB collection.
    *   **Usage:** Called by the `frontend.Frontend` class at line 244 in `Frontend.py`
    
    #### Function: `fetch_user`
    *   **Signature:** `def fetch_user(username)`
    *   **Description:** The function 'fetch_user' retrieves a user document from a MongoDB collection named 'dbusers' based on the provided username. It performs a lookup operation using the username as the unique identifier (_id) and returns the matching document. This function assumes that the 'dbusers' collection and the 'find_one' method are properly initialized and accessible within the scope.
    *   **Parameters:**
        *   **username** (`str`): The unique identifier (username) used to search for a specific user in the 'dbusers' collection.
    *   **Returns:**
        *   **result** (`Any`): The user document retrieved from the 'dbusers' collection, or None if no matching document is found.
    *   **Usage:** Not called by any other functions in the provided context.
    
    #### Function: `update_user_name`
    *   **Signature:** `def update_user_name(username, new_name)`
    *   **Description:** "This function updates the name field of a user document in a MongoDB collection identified by the user's username. It uses the MongoDB update_one method to modify only the name field, leaving other fields unchanged. The function returns the count of modified documents, which should be 1 if the update was successful."
    *   **Parameters:**
        *   **username** (`str`): The unique identifier (username) of the user whose name needs to be updated.
        *   **new_name** (`str`): The new name value to set for the specified user.
    *   **Returns:**
        *   **modified_count** (`int`): The number of documents that were successfully modified by the update operation.
    *   **Usage:** Not called by any other functions in the provided context.
    
    #### Function: `update_gemini_key`
    *   **Signature:** `def update_gemini_key(username, gemini_api_key)`
    *   **Description:** "This function updates the Gemini API key for a specified user in the database. It first encrypts the provided API key using a text encryption function, then performs an update operation on the 'dbusers' collection to store the encrypted key under the user's ID. The function returns the count of modified documents, indicating whether the update was successful."
    *   **Parameters:**
        *   **username** (`str`): The unique identifier for the user whose Gemini API key needs to be updated.
        *   **gemini_api_key** (`str`): The new Gemini API key to be stored for the user, which will be stripped of whitespace and encrypted before storage.
    *   **Returns:**
        *   **modified_count** (`int`): The number of documents that were successfully modified as a result of the update operation.
    *   **Usage:** Called by `save_gemini_cb` at line 35 in `Frontend.py`, and by `frontend.Frontend` at line 393 in `Frontend.py`
    
    #### Function: `update_ollama_url`
    *   **Signature:** `def update_ollama_url(username, ollama_base_url)`
    *   **Description:** "This function updates the Ollama base URL for a specified user in the database. It takes a username and a new Ollama base URL as inputs, strips any leading or trailing whitespace from the URL, and performs an update operation on the user document in the database. The function returns the count of modified documents, which should be 1 if the update was successful."
    *   **Parameters:**
        *   **username** (`str`): The unique identifier of the user whose Ollama base URL needs to be updated.
        *   **ollama_base_url** (`str`): The new Ollama base URL to be set for the specified user. Leading and trailing whitespace will be stripped.
    *   **Returns:**
        *   **modified_count** (`int`): The number of documents that were successfully modified by the update operation. Typically 1 if the user exists and the update was applied.
    *   **Usage:** Called by `save_ollama_cb` at line 42 in `Frontend.py`, and by `frontend.Frontend` at line 407 in `Frontend.py`
    
    #### Function: `fetch_gemini_key`
    *   **Signature:** `def fetch_gemini_key(username)`
    *   **Description:** "The function retrieves a Gemini API key associated with a given username from a MongoDB collection. It queries the 'dbusers' collection to find a document matching the username and extracts the 'gemini_api_key' field. If no matching user is found, it returns None."
    *   **Parameters:**
        *   **username** (`str`): The unique identifier for the user whose Gemini API key is to be retrieved.
    *   **Returns:**
        *   **gemini_api_key** (`str or None`): The Gemini API key associated with the user, or None if the user is not found.
    *   **Usage:** Not called by any other functions in the provided context.
    
    #### Function: `fetch_ollama_url`
    *   **Signature:** `def fetch_ollama_url(username)`
    *   **Description:** "The function retrieves the Ollama base URL associated with a given username from a MongoDB collection. It queries the 'dbusers' collection to find a document matching the username and extracts the 'ollama_base_url' field. If no matching user is found, it returns None."
    *   **Parameters:**
        *   **username** (`str`): The unique identifier for the user whose Ollama base URL is to be retrieved.
    *   **Returns:**
        *   **ollama_base_url** (`str | None`): The Ollama base URL associated with the user, or None if the user is not found.
    *   **Usage:** Not called by any other functions in the provided context.
    
    #### Function: `delete_user`
    *   **Signature:** `def delete_user(username)`
    *   **Description:** The function 'delete_user' removes a user document from a MongoDB collection based on the provided username. It performs a delete operation using the 'delete_one' method and returns the count of deleted documents. This function assumes the existence of a global 'dbusers' variable representing a MongoDB collection.
    *   **Parameters:**
        *   **username** (`str`): The unique identifier (username) of the user to be deleted from the database.
    *   **Returns:**
        *   **deleted_count** (`int`): The number of documents deleted as a result of the operation, typically 0 or 1.
    *   **Usage:** Not called by any other functions in the provided context.
    
    #### Function: `get_decrypted_api_keys`
    *   **Signature:** `def get_decrypted_api_keys(username)`
    *   **Description:** "This function retrieves and decrypts API keys for a given username from a database. It first fetches the user document using the username as the identifier. If the user does not exist, it returns two None values. If the user exists, it attempts to decrypt the 'gemini_api_key' field using a decryption function and retrieves the 'ollama_base_url' directly. It then returns both the decrypted Gemini API key and the Ollama base URL."
    *   **Parameters:**
        *   **username** (`str`): The unique identifier for the user whose API keys are to be retrieved.
    *   **Returns:**
        *   **gemini_plain** (`str`): The decrypted Gemini API key for the user, or an empty string if not found.
        *   **ollama_plain** (`str`): The Ollama base URL for the user, or an empty string if not found.
    *   **Usage:** Called by `frontend.Frontend` at lines 380 and 479 in `Frontend.py`
    
    #### Function: `insert_chat`
    *   **Signature:** `def insert_chat(username, chat_name)`
    *   **Description:** "The function 'insert_chat' creates a new chat entry in the database with a unique identifier, associated username, chat name, and timestamp. It generates a UUID for the chat ID, records the current datetime, and inserts the chat document into the 'dbchats' collection. The function then returns the ID of the inserted document."
    *   **Parameters:**
        *   **username** (`str`): The username associated with the chat.
        *   **chat_name** (`str`): The name of the chat.
    *   **Returns:**
        *   **result.inserted_id** (`str`): The unique identifier of the newly inserted chat document.
    *   **Usage:** Called by `load_data_from_db` at line 81 in `Frontend.py`, `handle_delete_chat` at line 122 in `Frontend.py`, and `frontend.Frontend` at line 344 in `Frontend.py`
    
    #### Function: `fetch_chats_by_user`
    *   **Signature:** `def fetch_chats_by_user(username)`
    *   **Description:** "Die Funktion fetch_chats_by_user ruft alle Chats eines bestimmten Benutzers aus einer MongoDB-Datenbank ab. Sie verwendet einen Datenbankzugriff über dbchats, um Dokumente mit dem angegebenen Benutzernamen zu finden und diese nach dem Erstellungsdatum sortiert zurückzugeben."
    *   **Parameters:**
        *   **username** (`str`): Der Name des Benutzers, dessen Chats abgerufen werden sollen.
    *   **Returns:**
        *   **chats** (`list`): Eine Liste der Chats des Benutzers, sortiert nach Erstellungsdatum in aufsteigender Reihenfolge.
    *   **Usage:** Called by the `load_data_from_db` function in `Frontend.py`.
    
    #### Function: `check_chat_exists`
    *   **Signature:** `def check_chat_exists(username, chat_name)`
    *   **Description:** "This function checks whether a specific chat entry exists in the database for a given username and chat name. It performs a query using MongoDB's find_one method to locate a document matching both the username and chat name. If such a document is found, the function returns True; otherwise, it returns False."
    *   **Parameters:**
        *   **username** (`str`): The username associated with the chat.
        *   **chat_name** (`str`): The name of the chat to check for existence.
    *   **Returns:**
        *   **exists** (`bool`): True if a chat with the specified username and chat name exists in the database, False otherwise.
    *   **Usage:** Not called by any other functions in the provided context.
    
    #### Function: `rename_chat_fully`
    *   **Signature:** `def rename_chat_fully(username, old_name, new_name)`
    *   **Description:** "This function renames a chat and updates all associated exchanges in the database. It first updates the chat entry in the chats collection, then updates all related exchange entries in the exchanges collection to reflect the new chat name. The function returns the number of modified chat documents."
    *   **Parameters:**
        *   **username** (`str`): The username associated with the chat to be renamed.
        *   **old_name** (`str`): The current name of the chat to be renamed.
        *   **new_name** (`str`): The new name to assign to the chat.
    *   **Returns:**
        *   **modified_count** (`int`): The number of chat documents that were successfully modified during the renaming operation.
    *   **Usage:** Called by the `frontend.Frontend` class at line 462 in `Frontend.py`.
    
    #### Function: `insert_exchange`
    *   **Signature:** `def insert_exchange(question, answer, feedback, username, chat_name, helper_used='', main_used='', total_time='', helper_time='', main_time='')`
    *   **Description:** "This function inserts a new exchange record into a MongoDB collection. It generates a unique ID for the exchange, constructs a dictionary with all the provided details including optional fields, and attempts to insert this document into the database. If the insertion is successful, it returns the generated ID; otherwise, it catches any exceptions, prints an error message, and returns None."
    *   **Parameters:**
        *   **question** (`str`): The question asked in the exchange.
        *   **answer** (`str`): The answer provided in response to the question.
        *   **feedback** (`str`): Feedback associated with the exchange.
        *   **username** (`str`): The username of the user involved in the exchange.
        *   **chat_name** (`str`): The name of the chat session.
        *   **helper_used** (`str`): The helper tool used during the exchange (optional).
        *   **main_used** (`str`): The main tool used during the exchange (optional).
        *   **total_time** (`str`): Total time taken for the exchange (optional).
        *   **helper_time** (`str`): Time spent using the helper tool (optional).
        *   **main_time** (`str`): Time spent using the main tool (optional).
    *   **Returns:**
        *   **new_id** (`str`): The unique identifier of the inserted exchange record, or None if insertion fails.
    *   **Usage:** Called by the `frontend.Frontend` class at line 530 in `Frontend.py`.
    
    #### Function: `fetch_exchanges_by_user`
    *   **Signature:** `def fetch_exchanges_by_user(username)`
    *   **Description:** "This function retrieves all exchange records from a MongoDB collection for a given username, sorted by creation timestamp in ascending order. It uses the 'dbexchanges' collection and filters documents based on the 'username' field. The results are returned as a list of dictionaries representing the exchange records."
    *   **Parameters:**
        *   **username** (`str`): The username to filter exchange records by.
    *   **Returns:**
        *   **exchanges** (`list`): A list of exchange records (dictionaries) associated with the given username, sorted by creation timestamp in ascending order.
    *   **Usage:** Called by the `load_data_from_db` function in `Frontend.py`.
    
    #### Function: `fetch_exchanges_by_chat`
    *   **Signature:** `def fetch_exchanges_by_chat(username, chat_name)`
    *   **Description:** This function retrieves a sorted list of exchanges from a MongoDB collection based on a given username and chat name. It queries the 'dbexchanges' collection with specific criteria and orders the results by creation date in ascending order. The function returns the fetched exchanges as a list.
    *   **Parameters:**
        *   **username** (`str`): The username associated with the exchanges to be retrieved.
        *   **chat_name** (`str`): The name of the chat associated with the exchanges to be retrieved.
    *   **Returns:**
        *   **exchanges** (`list`): A list of exchange documents matching the provided username and chat name, sorted by creation date in ascending order.
    *   **Usage:** Not called by any other functions in the provided context.
    
    #### Function: `update_exchange_feedback`
    *   **Signature:** `def update_exchange_feedback(exchange_id, feedback)`
    *   **Description:** "This function updates the feedback field of a document in the 'dbexchanges' collection within a MongoDB database. It takes an exchange ID and a feedback value, then attempts to update the corresponding document with the new feedback value. The function returns the number of documents modified as a result of the operation."
    *   **Parameters:**
        *   **exchange_id** (`Any`): The unique identifier of the exchange document to be updated.
        *   **feedback** (`int`): The feedback value to be set in the document.
    *   **Returns:**
        *   **modified_count** (`int`): The number of documents that were successfully modified by the update operation.
    *   **Usage:** Called by the `handle_feedback_change` function in `Frontend.py` at line 98.
    
    #### Function: `update_exchange_feedback_message`
    *   **Signature:** `def update_exchange_feedback_message(exchange_id, feedback_message)`
    *   **Description:** "This function updates the feedback message associated with a specific exchange document in a MongoDB collection. It takes an exchange ID and a new feedback message as inputs, then performs an atomic update operation on the database to set the feedback_message field. The function returns the count of modified documents, which should be 1 if the update was successful."
    *   **Parameters:**
        *   **exchange_id** (`Any`): The unique identifier of the exchange document to be updated.
        *   **feedback_message** (`str`): The new feedback message to be stored in the exchange document.
    *   **Returns:**
        *   **modified_count** (`int`): The number of documents that were successfully modified by the update operation.
    *   **Usage:** Called by the `render_exchange` function in `Frontend.py` at line 211.
    
    #### Function: `delete_exchange_by_id`
    *   **Signature:** `def delete_exchange_by_id(exchange_id)`
    *   **Description:** This function deletes a document from the 'dbexchanges' collection in a MongoDB database based on a given exchange ID. It performs a delete operation and returns the count of deleted documents. The function takes a single string parameter representing the exchange ID and uses the pymongo library to interact with the database.
    *   **Parameters:**
        *   **exchange_id** (`str`): A string identifier used to locate and delete a specific document in the 'dbexchanges' collection.
    *   **Returns:**
        *   **result.deleted_count** (`int`): The number of documents deleted as a result of the delete operation, typically 0 or 1.
    *   **Usage:** Called by the `handle_delete_exchange` function in `Frontend.py` at line 102.
    
    #### Function: `delete_full_chat`
    *   **Signature:** `def delete_full_chat(username, chat_name)`
    *   **Description:** "This function deletes a complete chat session along with all associated exchanges from the database. It first removes all exchange records linked to the specified username and chat name, followed by deleting the chat record itself. The function returns the count of deleted chat documents, ensuring consistency between frontend and backend data states."
    *   **Parameters:**
        *   **username** (`str`): The username associated with the chat to be deleted.
        *   **chat_name** (`str`): The name of the chat session to be deleted.
    *   **Returns:**
        *   **del_chat.deleted_count** (`int`): The number of chat documents that were successfully deleted from the database.
    *   **Usage:** Called by the `handle_delete_chat` function in the `Frontend.py` file at line 110.
    
    
    ### File: `frontend/Frontend.py`
    
    #### Function: `save_gemini_cb`
    *   **Signature:** `def save_gemini_cb()`
    *   **Description:** "This function handles the saving of a Gemini API key entered by the user in a Streamlit frontend application. It retrieves the key from the session state, updates the database with the new key associated with the user's username, clears the input field, and displays a success message to the user."
    *   **Parameters:**
    *   **Returns:**
    *   **Usage:** Not called by any other function in the provided context.
    
    #### Function: `save_ollama_cb`
    *   **Signature:** `def save_ollama_cb()`
    *   **Description:** "This function handles the callback for saving an Ollama URL entered by the user in a Streamlit frontend. It retrieves the URL from the session state, updates the database with the new URL associated with the user's username, and displays a success toast message. The function does not take any parameters and does not return any value."
    *   **Parameters:**
    *   **Returns:**
    *   **Usage:** Not called by any other function in the provided context.
    
    #### Function: `load_data_from_db`
    *   **Signature:** `def load_data_from_db(username)`
    *   **Description:** "Die Funktion 'load_data_from_db' lädt Chats und Exchanges konsistent aus einer Datenbank für einen bestimmten Benutzer. Sie prüft zunächst, ob der Benutzer bereits geladen wurde, und lädt dann die Chats und Exchanges entsprechend. Dabei werden auch Legacy-Chats unterstützt und ein Standard-Chat wird erstellt, falls keine Chats existieren. Die Funktion aktualisiert den Session-State mit den geladenen Daten und setzt den aktiven Chat."
    *   **Parameters:**
        *   **username** (`str`): Der Name des Benutzers, für den die Daten aus der Datenbank geladen werden sollen.
    *   **Returns:**
    *   **Usage:** Called by `frontend.Frontend` at line 310 in `Frontend.py`.
    
    #### Function: `handle_feedback_change`
    *   **Signature:** `def handle_feedback_change(ex, val)`
    *   **Description:** "This function updates the feedback value for a given exchange object and persists the change to the database. It then triggers a re-render of the Streamlit application to reflect the updated feedback. The function takes two arguments: an exchange dictionary and a new feedback value. It modifies the exchange dictionary in place by updating its 'feedback' key, calls a database update function to store the new feedback, and finally invokes a Streamlit rerun command to refresh the UI."
    *   **Parameters:**
        *   **ex** (`dict`): A dictionary representing an exchange object, expected to contain keys such as 'feedback' and '_id'.
        *   **val** (`Any`): The new feedback value to be assigned to the exchange object.
    *   **Returns:**
    *   **Usage:** Called by the `render_exchange` method at lines 199 and 204 in `Frontend.py`.
    
    #### Function: `handle_delete_exchange`
    *   **Signature:** `def handle_delete_exchange(chat_name, ex)`
    *   **Description:** "This function handles the deletion of an exchange from the database and updates the session state accordingly. It first deletes the exchange from the database using its ID, then checks if the exchange exists in the session state for a given chat and removes it if found. Finally, it triggers a rerun of the Streamlit app to reflect the changes."
    *   **Parameters:**
        *   **chat_name** (`str`): The name of the chat from which the exchange is to be deleted.
        *   **ex** (`dict`): A dictionary representing the exchange to be deleted, expected to contain an '_id' key.
    *   **Returns:**
    *   **Usage:** Called by `render_exchange` at lines 228 and 234 in `Frontend.py`.
    
    #### Function: `handle_delete_chat`
    *   **Signature:** `def handle_delete_chat(username, chat_name)`
    *   **Description:** "The function handles the deletion of a chat by first removing the chat from the database and then cleaning up the session state. It ensures that the active chat is updated appropriately, either by selecting another existing chat or by creating a new default chat if none remain. Finally, it triggers a rerun of the Streamlit app to reflect the changes."
    *   **Parameters:**
        *   **username** (`str`): The username associated with the chat to be deleted.
        *   **chat_name** (`str`): The name of the chat to be deleted.
    *   **Returns:**
    *   **Usage:** Called by the `Frontend` class at line 367 in `Frontend.py`.
    
    #### Function: `extract_repo_name`
    *   **Signature:** `def extract_repo_name(text)`
    *   **Description:** "The function 'extract_repo_name' takes a text input and attempts to extract a repository name from any URL present in the text. It uses regular expressions to find a URL, parses it using urllib.parse.urlparse, extracts the path component, and then derives the repository name from the last segment of the path. If the repository name ends with '.git', it removes the extension. If no URL is found or the path is empty, it returns None."
    *   **Parameters:**
        *   **text** (`str`): A string that may contain a URL from which to extract the repository name.
    *   **Returns:**
        *   **repo_name** (`str`): The extracted repository name from the URL, with '.git' suffix removed if present.
        *   **None** (`NoneType`): Returned when no valid URL is found in the input text or when the URL path is empty.
    *   **Usage:** Called by the `frontend.Frontend` class at line 442 in `Frontend.py`.
    
    #### Function: `stream_text_generator`
    *   **Signature:** `def stream_text_generator(text)`
    *   **Description:** "The function `stream_text_generator` takes a string of text as input and yields each word in the text followed by a space, with a small delay between each word. This creates a streaming effect where words are produced one at a time. The function uses `time.sleep(0.01)` to introduce a brief pause between yielding each word."
    *   **Parameters:**
        *   **text** (`str`): A string containing the text to be streamed word by word.
    *   **Returns:**
    *   **Usage:** Called by the function `render_text_with_mermaid` at line 160 in `Frontend.py`.
    
    #### Function: `render_text_with_mermaid`
    *   **Signature:** `def render_text_with_mermaid(markdown_text, should_stream=False)`
    *   **Description:** "This function processes a markdown text string to identify and render Mermaid diagrams embedded within code blocks. It splits the input text based on Mermaid code block delimiters and handles regular markdown content versus Mermaid diagram content differently. Regular markdown content is rendered using Streamlit's markdown functionality, while Mermaid diagrams are rendered using a dedicated mermaid component. If rendering fails, it falls back to displaying the Mermaid code as plain code."
    *   **Parameters:**
        *   **markdown_text** (`str`): A string containing markdown text that may include Mermaid code blocks enclosed in triple backticks with 'mermaid' language specifier.
        *   **should_stream** (`bool`): A boolean flag indicating whether to stream the markdown text rendering or render it directly.
    *   **Returns:**
    *   **Usage:** Called by `render_exchange` at line 238 in `Frontend.py` and also by the `frontend.Frontend` module at line 524.
    
    #### Function: `render_exchange`
    *   **Signature:** `def render_exchange(ex, current_chat_name)`
    *   **Description:** "The function `render_exchange` renders a chat message exchange in a Streamlit interface, displaying a user question and an assistant response. It handles both successful responses and error cases, providing interactive feedback mechanisms such as like/dislike buttons, comment popovers, download options, and delete functionality. The assistant's response is rendered with Mermaid support. It uses various Streamlit components for UI rendering and integrates with backend functions for handling feedback and deletions."
    *   **Parameters:**
        *   **ex** (`dict`): A dictionary containing the exchange data, including the question, answer, feedback, and other metadata.
        *   **current_chat_name** (`str`): The name of the current chat session, used for deleting exchanges.
    *   **Returns:**
    *   **Usage:** Called by the `frontend.Frontend` class at line 429 in `Frontend.py`.
    
    
    ### File: `schemas/types.py`
    
    #### Class: `ParameterDescription`
    *   **Summary:** The ParameterDescription class is a Pydantic BaseModel designed to represent and validate the metadata of a single function parameter. It encapsulates three essential attributes: the parameter's name, its type, and a descriptive explanation. This class serves as a structured way to define and enforce the schema of parameter descriptions, ensuring consistency and type safety when working with function parameter metadata.
    *   **Instantiation:** Not instantiated by any components in the provided context.
    *   **Dependencies:** None explicitly listed.
    *   **Constructor:**
        *   *Description:* "Initializes a ParameterDescription instance with three required fields: name, type, and description. These fields are defined as string types and are used to store information about a function parameter."
        *   *Parameters:*
            *   **name** (`str`): The name of the function parameter.
            *   **type** (`str`): The data type of the function parameter.
            *   **description** (`str`): A textual description of the function parameter's purpose or usage.
    *   **Methods:**
    
    #### Class: `ReturnDescription`
    *   **Summary:** The ReturnDescription class is a Pydantic model designed to represent and validate the description of a function's return value. It encapsulates three key pieces of information: the name of the return value, its type, and a textual description. This class ensures data integrity and structure for return value metadata, making it suitable for use in API schemas, documentation generators, or any system requiring standardized return value definitions.
    *   **Instantiation:** Not instantiated by any components in the provided context.
    *   **Dependencies:** None explicitly listed.
    *   **Constructor:**
        *   *Description:* "Initializes a ReturnDescription instance with a name, type, and description. This constructor leverages Pydantic's BaseModel functionality to enforce type safety and validation for the fields."
        *   *Parameters:*
            *   **name** (`str`): The name of the return value.
            *   **type** (`str`): The type of the return value.
            *   **description** (`str`): A textual description of the return value.
    *   **Methods:**
    
    #### Class: `UsageContext`
    *   **Summary:** The UsageContext class is a Pydantic model designed to represent and validate the calling context of a function, specifically capturing information about what functions are called and by whom. It provides a structured way to define and enforce the expected format of usage context data.
    *   **Instantiation:** Not instantiated by any components in the provided context.
    *   **Dependencies:** None explicitly listed.
    *   **Constructor:**
        *   *Description:* Initializes a new instance of the UsageContext class with the specified 'calls' and 'called_by' attributes.
        *   *Parameters:*
            *   **calls** (`str`): A string describing the functions or methods that are called within the context.
            *   **called_by** (`str`): A string describing the function or method that calls the current context.
    *   **Methods:**
    
    #### Class: `FunctionDescription`
    *   **Summary:** The FunctionDescription class is a Pydantic model designed to encapsulate detailed information about a function's purpose, parameters, return values, and usage context. It serves as a structured representation for documenting function signatures and behaviors, making it easier to analyze and communicate function details within a codebase.
    *   **Instantiation:** Not instantiated by any components in the provided context.
    *   **Dependencies:** None explicitly listed.
    *   **Constructor:**
        *   *Description:* "Initializes a FunctionDescription instance with fields for overall function description, a list of parameter descriptions, a list of return value descriptions, and usage context information."
        *   *Parameters:*
    *   **Methods:**
    
    #### Class: `FunctionAnalysis`
    *   **Summary:** The FunctionAnalysis class serves as the primary data model for representing the complete JSON schema of a function. It encapsulates essential information about a function including its unique identifier, a detailed description, and an optional error field that can indicate issues during processing. This class is designed to provide a standardized structure for documenting and validating function metadata.
    *   **Instantiation:** Not instantiated by any components in the provided context.
    *   **Dependencies:** None explicitly listed.
    *   **Constructor:**
        *   *Description:* "Initializes a FunctionAnalysis instance with required fields for identifier and description, and an optional error field."
        *   *Parameters:*
            *   **identifier** (`str`): A unique string identifier for the function.
            *   **description** (`FunctionDescription`): An object containing detailed information about the function's purpose, parameters, and behavior.
            *   **error** (`Optional[str]`): An optional string field that can contain error messages related to the function analysis.
    *   **Methods:**
    
    #### Class: `ConstructorDescription`
    *   **Summary:** The ConstructorDescription class is a Pydantic model designed to represent and validate the description of a class's __init__ method. It encapsulates two key pieces of information: a textual description of the constructor and a list of parameter descriptions. This class serves as a structured way to document and enforce the schema of constructor metadata, particularly useful in contexts such as API documentation or code analysis tools where detailed information about class constructors is required.
    *   **Instantiation:** Not instantiated by any components in the provided context.
    *   **Dependencies:** None explicitly listed.
    *   **Constructor:**
        *   *Description:* "Initializes a ConstructorDescription instance with a description string and a list of parameter descriptions. The class inherits from pydantic.BaseModel, enabling automatic validation and serialization based on the defined fields."
        *   *Parameters:*
            *   **description** (`str`): A textual description of the __init__ method.
            *   **parameters** (`List[ParameterDescription]`): A list of ParameterDescription objects detailing each parameter of the constructor.
    *   **Methods:**
    
    #### Class: `ClassContext`
    *   **Summary:** The ClassContext class is a Pydantic model designed to encapsulate information about a class's external dependencies and the entities that instantiate it. It serves as a structured representation of metadata related to class usage and integration within a system.
    *   **Instantiation:** Not instantiated by any components in the provided context.
    *   **Dependencies:** None explicitly listed.
    *   **Constructor:**
        *   *Description:* "Initializes a ClassContext instance with two string attributes: 'dependencies' and 'instantiated_by'. These fields are intended to store information about the class's external dependencies and the entities that create instances of the class, respectively."
        *   *Parameters:*
            *   **dependencies** (`str`): A string describing the external dependencies of the class.
            *   **instantiated_by** (`str`): A string describing the entities or components that instantiate this class.
    *   **Methods:**
    
    #### Class: `ClassDescription`
    *   **Summary:** The ClassDescription class is a Pydantic model designed to encapsulate a comprehensive analysis of a Python class. It holds information about the class's overall purpose, its constructor details, a list of its methods along with their descriptions, and contextual usage information. This class serves as a structured representation for documenting and communicating the essential characteristics and behaviors of a class within a system.
    *   **Instantiation:** Not instantiated by any components in the provided context.
    *   **Dependencies:** None explicitly listed.
    *   **Constructor:**
        *   *Description:* Initializes a new instance of the ClassDescription class with default values for all fields. The constructor sets up the structure for storing detailed class analysis information.
        *   *Parameters:*
    *   **Methods:**
    
    #### Class: `ClassAnalysis`
    *   **Summary:** The ClassAnalysis class serves as the primary data model for representing the complete JSON schema of a class. It encapsulates essential information about the class, including its identifier, a detailed description, and an optional error field. This model is designed to provide a standardized structure for documenting class metadata and associated descriptions.
    *   **Instantiation:** Not instantiated by any components in the provided context.
    *   **Dependencies:** None explicitly listed.
    *   **Constructor:**
        *   *Description:* "Initializes the ClassAnalysis instance with an identifier, a ClassDescription object, and an optional error string. The constructor sets up the basic structure required to represent a class's metadata and description."
        *   *Parameters:*
            *   **identifier** (`str`): A unique string identifier for the class being analyzed.
            *   **description** (`ClassDescription`): An object containing detailed descriptive information about the class.
            *   **error** (`Optional[str]`): An optional string field that can hold error messages related to the class analysis.
    *   **Methods:**
    
    #### Class: `CallInfo`
    *   **Summary:** The CallInfo class represents a specific call event from the relationship analyzer, used to track information about function calls including the file, function name, call mode, and line number. It serves as a data structure for documenting call relationships within the system.
    *   **Instantiation:** Not instantiated by any components in the provided context.
    *   **Dependencies:** None explicitly listed.
    *   **Constructor:**
        *   *Description:* "Initializes a CallInfo instance with file, function, mode, and line attributes to represent a call event."
        *   *Parameters:*
            *   **file** (`str`): The file path where the call occurred.
            *   **function** (`str`): The name of the function that made the call.
            *   **mode** (`str`): The mode of the call, such as 'method', 'function', or 'module'.
            *   **line** (`int`): The line number in the file where the call occurred.
    *   **Methods:**
    
    #### Class: `FunctionContextInput`
    *   **Summary:** The FunctionContextInput class is a Pydantic model designed to structure contextual information for analyzing a function. It encapsulates two key pieces of information: a list of function names that the analyzed function calls, and a list of CallInfo objects representing the functions that call the analyzed function. This model serves as a standardized way to represent and validate the call graph context of a function within a larger system.
    *   **Instantiation:** `main_workflow` at line 223 in `main.py`, `prepare_shared_input` at line 152 in `MainLLM_evaluation.py`, `evaluation` at line 162 in `HelperLLM_evaluation.py`
    *   **Dependencies:** None explicitly listed.
    *   **Constructor:**
        *   *Description:* "The class is initialized with two attributes: 'calls', which is a list of strings representing function names called by the analyzed function, and 'called_by', which is a list of CallInfo objects indicating the functions that call the analyzed function."
        *   *Parameters:*
            *   **calls** (`List[str]`): A list of strings representing the names of functions called by the analyzed function.
            *   **called_by** (`List[CallInfo]`): A list of CallInfo objects representing the functions that call the analyzed function.
    *   **Methods:**
    
    #### Class: `FunctionAnalysisInput`
    *   **Summary:** The FunctionAnalysisInput class serves as a data structure for encapsulating the necessary inputs required to generate a FunctionAnalysis object. It defines the expected fields including the mode, identifier, source code, imports, and contextual information.
    *   **Instantiation:** `main_workflow` at line 228 in `main.py`, `prepare_shared_input` at line 157 in `MainLLM_evaluation.py`, `evaluation` at line 167 in `HelperLLM_evaluation.py`
    *   **Dependencies:** None explicitly listed.
    *   **Constructor:**
        *   *Description:* "Initializes the FunctionAnalysisInput instance with the specified parameters, setting up the structure for function analysis input data."
        *   *Parameters:*
            *   **mode** (`Literal["function_analysis"]`): A literal string indicating the mode of operation, specifically set to "function_analysis".
            *   **identifier** (`str`): A string identifier for the function being analyzed.
            *   **source_code** (`str`): The raw source code of the function to be analyzed.
            *   **imports** (`List[str]`): A list of import statements used in the function's source code.
            *   **context** (`FunctionContextInput`): An object containing contextual information about the function's environment and usage.
    *   **Methods:**
    
    #### Class: `MethodContextInput`
    *   **Summary:** The MethodContextInput class is a Pydantic model designed to structure contextual information about a method within a class. It encapsulates details such as the method's identifier, the methods it calls, the methods that call it, its arguments, and its docstring. This class serves as a standardized way to represent and exchange method-level metadata, facilitating better understanding and analysis of code structures.
    *   **Instantiation:** `main_workflow` at line 248 in `main.py`, `prepare_shared_input` at line 177 in `MainLLM_evaluation.py`, `evaluation` at line 187 in `HelperLLM_evaluation.py`
    *   **Dependencies:** None explicitly listed.
    *   **Constructor:**
        *   *Description:* "The class is initialized with a set of predefined attributes that define the structure of method context information. It inherits from BaseModel, leveraging Pydantic's validation capabilities to ensure data integrity."
        *   *Parameters:*
            *   **identifier** (`str`): The identifier of the method.
            *   **calls** (`List[str]`): A list of methods called by this method.
            *   **called_by** (`List[CallInfo]`): A list of CallInfo objects indicating methods that call this method.
            *   **args** (`List[str]`): A list of argument names for the method.
            *   **docstring** (`Optional[str]`): The docstring of the method, if available.
    *   **Methods:**
    
    #### Class: `ClassContextInput`
    *   **Summary:** The ClassContextInput class is a Pydantic model designed to encapsulate structured context information for analyzing a class. It holds three key pieces of information: a list of dependencies, a list of CallInfo objects indicating where the class is instantiated, and a list of MethodContextInput objects describing the context of methods within the class.
    *   **Instantiation:** `main_workflow` at line 260 in `main.py`, `prepare_shared_input` at line 189 in `MainLLM_evaluation.py`, `evaluation` at line 199 in `HelperLLM_evaluation.py`, `main_orchestrator` at line 369 in `HelperLLM.py`
    *   **Dependencies:** None explicitly listed.
    *   **Constructor:**
        *   *Description:* "The constructor initializes the ClassContextInput instance with three attributes: dependencies, instantiated_by, and method_context. These attributes are expected to hold lists of strings, CallInfo objects, and MethodContextInput objects respectively."
        *   *Parameters:*
            *   **dependencies** (`List[str]`): A list of string identifiers representing the dependencies of the class.
            *   **instantiated_by** (`List[CallInfo]`): A list of CallInfo objects detailing where and how the class is instantiated.
            *   **method_context** (`List[MethodContextInput]`): A list of MethodContextInput objects providing context for each method within the class.
    *   **Methods:**
    
    #### Class: `ClassAnalysisInput`
    *   **Summary:** The ClassAnalysisInput class serves as a structured input model for generating a ClassAnalysis object. It encapsulates all necessary information required for analyzing a Python class, including the class's source code, its identifier, associated imports, and contextual metadata.
    *   **Instantiation:** `main_workflow` at line 266 in `main.py`, `prepare_shared_input` at line 195 in `MainLLM_evaluation.py`, `evaluation` at line 205 in `HelperLLM_evaluation.py`, `main_orchestrator` at line 338 in `HelperLLM.py`
    *   **Dependencies:** None explicitly listed.
    *   **Constructor:**
        *   *Description:* "Initializes the ClassAnalysisInput with fields representing the mode of analysis, the class identifier, the source code of the class, a list of import statements, and contextual information."
        *   *Parameters:*
            *   **mode** (`Literal["class_analysis"]`): A literal string indicating the mode of analysis, specifically set to "class_analysis".
            *   **identifier** (`str`): A string identifier for the class being analyzed.
            *   **source_code** (`str`): The raw source code of the class being analyzed.
            *   **imports** (`List[str]`): A list of import statements associated with the class.
            *   **context** (`ClassContextInput`): An object containing contextual information about the class, such as dependencies and instantiation details.
    *   **Methods:**
    
    #### Function: `backend.main.update_status`
    *   **Summary:** The function `update_status` is designed to handle status updates by invoking an optional callback function if one is defined, and then logging the message using the standard logging module. It serves as a centralized mechanism for reporting status messages throughout the application.
    *   **Parameters:**
        *   **msg** (`Any`): The status message to be processed and logged.
    *   **Returns:**
    *   **Usage:** Called multiple times (14 instances) from the `main_workflow` function in `main.py`.
    *   **Description:** The function 'update_status' is designed to handle status updates by invoking an optional callback function if one is defined, and then logging the message using the standard logging module. It serves as a centralized mechanism for reporting status messages throughout the application.
    *   **Parameters:**
        *   **msg** (`Any`): The status message to be processed and logged.
    *   **Returns:**
    *   **Usage:** Called multiple times (14 instances) from the `main_workflow` function in `main.py`, typically to report progress or status changes during execution.